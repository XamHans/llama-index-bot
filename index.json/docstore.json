{"docstore/data": {"b38ad971-09ae-4992-a330-a66c4c1ea89c": {"__data__": {"id_": "b38ad971-09ae-4992-a330-a66c4c1ea89c", "embedding": null, "metadata": {"page_label": "i", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "bb0e582f4d0dbf5270a8c8b8a4c49943571bb2854446b41eef091455684c3653", "text": "Government Lens\nAWS Well-Architected Framework", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5f106622-5002-4af2-a057-d9b680bc55d3": {"__data__": {"id_": "5f106622-5002-4af2-a057-d9b680bc55d3", "embedding": null, "metadata": {"page_label": "ii", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3b1f727e9396931c854394387b4696632b267b1e445dddf40a707e5621d1596b", "text": "Government Lens AWS Well-Architected Framework\nGovernment Lens: AWS Well-Architected Framework\nCopyright \u00a9 2023 Amazon Web Services, Inc. and/or its a\ufb03liates. All rights reserved.\nAmazon's trademarks and trade dress may not be used in connection with any product or service that is not \nAmazon's, in any manner that is likely to cause confusion among customers, or in any manner that disparages or \ndiscredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may \nor may not be a\ufb03liated with, connected to, or sponsored by Amazon.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "65d8966f-d13f-4693-a654-1f7dcabe2735": {"__data__": {"id_": "65d8966f-d13f-4693-a654-1f7dcabe2735", "embedding": null, "metadata": {"page_label": "iii", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3d1f009cdc5a54df58933640f9f327e1d5d783030d0653bd7cac756c25442b09", "text": "Government Lens AWS Well-Architected Framework\nTable of Contents\nAbstract and introduction....................................................................................................................i\nIntroduction..............................................................................................................................1\nCustom lens availability..............................................................................................................1\nDe\ufb01nitions .........................................................................................................................................2\nGeneral design principles ....................................................................................................................3\nDesign with purpose ...................................................................................................................3\nDesign with end users (citizens, residents, businesses).....................................................................4\nMake the service simple and intuitive...........................................................................................4\nIterate and improve frequently (with end user and sta\ufb00 feedback)....................................................4\nCollaborate and work in the open by default.................................................................................5\nAddress security and privacy risks................................................................................................5\nBuild inclusive services................................................................................................................6\nDesign trustworthy services.........................................................................................................6\nMeasure, report, and take data-driven decisions.............................................................................6\nConsider composable architecture and reusability..........................................................................7\nMaintain service continuity..........................................................................................................7\nScenarios\u00a0..........................................................................................................................................8\nArti\ufb01cial intelligence in the public sector......................................................................................8\nClassi\ufb01ed information systems ...................................................................................................12\nCitizen engagement reference architecture..........................................................................13\nRegulatory reporting reference architecture.........................................................................14\nDistributed processing of sensitive documents reference architecture......................................15\nOmni-channel public services.....................................................................................................16\nConceptual architecture....................................................................................................17\nOpen government methods, infrastructure, and tools...................................................................17\nWorking in the open.........................................................................................................18\nOpen-source software publication and reuse........................................................................18\nAlgorithmic transparency...................................................................................................18\nPerformance reporting......................................................................................................18\nOpen government data.....................................................................................................18\nVeri\ufb01able credentials (claims) for government..............................................................................19\nConceptual architecture....................................................................................................20\nPillars of the Well-Architected Framework...........................................................................................22\nOperational excellence pillar......................................................................................................22\nReshape the operating model............................................................................................22\nOrganizational risk\u00a0...........................................................................................................25\nResources........................................................................................................................26\nSecurity pillar..........................................................................................................................26\nVerifying privacy-by-design...............................................................................................26\nShifting to a real time security model.................................................................................27\nConsidering national implications .......................................................................................27\nResources........................................................................................................................28\nReliability pillar........................................................................................................................28\nResources........................................................................................................................28\nPerformance e\ufb03ciency pillar......................................................................................................29\nResources........................................................................................................................29\nCost optimization pillar .............................................................................................................29\nResources........................................................................................................................30\nSustainability pillar...................................................................................................................30\nClimate action and technology...........................................................................................31\nResources........................................................................................................................32\nEnabling services outcomes for government........................................................................................33\nConclusion .......................................................................................................................................36\nContributors ....................................................................................................................................37\niii", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8f0505f8-e679-49ee-add1-1359ff3fb459": {"__data__": {"id_": "8f0505f8-e679-49ee-add1-1359ff3fb459", "embedding": null, "metadata": {"page_label": "iv", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0b5339fa11cb88676cb978a91fc25c02a8dd39a1cbc7d18bbb2e4883caeed20f", "text": "Government Lens AWS Well-Architected Framework\nDocument history.............................................................................................................................38\nNotices............................................................................................................................................39\nAWS glossary...................................................................................................................................40\niv", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f7dbc5ad-eb28-4b98-a7a1-bab3be464fb0": {"__data__": {"id_": "f7dbc5ad-eb28-4b98-a7a1-bab3be464fb0", "embedding": null, "metadata": {"page_label": "1", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b29923a447e57791498c6699569d132db4a9b658ecd23f03d922c2ecfe0ace3c", "text": "Government Lens AWS Well-Architected Framework\nIntroduction\nGovernment Lens\nPublication date: August 18, 2023  (Document history (p. 38))\nThis whitepaper describes the\u00a0Government Lens for the AWS Well-Architected Framework including \ngeneral design principles, best practices, government-speci\ufb01c guidance for the pillars of the Framework, \nand an additional chapter for government service outcomes. The Government Lens is based on other \ndomain lenses, such as the\u00a0 Financial Services Industry Lens. This whitepaper is designed to be used by \nanyone responsible for, or involved in the design and delivery of government services, including service \nand product owners, architects, engineers,\u00a0policy sta\ufb00, and program managers. A government service \nmight include multiple workloads.\nIntroduction\nGovernment customers have a special set of legal, legislative, accountability, and trust requirements. \nThese requirements need to inform architectural and delivery considerations for solutions that support \ngovernment services. Government policies and services often have a signi\ufb01cant impact on society, \nwhich creates a strong but understandable culture around responsible risk management. Governments \neverywhere are prioritizing and investing in high veracity, modern, and omni-channel citizen-centric \nservices that meet the special requirements of government. To improve agility in a rapidly changing \nworld, they also are creating reusable and modular architectures.\nThe Government Lens helps people understand the special context and requirements of government \nand how to best deliver meaningful outcomes on AWS. This lens drives architectural qualities that layer \ngovernment-speci\ufb01c best practices for progressive enhancement as a service design assurance function. \nFor example, government customers can use the new service outcomes chapter as an indicator of \nreadiness for government service launches, and to inform AWS Enterprise Support event management.\nThe Government Lens should be applied as an expansion to the AWS Well-Architected Framework. \nThe output of both the AWS Well-Architected Framework review process and this Government Lens is \na report containing applicable best practices and if they are in use at the time of review. Government \ncustomers can use these outputs to improve the impact and outcomes of their services, and to engage \nwith their own governance mechanisms in a meaningful way.\nIt is important to note that every government operates in a unique cultural and historical context, \nwhich means di\ufb00erent expectations, needs, mandates and even a di\ufb00erent perspective about the role of \ngovernment in that society. Anyone responsible for delivering services in government must make sure \nto learn and understand the special context of that government customer to apply what is appropriate \nfrom this Lens. The Government Lens is informed by frameworks from the AWS global experience \nworking with government customers.\nCustom lens availability\nCustom lenses extend the best practice guidance provided by AWS Well-Architected Tool. AWS WA Tool \nallows you to create your own custom lenses , or to use lenses created by others that have been shared \nwith you.\nTo determine if a custom lens is available for the lens described in this whitepaper, reach out to your \nTechnical Account Manager (TAM), Solutions Architect (SA), or AWS Support.\n1", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2da8750a-2945-4a9a-8465-05d3ad7a56f9": {"__data__": {"id_": "2da8750a-2945-4a9a-8465-05d3ad7a56f9", "embedding": null, "metadata": {"page_label": "2", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "77b1fdce8c33b460587bcaf6baf997553161d57ff5a184c35bcf5e7594d8c597", "text": "Government Lens AWS Well-Architected Framework\nDe\ufb01nitions\nThese de\ufb01nitions mean to provide AWS builders, architects, and technologists with a starting point for \ncommonly used terms and phrases used within the government sector.\u00a0 Speci\ufb01cs of the terms and how \nthey are applied can vary by jurisdiction.\u00a0\nPublic Sector: The portion of the economy composed of all levels of government and government-\ncontrolled entities, usually de\ufb01ned in legislation or by Administrative Orders.\nDigital Nations:  A collection of ten governments\u00a0committed to digital reform and best practices. Usually \nled the by the national digital government unit or Chief Digital O\ufb03cer for the jurisdiction.\nGovernment versus government: Government (with a capital G) refers to the political system or form \nby which a country or community is administered and regulated. The Government is supported by the \npublic sector to ful\ufb01ll the obligations of that jurisdiction and to represent the best interests of the \npeople served. The public sector is often referred to as the government (lower case g).\nOpen Government: The governing doctrine which maintains that citizens have the right to access \nthe documents and proceedings of government to allow for e\ufb00ective public oversight.\u00a0 This doctrine \nincludes transparency, public reporting, and accountability mechanisms, and is often inclusive of public \nparticipation in improving public services and policies.\u00a0\nOpen Government Partnership: A collection of over 75 countries committed to open government \nmeasures. Usually led by a central government department responsible for transparency and \naccountability, such as a Department for the Attorney General, although it\u2019s sometimes led by the head \nof state.\nProtection of Civil Rights and Privacy:\u00a0 The degree to which government entities are required to verify \nthat information relating to citizens collected and held by Government is secure and con\ufb01dential, that \nthe privacy rights of individuals are not breached by governments or non-governmental actors, and that \na range of civil rights are protected.\u00a0\nAccountability: Enabling public, parliamentary, independent, and internal oversight of government \nactivities.\nAccess to information: Mechanisms that govern the release of government-held information into the \npublic domain.\u00a0\nOpen Information or Data:  Data (or information) that is provided publicly to be freely accessed, used, \nor shared. Includes mechanisms to encourage non-government actors and other governments to reuse \ngovernment information and data.\nJurisdiction:\u00a0A jurisdiction is an area with a set of laws under the control of a system of courts or \ngovernment entity that are di\ufb00erent from neighboring areas. A jurisdiction might be at a national/\nfederal level, a provincial/state/territory level, or a local level. Countries such as Australia, Canada, and \nthe United States have three levels of government. Other countries, such as New Zealand, have two \nlevels. It\u2019s important to be aware of the jurisdictional context of the government customer.\nPublic or government services: The services provided by the government or public sector to the public. \nPrograms intended to improve public services usually refer to raising the quality of services to the public, \nmaking them more accessible, end user friendly, inclusive, and e\ufb00ective at driving policy outcomes.\nTransparency: Promote corporate and operational accountability, including programs that encourage \ntransparency and ethical conduct, while tackling corruption.\n2", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1e464a5b-33a7-4909-9a59-a05023940ce2": {"__data__": {"id_": "1e464a5b-33a7-4909-9a59-a05023940ce2", "embedding": null, "metadata": {"page_label": "3", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "96f01e8af7c0c17275dee588b29d7ef3585183dfb04921890ef81bad20004c88", "text": "Government Lens AWS Well-Architected Framework\nDesign with purpose\nGeneral design principles\nThis Government Lens lists high level design principles that government customers expect to be \napplied to services being developed with and for them. A version of these principles is found in most \ngovernments today and in some jurisdictions. Services can be audited to verify that they comply \nwith service standards. Each principle has one or more questions to consider that support the pillar \nassessment.\u00a0The principles outlined in this whitepaper draw from the\u00a0Australian Digital Service Standard, \nthe Canadian Digital Standards, the New Zealand Digital Service Standard, the\u00a0 UK Government Service \nStandard, and the US Government Digital Services Playbook. It\u2019s important that builders are aware of the \nstandards for their jurisdiction. It is also worth being aware of the\u00a0Digital Nations Charter, \ufb01rst signed in \n2014 by the Digital Nations cohort, including leading digital government from around the world.\u00a0\nThe general design principles are:\n\u2022Design with purpose  (p. 3)\n\u2022Design with end users (citizens, residents, businesses) (p. 4)\n\u2022Make the service simple and intuitive (p. 4)\n\u2022Iterate and improve frequently (with end user and sta\ufb00 feedback) (p. 4)\n\u2022Collaborate and work in the open by default (p. 5)\n\u2022Address security and privacy risks (p. 5)\n\u2022Build inclusive services (p. 6)\n\u2022Design trustworthy services (p. 6)\n\u2022Measure, report, and take data-driven decisions (p. 6)\n\u2022Consider composable architecture and reusability (p. 7)\n\u2022Maintain service continuity (p. 7)\nDesign with purpose\nAll government systems, programs, services, and policies are meant to deliver an outcome. Whether \nit is for the department mission, legislative responsibilities, a policy objective, or something else, it\u2019s \nimportant that those designing and delivering government solutions understand the purpose and \nintent behind the service, as well as how it\u2019s meant to impact the public. These factors should inform \nthe design, success criteria, end-user research, engagement strategy, architectural design, and the \nmeasurement framework for the system.\u00a0\nQuestions to ask: \u00a0\n\u2022Do you understand the mission, mandate, and policy objectives of the government customers? How \nwill you measure success?\n\u2022What is the intended impact of the system or service? Are you measuring or tracking that impact from \nthe beginning?\u00a0\n\u2022Does the measurement framework include customer and end-user feedback and satisfaction? Does it \ninclude sta\ufb00 feedback the intended policy impacts and monitoring for unintended human impacts?\n\u2022Have you considered the potential risks of this service to the community?\n3", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8c2ce767-4d92-458d-8296-c3c74b15bf8a": {"__data__": {"id_": "8c2ce767-4d92-458d-8296-c3c74b15bf8a", "embedding": null, "metadata": {"page_label": "4", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7025a0d3dd2b0f6ab3b36790e3a214236ad891b5215247709158d9ddb2aa0d3d", "text": "Government Lens AWS Well-Architected Framework\nDesign with end users (citizens, residents, businesses)\nDesign with end users (citizens, residents, \nbusinesses)\nService design provides a good framework for a multi-disciplinary team to deliver a design-led and end-\nuser engaged service. People responsible for service delivery must engage end users early in the design \nand iteration process, and consider their feedback for validating the best potential design, governance, \nand the continuous improvement process for a service. Concept testing should be conducted well before \na solution is decided upon or anything is built.\u00a0It\u2019s important to keep in mind that public-facing services \nmight include third parties delivering services on behalf of Government, suppliers, and business end \nusers in addition to citizens.\u00a0\nQuestions to ask: \u00a0\n\u2022Who is the service design lead on your project or product team?\u00a0\n\u2022Have you clearly de\ufb01ned who your end users are?\u00a0\n\u2022Have you included end users in the research, design, concept testing, user testing, and continuous \nimprovement of the service?\n\u2022How many potential solution\u00a0concepts have you tested with end users? (This should be more than just \none.)\n\u2022How can a user provide feedback, either positive or negative, that directly goes into the continuous \nimprovement of the system or service?\nMake the service simple and intuitive\nMost government service standards talk about making it simple for people to get what they need from \nthe government service. Designing with users will help facilitate this goal, but it\u2019s a good additional \ndesign principle to purposefully do the hard work to make it simpler to use. Try to integrate or \nincorporate functionality rather than redirecting to an existing service. Take a whole of experience \napproach rather than just a transactional step improvement. Use simple and clear language. Use and \ncontribute to common design services to maintain a common look and feel for government services.\nQuestions to ask: \u00a0\n\u2022How are you measuring and designing for simplicity and intuitive services?\n\u2022How are you engaging with a diverse group of users through the product design and development?\u00a0\n\u2022What customer experience (CX) and user satisfaction measures are you implementing?\n\u2022How readable and simple to understand is the language used across the service?\n\u2022How consistent and intuitive is the design of the service?\nIterate and improve frequently (with end user and \nsta\ufb00 feedback)\nContinuous improvement of services in response to events or initiatives impacting society, citizens, end \nusers, and public sector employees is vital to maintain trust and veri\ufb01es that service delivery can evolve \nin a timely manner. Therefore, mechanisms for collecting and responding to requirements need to be \nestablished. People responsible for service delivery can ask themselves how the service will be managed \nafter launch, and if there is a supporting operating model with continuous improvement mechanisms \nin place. This approach also could include automation of testing and deployment, load testing at scale, \n4", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "95c10028-2833-4cf8-ba34-a10acf6961bc": {"__data__": {"id_": "95c10028-2833-4cf8-ba34-a10acf6961bc", "embedding": null, "metadata": {"page_label": "5", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "ed38c112920b5f5c86a2c6dc414de85d8fc8bda570f3a97519f1ea7e2d378f31", "text": "Government Lens AWS Well-Architected Framework\nCollaborate and work in the open by default\nand other ways to improve consistency of continuous change deployment to reduce unexpected issues or \nunnecessary human error.\nQuestions to ask: \u00a0\n\u2022How will the product management team identify, escalate, prioritize, and implement change from user \nand sta\ufb00 feedback?\n\u2022How often can product improvements happen? Daily, weekly, monthly, quarterly?\u00a0\n\u2022How long does it take and how much e\ufb00ort is needed to push iterations or improvements to the \nservice?\n\u2022Does the service have funding and the necessary resources to manage it past the initial launch?\u00a0\n\u2022Who is the product owner and how will they engage with the development and design teams through \nthe lifecycle of the service?\nCollaborate and work in the open by default\nOpen Government is a concept that can not only improve public trust, but also improve services and \npolicy outcomes. In addition, some governments have a legal requirement to consider or publish \nservice reporting or open source code. People working with government directly or as a third party \nmust consider how government can share the service\u2019s non-sensitive data, code, evidence, research, \nand decision making openly. This includes using open standards where possible and open-source \nlicensing where required. The Digital Nations Charter recommends that government prioritize open \ngovernment, open data, open source, open standards, and open markets to maintain sustainable digital \ntransformation of governments.\nQuestions to ask: \u00a0\n\u2022How will the general public \ufb01nd out information about the service, such as its compliance or \nperformance?\n\u2022How will citizens participate in the design or ongoing improvements to the system or service?\n\u2022Have you explored how other governments might have solved this problem, including the use of \nreusable tools?\n\u2022How might the government customer share information across their own organization and \njurisdiction?\n\u2022How does the government customer want to share this work so that other governments can reuse it?\n\u2022Can you share your outputs with appropriate open source licenses and channels?\nAddress security and privacy risks\nThe privacy requirements of government services can be extremely strict. Take a balanced approach \nto managing risk by implementing appropriate privacy and security measures, and by understanding \nthe real impact of the system on the people, communities, and businesses a\ufb00ected. Support a security \nculture where security measures are frictionless for service operations, and do not place additional \nburden on users. This includes responsible, accountable and auditable stewardship of government data \nand systems.\u00a0\nQuestions to ask: \u00a0\n\u2022How can you demonstrate and monitor for security in your system or service?\n\u2022How can you demonstrate compliance to and stewardship of privacy for all data and systems?\n\u2022What are the jurisdictional requirements around identity, including\u00a0identity frameworks, data sharing \nlegislation, privacy impact assessments, and so on?\n5", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "4e4297a0-8686-4c0a-96da-d64efe42c342": {"__data__": {"id_": "4e4297a0-8686-4c0a-96da-d64efe42c342", "embedding": null, "metadata": {"page_label": "6", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "4f840e05374c00cd99f00b0e1baec767dc82a644a961e653ea4ad54f8760e458", "text": "Government Lens AWS Well-Architected Framework\nBuild inclusive services\nBuild inclusive services\nGovernment services are not usually optional for people, so they often need to be accessible to \neveryone. Services should meet or exceed accessibility standards and be inclusive by design. No \nperson should be excluded by service, which means there will always be a need for o\ufb04ine options to \ncomplement online channels. Design omni-channel services, and verify that needs have a pathway to the \nservice. Users with distinct needs should be engaged from the outset to verify what is delivered will work \nfor them. In any project that you do with the government, even if they aren\u2019t asking for it, you need an \nanswer to the question \u201cIs this an inclusive service?\u201d and if not, then what are the alternative options.\u00a0\nQuestions to ask: \u00a0\n\u2022Do you know who all the potential users of the service are? Is this system or service inclusive for all \nthose users?\n\u2022Have you taken into account di\ufb00erent language and literacy requirements for end users?\n\u2022Have you involved diverse representation of your users in the design and testing of your system or \nservice?\n\u2022Can users get access to an assisted version of the service (such as in person, or over the phone) as well \nas by self-service online?\n\u2022Are there minimum legal requirements around accessibility or access for this government customer?\nDesign trustworthy services\nGovernment services can become contentious if they don\u2019t verify that everyone receives fair and \nequitable treatment, and governments are expected to deliver value and bene\ufb01ts to the community. \nIt\u2019s critical that government services are explainable so they can be audited and appealed\u00a0(as per \nadministrative law and other requirements). It is important to verify that ethical considerations are part \nof the design, implementation and governance models for the service.\nGovernment services also need to comply with relevant\u00a0ethical guidelines in the design and use of all \nsystems, especially for automated decision making (such as the use of arti\ufb01cial intelligence).\nQuestions to ask: \u00a0\n\u2022Do you know the relevant ethics frameworks and requirements for the jurisdictions?\n\u2022Is your system designed to have privacy, dignity, legitimacy, and accountability by design?\u00a0\n\u2022Can an end user understand and challenge the output from the system?\u00a0\n\u2022How do you audit and monitor decisions, accuracy, and legal authority or compliance, in real time?\n\u2022How do you know whether your service is having a fair, positive, or negative impact on people?\n\u2022How have you veri\ufb01ed that independent oversight and e\ufb00ective governance?\n\u2022How could you earn social license and operate this service in a way that the public will consider \ntrustworthy?\n\u2022What are the jurisdictional requirements around transparency? For example, do you need to publish \nalgorithms, or apply a special risk assessment?\nMeasure, report, and take data-driven decisions\nWork out what success looks like for the government service or system and identify metrics that will tell \nthe end user and\u00a0the government itself what\u2019s working and what can be improved. Combine this e\ufb00ort \nwith user research. Support the government to build measurement capabilities from the beginning, \n6", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0631ae6e-79f0-4349-812d-04b6abe3c508": {"__data__": {"id_": "0631ae6e-79f0-4349-812d-04b6abe3c508", "embedding": null, "metadata": {"page_label": "7", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "34f961d2ce82590ddd956b2ee34a43e899a4739ebc3a545ce8139fb0e5fea753", "text": "Government Lens AWS Well-Architected Framework\nConsider composable architecture and reusability\nso that they can baseline and measure the impact of their service, taking into account the service \nperformance, user experience, intended policy impact, and measurable impact. Use testing and actual \ndata to drive decision making, so that changes and improvements have a higher chance of success.\nQuestions to ask: \u00a0\n\u2022Have you established the measurement and monitoring systems to enable data-driven decision \nmaking?\n\u2022Are threats or anti-patterns identi\ufb01ed and escalated in close to real time?\n\u2022How is the system performance, user experience, policy impact, and human impact measured and \nmonitored?\n\u2022What do you need to measure in order to determine performance success outcomes and impact?\nConsider composable architecture and reusability\nDesigning composable, modular architecture allows the government customer to identify repeatable \narchitectural patterns to inform product design, development, and procurement.\u00a0Many jurisdictions have \nestablished design systems or component catalogs that can be used to simplify and standardize the end-\nuser experience, to accelerate service delivery, reduce operations overheads and improve consistency so \nusers do not have to constantly relearn how to interact with a jurisdiction\u2019s digital services.\u00a0To promote \nreuse and reduce complexity, some jurisdictions might have de\ufb01ned core environments or components to \nbe used as part of new services. These elements are usually de\ufb01ned as part of a jurisdiction\u2019s enterprise \narchitecture.\nLeveraging government environments and procurement agreements allow builders to take advantage \nof particular terms and standards already agreed upon between the vendor and the government, which \nimproves and speeds up delivery and helps make compliance with government standards simpler. \nBuilders should identify and engage with Government architectural standards and groups where a \nservice they are building might deliver services across multiple departments of agencies, and should be \naware of whole government patterns that can be leveraged.\nQuestions to ask:\n\u2022Have you considered a modular, extendable, and composable architecture for this service?\n\u2022What platforms, frameworks, agreements, and patterns exist that you can leverage (for example, from \nthis jurisdiction and others)?\n\u2022How di\ufb03cult is it to reuse an existing agreement, environment, or pattern, and what ongoing e\ufb00ort is \nrequired to maintain it?\nMaintain service continuity\nParticular government services must not have unexpected downtime due to the risk of immediate \ndangers to the quality of life for citizens, for example, emergency services, social welfare payments, \npolicing systems, and healthcare services. Resilient architectures are key to support this design principle, \nand the people responsible for service delivery must take a risk-based approach to architectural decisions \nto support critical government services. Make deliberate use of the AWS Well-Architected Framework \nReliability Pillar to inform your decision making.\nQuestions to ask: \u00a0\n\u2022How will your system or service handle an attack or disruption? What backup options exist for users?\n\u2022How will a disruption to service be detected and escalated proportionately to the risk and impact of \nthe service?\n7", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0e5a0d8e-cbab-455e-baf4-6d86e578df4a": {"__data__": {"id_": "0e5a0d8e-cbab-455e-baf4-6d86e578df4a", "embedding": null, "metadata": {"page_label": "8", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "4cf4681914efffdc3e6194faefe59de7c8f4e299e3f79f6ece01c4fe62ebde48", "text": "Government Lens AWS Well-Architected Framework\nArti\ufb01cial intelligence in the public sector\nScenarios\u00a0\nIn this section, we provide common government scenarios with guidance to inform your architectural \ndesign. Each scenario includes best practices, characteristics, considerations, and reference architectures \nwhere applicable.\u00a0\nScenarios\n\u2022Arti\ufb01cial intelligence in the public sector (p. 8)\n\u2022Classi\ufb01ed information systems  (p. 12)\n\u2022Omni-channel public services (p. 16)\n\u2022Open government methods, infrastructure, and tools (p. 17)\n\u2022Veri\ufb01able credentials (claims) for government  (p. 19)\nArti\ufb01cial intelligence in the public sector\nArti\ufb01cial intelligence (AI) provides signi\ufb01cant opportunities for better public policy and services that \ndeliver more equitable and scalable support for the community. But poorly designed AI systems \ncan similarly create di\ufb03culty at a scale not possible in other sectors due to the special context of \ngovernment. For this reason, careful design and governance of AI in government, including in the context \nof usage patterns and public impact, is critical for maintaining responsible and trustworthy AI systems in \ngovernment.\nUnderstanding the\u00a0broad categories of how, and in which context you can use AI helps to establish the \nright controls and approaches to appropriately govern, design, manage, and mitigate risks with your \nAI systems.\u00a0In this scenario, we explore common patterns for how AI is broadly used with pragmatic \nguidance and recommendations to maintain responsible, ethical, and high integrity outcomes from AI in \nthe special context of government.\nCharacteristics of a good AI architecture in government include:\n\u2022Clear delineation between systems that require explainability (such as deciding eligibility to social \nservices) and systems that don\u2019t (such as general research or patterns analysis). Explainability is the \nability to describe why a machine learning (ML) model makes a speci\ufb01c prediction.\n\u2022Good practice approaches to identifying, addressing, and ongoing monitoring for bias in data for \ntraining AI models and the AI models themselves.\n\u2022Monitoring for the measurable intended and unintended impact on people, communities and the \nenvironment.\n\u2022Support for ongoing end user and sta\ufb00 feedback to inform continuous improvement and quantitative \nimpact analysis.\n\u2022Demonstrable lawfulness of the outcome (particularly in the case of decision making systems).\n\u2022Transparency for when and how AI is used.\n\u2022Augmentation that improves policy and community outcomes, rather than just e\ufb03ciency through \nautomation.\n\u2022The system is perceived as lawful, fair, and trustworthy by the public.\nThe following patterns of AI usage can stand alone or be combined with others. This makes it simpler \nto verify that standalone use cases are not over governed, but also that combinations of usage \npatterns into a solution can address the relevant aspects of good governance. Each usage category \nincludes\u00a0analysis on the suitability of the two mainstream types of AI, rules based (RB), and machine \nlearning (ML), and some ideas on risk pro\ufb01le and remediations.\u00a0\n8", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9c895da6-46ff-4858-a64b-0ce6e85a0e20": {"__data__": {"id_": "9c895da6-46ff-4858-a64b-0ce6e85a0e20", "embedding": null, "metadata": {"page_label": "9", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "39bb7d8c92a40d997fdc7df984e0a363d13eb8c6b2cfcb197fac5f35a14d0082", "text": "Government Lens AWS Well-Architected Framework\nArti\ufb01cial intelligence in the public sector\nUsage patterns DescriptionSuitability of AI \ntypesRisk pro\ufb01le Risk management \ntools\nAnalytical AI systems that \nperform\u00a0 analysis, \n\u00a0 identify patterns, \nproduce trends \nand insights. \nExamples include \nrisk\u00a0 assessment\u00a0 \nsystems, patterns \nanalysis\u00a0 in \nhelpdesk data to \nidentify bias, and \ntrends\u00a0\u00a0 projection.RB: Low, as it \ndoesn\u2019t\u00a0 scale and \nonly\u00a0 useful for \npre-determined \ninquiry. ML: \nHigh, both for\u00a0 \nscalability and to\u00a0 \nexplore unknown \nunknowns in data.Both RB and ML \nbased systems \nrun the risk of \nperpetuating bias \nand\u00a0 inaccuracies \nfrom past systems. \n\u00a0 However,\u00a0 if the \noutputs from \nsuch systems \nare treated as \nindicators, and \n\u00a0 supplemented \nby robust \ninformation, they \n\u00a0 can be extremely \nuseful.\u2022The assessed \nlevel of impact \nshould inform \ngovernance.\n\u2022Either use AI \nto \ufb01nd\u00a0and \nmitigate bias, \nor make sure \nthat data bias \nis\u00a0addressed.\n\u2022Verify that \nanalysis\u00a0outcomes \nare \nsupplemented \nwith other \ninputs.\n\u2022Transparency on \nuse of\u00a0AI for all \nuse cases.\n\u2022Provenance of \nsources will help \nmake sure that \noutputs are not \nmanipulated.\nProcess \nAutomationAI systems that \nautomate a \nprocess, whether \nit be an existing,\u00a0 \npre-de\ufb01ned, or an \ninferred process \ncreated\u00a0 from data \nor model training. \nExamples include \nautomatic triaging \nof calls or email\u00a0 \nbased on rules or \ndata, application \nsorting, and \ndigitizing PDF \n\ufb01les.RB: Medium, \nprovides \nconsistency \nof processes \nautomated, but \ndoesn\u2019t scale or\u00a0 \nlearn. \u00a0 ML: High, \nscales and can \nimprove processes \nover time.Depends on the \nprocess, who is \nimpacted by the \nprocess, and the \nworst\u00a0 possible \nlikely impact. \nIf the impact is \nconsidered low \nand the output is \nnot \u00a0 something \nthat needs to be \nappealable, then \nrisk is likely low. \nIf explanation\u00a0 is \nneeded or if the \nworst likely impact \nis high, then risk is \nhigh.\u2022The assessed \nlevel of impact \nshould inform \ngovernance.\n\u2022Make sure \nthat data bias \nis\u00a0addressed.\n\u2022If process \nautomation\u00a0informs \na decision \nor action, \ninclude risk\u00a0 \nmitigations for \nthat category.\n\u2022Transparency on \nuse of\u00a0AI for all \nuse cases.\n\u2022Make sure that \nunintended \nimpacts are \nmonitored for \nand addressed.\nAutomated \nDecision Making\n(ADM)AI systems that \ngenerate a speci\ufb01c \ndecision or action, \neither from rules RB: Medium to \nHigh, rules-based \nADM systems \nprovide consistent Risk is based on \nthe worst likely \nimpact on the \nend-user, citizen, \u2022The assessed \nlevel of impact \nshould inform \ngovernance.\n9", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "29009cc5-7cec-4414-b6b5-1122b0dcc608": {"__data__": {"id_": "29009cc5-7cec-4414-b6b5-1122b0dcc608", "embedding": null, "metadata": {"page_label": "10", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7ce0542130ab8f97bb24f4781857dda6a8219ed56064f81e871b37a37a7707e5", "text": "Government Lens AWS Well-Architected Framework\nArti\ufb01cial intelligence in the public sector\nUsage patterns DescriptionSuitability of AI \ntypesRisk pro\ufb01le Risk management \ntools\nor\u00a0 data. Examples \ninclude social \nservice eligibility \ndecision systems, \n\u00a0 autonomous \ncars, and chess \nand game playing \nengines.and traceable\u00a0 \noutputs. ML: Low \nto medium, ML \nADM systems \nare currently not \ntraceable to legal \n\u00a0 authority, nor \ndo they provide \nconsistent outputs \nover time.or company.\u00a0 If the \ndecision or action \nbeing automated \nis subject to \nadministrative law, \nthen the risk of\u00a0 \nML based systems \nis much higher to \nmitigate.\u2022Make sure \nthat data bias \nis\u00a0addressed \nup front and \nmonitored over \ntime.\n\u2022Make sure that \nADM outputs \nare\u00a0explainable \nor at least \ntestable against \ntheir\u00a0 legal \nauthorities \nto help verify \nlegislative \ncompliance.\n\u2022Transparency on \nuse of AI to end \nusers.\n\u2022Ease of appeal \navailable to end \nusers.\n\u2022Continuous \nservice design, \nmonitoring, and \nimprovements \nbased on public\u00a0 \nfeedback.\n\u2022Provenance of \nsources will help \nmake sure that \noutputs are not \nmanipulated.\nGenerative AI systems \nthat produce \nsome form of \nconsumable \ncontent, such as \nvideo, text,\u00a0 audio, \nimages, code, or \nrecommendations.RB: Low. RB \nsystems don\u2019t \ntend to deliver \nquality new \nartefacts. ML: \nHigh. ML-based \nsystems can \nuse enormous \nquantities of \ninputs and\u00a0 \ndramatically \nimprove generated \noutputs over time.If the artefact \nbeing generated \nis considered \nrepresenting \ngovernment, \nthe\u00a0 risk could \nbe high due to \nreputational risk, \nmisdirected e\ufb00orts \nin an\u00a0 emergency, \nor electoral or \npolicy distrust. \nPublic trust and \ncon\ufb01dence can\u00a0 \nbe undermined if \nthey can\u2019t validate \nauthenticity.\u2022The assessed \nlevel of impact \nshould inform \ngovernance.\n\u2022Transparency on \nuse of\u00a0AI for all \nuse cases.\n\u2022Human review \nis critical for \nall decision \nmaking and \npublic facing \nusage.\n\u2022Provenance of \nsources will help \nmake sure that \noutputs are not \nmanipulated.\n10", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6c109ac7-b9c5-4c50-b021-1109bed04c4c": {"__data__": {"id_": "6c109ac7-b9c5-4c50-b021-1109bed04c4c", "embedding": null, "metadata": {"page_label": "11", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7978f7a313248188f2b1b9ab448419a7100fb2ba7822ca7deca60fc16247efb9", "text": "Government Lens AWS Well-Architected Framework\nArti\ufb01cial intelligence in the public sector\nUsage patterns DescriptionSuitability of AI \ntypesRisk pro\ufb01le Risk management \ntools\nVirtual assistanceAI systems that \nprovide assistance \nor augment \nthe experience \nof a person in \n\u00a0 the moment. \nExamples \ninclude chatbots \n(either rules- \nor data-based), \naugmented\u00a0 and \nmixed reality \n(for example, \napplications \nfor emergency \nresponse \nsupport),\u00a0 or \npersonal assistant \ntechnologies (such \nas Amazon Alexa.)RB: Low. RB \nassistants and \nchatbots work \nfor very limited \nuse cases, but \nare at least \nconsistent. ML: \nHigh. ML will drive \nimprovement \nin service and \nfunctionality of \nvirtual assistants \nover time, \nresponding to \nchanging use \ncases and user \nneeds.High: Government \nuse of this \ncategory can be \nhigh risk, because \nthe information \nor service an \nindividual \nor business \nreceives from \nthis application \nis likely subject \nto the same \nrequirements as \nADM (namely, \nexplainable \ntraceability, \nappealability) and \ndirectly in\ufb02uences \nthe public \nperception of \npublic institutions \nand government.\u2022The assessed \nlevel of impact \nshould inform \ngovernance.\n\u2022Make sure \nthat ADM risk \nmitigations are \nimplemented if \nsolution makes \ndecisions or \nprovides advice.\n\u2022Continuous \nservice design, \nmonitoring, and \nimprovements \nbased on public \nfeedback.\n\u2022Provenance of \nsources will help \nmake sure that \noutputs are not \nmanipulated.\nThis reference architecture illustrates a secure, self-service, data science environment using Amazon \nSageMaker Studio. It provides data scientists with access to a secure and persistent experimentation \nenvironment as well as\u00a0continuous integration and continuous deployment (CI/CD) pipelines to perform \ndata science and machine learning at scale.\n11", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "aca4d3a9-72f6-4864-9b8d-41b1a569250c": {"__data__": {"id_": "aca4d3a9-72f6-4864-9b8d-41b1a569250c", "embedding": null, "metadata": {"page_label": "12", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a526bf91f615bd35aa71cd791f0c0ef912c17bed3fd5fe0d868f0c33fff22b04", "text": "Government Lens AWS Well-Architected Framework\nClassi\ufb01ed information systems\nFigure 1: A sample reference architecture to enable public sector customers with AI\nThis architecture demonstrates a self-service model for enabling multiple project teams to create \nenvironments and details the design choices and security controls that your organization can rely on in \nthese environments.\u00a0Organizations should modify these controls to verify that they meet their speci\ufb01c \nrequirements.\nThis architecture is capable of supporting some of the hardest challenges for the public sector when \nimplementing ML programs such as:\u00a0\n\u2022Management and governance: Public sector organizations need to provide increased visibility into \nmonitoring and auditing ML workloads. Changes need to be tracked in several places, including \ndata sources, data models, data transfer, transformation mechanisms, deployments, and inference \nendpoints.\u00a0\n\u2022Bias and explainability: Given the impact of public sector organizations on citizens, the ability to \nunderstand why a ML model makes a speci\ufb01c prediction becomes paramount\u2014this is also known \nas ML explainability. Organizations are under pressure from policymakers and regulators to verify \nthat ML- and data-driven systems do not violate ethics and policies, and do not result in potentially \ndiscriminatory behavior.\n\u2022ML Operations (MLOps): Integrating ML into business operations, referred to as MLOps, requires \nsigni\ufb01cant planning and preparation. One of the major hurdles facing government organizations is the \nneed to create a repeatable process for deployment that is consistent with their organizational best \npractices. Mechanisms must be put in place to maintain scalability and availability, as well as ensuring \nrecovery of the models in case of disasters. Another challenge is to e\ufb00ectively monitor the model in \nproduction to verify that ML models do not lose their e\ufb00ectiveness due to the introduction of new \nvariables, changes in source data, or issues with source data.\u00a0\nThe following list provides some examples of public sector use cases for AI and ML in AWS. For a more \ncomprehensive list, refer to the AWS Blog.\n\u2022The AWS toolkit for responsible use of arti\ufb01cial intelligence and machine learning\n\u2022Improve governance of your machine learning models with Amazon SageMaker\n\u2022Protecting Consumers and Promoting Innovation \u2013 AI Regulation and Building Trust in Responsible AI\n\u2022How NASA uses AWS to Protect Life and Infrastructure\n\u2022Paper on Forecasting Spread of COVID-19 Wins Best Paper Award\n\u2022Amazon Supports NSF Research in Human/AI Interaction Collaboration\n\u2022Using AI to rethink document automation and extract insights\n\u2022Chester\ufb01eld County Public Schools uses machine learning to predict county\u2019s chronic absenteeism\n\u2022Using advanced analytics to accelerate problem solving in the public sector\n\u2022How AI and ML are helping tackle the global teacher shortage\n\u2022Improving school safety: How the cloud is helping K12 students in the wake of violent incidents in \nschools\n\u2022Heading into Hurricane Season\nClassi\ufb01ed information systems\nClassi\ufb01ed information is information that a government or agency deems sensitive enough to national \nsecurity that access must be controlled and restricted. Every government has di\ufb00ering levels of \nclassi\ufb01cation that are speci\ufb01c to their own context. For example, the U.S. Government uses three levels \nof classi\ufb01cation to designate how sensitive certain information is: con\ufb01dential, secret, and top secret. The \nlowest level, con\ufb01dential, designates information that, if released, could damage U.S. national security. \nThe other designations refer to information, the disclosure of which, could cause serious  (secret) or\n12", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d91a466e-171b-49c8-86d0-d830bb2afa66": {"__data__": {"id_": "d91a466e-171b-49c8-86d0-d830bb2afa66", "embedding": null, "metadata": {"page_label": "13", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e05472e247fb3235907fea21b43a14ef4509f2bcac15ccb46caee9dd02271b03", "text": "Government Lens AWS Well-Architected Framework\nCitizen engagement reference architecture\nexceptionally grave (top secret) damage to national security. Some data and information is considered \nunclassi\ufb01ed and low risk, but this scenario is for higher risk and classi\ufb01ed information systems.\nThe decisions concerning the level of data classi\ufb01cation are often based on a risk approach and are often \ndependent on regulatory and compliance requirements. These requirements are often re\ufb02ective of the \ndata types. for example, personally identi\ufb01able information (PII) or personal health information (PHI), or \ninformation related to ITAR, HIPAA, IRAP, GDPR, or other compliance and regulatory requirements.\nOften, the standards do not prescribe how agencies should meet the requirements, as agencies vary in \nsize and complexity. Every agency has a unique information management environment with varying \nculture, risk tolerance, legacy systems, and resources. Agencies should implement the principles and \ncharacteristics to meet their speci\ufb01c circumstances.\u00a0\nCharacteristics and principles of classi\ufb01ed information systems architectures include:\n\u2022Business information is systematically and holistically governed throughout its lifecycle.\n\u2022Only necessary business information is created.\n\u2022Business information is adequately described.\n\u2022Business information is suitably stored and preserved.\n\u2022It is known how long business information should be kept.\n\u2022Business information is accountably destroyed or transferred.\n\u2022Business information is saved in systems where it can be appropriately managed and monitored.\n\u2022Business information is available for use and reuse.\nCitizen engagement reference architecture\nGovernments are increasingly investing in citizen facing channels: mobile applications, web portals, call \ncenter agents, and chatbots to enhance the overall citizen experience. In a regulated industry space, user \nengagement architectures challenge the segregation often recommended for classi\ufb01ed workloads and in \nsome cases with citizen engagement it\u2019s based on veri\ufb01able identity along with:\n\u2022High volumes of real-time ingestion from public and private sources.\n\u2022The requirement for di\ufb00erent data protection based on data classi\ufb01cation.\n\u2022Use of event-driven architectures to leverage on-demand scalability and pay-per-use model.\n\u2022Inclusion of real-time and archival \ufb02ows.\n13", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "40f2f61c-d30b-4f64-a6a4-b696b779f3ca": {"__data__": {"id_": "40f2f61c-d30b-4f64-a6a4-b696b779f3ca", "embedding": null, "metadata": {"page_label": "14", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "531c3fc129121774587cf4083269d05a792904a67a21f840ca04a6614fa6d00b", "text": "Government Lens AWS Well-Architected Framework\nRegulatory reporting reference architecture\nFigure 2: Reference architecture for a citizen engagement solution\nRegulatory reporting reference architecture\nEvery government institution deals with volumes of information for legislative or regulatory reporting. \nStatic legacy infrastructure and ine\ufb03cient reporting processes can make reporting costly and prevent \ncustomers from responding quickly to regulatory changes. Building a reporting data lake on AWS \nand using the rich set of services available can address many of the issues that complicate regulatory \nreporting, such as data residing in disconnected silos and distributed ETL processes. After customers \nintegrate reporting data into a consistent dataset or data pipeline, they can use that data to gain \nadditional insights through advanced analytics and machine learning.\u00a0\nData lake architectures supporting these government services use cases share the following \ncharacteristics:\u00a0\n\u2022They implement data quality, integrity, and lineage into the ingest and processing pipelines.\n\u2022They require that data is encrypted at rest and in transit.\u00a0\n\u2022They mask or tokenize personally identi\ufb01able information (PII) data to help align with regulatory \nrequirements (for example, EU General Data Protection Regulation).\u00a0\n\u2022They use data catalogs with \ufb01ne-grained access control and entitlements.\n14", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a7f77840-1699-4a9c-a4e0-a8930859e108": {"__data__": {"id_": "a7f77840-1699-4a9c-a4e0-a8930859e108", "embedding": null, "metadata": {"page_label": "15", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "95082600a2a657520fe07c8a3bd80fc938d07d8a3e596dbc2675c6abc64be71c", "text": "Government Lens AWS Well-Architected Framework\nDistributed processing of sensitive \ndocuments reference architecture\nFigure 3: Reference architecture for a regulatory reporting solution\nDistributed processing of sensitive documents \nreference architecture\nGovernments often need to separate their processing in segmented ways to heighten the level of \nsecurity. This often occurs when the information is classi\ufb01ed as con\ufb01dential. However, there is still a need \nto e\ufb00ectively process the data in segregated environments. In this scenario, the processing of sensitive \ndocuments might involve distributed and separated systems.\n15", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "45fce943-29a5-447f-b479-0a5f6c56c3dc": {"__data__": {"id_": "45fce943-29a5-447f-b479-0a5f6c56c3dc", "embedding": null, "metadata": {"page_label": "16", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0856fe5bb8d63b801847f9d5544a514eabd85b2f7656bcc00d6eb660e8d4a7c4", "text": "Government Lens AWS Well-Architected Framework\nOmni-channel public services\nFigure 4: Reference architecture for the distributed processing of sensitive data\nOmni-channel public services\nPublic-facing government services should have online and o\ufb04ine options to verify that they are \ninclusive and accessible by all. In many cases, this requirement will be legislated.\u00a0If a digital service is \nbuilt in isolation to a phone or in-person channel, then you might have a duplication of functions and \nincreased management costs, as well as potential inconsistency across channels. Inconsistency can lead \nto\u00a0inequities, especially given the reality of many government services being either mandatory (such as \nsubmitting a tax return) or a last resort for people at their most vulnerable (such as emergency payments \nor social services).\u00a0\nOmni-channel public services\u00a0help provide a consistent experience for users, including sta\ufb00, by providing \na virtualized presentation layer. This approach makes reusable service components and capabilities \navailable to channels through an integration layer.\u00a0This means that the backend and business systems \ncan be consumed across all channels in a consistent way, while still providing \ufb02exibility to the public-\nfacing services to optimize interactions for di\ufb00erent channels.\nThrough this integration layer, governments should also consider providing a set of highly reusable \nmodular components for the most commonly needed functions within digital services, such as taking \npayments, sending noti\ufb01cations, verifying identity, and collecting form data. This approach is often \nreferred to as Government as a Platform (GaaP), where collectively these modular commodity service \ncomponents provide a platform for services to be built upon. GaaP allows service teams to consume \nexisting commodities so that they can spend more time on what is unique to their service and users.\nCharacteristics of a good omni-channel architecture:\n16", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3c38926b-1165-4b7e-874e-61f5451caeb8": {"__data__": {"id_": "3c38926b-1165-4b7e-874e-61f5451caeb8", "embedding": null, "metadata": {"page_label": "17", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8a6cfafbd1d390f7ddabff9ef4cb21fc7ae0a30eddffe81c7c63a6d648997094", "text": "Government Lens AWS Well-Architected Framework\nConceptual architecture\n\u2022Consistency of functionality and features across channels.\u00a0\n\u2022A virtualized presentation layer, where all channels draw on common business functions through a \ncommon integration layer.\n\u2022An integration layer that provides secure, consistent, and common management of data, content, \nrules, and transactional functions across all channels.\n\u2022Channel agility, where channels can rapidly evolve and change according to new technologies, devices, \nand user needs as they emerge, decoupled from the management of business systems.\n\u2022Policy and program teams can use the same infrastructure to measure, monitor, and model the \nintended and unintended impacts of government services.\nConceptual architecture for omni-channel public \nservices\nFigure 5: The omni-channel architectural framework for government services\nOpen government methods, infrastructure, and \ntools\nTo maintain the trust of the people they serve, governments need to be transparent, accountable, and \ntruthful. This covers many di\ufb00erent aspects of government operations such as how and with whom \ntaxpayer money is spent, how e\ufb00ective policy initiatives are, what the laws are and the penalties for \nbreaking them, and how decisions are taken. Being open is essential to help avoid perceptions of \ncorruption or unfairness in society.\u00a0There are a number of open government tools and approaches that \ncan be used by governments as they develop public services that can increase trust, improve outcomes \nand, in some cases, help verify that legal or regulatory obligations are met.\nCharacteristics and principles of open government system architectures include:\n\u2022High public trust and con\ufb01dence in government systems and services\n17", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "7ac7b86a-c241-40c3-aa5e-633d57664ae1": {"__data__": {"id_": "7ac7b86a-c241-40c3-aa5e-633d57664ae1", "embedding": null, "metadata": {"page_label": "18", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "1f26d7d4cbf9cd5b69453d09a40d8f354f63ddefcb1d3c0bec5b503c576a016e", "text": "Government Lens AWS Well-Architected Framework\nWorking in the open\n\u2022Clear accountability and reporting measures\n\u2022Public visibility and participation of programs, projects, services, and policies\n\u2022Open feedback mechanisms for the public\u00a0\nWorking in the open\nWorking in the open has bene\ufb01ts to both government and society. It provides a scalable mechanism for \npeer review, partnerships, and public participation as well as greater opportunities for collaboration and \nreuse between government teams, departments, and jurisdictions. Blogging, sharing tools and code, \nshowcases, feedback opportunities, open prototyping, and visible product management can all bene\ufb01t \nthe quality of delivery. AWS architecture and delivery practices exemplify many of these open ways of \nworking.\nOpen-source software publication and reuse\nMany governments have a policy of publishing code repositories that they have developed under an \nopen source license to increase transparency and allow for reuse by others. This approach can also \nextend to infrastructure as code (IaC) con\ufb01gurations. It\u2019s\u00a0important to understand if the government \nsystems and services you work on will be published as open source so that information not intended \nfor the public domain isn\u2019t published in the code repository, and that no proprietary code is included. \nIncreasingly, governments have open-source software policies that encourage or require teams delivering \nnew systems or services to explore the reuse of existing open-source solutions before investing time \nor money into building new ones. In some countries, these requirements are legislated. It is therefore \nimportant to understand any open-source software policies when designing and architecting new \ngovernment systems and services, and to support government organizations to evaluate open source \no\ufb00erings as part of these processes. AWS provides an open source repository and guidance to help.\nAlgorithmic transparency\nTo maintain trust and fairness when using algorithms for automated or semi-automated decision \nmaking, it\u2019s important to consider whether the algorithms used can be published. A number of \ngovernment organizations maintain a public register of algorithms used within their systems for this \npurpose. Not all algorithms will be appropriate for publication, for example, some fraud detection \nmeasures, however, where automated decisions are taken that directly a\ufb00ect people\u2019s lives and \nlivelihoods, consideration should be made around publication of the algorithm and what mechanism \nis most appropriate for doing so. Algorithmic transparency could also mean traceable explainability to \nthe legislation or rules used to make a decision, or providing transparency to end users on when they \nare interacting with algorithms. Finally, it can be useful to test inputs/outputs of algorithmic decision \nmaking against the relevant legislation/regulation as code, to work toward compliance.\nPerformance reporting\nA key tool for government accountability is monitoring, measuring, and publishing performance data of \npublic services and policy initiatives through public facing dashboards. Dashboards provide a simple way \nfor the public and policymakers to visualize, and access the data and insights around the performance \nof important government operations. Considerations should be made around what metrics are useful \nindicators for performance, what mechanisms are required to derive those metrics, and how this data can \nbe published.\nOpen government data\nGovernment organizations generate and manage a wide array of data and information for which \nthey are the canonical source. While much of this data contains private information, such as personal, \n18", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2005b2e7-6ef5-48ba-87d5-84c5ca28f2a0": {"__data__": {"id_": "2005b2e7-6ef5-48ba-87d5-84c5ca28f2a0", "embedding": null, "metadata": {"page_label": "19", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "11bb7cde7e9a0abcade01de5ba88446e38b621aff1f3cc0c574a43ffc0840dfd", "text": "Government Lens AWS Well-Architected Framework\nVeri\ufb01able credentials (claims) for government \ncon\ufb01dential, or classi\ufb01ed, there is a large amount of non-private data and information that can provide \nsigni\ufb01cant value to society if openly shared and licensed for reuse. This sharing allows others to build \non this data to create innovative solutions. Common examples of open data range from the large scale, \nsuch as geospatial information, population statistics or weather data, to the smaller scale, such as \nlocations of public toilets, lists of local authorities, and academic institutions. You should consider if your \nservice holds data that is appropriate for open publication. If it does, you should explore mechanisms \nfor publishing and providing both programmatic and manual access to the data, and that the data is \nlicensed for reuse.\nVeri\ufb01able credentials (claims) for government\nThere are several scenarios where veri\ufb01able credentials (VCs) make sense in a government context. \n\u00a0 Veri\ufb01able credentials provide a repeatable pattern in scenarios where assertions about the state \nof something is useful and those assertions are valuable outside the four walls of government or a \nspeci\ufb01c department.\u00a0 Examples include trade, identity, technology bill of materials, inspections, and \ncerti\ufb01cations.\u00a0 The key concept for government is that they are in a unique position in society to be a\ntrust anchor  for speci\ufb01c types of claims that become a tether for chains of claims .\u00a0\nIn most economies, the trust anchors are government agencies and accreditation authorities. The role \nof trust anchors is to issue digital credentials to their community members, which the members can \nuse to make their own credentials more trustworthy. For example, a national company\u2019s register that \ntraditionally issues company registration certi\ufb01cates as paper or a PDF \ufb01le, can now issue them as VCs \nso that the company can prove its identity to any veri\ufb01er. A fundamentally important advantage of \nthe decentralized architecture of VCs and Digital Identities (DIDs) is that there is no need for a direct \nrelationship between the issuer (for example, the company\u2019s register) and the veri\ufb01er who, for cross \nborder trade scenarios, is most likely in another country.\nHere\u2019s how it works:\n\u2022A member of a regulated community (such as a company director) creates a DID and associated public \nand private key pair using the software of their choice.\n\u2022The member authenticates to the trust anchor service (such as the company\u2019s register) as they would \nnormally do when interacting with the regulator or trust anchor.\n\u2022The member presents evidence that they are the owner of the DID (a digital signature using the DID \nprivate key) that the trust anchor can verify using the public key.\n\u2022The trust anchor issues a VC with the member DID as subject that contains relevant claims (for \nexample, that the DID subject is indeed an authorized o\ufb03cer of the company).\n\u2022The member (that is, the company) can now leverage this regulator-attested digital identity as part of \nits normal business. For example, the company issues a commercial invoice with their DID as the issuer. \nThe invoice VC includes a link to the company registration VC.\n\u2022The invoice recipient can now verify that the invoice VC was issued by the company DID and hasn\u2019t \nbeen tampered with, and that the registration VC was issued by the authorized government regulator \nand con\ufb01rms that the same DID is for the same company.\n\u2022If the company is de-registered, the regulator can revoke the registration VC. Immediately after \nrevocation, any veri\ufb01cation of the original VC will result in failure.\nIt\u2019s important to re-emphasize that the trust anchor is still doing their normal business of issuing \ncerti\ufb01cates, permits, registrations, and licenses to their members\u2014they are just doing it digitally. There is \nno relationship between the trust anchor and veri\ufb01ers. The digital credentials are also paper-compatible, \nfor example, they can be made available as a QR link on a paper or PDF certi\ufb01cate. Whether the member \nmakes use of the digital credential for downstream proofs is up to the member.\nWhen well-implemented, a VC architecture has the following characteristics:\n19", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "177739f7-3b26-4aa1-9b09-6bc7f6216cb1": {"__data__": {"id_": "177739f7-3b26-4aa1-9b09-6bc7f6216cb1", "embedding": null, "metadata": {"page_label": "20", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "ba599712665971f92dfd9999c16ed1c1a61156b2f4b0084bed7fb328599c5c19", "text": "Government Lens AWS Well-Architected Framework\nConceptual architecture\n\u2022Claims and credentials are able to be quickly and programmatically veri\ufb01ed in real time by relevant \nauthorities.\n\u2022The claims and credentials are considered trustworthy for major stakeholders.\n\u2022An end user gets a more personalized service without having to over share personal information.\n\u2022VC is made available as a utility to serve multiple use cases.\n\u2022VCs are signed from a central, reliable, and trustable source \u2013 that is, at the organizations domain (that \nis, from did=trade.govx ) so that people, systems, and organizations can rely on the claim issued by \nthe trust anchor.\n\u2022VCs issued from the organization are within the legislative or administrative scope of the department.\n\u2022VCs issued have a human understandable description that maps back to the organization\u2019s scope or \nlegislation.\n\u2022VC domains map to legislative, international agreements, or both so that claims are understandable \nbeyond just the scope of the department.\n\u2022VC domains are validated against the organizations legislative or administrative scope.\n\u2022Test architectures, methodologies, and infrastructure are in place to verify that only quality claims are \nissued.\nConceptual architecture\nThe following diagram represents a trust graph  combining several claims from various departments for \nthe bene\ufb01t of the community.\u00a0\nFigure 6: Illustration of the range of government digital identity proofs\nFigure 6 shows a range of government digital identity proofs examples (Customs, Department of \nAgriculture, Department of Trade, Accreditation Authority, and Trademarks o\ufb03ce), each of which can \nissue a veri\ufb01able identity of an entity (exporter, inspector, chamber, certi\ufb01er and producer, respectively) \nor a veri\ufb01able piece of information that relates to a consignment, shipment, product, or producer (such \nas source, supply chain, or ingredients). This leads to a bank being able to issue a Letter of Credit decision \nwhich can automatically verify the invoice integrity, seller integrity, and goods origin from each of the \nrelevant authorities through the veri\ufb01able credentials system. It also enables an importer to make a \npurchase decision by being able to automatically verify the goods authenticity and product sustainability \nthrough relevant veri\ufb01able credentials.\n20", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "20cdffd4-ac78-4277-9648-78030b9c6947": {"__data__": {"id_": "20cdffd4-ac78-4277-9648-78030b9c6947", "embedding": null, "metadata": {"page_label": "21", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0c2e28e5ca7507efb749331e4c0bd0e5d9603974e1bfad49f8076bb64edcc99a", "text": "Government Lens AWS Well-Architected Framework\nConceptual architecture\nA single veri\ufb01able credential allows an issuer to make one or more veri\ufb01able claims about a subject.\u00a0 For \nexample, an exporter might issue a commercial invoice for a given shipment of goods as a VC. A veri\ufb01er \ncan be con\ufb01dent that the invoice was issued by the identi\ufb01ed exporter and hasn\u2019t been tampered with. \nSimilarly, a certi\ufb01er can issue an ISO-14000 environment certi\ufb01cate to an identi\ufb01ed producer that can be \npresented to a party for digital veri\ufb01cation of ISO certi\ufb01cation.\u00a0\nThese uses are valuable in themselves, but credentials can be chained together to create trust graphs\nthat release much greater value. The connections that make up the graph can be explicit (for example, \na credential includes a link to another credential) or implicit (for example, the same DID appears in two \nseparate credentials). Consider the previous example, in which nodes represent DIDs and links are VCs.\nReferences\n\u2022Section 3.4 of UN/CEFAFT White Paper on eDATA Veri\ufb01able Credentials for Cross Border Trade\n21", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "14c811f9-f598-4207-927e-db7b44ec50a8": {"__data__": {"id_": "14c811f9-f598-4207-927e-db7b44ec50a8", "embedding": null, "metadata": {"page_label": "22", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b966b1f9a1e23c10525e194a4d26886b448b8079f583aadfb9db5ea24bc69587", "text": "Government Lens AWS Well-Architected Framework\nOperational excellence pillar\nPillars of the Well-Architected \nFramework\n\u00a0This section maps the six pillars of the Well-Architected Framework to government environments.\u00a0\nPillars\n\u2022Operational excellence pillar (p. 22)\n\u2022Security pillar (p. 26)\n\u2022Reliability pillar (p. 28)\n\u2022Performance e\ufb03ciency pillar (p. 29)\n\u2022Cost optimization pillar  (p. 29)\n\u2022Sustainability pillar (p. 30)\nOperational excellence pillar\nIn the Government Lens, the operational excellence pillar describes the ability to support \nthe\u00a0departmental mandate and government priorities to run services e\ufb00ectively, gain insight into \noperations, and to continually improve supporting processes and procedures to deliver policy outcomes \nand public\u00a0value.\nThe following questions and best practices complement the best practices in the Operational Excellence \nPillar whitepaper .\nReshape the operating model\nAs governments seek to digitally transform, technology expertise and experience is essential to achieving \nstrategic policy outcomes. To verify that digital delivery of mission objectives can consistently evolve and \nbe delivered successfully, organizational structures must be reshaped and be inclusive of both business \nand technology experts.\nMany government departments have functionally segmented, bureaucratic structures that create a \nchallenge for modern delivery of portfolio objectives. These departments often use technology in a \ncorporate silo or have outsourced their technology entirely. This structure has left many governments \nwith an operational divide between their business and technology sta\ufb00 that slows or prevents the \nrealization of new strategic intent.\nGL-OPS-01:\u00a0How do you adjust the\u00a0organizational structure to better realize strategic policy \noutcomes?\n\u2022Support the establishment of persistent team structures: When services are developed as projects, \nand teams assembled for the project are disbanded at the end of the project, the service is left without \npersistent product management. Establish team structures and governance models that can persist \nbeyond the end of project.\n22", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "54c7cb72-fa64-4810-b4a3-ecf10c4fb96b": {"__data__": {"id_": "54c7cb72-fa64-4810-b4a3-ecf10c4fb96b", "embedding": null, "metadata": {"page_label": "23", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e2019b1738afc94f74e8b57b07da56776da17460e0a68cbc68d93b03886533cb", "text": "Government Lens AWS Well-Architected Framework\nReshape the operating model\n\u2022Enable hierarchy, team structures, and appropriate governance to delegate decision \nmaking:\u00a0 Service and product owners require autonomy to realize continuous improvement and \noperational reform in a timely manner. This autonomy has the bene\ufb01t of streamlining escalation, \nunblocking slow and laborious go-live protocols, and minimizing decision gaps between business \nowners and technology people.\u00a0\n\u2022Build capability across the organization: To bridge the digital divide, the organizational structure \nmust enable both business and technology people to elevate their functional and non-functional skills \nto collaborate e\ufb00ectively.\n\u2022Develop a concept of operations document:\u00a0Create a concept of operations document that explicitly \ndescribes how the service will continually improve over time, with supported and authorized product \nmanagement and team. Its contents might include delegated decision-making mechanisms, product \nmanagement in government, outcomes or product-based funding, and how to bring multi-disciplinary \nteams together to manage aspects of the service.\n\u2022Consider public, sta\ufb00, and parliamentary feedback loops: Consider what additional feedback loops \nmight complement the feedback loops de\ufb01ned in the Operational Excellence Pillar in the special \ncontext of the department and jurisdiction. For example, how might sta\ufb00 or the public report legal or \nimpact concerns.\n\u2022Consider a minimum viable product (MVP) deployment model where viable: Many government \nprojects take a big bang  deployment model approach, attempting to develop all features and then \nlaunch a fully formed product. This approach creates a substantial risk that individual features might \nnot be e\ufb00ective, and provides no means to iterate or test in advance of launch. An MVP deployment \nmodel identi\ufb01es the minimum features needed for a functional product to launch, often initially to \na subset of end users, and then scales and adds features in a test-driven way. This method minimizes \nrisk, delivers early value, and veri\ufb01es that all product features are tested for e\ufb00ectiveness with end \nusers.\n\u2022Create the conditions for operational excellence when outsourcing: De\ufb01ne goals and measure \nvendors on the best practices within this lens to embed a mechanism for innovation, and to deliver \nbetter government services and outcomes into outsourced contracts.\u00a0Verify that there is a minimum \nviable internal capability (or have a plan to build it) around the core competencies required to operate \nand improve the service. These competencies can be complemented and supported by vendors, \nbut maintain the necessary internal agility for operational excellence. Explore \ufb02exible procurement \narrangements, such as sprint- or outcome-based procurement.\n\u2022Document and engage with cultural context: Understand the cultural context, including indigenous \nor First Nations needs, and the requirements around partnerships or treaty agreements with \nindigenous peoples.\nGL-OPS-02:\u00a0How do you verify that digital experiences remain operational and relevant over time?\nSome government departments can only fund changes to a service through a new funding application, \nwhich can make change slow and expensive. This funding model can lead to a great product becoming \nless than great over time.\n\u2022Verify that government sta\ufb00 are well supported to operate the service: The more empowered public \nservants are to understand, manage, and improve their services, the more they are positioned to be \nproactive and e\ufb00ective in delivering great services, both directly and with vendors.\n\u2022Embed continuous improvement into the operating model: Continuous improvement helps make \nsure that public-facing government digital experiences don\u2019t deteriorate over time.\u00a0Investment \nmust be made to maintain the continuous evolution and maintenance of the service to match the \nexpectations and feedback of consumers. If you have a \ufb01xed or scheduled approach to improvement, \nsupport the best practices possible.\n\u2022Implement an agile development framework: Deliver the minimum viable product (MVP) or service \nthat enables:\n23", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9b12d3d6-074f-4c98-ae23-064e3c69f9d2": {"__data__": {"id_": "9b12d3d6-074f-4c98-ae23-064e3c69f9d2", "embedding": null, "metadata": {"page_label": "24", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b880306602e1f437f118190076b09e1b3e9f0ce0cf9afe089adaa067d33b94c1", "text": "Government Lens AWS Well-Architected Framework\nReshape the operating model\n\u2022Early feedback on requirements from citizens, industry, and government\n\u2022Testing and evolving of non-technical go-live processes the government might need to conduct\n\u2022Consistently and continuously evolve functionality as the service feedback and requirements mature \nover time\n\u2022Align with the concept of operations document to make sure that expectations are met during \nservice development.\n\u2022Document the mechanisms for funding iterative changes to the service:\u00a0Support mechanisms are \nrequired for continuous improvement. Agile funding mechanisms are critical to verify that continuous \nimprovement is continuously resourced, rather than relying on purely project-based funding.\u00a0\nGL-OPS-03:\u00a0How do you verify that the service meets operational transparency requirements?\n\u2022Document how the service delivers operational accountability requirements: Many governments \nhave strong requirements around operational accountability through various audit and reporting \nmechanisms. In some jurisdictions, there are public reporting requirements for public facing services.\n\u2022Document how citizens and companies will be kept informed:\u00a0To manage expectations and make \nit simple for consumers to use the service, create high quality communications (both marketing and \ntransactional), supporting information, and technical documentation for the service.\u00a0\n\u00a0When considering technology acquisition for a service, you\u2019ll need a business level understanding of the \ngovernment mission and policy objectives, government process, standards, and how these map to service \ncapabilities, which then inform solution requirements.\u00a0\nGL-OPS-04: How can you improve solution de\ufb01nition criteria?\nVerify that multiple concepts are tested with end users prior to deciding on a solution: Testing \nconcepts provides the opportunity to validate assumptions about what might work, and to proceed only \nwith tested policy interventions. Sometimes the best solution is no solution at all, a regulation, or a \nchange to an existing service.\n\u2022Identify patterns in the desired service capabilities and intended service usage: Patterns might \nappear as emergent (such as self-sovereign digital identity), or common (such as a noti\ufb01cation service, \nor application of government legislation and rules in a desired service capability). Patterns should \nhave broad use case applicability with high volumes of reuse and could be candidates for whole of \ngovernment reusable capabilities.\n\u2022De\ufb01ne foundational reusable components: Informed by the previous pattern identi\ufb01cation, look \nfor opportunities to standardize people, processes, and technology solutions to optimize delivery, \nimplementation, and operation of one or many components that support a service capability.\nGL-OPS-05: How can you improve solution acquisition criteria?\nNot all components will have the same business and technical requirements. Consider the following best \npractices when designing, evaluating, or acquiring solutions and technologies:\n\u2022Reuse: Use existing open source and open government solutions, where feasible.\n\u2022Rearchitect: Consider the suitability of existing architecture and whether rearchitecture is required.\n24", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "c21c532a-4f79-46c1-be9e-4df8a747d0f7": {"__data__": {"id_": "c21c532a-4f79-46c1-be9e-4df8a747d0f7", "embedding": null, "metadata": {"page_label": "25", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "ffe85bd7423df234deed8e8ecd7ed074450cd00c7ce19940698e4e18bcea948b", "text": "Government Lens AWS Well-Architected Framework\nOrganizational risk\u00a0\n\u2022Build: If you require service agility, if a solution does not yet exist, or if you want to integrate multiple \nsystems into a channel, consider building it. The capabilities and strengths of the customer's team \nshould be considered and planned for to achieve service viability, both technically and \ufb01nancially.\n\u2022Give back: Reusable foundational components and solutions can be shared back to the open \ngovernment community through open-source licensing.\n\u2022Buy o\ufb00 the shelf:  Where minimal customization is required and the solution is mission-aligned, \npurchase a solution.\u00a0\n\u2022Outsourcing:  If there is a people constrain for design, implementation, and ongoing operations, this \nmight be suitable. Customers are encouraged to maintain a minimum viable internal expertise and \ndelivery capability, in order to maintain control over the strategic direction and the selection criteria as \nabove.\n\u2022Think critically about licensed software: Licensing has the potential to be prohibitive in several ways, \nsuch as:\n\u2022If a user-based license model is used for a government service with signi\ufb01cant citizen uptake\n\u2022Containing license terms that are bound by hardware con\ufb01gurations, which have agility and \ufb01nancial \nconsequences to scaling the government service as demand evolves\n\u2022Creating a preferential technology ecosystem that inhibits the government\u2019s use of other \ntechnologies.\n\u2022Vendor reputation: Are the vendors you are considering at low risk of creating political challenges for \nyour government service, such as un\ufb02attering news headlines, or poor professional conduct.\nOrganizational risk\u00a0\nEvery service should have a risk management plan to assess and manage risk. Risk management should \nbe comprehensive to consider all hazards, including how the cloud service supports risk mitigation \nby design. This assessment is essential to make informed design decisions. Service risk must be \ncontextualized as part of the broader organization risk strategy.\nGL-OPS-6: Do you have adequate people and process risk management systems in place covering a \nbroad risk spectrum?\n\u2022Take an all-hazards approach: Include consideration of personnel, supply chain, cyber security, \ninformation security, and natural risks.\u00a0\n\u2022Have a strong understanding of controls that can be inherited from the cloud service provider, for \nexample, the physical security of data centers.\u00a0\n\u2022Consider sovereign resilience requirements, which can aid in the survival of government in extreme \ncircumstances.\n\u2022Develop a risk management plan: Have a plan that supports ongoing risk assessment and treatment, \nand veri\ufb01es that the service risk is contextualized as part of the organization\u2019s risk pro\ufb01le.\u00a0\n\u2022Decide what matters most to your organization, and to your service. Considerations include social, \ncultural, political or regional issues, economic and technology trends, policy and law, and your \norganizations aims, policies and strategies.\u00a0\n\u2022Identify, analyze, and evaluate risks to help make sure that adequate treatments are identi\ufb01ed so \nthat your service is resilient.\u00a0\n\u2022When considering the risk of a service, consider whether the risk is acceptable for the associated \nservice outcome it achieves.\u00a0\n\u2022Align with compliance: When implementing compliance frameworks such as CSA, NIST, CISPE, ISM, \nand ISO, verify that the framework is appropriate for the risks requiring mitigation and that it is \nconsidered as part of the broader organizations risk strategy and risk appetite statement.\n25", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3842e99a-2650-40c0-b16a-b61e78d1e9ed": {"__data__": {"id_": "3842e99a-2650-40c0-b16a-b61e78d1e9ed", "embedding": null, "metadata": {"page_label": "26", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "57647cb555aeae68f1a955dc392c964238ba2eaa8be5bfefd3a5e48fb0c96579", "text": "Government Lens AWS Well-Architected Framework\nResources\n\u2022Determine the necessary conditions of engagement:\u00a0Consider the Business Impact Level (BIL) of the \nservice to determine personnel requirements, such as security clearances, vetting, data handling, and \nrisk training.\nResources\n\u2022Digital Transformation: The Why, Who, How, and What \u2013 Part 1, \u201cThe Why\u201d\n\u2022Digital Transformation: The Why, Who, How, and What \u2013 Part 2, \u201cThe Who\u201d\n\u2022An Overview of the AWS Cloud Adoption Framework\n\u2022Building your Cloud Operating Model\n\u2022Four Steps Toward Digital Government\n\u2022How governments can transform services securely in the cloud\n\u2022Risk Management in the AWS Cloud Adoption Framework\n\u2022AWS risk and compliance program\n\u2022AWS Compliance Programs\n\u2022AWS Digital Sovereignty Pledge: Control without compromise\nSecurity pillar\nThe security pillar encompasses the ability to protect data, services, and systems by taking advantage \nof cloud technologies to improve your security, including practices for understanding the threat and \nrisks, empowering end users to control how their data is used,\u00a0and shifting to real time monitoring and \nescalation models for security.\nThe following questions and best practices are designed to complement the best practices in the Security \nPillar whitepaper .\nNote\nGovernments have di\ufb00erent security, risk, and compliance requirements, which might be \nenforced through rules, regulations, and laws. It\u2019s important for you to understand your \nobligations as a person involved with a government service. This topic is also covered in the \nservices outcomes pillar.\nVerifying privacy-by-design\nGL-SEC-01: What privacy practices have you adopted relating to the use of data?\n\u2022Elevate encryption beyond the basics: Cloud technologies make it simpler and cost e\ufb00ective to \nencrypt data. Government jurisdictions have speci\ufb01c compliance and data classi\ufb01cation requirements. \nFor example, they might have hardware or software certi\ufb01cation requirements, or require that \ncryptographic controls be managed independently of the cloud service provider\u2019s managed encryption \nservices.\n\u2022Document how privacy and end user control has been considered: The possibilities for a \npersonalized government service delivery must be balanced with maintaining end user control \nand privacy to maintain public trust.\u00a0Government services should be designed to be as private as \npossible.\u00a0Architects can link to data in place, use veri\ufb01able claims and credentials where possible, to \nmaintain strong privacy controls and minimize any requirement to create new copies of data. Validate \nthat sensitive data is protected, removed, or obfuscated to limit exposure. Use\u00a0detection controls \n26", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "42bd699d-fa8d-4a09-bb41-8860b20e9f5d": {"__data__": {"id_": "42bd699d-fa8d-4a09-bb41-8860b20e9f5d", "embedding": null, "metadata": {"page_label": "27", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "21fdbfeea7987bc2a55803cd1352cc0243d578eed856e976ec00a4898f77afb7", "text": "Government Lens AWS Well-Architected Framework\nShifting to a real time security model\nso that the operations team knows where sensitive data exists in the service. Access to data should \nrequire users and systems to demonstrate a strong security posture assessment, enforced with \ufb01ne-\ngrained authorization rules and multiple authentication controls.\n\u2022Give end users appropriate control: To help alleviate privacy concerns, provide end users as much \ncontrol over their experience as possible. This control can include the ability to dial up or down \nthe helpfulness of the service, for example, the level of prompting, proactive delivery, or other \nforms of personalization. Be transparent about data storage, use, transmission, and access. Modern \ntechnologies must allow for continuous and informed consent mechanisms where users can be \ninvolved in the decision to share their data. Make it simple for end users to understand what has been \nshared, with whom, and for what purpose. Enable them\u00a0to revoke consent at will, and verify that \naccess to the data is immediately restricted.\u00a0\n\u2022Minimize data copies where avoidable: In some circumstances, the ability to link to existing data \nmight not be possible. Make use of aggregated data, synthetic data, or both. Use techniques such as \nveri\ufb01able claims or con\ufb01dential computing to verify that the service can be operated with similar data \nto what is expected, while minimizing the risk of exposure or re-identi\ufb01cation of personally identi\ufb01able \ninformation (PII).\u00a0\u00a0 \n\u2022Enforcing exposure consequences: Verify that vendor contracts inherit these obligations, and use \nlegal and contractual means to prohibit the sharing, reuse, or storing of the data for any purpose other \nthan delivering the government service.\nShifting to a real time security model\nGL-SEC-02: How do you handle real time responsiveness to security (including national security) \nthreats?\n\u2022Do threat modelling and scenario planning\u00a0to assess and inform business continuity planning, \nincluding an incident response plan within your ecosystem.\n\u2022Document how security threats are detected and disrupted in real time , including the escalation \nplan and mechanisms to relevant security and intelligence agencies for that jurisdiction.\n\u2022Document the critical infrastructure considerations, as this is of particular importance for national \ncritical infrastructure.\u00a0\nNote\nThe operational excellence pillar addresses agile operating models which support this \noutcome.\nConsidering national implications\nGL-SEC-03: What national security and defense implications have you identi\ufb01ed for the system?\nConsider and document reasonable implications to national security and defense: With a focus on \nprotecting sensitive government and citizen data and service continuity at all times, be able to detect \nand act upon threats in real time, including at a national and regional level. This should address the \nlikely impact of the service or data and potential impacts of bad actors or manipulation, taking into \nconsideration:\n\u2022Whether the service is considered critical infrastructure\n\u2022Countering outside interference, such as from other governments and entities\n27", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "812766a6-45d3-4d20-bd04-ad94a48d0d33": {"__data__": {"id_": "812766a6-45d3-4d20-bd04-ad94a48d0d33", "embedding": null, "metadata": {"page_label": "28", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5ea2b7d110e0b0ef45b3cba3a79cf0c47ab66eb6b6e1c480367ef18ab05ecccf", "text": "Government Lens AWS Well-Architected Framework\nResources\n\u2022Maintaining disaster preparedness (see the operational excellence pillar)\n\u2022Sovereign resilience\u2014the ability for the government to adapt to change and threat\nResources\n\u2022Security, Identity, and Compliance on AWS\n\u2022AWS Risk and Compliance whitepaper\n\u2022AWS Clean Rooms\n\u2022Why AWS Data Exchange?\nReliability pillar\nThe reliability pillar encompasses the ability of a service to perform its intended function correctly and \nconsistently when it\u2019s expected to. This includes the ability to operate and test the service through its \ntotal lifecycle\u00a0and includes a high level of planning around service continuity and perceived reliability by \nthe public.\nThe following questions and best practices are designed to complement the best practices in the\nReliability Pillar whitepaper.\nGL-REL-01: How do you test the service and demonstrate resilience?\nEstablish and document test-driven design and implementation:\u00a0Establish system and process \ntest environments, including scaled functional testing, user testing with the public, war gaming for \nprocedural and scenario testing, and regulatory sandboxes for policy testing.\nGL-REL-02: How do you plan for service continuity?\nContinuity of service is one of the highest priorities for government services. Many government services \nare not optional for people. These services are relied upon when we are at our most vulnerable. Business \ncontinuity is especially important to verify that end users are not put at risk from a lack of access to \ncritical government services and systems.\n\u2022Assess the impact of downtime and service deadlines: Test and document the assumptions about \nthe likely impacts of service downtime, especially on vulnerable people and communities, and around \nanticipated deadlines such as elections, and waiting times at medical care facilities. Capture these \nassumptions in user journey maps.\n\u2022Plan fail-overs and alternative service pathways: Verify that the service has appropriate fail-over \nstrategies proportionate to the risk, and identify alternative pathways to the service, including o\ufb04ine \nand phone-based user journeys. Verify that alternative service pathways are quickly discoverable by \nend users, even if the digital services are down. Have a\u00a0stakeholder list, FAQs, and a communications \nplan prepared.\u00a0\u00a0 \nResources\n\u2022\u00a0Protect critical services with new Continuity of Government IT on AWS solution guide\n28", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "dfa9253f-bed4-4ddc-a803-aec564ff8dad": {"__data__": {"id_": "dfa9253f-bed4-4ddc-a803-aec564ff8dad", "embedding": null, "metadata": {"page_label": "29", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e12697b36cb07e220caf0ebc1dec19c5e28507b31dbce33e4be00f5623d1b770", "text": "Government Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar\n\u2022\u00a0Leverage the latest cloud technologies to build a resilient organization\n\u2022\u00a0Modernizing government for the new normal: Advice for building resilience\nPerformance e\ufb03ciency pillar\nThe performance e\ufb03ciency pillar includes the ability to e\ufb03ciently adhere to policy and mandate \nrequirements, and to maintain that e\ufb03ciency as demand or policy changes and technologies evolve.\nThe following questions and best practices are designed to complement the best practices in the\nPerformance E\ufb03ciency Pillar whitepaper.\u00a0\nGL-PERF-01: How do you report outcomes performance of this solution?\n\u2022Document the public and governmental reporting mechanisms: Government services are expected \nto be reliable. Demonstrate how the public would have visibility to the reliability of the service through \npublic dashboards, reporting, performance metrics, or annual reports. In some jurisdictions, this public \nreporting might include program reviews, where funds to deliver the service were allocated in the \nbudget process.\u00a0\n\u2022Document the measurement and monitoring approach:  Service and product owners must verify \nthat government services are measuring and monitoring in a way that aligns with an agency\u2019s key \nperformance indicators (KPIs), as well as to monitor for service performance and user satisfaction.\u00a0\n\u2022Document the e\ufb00ort for compliance and audit: Identity opportunities to keep repeatability to a \nminimum, and opportunities to automate and streamline e\ufb03ciencies.\nGL-PERF-03: How do you manage continuous change and improvements?\nDocument the process, cost, and resourcing for change using a range of likely change scenarios. These \nscenarios include changes to load (for example, major expected changes, unexpected public usage, or \nmalicious events) and changes to service ranging from simple changes (such as updating content and \nminor feature changes), to new functionality and major changes. This can help to identify and manage \nperformance e\ufb03ciency as demand changes and technologies evolve, and can help identify structural or \noperational challenges for change agility.\nResources\n\u2022\u00a0New Performance Dashboard on AWS makes delivering open, responsive government simple\n\u2022\u00a0Four steps to build a data strategy for managing performance in the public sector\n\u2022\u00a0Raising the bar on accessibility for open-source public sector solutions\nCost optimization pillar\nThe cost optimization pillar includes the ability to run\u00a0services which deliver policy intent and user \noutcome\u00a0at the best value.\u00a0\nThe following question and best practices are designed to complement the best practices in the Cost \nOptimization Pillar whitepaper .\n29", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "fda2ce6f-0d7b-4009-b497-99e86f975da3": {"__data__": {"id_": "fda2ce6f-0d7b-4009-b497-99e86f975da3", "embedding": null, "metadata": {"page_label": "30", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "76b6329e170a988ea079505266c30e032e993eaa72ccea686e0e118fdf71d7a9", "text": "Government Lens AWS Well-Architected Framework\nResources\nGL-COST-01: How do you demonstrate an understanding of \u201cvalue for money\u201d in the customer\u2019s \ncontext?\nMost government entities have clear rules around how they assess \u201cvalue for money\u201d, but this can be \nsubtly di\ufb00erent across jurisdictions. For some countries, value for money is considered whatever is the \nbest functionality for the cost to deliver the desired policy outcome. Other countries take into account \nthe best balance of social, public, and environmental bene\ufb01ts along with cost.\nThese procurement rules translate to how cost optimization is perceived, with broader analysis of \nthe public value or policy realization sometimes considered as pure cost e\ufb03ciencies. For this reason, \nrunning services at the lowest price point to deliver policy outcomes may or may not be considered cost \noptimization for the government department, although it's still a generally useful goal.\nBelow is a list of considerations and good practices to explore with the customer and to document to \nmake sure that \"value for money\" is achieved in a government context.\n\u2022Document the de\ufb01nition of \u201cvalue for money\u201d for the jurisdictional and portfolio context, and how \nthis service meets that de\ufb01nition.\n\u2022De\ufb01ne how the cost and value is reported to oversight and governance bodies (for example, \nparliament,\u00a0and public scrutiny).\n\u2022Build in-house capability\u00a0manage costs through training and equipping teams.\n\u2022Avoid silos of delivery that create higher cost of change. Support cross-governmental networks to \ndeliver services that reuse environments, panels, and solutions where possible.\u00a0\n\u2022Optimize for speed of change.\u00a0 It\u2019s sometimes necessary to optimize for speed to respond to a citizen \nneed or department mandate rapidly. Government solutions might need to initially overcompensate \non capacity to maintain service reliability during peak popularity, for example, at the time of a press \nrelease, to avoid breaking citizen trust. Fortunately, this necessary choice is temporary and works well \nwith cloud economics. Services can cost optimize and consider automatic scaling after release events, \nwhen utilization and popularity normalizes.\n\u2022Optimize for budget planning processes in the jurisdiction to take into account funding cycles and \nmaintain continuity of service.\u00a0 Often, there is low \ufb02exibility in these cycles, however, government \ncustomers can be supported to build more \ufb02exibility into the program, project, or product-based \nfunding mechanisms.\nResources\n\u2022\u00a0How cloud can help agencies enhance security, save costs, and improve mission delivery through the \nTechnology Modernization Fund (TMF)\n\u2022\u00a0For Small Governments \u2013 The Cloud is Only as Big as You Want it to Be\n\u2022\u00a0Optimizing nonpro\ufb01ts\u2019 costs in the cloud\nSustainability pillar\nThe sustainability pillar focuses on environmental impacts from government systems, services, and \npolicies, especially energy consumption and e\ufb03ciency. The government typically has the largest \ninformation and communications technology (ICT) expenditure in a jurisdiction, so environmentally \nsustainable practices in government is key to driving a national sustainability agenda.\nThe following questions and best practices are designed to complement the best practices in the\nSustainability Pillar whitepaper.\n30", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3ec3ae7a-ffac-4c87-8c04-caa72a303f67": {"__data__": {"id_": "3ec3ae7a-ffac-4c87-8c04-caa72a303f67", "embedding": null, "metadata": {"page_label": "31", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "82a675767b1bb89c11691b0ab9cd2f4897ea9ccdc8257d9e32df65980e2fb51d", "text": "Government Lens AWS Well-Architected Framework\nClimate action and technology\nClimate action and technology\nMany governments around the world have made commitments to introduce measures to reduce their \nimpact on the climate, and have become signatories to the Paris Agreement committing to introduce \nspeci\ufb01c emission reductions by 2050. The sustainability pillar supports this action by exploring how \na government might reduce the environmental impact of its own services.\u00a0Many jurisdictions have \nintroduced sustainable procurement rules that provide broad guidance of the considerations an entity \nshould undertake when considering the procurement of a new product or service.\nExploring the digitization of other government functions will contribute to how a government might \nreduce the climate impacts of its operations. The government will need to review existing digitized \nservices and identifying opportunities for optimization, while also exploring how digital technologies \nmight be deployed to accelerate sustainability outcomes.\u00a0\nSustainable digital services are designed, developed, and operated in a way that minimizes their impact \non the environment while still meeting business goals and user needs. These services are designed to \nsupport sustainability goals by reducing energy consumption, reducing carbon emissions, minimizing \nwaste, and promoting resource e\ufb03ciency. In some jurisdictions, there are speci\ufb01c targets to meet.\nGL-SUS-01: What are the sustainability policies for the jurisdiction your service operates within?\n\u2022Identify relevant sustainability metrics, reporting, targets, and policies that not only reduce resource \nusage for the government\u00a0customer, but also across the sector and nationally.\n\u2022Leverage and enable reusable environments, patterns, and marketplaces as a way to minimize \nduplication of computing power.\n\u2022Use cross-agency, cross-jurisdiction, and cross-sector collaboration to identify\u00a0and learn from \nexamples of similar problems in other areas.\n\u2022Explore data and tools. New models for democratization of data, APIs, and tools can be leveraged by \nthe broader economy and community to spur the scaling of digital government applications.\n\u2022Support the customer to create the\u00a0best governance arrangement for the system\u2014from hierarchies, to \nindustries, to networks, to communities.\n\u2022Identify any sustainable procurement guidelines or policies that a jurisdiction might have to adopt, \nsuch as the Green Public Procurement in the EU.\u00a0\nGL-SUS-02: What design choices have been made in the service de\ufb01nition that is inclusive of \nsustainability policy outcomes and reporting requirements?\n\u2022Verify that national\u00a0sustainability goals and reporting are built in from the beginning, or have a funded \nplan to have them created over time.\n\u2022Take a more holistic view using modes, such as life events or user journeys, to produce an improved \ncustomer experience as well as better sustainability outcomes by reducing duplication and \nconsolidating services.\u00a0 \u00a0 \n\u2022Design services so that they can be completed end to end digitally by reducing the need for printing \ndocuments, such as eliminating the need for physical signatures or documents.\u00a0\u00a0\u00a0 \nGL-SUS-03: How might this solution be built to be extendable to other opportunities in the future?\n31", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "68b365e1-80a1-4472-8d72-98af9ddd4896": {"__data__": {"id_": "68b365e1-80a1-4472-8d72-98af9ddd4896", "embedding": null, "metadata": {"page_label": "32", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "033e25f7bbdb00c9ce900e69c0e4aac774191deb0b83e5eb1f42950c33ecd3d8", "text": "Government Lens AWS Well-Architected Framework\nResources\n\u2022Explore the opportunity to deploy digital technologies by rethinking existing\u00a0processes that \nmight improve operational e\ufb03ciencies, for example, using smart technologies to manage built \nenvironments.\u00a0\n\u2022Leverage new technologies, such as IoT, digital twins, and AI analysis and modelling to support more \nsustainable systems, decision making, and services.\nResources\n\u2022General guidance on implementation can be found in the Well-Architected\u00a0Sustainability Pillar \nwhitepaper .\n\u2022AWS Customer Carbon Footprint Tool\n32", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9b0fceb8-0bc8-41c2-aed1-f97a08ef3f3a": {"__data__": {"id_": "9b0fceb8-0bc8-41c2-aed1-f97a08ef3f3a", "embedding": null, "metadata": {"page_label": "33", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "9820f8c9970849d58272121ebc13df8bb85271b2dd6dec7acb0db569aa10f0ca", "text": "Government Lens AWS Well-Architected Framework\nEnabling services outcomes for \ngovernment\nAn additional and necessary set of considerations for government services covers best practices to \nverify that services measurably meet the intended policy or service outcomes, whether for public facing \nservices (online or o\ufb04ine), grants management, budgeting, law enforcement or any other function of \ngovernment. Service e\ufb00ectiveness is a responsibility of the government, but understanding the intended \npurpose and context of a service helps all parties involved to develop e\ufb00ective services with, or for, \ngovernment customers. As such, this chapter should be considered for government services to maintain \nappropriate outcomes.\nIdentify the policy or purpose of this service with measurable success criteria\nMost systems and services traditionally only measure operational performance (such as uptime, and \nthe number of concurrent users) and e\ufb03ciency (such as cost per transaction, staying within budget, and \nrevenue). In the case of government systems and services, it\u2019s increasingly important to understand \nhow\u00a0e\ufb00ective  a system is regardless of its performance or\u00a0e\ufb03ciency. Service e\ufb00ectiveness measurement \ncould include both the policy and purpose measures, and the ongoing human impact measures.\u00a0\n\u2022Policy outcomes: Every service is meant to deliver on some form of policy outcome. The purpose \nor intention of a system or service might be found in government policy, legislation, regulation, the \nmission or mandate of a department or ministry, or perhaps even in the constitutional foundations \nof that government. Whatever the intended policy outcome, relevant metrics and indicators should \nbe identi\ufb01ed which the system or service needs to measure and monitor in order to demonstrate the \npolicy e\ufb00ectiveness of the system or service.\n\u2022Human outcomes and impact: Because government services can a\ufb00ect a large percentage of the \npopulation, and because these services are often either unavoidable or required, it\u2019s important to \nidentify some baseline quality of life measurements to measure and monitor for unintended impacts \non people and communities. For example, monitoring known quality of life measures, such as health \nindicators, employment, homelessness, and household debt, and constantly seeking unknown patterns \nof impacts of speci\ufb01c cohorts. This helps grow and maintain public trust and con\ufb01dence in government \nsystems and services, and also helps verify that any unintended harm from a system or service is able \nto be quickly identi\ufb01ed and mitigated.\n\u2022Establish mechanisms to measure, monitor, and escalate trends or patterns of policy or human \nimpacts: Verify that your service measurement infrastructure includes policy and human outcomes \nmeasurement and monitoring, with deviations or divergent trends being escalated in the same way \nthat security or performance issues are escalated, and enable real-time response to change and \nunintended impacts. Policy impacts might include the target measures and metrics of the relevant \npolicy. Intended human impacts might include quality of life measures like positive housing, health, or \nwell-being outcomes for that person and their family as a result of the service.\nIdentify and test multiple ways to meet the desired outcome\n\u2022Produce a discovery report with concept testing outcomes: Verify that each service includes a\ndiscovery phase to describe the problem or opportunity space, and explore and test with end users a \n33", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8767b2d6-be0a-4a23-800f-265bbf9a5f3c": {"__data__": {"id_": "8767b2d6-be0a-4a23-800f-265bbf9a5f3c", "embedding": null, "metadata": {"page_label": "34", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "bc2d2ab997edff55d8964a04710d354920aa2aa69387d30b5150ed03724715e3", "text": "Government Lens AWS Well-Architected Framework\nvariety of concepts before heading into prototyping or solution design and architecture. Document the \nconcepts, the results of user testing, and the resulting preferred solutions with rationale.\nIdentify the user needs and measures for success\n\u2022Document the user needs and measures for success:\u00a0 Government services that a person or business \ninteract with should also measure the user outcomes and satisfaction of the service.\u00a0\n\u2022User outcomes: Identify what done  is for a user, and measure it to verify that the service is \ndelivering as expected outcomes for users. For example, a service might intend to support people to \nlive at home longer, reducing the pressure on aged care services. Or a service might be intended to \nalleviate the costs of living.\u00a0\n\u2022User satisfaction: A combination of measures should be used to monitor and measure the end-\nuser experience of the service, whether that user is a citizen, resident, refugee, a business, or even \nan internal team. Customer experience (CX) measures expectations using polling and other tools to \nverify that the user experience of the system or service is good. Government services are di\ufb00erent \nfrom those in the private sector as the end user might not have a choice and must interact with the \nservice (for example, tax, social support, and emergency services). User satisfaction isn\u2019t just about \nCX, it\u2019s also about whether the service meets the public expectations for that government system or \nservice.\n\u2022Document how the service has been designed inclusively: Demonstrate and document how the \nservice was designed and tested with a diverse variety of users that represent the needs of the \npopulation, and that there are multiple channels supported that take into account di\ufb00erent access \nrequirements.\n\u2022Document how the public have been engaged:\u00a0Ideally, the government customer would be engaging \nwith the general public on the reporting, design, delivery, and operational transparency of the service \nto grow and maintain public trust, con\ufb01dence, and perceived legitimacy of the system or service, and \nAWS can encourage and support this approach. Engagement with the public is also useful to design \nand test a range of public feedback mechanisms to verify that the continuous improvement of the \nservice over time aligns with changing public needs. Citizen participation is increasingly expected \nthrough novel forms of public engagement and participation in the design, delivery, and governance \nof policies and services.\n\u2022Identify and document the cultural context: Every government organization serves the public, so \nunderstanding the cultural context of the service is important to inform the architecture, design, \nneeds, and what it would take for the service to be considered welcoming and digni\ufb01ed. As part of this, \nit\u2019s helpful to consider both the demographic range of cultural needs, as well as the Indigenous and \nFirst Nations cultural context and needs, which will be di\ufb00erent in every country.\nIdentify the special requirements of the government customer for this service\n\u2022Document and understand the portfolio and jurisdictional policy context of the government \ncustomer: All systems administered by public institutions need to be compliant with and supportive of \nthe jurisdictional context (the constitutional and whole of government framework of that government) \nand of the portfolio context (the speci\ufb01c legislative or regulatory responsibilities of that department). \nBuilding in or documenting this context should be done in early stages to inform and in\ufb02uence design, \narchitecture, and delivery.\u00a0 Understanding these can help you to hone in on the special obligations, \nresponsibilities, and mission of your government customer, and to engage in conversations about what\nsuccess  looks like, so you can demonstrably and measurably design and deliver in accordance with \nthe jurisdictional and portfolio context of your customer. A portfolio mandate might include things \nsuch as the Social Security Act. A jurisdictional mandate might include the Constitution, or legislation \n34", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "dbe92b06-a541-41a7-8577-56b76deec4c2": {"__data__": {"id_": "dbe92b06-a541-41a7-8577-56b76deec4c2", "embedding": null, "metadata": {"page_label": "35", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "9f55ad40751f4e4f1633be764d934bac55f4a8fcd3939ac13a87f42a43752e74", "text": "Government Lens AWS Well-Architected Framework\nthat applies to the whole jurisdiction of a government customer, at a federal, state, or local level, like \nthe Privacy Act. This might also include policy requirements like whether the service must consider \nopen source options \ufb01rst (a requirement in the UK Government), or whether there are architectural \nstandards or Indigenous engagement or procurement requirements (a requirement in the New Zealand \nGovernment).\u00a0\n\u2022Document how the service will meet public transparency and appeal-ability requirements: How \nwill your service provide ease of citizens\u2019 and Parliamentary access to information on service delivery, \nperformance, reporting, explanations, and ease of avenues to appeal? Most governments have \ntransparency requirements, such as publishing certain types of data, public reporting of metrics, and \nannual reports, so identifying the transparency and open government requirements for the customer \nis also important.\n\u2022Align with compliance to the jurisdictional equivalent of Administrative Law: In all governments, \nthere are rules that govern how the public sector has to operate. For example, in Westminster-based \ngovernments, all systems and processes need to comply with the principles of Administrative Law and\nRule of Law, which requires among other things, that decision making is explainable, accountable, \nappealable, consistent with the law, and consistently applied.\nAlternatively, if you can't explain a decision, you should at least be able to validate that it\u2019s legally \ncompliant. High-integrity records keeping is also critical. A service can be beautifully designed, \narchitected, delivered, and operating perfectly, but if it isn\u2019t demonstrably lawful or considered \nlegitimate in the context of government, then it creates signi\ufb01cant issues for the government \norganization and for the public, resulting in public distrust. Ideally, a modern government service \nshould be\u00a0 auditable in real time , and have governance  that assures oversight and escalation of issues as \nthey emerge.\n35", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d26f97ed-ad92-4474-b9c3-7e9de017d41a": {"__data__": {"id_": "d26f97ed-ad92-4474-b9c3-7e9de017d41a", "embedding": null, "metadata": {"page_label": "36", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "df60a0cc2c3ad79aa7e6b736e48469074fb4d9a6f2ab209e565dcdbd57f53087", "text": "Government Lens AWS Well-Architected Framework\nConclusion\nThe goal of the Government Lens for the Well-Architected Framework is to provide architectural and \noperational best practices for designing and operating reliable, secure, e\ufb03cient, e\ufb00ective, sustainable, \nand compliant government services on AWS. The considerations for the traditional Well-Architected \npillars, combined with an additional section on enabling service outcomes for government,\u00a0provides a \nwell-rounded framework for verifying that government services built on AWS are best able to meet the \nspecial needs, context, and purpose of government customers. This approach is repeatable, extendable, \nand able to support meaningful discussions with government customers about the mission, purpose, and \nintended outcomes of their systems and services.\nArchitectures for government workloads need to incorporate policy considerations along with high \nprivacy, security, and evidence-based compliance design patterns, e\ufb00ective measurement and feedback \nloops for continuous improvement, and strong governance to help maintain compliant, legitimate \nservices and systems that can withstand the necessary accountability and scrutiny of government. \nGovernment customers need to continually monitor, measure, and detect changes or unintended \nimpacts to meet their policy and legislative requirements.\nBusiness continuity is critical not only to achieve business resiliency and performance objectives, but \nalso to verify that people and communities are supported in times of high stress or emergencies. This \nlens was designed to support AWS builders and architects to take government needs and context into \naccount in the design, delivery, and operation of government systems and services.\u00a0\u00a0 \n36", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e3cee8ab-c185-4092-a5fb-9f719b5cb2d7": {"__data__": {"id_": "e3cee8ab-c185-4092-a5fb-9f719b5cb2d7", "embedding": null, "metadata": {"page_label": "37", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f2f452003dc2f95d16a7a9b9942ecf86a13d5c9dcc5fcdd9b439e415d3a91d48", "text": "Government Lens AWS Well-Architected Framework\nContributors\nContributors to this document include:\u00a0\n\u2022Pia Andrews, Strategic Advisor (Public Sector), Strategic Development, APAC\n\u2022Jithma\u00a0 Beneragama, Strategic Advisor (Public Sector), Strategic Development, APAC\u00a0 AWS\n\u2022Bruce Haefele, Head of Strategic Development, APAC\n\u2022Pete Herlihy, Senior Tech Product Manager, GTT, AWS WWPS\n\u2022Andrew Hodges, Senior Security Advisor, WWPS APJ\n\u2022Peter James, Principal Solutions Architect, AWS WWPS Geo APAC SA\n\u2022Jess Modini, Advisory Solutions Architect, AWS WWPS Geo APAC SA\n\u2022Ash Wallace,\u00a0Senior Solutions Architect, APAC\n\u2022Emma Whitty, Senior Customer Solutions Manager, AWS WWPS\n\u2022Bruce Ross, Global Lens Lead for the Well-Architected Framework\n37", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "457d42a9-59ef-42d9-8b35-5a58df3e85d9": {"__data__": {"id_": "457d42a9-59ef-42d9-8b35-5a58df3e85d9", "embedding": null, "metadata": {"page_label": "38", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "584d1b4905534452dfd51ce4800fd89bba1230d976e2ad7454050095a0afbf9b", "text": "Government Lens AWS Well-Architected Framework\nDocument history\nTo be noti\ufb01ed about updates to this whitepaper, subscribe to the RSS feed.\nChange Description Date\nMinor update  (p. 38) Corrected broken link. August 29, 2023\nInitial publication  (p. 38) Government Lens \ufb01rst published.August 18, 2023\nNote\nTo subscribe to RSS updates, you must have an RSS plug-in enabled for the browser that you are \nusing.\n38", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8b7e2e61-199a-497a-bf99-02119a3abdf5": {"__data__": {"id_": "8b7e2e61-199a-497a-bf99-02119a3abdf5", "embedding": null, "metadata": {"page_label": "39", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "ec9ac762dadf4956c12283ee06d03939cc51a0540d86964c2381d1a2c904ec6d", "text": "Government Lens AWS Well-Architected Framework\nNotices\nCustomers are responsible for making their own independent assessment of the information in this \ndocument. This document: (a) is for informational purposes only, (b) represents current AWS product \no\ufb00erings and practices, which are subject to change without notice, and (c) does not create any \ncommitments or assurances from AWS and its a\ufb03liates, suppliers or licensors. AWS products or services \nare provided \u201cas is\u201d without warranties, representations, or conditions of any kind, whether express or \nimplied. The responsibilities and liabilities of AWS to its customers are controlled by AWS agreements, \nand this document is not part of, nor does it modify, any agreement between AWS and its customers.\n\u00a9 2023 Amazon Web Services, Inc. or its a\ufb03liates. All rights reserved.\n39", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8b9d7a58-c4db-42e9-99fe-a2eb40df8844": {"__data__": {"id_": "8b9d7a58-c4db-42e9-99fe-a2eb40df8844", "embedding": null, "metadata": {"page_label": "40", "file_name": "government-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3318cf1210fa5f7684de87616a879be9c63b5cb8a59450039bf0dea18320c345", "text": "Government Lens AWS Well-Architected Framework\nAWS glossary\nFor the latest AWS terminology, see the AWS glossary in the AWS Glossary Reference.\n40", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a20be1d1-4818-4dfe-ae67-d94bd94f4c73": {"__data__": {"id_": "a20be1d1-4818-4dfe-ae67-d94bd94f4c73", "embedding": null, "metadata": {"page_label": "i", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "95e9bf14ed75e5e178c6f8fbc96835a16c3060ab447b386f4684fda1e0a9a3ee", "text": "IoT Lens\nAWS Well-Architected Framework", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "cd0d76de-e528-442f-87ef-29d1dab122b1": {"__data__": {"id_": "cd0d76de-e528-442f-87ef-29d1dab122b1", "embedding": null, "metadata": {"page_label": "ii", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3063780501c76d6038167f3f5d71a1dd8b28b01a66ed763cabb8ee1182a56a31", "text": "IoT Lens AWS Well-Architected Framework\nIoT Lens: AWS Well-Architected Framework\nCopyright \u00a9 2023 Amazon Web Services, Inc. and/or its a\ufb03liates. All rights reserved.\nAmazon's trademarks and trade dress may not be used in connection with any product or service that is not \nAmazon's, in any manner that is likely to cause confusion among customers, or in any manner that disparages or \ndiscredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may \nor may not be a\ufb03liated with, connected to, or sponsored by Amazon.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "34917ff7-256a-4baf-a212-b45eb3d01c07": {"__data__": {"id_": "34917ff7-256a-4baf-a212-b45eb3d01c07", "embedding": null, "metadata": {"page_label": "iii", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b15f569c81889674755b4bcc8db2c094d40f9581697ff14d9e49f759256e73cf", "text": "IoT Lens AWS Well-Architected Framework\nTable of Contents\nAbstract and introduction...................................................................................................................1\nIntroduction..............................................................................................................................1\nDe\ufb01nitions .........................................................................................................................................2\nDesign and manufacturing layer..................................................................................................2\nEdge layer.................................................................................................................................2\nFleet provisioning layer...............................................................................................................4\nCommunication layer..................................................................................................................4\nIngestion layer...........................................................................................................................5\nAnalytics layer...........................................................................................................................6\nStorage services.................................................................................................................6\nAnalytics and machine learning services................................................................................6\nApplication layer........................................................................................................................7\nManagement applications ...................................................................................................7\nUser applications ................................................................................................................7\nDatabase services...............................................................................................................8\nCompute services...............................................................................................................8\nGeneral design principles ....................................................................................................................9\nScenarios.........................................................................................................................................11\nDevice provisioning...................................................................................................................11\nDevice telemetry......................................................................................................................13\nDevice commands.....................................................................................................................14\nAWS IoT Device Shadow service.........................................................................................15\nAWS IoT Jobs for device commands....................................................................................16\nFirmware updates.............................................................................................................16\nThe pillars of the Well-Architected Framework.....................................................................................18\nOperational excellence..............................................................................................................18\nDesign principles ..............................................................................................................18\nBest practices..................................................................................................................19\nKey AWS services.............................................................................................................29\nResources........................................................................................................................29\nSecurity...................................................................................................................................30\nDesign principles ..............................................................................................................30\nBest practices..................................................................................................................31\nKey AWS services.............................................................................................................49\nResources........................................................................................................................50\nReliability................................................................................................................................50\nDesign principles ..............................................................................................................51\nBest practices..................................................................................................................51\nKey AWS services.............................................................................................................62\nResources........................................................................................................................63\nPerformance e\ufb03ciency..............................................................................................................63\nDesign principles ..............................................................................................................63\nBest practices..................................................................................................................64\nKey AWS services.............................................................................................................74\nResources........................................................................................................................74\nCost optimization .....................................................................................................................75\nDesign principles ..............................................................................................................75\nBest practices..................................................................................................................75\nKey AWS services.............................................................................................................83\nResources........................................................................................................................83\nSustainability...........................................................................................................................83\nConclusion .......................................................................................................................................84\nContributors ....................................................................................................................................85\nDocument revisions..........................................................................................................................86\niii", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "489dc0a1-7c0f-48bc-b46a-205f9c4516b4": {"__data__": {"id_": "489dc0a1-7c0f-48bc-b46a-205f9c4516b4", "embedding": null, "metadata": {"page_label": "iv", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c8834a8ce2385bbaddbad52e1398af97ccac6272fa6830fbcad18554362f16ad", "text": "IoT Lens AWS Well-Architected Framework\nAWS glossary...................................................................................................................................87\nNotices............................................................................................................................................88\niv", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b31f59b9-5b0a-4462-bdc8-38789cca3443": {"__data__": {"id_": "b31f59b9-5b0a-4462-bdc8-38789cca3443", "embedding": null, "metadata": {"page_label": "1", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a07edc4be7ef72bbdd7e46d7a833d95a512ab9c81cc154087f742945f2d9d93f", "text": "IoT Lens AWS Well-Architected Framework\nIntroduction\nIoT Lens\nPublication date: March 31, 2023  (Document revisions  (p. 86))\nThis whitepaper describes the AWS IoT Lens for the AWS Well-Architected Framework, which enables \ncustomers to review and improve their cloud-based architectures and better understand the business \nimpact of their design decisions. The document describes general design principles, as well as speci\ufb01c \nbest practices and guidance for the pillars of the Well-Architected Framework\nIntroduction\nThe AWS Well-Architected Framework helps you understand the pros and cons of the decisions you make \nwhen building systems on AWS. Using the Framework allows you to learn architectural best practices \nfor designing and operating reliable, secure, e\ufb03cient, and cost-e\ufb00ective systems in the cloud. The \nFramework provides a way for you to consistently measure your architectures against best practices and \nidentify areas for improvement. We believe that having well-architected systems greatly increases the \nlikelihood of business success.\nIn this \u201cLens\u201d we focus on how to design, deploy, and architect your IoT (Internet of Things) workloads \nat the edge and in the AWS Cloud. The guidance provided includes both IoT and industrial IoT (IIoT) \nworkloads and the document calls out speci\ufb01c guidance for segments such as consumer, commercial \nand industrial when relevant. To implement a well-architected IoT application, you must follow well-\narchitected principles, starting from the procurement of connected physical assets (things), operating the \nasset to the eventual decommissioning of those same assets in a secure, reliable, scalable, sustainable \nand automated fashion. In addition to AWS Cloud best practices, this document also articulates the \nimpact, considerations, and recommendations for connecting physical assets to the internet.\nThis document only covers IoT speci\ufb01c workload details from the Well-Architected Framework. We \nrecommend that you read the AWS Well-Architected Framework whitepaper and consider the best \npractices and questions for other lenses.\nThis document is intended for those in technology roles, such as chief technology o\ufb03cers (CTOs), \narchitects, developers, embedded engineers, security and operations team members. After reading this \ndocument, you will understand AWS best practices and strategies for IoT and IIoT applications.\n1", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9fc765de-0cdd-47dc-a129-b565c38d796f": {"__data__": {"id_": "9fc765de-0cdd-47dc-a129-b565c38d796f", "embedding": null, "metadata": {"page_label": "2", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3d3259977673045eb059a7c98af3150c3399ffd1b7f557a04eebebe37a020194", "text": "IoT Lens AWS Well-Architected Framework\nDesign and manufacturing layer\nDe\ufb01nitions\nThe AWS Well-Architected Framework is based on six pillars \u2014 operational excellence,\u00a0security, reliability, \nperformance e\ufb03ciency, cost optimization, and sustainability. When architecting technology solutions, \nyou must make informed tradeo\ufb00s between pillars based upon your business context. For IoT workloads, \nAWS provides multiple services that allow you to design robust architectures for your applications. \nInternet of Things (IoT) applications are composed of many devices (or things) that securely connect and \ninteract with complementary edge-based and cloud-based components to deliver business value. IoT \napplications gather, process, analyze, and act on data generated by connected devices. Industrial Internet \nof Things (IIoT) are systems that connect and integrates industrial control systems with enterprise \nsystems and the internet, business processes and analytics and is a key enabler for Smart Manufacturing \nand Industry 4.0. The AWS IoT Lens can be used across all IoT use cases including industrial, consumer \n(OEM), or and any other workload that has many devices connecting at scale for telemetry and command \nand control.\nThis section presents an overview of the AWS services that are used throughout this document to \narchitect IoT workloads. There are seven distinct logical layers to consider when building an IoT \nworkload.\nLayers\n\u2022Design and manufacturing layer (p. 2)\n\u2022Edge layer (p. 2)\n\u2022Fleet provisioning layer (p. 4)\n\u2022Communication layer (p. 4)\n\u2022Ingestion layer (p. 5)\n\u2022Analytics layer (p. 6)\n\u2022Application layer (p. 7)\nDesign and manufacturing layer\nThe design and manufacturing layer consist of product conceptualization, business and technical \nrequirements gathering, prototyping, product layout and design, component sourcing, manufacturing \nand distribution. Decisions made in each layer impact the next logical layers of the IoT workload \ndescribed in the following sections. For example, some IoT device creators prefer to have a common \n\ufb01rmware image installed and tested by the contract manufacturer. The decisions made at the design and \nmanufacturing layer will partly determine what steps are required during the provisioning layer.\nYou may go a step further and provision and install an X.509 certi\ufb01cate and its private key to each device \nduring manufacturing, or include a hardware security module with credentials already pre-provisioned. \nThis decision can impact the provisioning and communications layers, since the type of credential can \nimpact the subsequent selection of network protocols. If the credential never expires it can simplify the \ncommunications and provisioning layers at the possible expense of compromised security, data loss, or \nboth.\nEdge layer\nThe edge layer of your IoT workload consists of the physical hardware of your devices, the embedded \noperating system that manages the processes on your device, and the device \ufb01rmware, which is the \n2", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "835fdb68-abf3-4132-bf29-06ee797f10f1": {"__data__": {"id_": "835fdb68-abf3-4132-bf29-06ee797f10f1", "embedding": null, "metadata": {"page_label": "3", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a6b4f4cf8a7092d5a66dcc599701ea10d0987658c13b86ae4c5af0a1fe26a34d", "text": "IoT Lens AWS Well-Architected Framework\nEdge layer\nsoftware and instructions programmed onto your IoT devices. The edge is responsible for sensing and \nacting on other peripheral devices. Common use cases are reading sensors connected to an edge device, \nor changing the state of a peripheral based on a user action, such as turning on a light when a motion \nsensor is activated.\nWhile the AWS IoT Lens is applicable to all IoT systems, industrial IoT deployments often have additional \nsafety, resiliency, and compliance requirements.\nIndustrial IoT deployments consist of a combination of plant-local Operational Technology (OT), plant-\nlocal Information Technology (IT) resources, and remote IT resources, which might be in the public cloud \nor an enterprise datacenter. The bene\ufb01t of splitting workloads between local and remote processing is \nto balance the timeliness and high bandwidth of local resources with the scale and elasticity of remote \nresources.\nThe edge deployments are heavily in\ufb02uenced by what AWS calls the three laws of distributed computing: \nthe law of physics, which constrain the latency, throughput, and availability of network connectivity; the\nlaw of economics, which determine the cost-e\ufb00ectiveness of transferring ever-increasing volumes of \ndata; and the law of the land, which regulates how data is handled and where it can be stored.\nAWS o\ufb00ers the following software and services for the edge layer:\nAWS IoT device SDKs include open-source libraries, developer guides with samples, and porting guides \nso that you can build innovative IoT products or solutions with AWS IoT on your choice of hardware \nplatforms.\nFreeRTOS is a real time operating system for microcontrollers that lets you program small, low-power, \nedge devices while leveraging memory-e\ufb03cient, secure, embedded libraries.\nAWS IoT Greengrass is an IoT edge runtime and cloud service that helps you build, deploy, and manage \nintelligent IoT device software. It provides you with pre-built components for common capabilities, \nsuch as local and cloud MQTT messaging, support for local edge processing including machine learning \n(ML) inference, logging, monitoring, integration with other AWS services, and local data aggregation, \n\ufb01ltering, and transmission to cloud targets. After development is complete, you can seamlessly deploy \nand remotely manage device software on millions of devices.\nAWS IoT SiteWise Edge runs on premises at industrial sites and makes it easy to collect, process, and \nmonitor equipment data locally before sending the data to AWS Cloud destinations. AWS IoT SiteWise \nEdge can be installed on local hardware, such as third-party industrial gateways and computers, or on \nAWS Outposts and AWS Snow Family compute devices. It uses AWS IoT Greengrass, an edge runtime that \nhelps build, deploy, and manage applications.\nAWS IoT FleetWise Edge is the edge software component for AWS IoT FleetWise. AWS IoT FleetWise \nEdge allows connected vehicles to collect data and upload it to the AWS IoT FleetWise service. AWS IoT \nFleetWise helps to transform low-level messages into human-readable values and standardize the data \nformat in the cloud for data analyses. You can also de\ufb01ne data collection schemes to control what data \nto collect in vehicles and when to transfer it to the cloud.\nAWS IoT RoboRunner \ufb02eet management system gateway (FMSG) is the edge software component \nthat manages all connections between AWS IoT RoboRunner and robot vendor systems. It provides \napplications for polling robot properties and updating them in AWS IoT RoboRunner, and for enabling \nmulti-robot \ufb02eets to interoperate through shared spaces, such as intersections and narrow corridors. \nAdditionally, FMSG includes connectors to vendor \ufb02eet management systems.\nAWS IoT ExpressLink is connectivity software that powers a range of hardware modules developed and \no\ufb00ered by AWS partners, such as Espressif, In\ufb01neon, and u-blox. Integrating these wireless modules into \nthe hardware design of your device makes it faster and easier to build IoT products that connect securely \nwith AWS services. These modules provide cloud-connectivity and implement AWS recommended \nsecurity requirements.\n3", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "45154fc6-f116-43cc-8a6d-c29586fc99b8": {"__data__": {"id_": "45154fc6-f116-43cc-8a6d-c29586fc99b8", "embedding": null, "metadata": {"page_label": "4", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "78d5751f9f9fc91eeaf5ee42448a3b22ca465610108f5b368bf2e65dbf6ea945", "text": "IoT Lens AWS Well-Architected Framework\nFleet provisioning layer\nFleet provisioning layer\nThe provisioning layer of your IoT workloads consists of mechanisms used to create device identities \nand the application work\ufb02ow that provides con\ufb01guration data to the device. In many cases, it consists \nof a public key infrastructure (PKI). The provisioning layer is also involved with ongoing maintenance \nand eventual decommissioning of devices over time. IoT applications need a robust and automated \nprovisioning layer so that devices can be added and managed by your IoT application in a frictionless \nway. When you provision IoT devices, you must install a unique cryptographic credential onto them and \nsecurely store these credentials.\nBy using X.509 certi\ufb01cates, you can implement a provisioning layer that securely creates a trusted \nidentity for your device that can be used to authenticate and authorize against your communication \nlayer. X.509 certi\ufb01cates are issued by a trusted entity called a certi\ufb01cate authority (CA). While X.509 \ncerti\ufb01cates do consume resources on constrained devices due to memory and processing requirements, \nthey are an ideal identity mechanism due to their operational scalability and widespread support by \nstandard network protocols.\nThe AWS IoT Device Registry helps you manage and operate your things. A thing is a representation of \na speci\ufb01c device or logical entity in the cloud. Things can also have custom de\ufb01ned static attributes that \nhelp you identify, categorize, and search for your assets once deployed.\nAWS Private Certi\ufb01cate Authority (AWS Private CA) helps you automate the process of managing the \nlifecycle of private certi\ufb01cates for IoT devices using APIs. Private certi\ufb01cates, such as X.509 certi\ufb01cates, \nprovide a secure way to give a device an identity that can be created during provisioning and used to \nidentify and authorize device permissions against your IoT application.\nAWS IoT just-in-time registration (JITR) enables you to programmatically register devices to be used \nwith managed IoT services such as AWS IoT Core. With just-in-time-registration, when devices are \ufb01rst \nconnected to your AWS IoT Core endpoint, you can automatically start a work\ufb02ow that can determine \nthe validity of the certi\ufb01cate identity and determine what permissions it should be granted.\nProvisioning devices that don\u2019t have certi\ufb01cates: With AWS IoT \ufb02eet provisioning, AWS IoT can \ngenerate and securely deliver device certi\ufb01cates and private keys to your devices when they connect \nto AWS IoT for the \ufb01rst time. AWS IoT provides client certi\ufb01cates that are signed by the Amazon root \ncerti\ufb01cate authority (CA). There are two ways to use \ufb02eet provisioning:\nWith provisioning by claim, devices can be manufactured with a provisioning claim certi\ufb01cate and \nunique token (which are special purpose credentials) embedded in them. If these certi\ufb01cates are \nregistered with AWS IoT, the service can exchange them for unique device certi\ufb01cates that the device can \nuse for regular operations.\nWith provisioning by trusted user, a device connects to AWS IoT for the \ufb01rst time when a trusted user, \nsuch as an end user or installation technician, uses a mobile app to con\ufb01gure the device in its deployed \nlocation.\nCommunication layer\nThe communication layer handles the connectivity, message routing among remote devices, and routing \nbetween devices and the cloud. The communication layer lets you establish how IoT messages are sent \nand received by devices, and how devices represent and store their physical state in the cloud.\nAWS IoT Core helps you build IoT applications by providing a managed message broker that supports \nthe use of the MQTT protocol to publish and subscribe IoT messages between devices.\nWith the AWS IoT Device Shadow service, you can create a data store that contains the current state of \na particular device. The Device Shadow service maintains a virtual representation of each of your devices \n4", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "851590c6-153e-416c-8bad-f8c5d26ff028": {"__data__": {"id_": "851590c6-153e-416c-8bad-f8c5d26ff028", "embedding": null, "metadata": {"page_label": "5", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e25a1a590d86dbb89a0ad7f56ee595e69612af5084b551e0eb6ba8b425e4ab0b", "text": "IoT Lens AWS Well-Architected Framework\nIngestion layer\nyou connect to AWS IoT as a distinct device shadow. Each device's shadow is uniquely identi\ufb01ed by the \nname of the corresponding thing.\nAWS IoT Core for LoRaWAN is a fully managed LoRaWAN Network Server (LNS) that enables you to \nconnect wireless devices that use the LoRaWAN protocol for low-power, long-range wide area network \nconnectivity with the AWS Cloud. This can be useful in use cases such as asset tracking, irrigation \nmanagement, logistics and transportation management and smart cities.\nWith Amazon API Gateway, your IoT applications can make HTTP requests to control your IoT devices. \nIoT applications require API interfaces for internal systems, such as dashboards for remote technicians, \nand external systems, such as a home consumer mobile application. With Amazon API Gateway, you can \ncreate common API interfaces without provisioning and managing the underlying infrastructure.\nIngestion layer\nA key business driver for IoT is the ability to aggregate all the disparate data streams created by your \ndevices and transmit the data to your IoT application in a secure and reliable manner. The ingestion \nlayer plays a key role in collecting device data while decoupling the \ufb02ow of data with the communication \nbetween devices.\nWith AWS IoT rules engine, you can build IoT applications such that your devices can interact with AWS \nservices. AWS IoT rules are analyzed and actions are performed based on the topic a message is received \non.\u00a0\nBasic Ingest , can securely send device data to the AWS services supported by AWS IoT rule actions, \nwithout incurring messaging costs. Basic Ingest optimizes data \ufb02ow by removing the publish/subscribe \nmessage broker from the ingestion path, making it more cost e\ufb00ective.\nUsing AWS IoT Greengrass, data can be ingested in S3 buckets, Kinesis Data Firehose, AWS IoT SiteWise, \nAWS IoT Analytics, and with custom code to other AWS services.\nAWS IoT SiteWise is a managed service that simpli\ufb01es collecting, organizing, and analyzing industrial \nequipment data at scale to help you make better, data-driven decisions. You can use AWS IoT SiteWise to \nmonitor operations across facilities, quickly compute common industrial performance metrics, and create \napplications that analyze industrial equipment data.\nAWS IoT FleetWise is a managed service that makes it easy to collect, organize, and transfer vehicle data \nto the cloud so you can gain insights about your \ufb02eets of vehicles. After the data is ingested into AWS, \nit can be enriched, making it easier for data analytics. You can use data transferred to build applications \nthat quickly detect \ufb02eet-wide quality issues, remotely diagnose individual vehicle problems in near real-\ntime, and improve autonomous driving systems.\nAWS IoT RoboRunner is a service that provides infrastructure for robotics optimization from a single \nsystem view. With AWS IoT RoboRunner, you can build applications that help robots work seamlessly \ntogether. This service is designed for industrial customers who buy, deploy, and manage robotic and \nautomated industrial equipment, including automated guided vehicles (AGVs) and autonomous mobile \nrobots (AMRs). AWS IoT RoboRunner provides central and managed data repositories for storing and \nusing data from di\ufb00erent robot vendor systems and enterprise management systems. After robots \nand enterprise management systems are connected to AWS IoT RoboRunner, you can use the sample \nimplementations to create custom applications on top of the centralized data repositories, such as \nvisualization of the robot location and status on a single map view.\nAmazon Kinesis and Amazon Simple Queue Service (Amazon SQS) can be used in your IoT application \nto decouple the communication layer from your application layer. Amazon Kinesis is a managed service \nfor streaming data, enabling you to get timely insights and react quickly to new information from IoT \ndevices. Amazon Kinesis integrates directly with the AWS IoT rules engine, creating a seamless way of \nbridging from a lightweight device protocol of a device using MQTT with your internal IoT applications \n5", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "74366646-fecd-4f17-a0f7-66d10e37b486": {"__data__": {"id_": "74366646-fecd-4f17-a0f7-66d10e37b486", "embedding": null, "metadata": {"page_label": "6", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8d6d2af784092af4284d32ba19c0d8b5368f42fe332899dffa10a8ac640a9e86", "text": "IoT Lens AWS Well-Architected Framework\nAnalytics layer\nthat use other protocols. Amazon SQS enables an event-driven, scalable ingestion queue when your \napplication needs to process IoT applications once where message order is not required.\nAnalytics layer\nOne of the bene\ufb01ts of implementing IoT solutions is the ability to gain deep insights from data about \nwhat's happening in the local/edge environment. A primary way of realizing contextual insights is by \nimplementing solutions that can process and perform analytics on IoT data.\nStorage services\nIoT workloads are often designed to generate large quantities of data. Ensure that this discrete data is \ntransmitted, processed, and consumed securely, while being stored durably.\nAmazon S3 is\u00a0object-based storage engineered to store and retrieve any amount of data from anywhere \non the internet. With Amazon S3, you can build IoT applications that store large amounts of data for \na variety of purposes: regulatory, business evolution, metrics, longitudinal studies, analytics, security, \nmachine learning, and organizational enablement. Amazon S3 gives you a broad range of \ufb02exibility in \nthe way you manage data for cost optimization, latency, access control and compliance.\nAnalytics and machine learning services\nAfter your IoT data reaches a central storage location, you can begin to unlock the full value of IoT \nby implementing analytics and machine learning on device behavior. With analytics systems, you can \nbegin to operationalize improvements in your device \ufb01rmware, as well as your edge and cloud logic, by \nmaking data-driven decisions based on your analysis. With analytics and machine learning, IoT systems \ncan implement proactive strategies like predictive maintenance or anomaly detection to improve the \ne\ufb03ciencies of the system.\nAWS IoT Analytics makes it easy to run sophisticated analytics on large volumes of IoT data. AWS IoT \nAnalytics manages the underlying IoT data store, while you build di\ufb00erent materialized views of your \ndata using your own analytical queries or Jupyter notebooks.\nAWS IoT Events is a managed service that makes it easy to detect and respond to events from IoT \nsensors and applications. Events are patterns of data identifying more complicated circumstances than \nexpected.\nAWS IoT SiteWise is a managed service that simpli\ufb01es collecting, organizing, and analyzing industrial \nequipment data at scale to help you make better, data-driven decisions. You can use AWS IoT SiteWise \nto monitor operations across facilities, quickly compute common industrial performance metrics such as \noverall equipment e\ufb00ectiveness (OEE), and create applications that analyze industrial equipment data.\nAWS IoT SiteWise allows you to create no-code, fully managed web applications using AWS IoT SiteWise \nMonitor . With this feature, you can visualize and interact with operational data from devices and \nequipment connected to AWS IoT services.\nAmazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using \nstandard SQL. Athena is serverless, so there is no infrastructure to manage, and you pay only for the \nqueries that they run.\nAmazon SageMaker is a fully managed service that enables you to quickly build, train, and deploy \nmachine learning models in the cloud and the edge layer. With Amazon SageMaker, IoT architectures can \ndevelop a model of historical device telemetry to infer future behavior. Through the integration of AWS \nIoT Greengrass and Amazon SageMaker, you can automate the full ML lifecycle of collecting IoT data, \nML training in the cloud, deploying ML models to the edge for local inference, and then retraining and \nredeploying in a cycle for continuous improvement of their ML models.\n6", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "adc9f31c-d6d0-416e-9d9c-6902f3fec5db": {"__data__": {"id_": "adc9f31c-d6d0-416e-9d9c-6902f3fec5db", "embedding": null, "metadata": {"page_label": "7", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a41da9448a8baa623ba7e852ddf8f357011b548e068d4475bbc1da21e1cf3947", "text": "IoT Lens AWS Well-Architected Framework\nApplication layer\nAWS IoT TwinMaker is an AWS IoT service that you can use to build operational digital twins of physical \nand digital systems. AWS IoT TwinMaker creates digital visualizations using measurements and analysis \nfrom a variety of real-world sensors, cameras, and enterprise applications to help you keep track of your \nphysical factory, building, or industrial plant. You can use this real-world data to monitor operations, \ndiagnose and correct errors, and optimize operations.\nAmazon Managed Grafana is a fully managed service for open source Grafana developed in \ncollaboration with Grafana Labs.\u00a0Grafana is a popular open-source analytics environment that enables \nyou to query, visualize, alert on and understand your metrics no matter where they are stored. Grafana \nhas integrations with services such as AWS IoT TwinMaker to make visualizations easier.\nAmazon QuickSight is a cloud-scale business intelligence (BI) service that you can use to deliver easy-to-\nunderstand insights to the people who you work with, wherever they are. Amazon QuickSight connects \nto your data in the cloud and combines data from many di\ufb00erent sources from the IoT suite.\nApplication layer\nAWS IoT provides several ways to ease the way cloud native applications consume data generated by \nIoT devices. These connected capabilities include features from serverless computing, \ufb01t for purpose \ndatabase technologies such as time series databases to create materialized views of your IoT data, and \nmanagement applications to operate, inspect, secure, and manage your IoT operations.\nManagement applications\nThe purpose of management applications is to create scalable ways to operate your devices once they \nare deployed in the \ufb01eld. Common operational tasks such as inspecting the connectivity state of a \ndevice, ensuring device credentials are con\ufb01gured correctly, and querying devices based on their current \nstate must be in place before launch so that your system has the required visibility to troubleshoot \napplications.\nAWS IoT Device Defender is a fully managed service that audits your device \ufb02eets, detects abnormal \ndevice behavior, alerts you to security issues, and helps you investigate and mitigate commonly \nencountered IoT security issues.\nAWS IoT Device Management eases the organizing, monitoring, and managing of IoT devices at scale. \nAt scale, customers are managing \ufb02eets of devices across multiple physical locations. AWS IoT Device \nManagement enables you to group devices for easier management. You can also enable real-time search \nindexing against the current state of your devices through Device Management Fleet Indexing. Both \nDevice Groups and Fleet Indexing can be used with Over the Air Updates (OTA) when determining which \ntarget devices must be updated to target speci\ufb01c sub-\ufb02eets of devices when you want to deploy remote \noperations (for example, remote reboots, over-the-air (OTA) updates, con\ufb01guration pushes, and resets.) \nusing jobs. You can also gain privileged and synchronous access (for example, SSH) to your devices for \ndebugging and troubleshooting with Secure Tunneling.\nFleet Hub for AWS IoT Device Management is a fully managed web application that lets domain \nspecialists, such as support technicians and operators, monitor device \ufb02eets' health in near real-time, \nset alerts to notify them of unusual behavior, and take built-in corrective actions (for example, deploy \na patch or reboot a device) \u2013 all with no code. You can access near real-time state data from devices \nconnected to AWS IoT Core, such as connection status, \ufb01rmware version, or battery level.\nUser applications\nIn addition to managed applications, other internal and external systems need di\ufb00erent segments \nof your IoT data for building di\ufb00erent applications. To support end-user views, business operational \ndashboards, and the other net-new applications you build over time, you will need several other \n7", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1b181185-31e2-43c7-bcdc-03d7ecfa297c": {"__data__": {"id_": "1b181185-31e2-43c7-bcdc-03d7ecfa297c", "embedding": null, "metadata": {"page_label": "8", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "388691a2c86f76c78e44d2bdf3d370484c3d857a38b9c025f13dff84827de555", "text": "IoT Lens AWS Well-Architected Framework\nDatabase services \ntechnologies that can receive the required information from your connectivity and ingestion layer and \nformat them to be used by other systems.\nAmazon Cognito lets you add user sign-up, sign-in, and access control to your web and mobile apps \nquickly and easily. Amazon Cognito scales to millions of users and supports sign-in with social identity \nproviders, such as Apple, Facebook, Google, and Amazon, and enterprise identity providers via SAML 2.0 \nand OpenID Connect. \u00a0 \nDatabase services\nWhile a data lake can function as a landing zone for all of your unformatted IoT generated data, to \nsupport all the formatted views on top of your IoT data, you need to complement your data lake with \nstructured and semi structured data stores. For these purposes, you should use both NoSQL and SQL \ndatabases. These types of databases enable you to create di\ufb00erent views of your IoT data for distinct end \nusers of your application.\nAmazon DynamoDB is a fast and \ufb02exible NoSQL database service for IoT data. With IoT applications, \ncustomers often require \ufb02exible data models with reliable performance and automatic scaling of \nthroughput capacity.\nWith Amazon Aurora your IoT architecture can store structured data in a performant and cost-e\ufb00ective \nopen-source database. When your data needs to be accessible to other IoT applications for prede\ufb01ned \nSQL queries, relational databases provide you another mechanism for decoupling the device stream of \nthe ingestion layer from your eventual business applications, which need to act on discrete segments of \nyour data.\nAmazon Timestream is a fast, scalable, and serverless time series database service for IoT and \noperational applications that makes it easy to store and analyze trillions of events per day. The purpose-\nbuilt query engine in Timestream lets you access and analyze recent and historical data together, without \nneeding to specify explicitly in the query whether the data resides in the in-memory or cost-optimized \ntier. Amazon Timestream has built-in time series analytics functions, helping you identify trends and \npatterns in your data in near real-time.\nCompute services\nFrequently, IoT workloads require application code to be run when the data is generated, ingested, \nconsumed, or realized. Regardless of when compute code needs to be run, serverless compute is a highly \ncost-e\ufb00ective choice. Serverless compute can be leveraged from the edge to the core and from core to \napplications and analytics.\nAWS Lambda allows you to run code without provisioning or managing servers. Due to the scale \nof ingestion for IoT workloads, AWS Lambda is an ideal \ufb01t for running stateless, event-driven IoT \napplications in a managed environment.\n8", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a3d2784d-383b-4e04-a924-56ca3b9c49f8": {"__data__": {"id_": "a3d2784d-383b-4e04-a924-56ca3b9c49f8", "embedding": null, "metadata": {"page_label": "9", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "4cc6bc82bc6c83aea2bfa2fb15eb97c8152542e26e4d9a9b209c8b67defa7b51", "text": "IoT Lens AWS Well-Architected Framework\nGeneral design principles\nThe Well-Architected Framework identi\ufb01es the following design principles to facilitate good design in \nthe cloud with IoT:\n\u2022Decouple ingestion from processing: In IoT applications, the ingestion layer must be a highly scalable \nplatform that can handle a high rate of streaming device data. By decoupling the fast rate of ingestion \nfrom the processing portion of your application through the use of queues, bu\ufb00ers, and messaging \nservices, your IoT application can scale elastically as needed and make several decisions without \nimpacting devices, such as the frequency it processes data or the type of data it is interested in.\n\u2022Design for o\ufb04ine behavior: Due to situations such as connectivity issues or miscon\ufb01gured settings, \ndevices might go o\ufb04ine for longer periods of time than anticipated. Design your edge software to \nhandle extended periods of o\ufb04ine connectivity and create metrics in the cloud to track devices that \nare not connected or communicating on a regular timeframe.\n\u2022Design for lean data at the edge and enrich in the cloud: Given the constrained nature of IoT \ndevices, the initial device schema will be optimized for storage on the physical device and e\ufb03cient \ntransmissions from the device to your IoT application. For this reason, unformatted device data will \noften not be enriched with static application information that can be inferred from the cloud. As data \nis ingested into your application, you should \ufb01rst enrich the data with human readable attributes, \ndeserialize, or expand any \ufb01elds that the device serialized, and then format the data in a data store \nthat is tuned to support your applications read requirements.\n\u2022Handle personalization: Devices that connect to the edge or cloud using Wi-Fi must receive the SSID \nname and credentials as one of the \ufb01rst steps performed when setting up the device. This data is \nusually infeasible to write to the device during manufacturing since it\u2019s sensitive and site-speci\ufb01c, or \nfrom the cloud since the device isn\u2019t connected yet. These factors frequently make personalization \ndata distinct from the device client certi\ufb01cate and private key, which are conceptually upstream, \nand from cloud-provided \ufb01rmware and con\ufb01guration updates, which are conceptually downstream. \nSupporting personalization can impact design and manufacturing, since it may mean that the device \nitself requires a user interface for direct data input, or the need to provide a smartphone application to \nconnect the device to the local network.\n\u2022Ensure that devices regularly send status checks: Even if devices are regularly o\ufb04ine for extended \nperiods of time, ensure that the device \ufb01rmware contains application logic that sets a regular interval \nto send device status information to your IoT application. Devices must be active participants in \nensuring that your application has the right level of visibility. Sending this regularly occurring IoT \nmessage ensures that your IoT application gets an updated view of the overall status of a device, and \ncan create processes when a device does not communicate within its expected period of time.\n\u2022Use gateways for edge computing, network segmentation, security compliance and bridging \nadministrative domains: Splitting the workload between local and remote processing helps to balance \nthe timeliness and high bandwidth of local resources with the scale and elasticity of remote resources. \nEdge gateways can be used to mediate data \ufb02ows between a low latency local-area network (LAN) and \nresources on the high-latency wide-area network (WAN), protocols used in each environment and can \nalso mediate between security and administrative domains such as in a Perdue Enterprise Network \nArchitecture (PERA), ANSI/ISA-95 network segmentation. Edge gateways are also used in consumer IoT \nsystems, for example a smart home gateway which collects data from multiple smart home devices.\n\u2022Build security into your IoT solution and apply security at all layers: IoT implementations can have \nsome very unique challenges not present in traditional IT deployments. For example, deploying a \nconsumer IoT device can introduce a new classi\ufb01cation of threats that needs to be addressed and \nindustrial IoT requires more thought around reliability, safety and compliance. Many legacy OT \nsystems are insecure by design and use industrial protocols which don\u2019t support authentication, \nauthorization and encryption. In industrial IoT, the convergence of IT and OT systems is creating a \nmix of technologies that were designed to withstand hostile network environments and ones that \nwere not, which creates risk management di\ufb03culties that need to be controlled. So, building security \n9", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b066b474-fb1f-4e28-abe1-4145deb8d92a": {"__data__": {"id_": "b066b474-fb1f-4e28-abe1-4145deb8d92a", "embedding": null, "metadata": {"page_label": "10", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "92cfdd5de513cf1784f4d68f3266fdb814dd60a2dd1ecbac643052b27d7b763d", "text": "IoT Lens AWS Well-Architected Framework\ninto every part of your IoT solution is essential for minimizing risks to your data, business assets, and \nreputation. Apply a defense in-depth approach with multiple security controls.\n10", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "73edc339-2561-413c-be3c-e0108472c132": {"__data__": {"id_": "73edc339-2561-413c-be3c-e0108472c132", "embedding": null, "metadata": {"page_label": "11", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3fe13f6fe489bbdc88054bffb346ae93c1f3a789e1e9dfc8cbf386ed7e81c79b", "text": "IoT Lens AWS Well-Architected Framework\nDevice provisioning\nScenarios\nThis section addresses common scenarios related to IoT applications, with a focus on how each scenario \nimpacts the architecture of your IoT workload. These examples are not exhaustive, but they encompass \ncommon patterns in IoT applications. We present a background on each scenario, general considerations \nfor the design of the system, and a reference architecture of how the scenario should be implemented.\nScenarios\n\u2022Device provisioning (p. 11)\n\u2022Device telemetry (p. 13)\n\u2022Device commands (p. 14)\nDevice provisioning\nIn IoT, device provisioning is composed of sequential steps. The most important outcome is that each \ndevice must be given a unique identity and authenticated by your IoT application using that identity.\nThe \ufb01rst step to provisioning a device is to install an identity. The decisions you make in device design \nand manufacturing determines if the device has a production-ready \ufb01rmware image, a unique client \ncredential, or both by the time it reaches the customer. Your decisions determine whether there are \nadditional provisioning-time steps that must be performed before a production device identity can be \ninstalled.\nUse X.509 client certi\ufb01cates for your IoT devices \u2014 they tend to be more secure and easier to manage \nat scale than static passwords. In AWS IoT Core, the device is registered using its certi\ufb01cate along with \na unique thing identi\ufb01er. The registered device is associated with an IoT policy. An IoT policy allows you \nto create \ufb01ne-grained permissions per device. Fine-grained permissions ensure that only the device has \npermissions to interact with the right MQTT topics and messages.\nThe registration process ensures that a device is recognized as an IoT asset and that the data it generates \ncan be consumed through AWS IoT to other AWS services. One of the ways to provision a device, is \nthrough \ufb02eet provisioning. AWS IoT can generate and securely deliver device certi\ufb01cates and private keys \nto your devices when they connect to AWS IoT for the \ufb01rst time. AWS IoT provides client certi\ufb01cates that \nare signed by the AWS Private Certi\ufb01cate Authority (AWS Private CA). Fleet provisioning provides two \nways to implement this: by trusted user or by claim. Let us look at the process \ufb02ow for \ufb02eet provisioning \nby claim.\nSome devices do not have the capability to accept credentials over a secure transport, and the \nmanufacturing supply chain is not equipped to customize devices at manufacturing time. AWS IoT \nprovides a path for these devices to receive a unique identity when they are deployed.\nDevice makers must load each device with a shared claim certi\ufb01cate in \ufb01rmware. This claim certi\ufb01cate \nshould be unique per batch of devices. The \ufb01rmware containing the claim certi\ufb01cate is loaded by the \ncontract manufacturer without the need to perform any customization. When the device establishes \na connection with AWS IoT for the \ufb01rst time, it exchanges the claim certi\ufb01cate for a unique X.509 \ncerti\ufb01cate signed by the AWS certi\ufb01cate authority and a private key. The device should send a unique \ntoken, such as a serial number or embedded hardware secret with its provisioning request that the \ufb02eet \nprovisioning service can use to verify against an allow list.\n11", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ffff6569-b880-4212-9acf-94579d727b5e": {"__data__": {"id_": "ffff6569-b880-4212-9acf-94579d727b5e", "embedding": null, "metadata": {"page_label": "12", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "40dd6513c3a94b227f1d931064afece9f1f20fa1973cc47d1a8ac1c4a479f364", "text": "IoT Lens AWS Well-Architected Framework\nDevice provisioning\nFigure 1: Registration Flow\n1.Device connects with claim certi\ufb01cate to AWS IoT Core.\n2.The \ufb02eet provisioning service creates a new certi\ufb01cate and private key assigned with AWS Private CA.\n3.Device writes the unique private key and certi\ufb01cate to secure storage.\n4.With the parameters published from the device, the \ufb02eet provisioning service starts the pre-\nprovisioning Lambda function.\n12", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d2271768-c076-4390-8e40-646319ac6dbe": {"__data__": {"id_": "d2271768-c076-4390-8e40-646319ac6dbe", "embedding": null, "metadata": {"page_label": "13", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "32eb138055d5caefcc797b81459d4e186a6417f749c7f3eb9f26a113795a2867", "text": "IoT Lens AWS Well-Architected Framework\nDevice telemetry\n5.The Lambda function performs additional veri\ufb01cation logic, such as checking the hardware secret \nagainst a DynamoDB table with veri\ufb01ed devices.\n6.The \ufb02eet provisioning service create IoT thing, policy, and activates certi\ufb01cate based on provisioning \ntemplate and publishes this to the device.\n7.Device applies the new con\ufb01guration and connects with the unique private key, certi\ufb01cates, and \ncon\ufb01guration.\nDevice telemetry\nThere are many use cases where the value for IoT is in collecting telemetry on how a machine or asset \nis performing. For example, this data can be used to predict costly, unforeseen equipment failures. \nTelemetry must be collected from the machine and sent to an IoT application. Another bene\ufb01t of \nsending telemetry is the ability of your cloud applications to use this data for analysis and to interpret \noptimizations that can be made to your \ufb01rmware over time.\nRead-only telemetry data is collected and transmitted to the IoT application. Telemetry data and \ncommand and control should be kept on separate MQTT topic namespaces. Telemetry data topics should \nstart with a pre\ufb01x such as data , for example, data/device/sensortype . Control plane topics should \nstart with a pre\ufb01x such as command .\nFrom a logical perspective, we have de\ufb01ned several scenarios for capturing and interacting with device \ndata telemetry.\nOptions for capturing device data telemetry:\n1.One publishing topic and one subscriber. For example, a smart light bulb that publishes its brightness \nlevel to a single topic where only a single application can subscribe.\n2.One publishing topic with variables and one subscriber. For example, a collection of smart bulbs \npublishing their brightness on similar but unique topics. Each subscriber can listen to a unique publish \nmessage.\n3.Single publishing topic and multiple subscribers. In this case, a light sensor that publishes its values to \na topic that all the light bulbs in a house subscribe to.\n4.Multiple publishing topics and a single subscriber. For example, a collection of light bulbs with motion \nsensors. The smart home system subscribes to all of the light bulb topics, inclusive of motion sensors, \nand creates a composite view of brightness and motion sensor data.\n13", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "24182e46-ab35-422a-9c31-8f6be461b6b7": {"__data__": {"id_": "24182e46-ab35-422a-9c31-8f6be461b6b7", "embedding": null, "metadata": {"page_label": "14", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "621269097bb1bde04c633b70e12e817c4198a06c8470582f3886222d5a1bec69", "text": "IoT Lens AWS Well-Architected Framework\nDevice commands\n5.AWS IoT SiteWise Edge software running on an edge gateway is used to collect, organize, process, and \nmonitor equipment data on premises and sends it to AWS IoT SiteWise for data storage, organization \nand visualization.\nOther AWS IoT services which can be used for device telemetry data ingestion are AWS IoT SiteWise \nfor industrial data and AWS IoT FleetWise for vehicle data.\nDevice commands\nWhen you are building an IoT application, you need the ability to interact with your device through \ncommands remotely. An example in the industrial vertical is to use remote commands to request \nspeci\ufb01c data from a piece of equipment. An example usage in the smart home vertical is to use remote \ncommands to schedule an alarm system remotely.\nWith AWS IoT Core, you can use the bi-directional MQTT protocol to implement command and control of \ndevices. The device subscribes to a speci\ufb01c command MQTT topic. When the device receives a command \nmessage, it should verify that the message arrived in the correct order by implementing a sequential ID. \nThe device should then perform the action, and publish a message to the cloud with the results of the \ncommand. This ensures that commands are acted upon in order, and the device\u2019s current state is always \nknown and maintained in the cloud.\nAWS provides the AWS IoT Device Shadow service to implement command and control over MQTT using \nthese best practices. The device shadow has several bene\ufb01ts over using standard MQTT topics, such as \na clientToken, to track the origin of a request, version numbers for managing con\ufb02ict resolution, and \nthe ability to store commands in the cloud in the event that a device is o\ufb04ine and unable to receive the \ncommand when it is issued. The device\u2019s shadow is commonly used in cases where a command needs to \nbe persisted in the cloud even if the device is currently not online. When the device is back online, the \ndevice requests the latest shadow information and executes the command.\n14", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0f844ba7-a94a-4cbe-8138-a8b4bf346903": {"__data__": {"id_": "0f844ba7-a94a-4cbe-8138-a8b4bf346903", "embedding": null, "metadata": {"page_label": "15", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8b7ead7659f6b151469c11593e57f318c3a5774043bbf236f85cf15d867acc44", "text": "IoT Lens AWS Well-Architected Framework\nAWS IoT Device Shadow service\nFigure 2: Using a message broker to send commands to a device\nAWS IoT Device Shadow service\nIoT solutions that use the AWS IoT Device Shadow service in AWS IoT Core manage command requests \nin a reliable, scalable, and straightforward fashion. The AWS IoT Device Shadow service follows a \nprescriptive approach to both the management of device-related state and how the state changes \nare communicated. This approach describes how the service uses a JSON document to store a device's \ncurrent state, desired future state, and the di\ufb00erence between current and desired states.\nFigure 3: Using AWS IoT Device Shadow service with devices.\n1.The device should check its desired state as soon as it comes online by subscribing to the\n$aws/things/ <<thingName>> /shadow/name/ <<shadowName>> /get topic. A device \nreports initial device state by publishing that state as a message to the update topic\u00a0$aws/\nthings/<<thingName>> /shadow/name/ <<shadowName>> /update .\n2.The Device Shadow reads the message from the topic and records the device state in a persistent data \nstore.\n3.A device\u00a0subscribes\u00a0to the delta messaging topic\u00a0$aws/things/ <<thingName>> /shadow/\nname/<<shadowName>> /update/delta \u00a0upon which device-related state change messages will \narrive.\n4.A component of the solution publishes a\u00a0desired state\u00a0message to the topic $aws/\nthings/<<thingName>> /shadow/name/ <<shadowName>> /update and the Device Shadow \ntracking this device records the desired device state in a persistent data store.\n15", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0737c330-17b5-4818-8d7e-9f23dcc614d1": {"__data__": {"id_": "0737c330-17b5-4818-8d7e-9f23dcc614d1", "embedding": null, "metadata": {"page_label": "16", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c87cb3b2201f9f7bf1e4df076169a410c751ddc6613d134344e0f68f7ed66230", "text": "IoT Lens AWS Well-Architected Framework\nAWS IoT Jobs for device commands\n5.The Device Shadow publishes a delta message to the topic\u00a0$aws/things/ <<thingName>> /\nshadow/name/ <<shadowName>> /update/delta , and the Message Broker sends the message to \nthe device.\n6.A device receives the delta message and performs the desired state changes.\n7.A device\u00a0publishes an acknowledgment message re\ufb02ecting the new state to the update topic $aws/\nthings/<<thingName>> /shadow/name/ <<shadowName>> /update\u00a0and the Device Shadow \ntracking this device records the new state in a persistent data store.\n8.The Device Shadow publishes a message to the\u00a0$aws/things/ <<thingName>> /shadow/\nname/<<shadowName>> /update/accepted \u00a0topic.\n9.A component of the solution can now request the updated state from the Device Shadow.\nAWS IoT Jobs for device commands\nIn addition to the features described previously for device commands, you can also use AWS IoT Jobs \nto create a command pipeline , where the device infers the command from the payload of the MQTT \nmessage, as opposed to the topic. This enables you to perform new kinds of remote operations with \nminimal device-side code changes. You can control the rate of roll-outs using Jobs, and provide abort, \nretry, and timeout criteria to further customize the behavior of the job. AWS IoT Jobs integrates with \n\ufb02eet indexing and thing groups, which allows you to search your \ufb02eet and target devices in your \ufb02eet \nthat meet speci\ufb01c criteria. With job templates , you can pre-de\ufb01ne all kinds of device commands and \ncreate a library of reusable commands with just a few clicks on the target of your choice.\nFirmware updates\nSupporting \ufb01rmware updates without human intervention is critical for security, scalability, and \ndelivering new capabilities.\nAWS IoT Device Management provides a secure and easy way for you to manage IoT deployments \nincluding executing and tracking the status of \ufb01rmware updates. AWS IoT Device Management uses the \nMQTT protocol with AWS IoT message broker and AWS IoT Jobs to send \ufb01rmware update commands \nto devices, as well as to receive the status of those \ufb01rmware updates over time. AWS IoT Jobs also \nintegrates with AWS Signer to provide additional security to prevent unauthorized \ufb01rmware updates and \nman in the middle attacks. AWS Signer is a fully managed code-signing service to ensure the trust and \nintegrity of your code. With AWS Signer, you can validate code against a digital signature to con\ufb01rm that \nthe code is unaltered and from a trusted publisher. Firmware images can be signed with a private key \nin the cloud using the code signing feature, and the device veri\ufb01es the integrity of that \ufb01rmware image \nwith the corresponding public key.\nTo implement \ufb01rmware updates using AWS IoT Device Management and AWS IoT Jobs, see the following \ndiagram.\n16", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f41a0c8d-7fda-4dac-8b42-eeb0f16ff679": {"__data__": {"id_": "f41a0c8d-7fda-4dac-8b42-eeb0f16ff679", "embedding": null, "metadata": {"page_label": "17", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "624c071cbdb4ad2953ab955403027c6828d8cf9325b8a0e230670e5c8a77bbc8", "text": "IoT Lens AWS Well-Architected Framework\nFirmware updates\nFigure 4: Updating \ufb01rmware on devices.\n1.A device\u00a0subscribes to the IoT job noti\ufb01cation topic $aws/things/ <<thingName>> /jobs/notify-\nnext\u00a0upon which IoT job noti\ufb01cation messages will arrive.\n2.A device publishes a message to $aws/things/ <<thingName>> /jobs/start-next  to start \nthe next job and get the next job, its job document, and other details including any state saved in \nstatusDetails.\n3.The AWS IoT Jobs service retrieves the next job document for the speci\ufb01c device and sends this \ndocument on the subscribed topic $aws/things/ <<thingName>> /jobs/start-next/accepted  .\n4.A device performs the actions speci\ufb01ed by the job document using the $aws/\nthings/<<thingName>> /jobs/jobId/update  MQTT topic to report on the progress of the job.\n5.During the upgrade process, a device downloads \ufb01rmware using a pre-signed URL for Amazon S3. \nUse code-signing to sign the \ufb01rmware when uploading to Amazon S3. By code-signing your \ufb01rmware \nthe end-device can verify the authenticity of the \ufb01rmware before installing. FreeRTOS devices can \ndownload the \ufb01rmware image directly over MQTT to eliminate the need for a separate HTTPS \nconnection.\n6.The device publishes an update status message to the job topic\u00a0$aws/things/ <<thingName>> /\njobs/jobId/update \u00a0reporting success or failure.\n7.Because this job's execution status has changed to \ufb01nal state, the next IoT job available for running (if \nany) will change.\n17", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "132dc50c-6c11-4b5b-a5e1-e51309a2d38e": {"__data__": {"id_": "132dc50c-6c11-4b5b-a5e1-e51309a2d38e", "embedding": null, "metadata": {"page_label": "18", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "559bcbe2de5852f605b1be558b88bba6ff6217444fe3fe9df51dad19a0657d99", "text": "IoT Lens AWS Well-Architected Framework\nOperational excellence\nThe pillars of the Well-Architected \nFramework\nThis section describes each of the pillars and includes de\ufb01nitions, best practices, questions, \nconsiderations, and essential AWS services that are relevant when architecting solutions for AWS IoT.\nPillars\n\u2022Operational excellence pillar (p. 18)\n\u2022Security pillar (p. 30)\n\u2022Reliability pillar (p. 50)\n\u2022Performance e\ufb03ciency pillar (p. 63)\n\u2022Cost optimization pillar  (p. 75)\n\u2022Sustainability pillar (p. 83)\nOperational excellence pillar\nThe operational excellence pillar includes operational practices and procedures used to manage \nproduction workloads. Operational excellence comprises how planned changes are performed, as well as \nresponses to unexpected operational events. Change execution and responses should be automated. All \nprocesses and procedures of operational excellence must be documented, tested, and regularly reviewed.\nTopics\n\u2022Design principles  (p. 18)\n\u2022Best practices (p. 19)\n\u2022Key AWS services (p. 29)\n\u2022Resources (p. 29)\nDesign principles\nIn addition to the overall Well-Architected Framework operational excellence design principles, there are \n\ufb01ve design principles for operational excellence for IoT:\n\u2022Plan for device provisioning: Design your device provisioning process to create your initial device \nidentity in a secure location. Implement a public key infrastructure (PKI) that is responsible for \ndistributing unique certi\ufb01cates to IoT devices. As described above, selection of crypto hardware with a \npre-generated private key and certi\ufb01cate eliminates the operational cost of running a PKI. Otherwise, \nPKI can be done o\ufb04ine with a hardware security module (HSM) during the manufacturing process, \nor during device bootstrapping. Use technologies that can manage the Certi\ufb01cate Authority (CA) and \nHSM in the cloud.\n\u2022Implement device bootstrapping: Devices that support personalization by a technician (in the \nindustrial domain) or user (in the consumer domain) can also undergo provisioning. For example, \na smartphone application that interacts with the device over Bluetooth LE and with the cloud \nover Wi-Fi. You must design the ability for devices to programmatically update their con\ufb01guration \ninformation using a globally distributed bootstrap API. A bootstrapping design ensures that you \ncan programmatically send the device new con\ufb01guration settings through the cloud. These changes \nshould include settings such as which IoT endpoint to communicate with, how frequently to send an \noverall status for the device, and any updated security settings such as server certi\ufb01cates. The process \n18", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e886fd8e-fef8-4591-bc30-3450723143ab": {"__data__": {"id_": "e886fd8e-fef8-4591-bc30-3450723143ab", "embedding": null, "metadata": {"page_label": "19", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "cb3c419406c3e82798c9dd605fd12b4469232a68b0f0bf50790329f5d420f075", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nof bootstrapping goes beyond initial provisioning and plays a critical role in device operations by \nproviding a programmatic way to update device con\ufb01guration through the cloud. A bootstrapping API \nand endpoint must be available for the entire de\ufb01ned life of all devices, and must be able to respond \nto requests for all versions of \ufb01rmware that have ever been deployed on a device.\n\u2022Document device communication patterns: In an IoT application, device behavior is documented \nby hand at the hardware level. In the cloud, an operations team must formulate how the behavior \nof a device will scale once deployed to a \ufb02eet of devices. A cloud engineer should review the device \ncommunication patterns and extrapolate the total expected inbound and outbound tra\ufb03c of device \ndata and determine the expected infrastructure necessary in the cloud to support the entire \ufb02eet of \ndevices. During operational planning, these patterns should be measured using device and cloud-side \nmetrics to ensure that expected usage patterns are met in the system.\n\u2022Implement over-the-air (OTA) updates: To bene\ufb01t from long-term investments in hardware, you must \nbe able to continually update the \ufb01rmware on the devices with new capabilities. In the cloud, you can \napply a robust \ufb01rmware update process that allows you to target speci\ufb01c devices for \ufb01rmware updates, \nroll out changes over time, track success and failures of updates, and have the ability to roll back or \nput a stop to \ufb01rmware changes based on key performance indicators (KPIs).\n\u2022Implement functional testing on physical assets: IoT device hardware and \ufb01rmware must undergo \nrigorous testing before being deployed in the \ufb01eld. Acceptance and functional testing are critical \nfor your path to production. The goal of functional testing is to run your hardware components, \nembedded \ufb01rmware, and device application software through rigorous testing scenarios, such as \nintermittent or reduced connectivity or failure of peripheral sensors, while pro\ufb01ling the performance \nof the hardware. The tests ensure that your IoT device will perform as expected when deployed.\n\u2022Design and build for operations at scale: Design and build a solution for logging, monitoring, \ntroubleshooting, \ufb02eet management, life cycle device and application management at scale.\nBest practices\nThere are three best practice areas for operational excellence:\nTopics\n\u2022Prepare  (p. 19)\n\u2022Operate  (p. 20)\n\u2022Evolve  (p. 21)\nIn addition to what is covered by the Well-Architected Framework concerning process, runbooks, \nand game days, there are speci\ufb01c areas you should review to drive operational excellence within IoT \napplications.\nPrepare\nFor IoT applications, the need to procure, provision, test, and deploy hardware in various environments \nmeans that the preparation for operational excellence must be expanded to cover aspects of your \ndeployment that will primarily run-on physical devices and will not run in the cloud. Operational metrics \nmust be de\ufb01ned to measure and improve business outcomes and then determine if devices should \ngenerate and send any of those metrics to your IoT application. You also must plan for operational \nexcellence by creating a streamlined process of functional testing that allows you to simulate how \ndevices may behave in their various environments.\nIt is essential that you ask how to ensure that your IoT workloads are resilient to failures, how devices \ncan self-recover from issues without human intervention, and how your cloud-based IoT application will \nscale to meet the needs of an ever-increasing load of connected hardware.\nWhen using an IoT platform, you have the opportunity to use additional components and tools for \nhandling IoT operations. These tools include services that allow you to monitor and inspect device \n19", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e13ea540-a15e-4464-b390-633ae96d583b": {"__data__": {"id_": "e13ea540-a15e-4464-b390-633ae96d583b", "embedding": null, "metadata": {"page_label": "20", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7c7ec2343d0843584e275d7ca538f3023d01a9e7969edd5f5ecf68234ae4a3d0", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nbehavior, capture connectivity metrics, provision devices using unique identities, and perform long-term \nanalysis of device data.\nIOTOPS 1. What factors drive your operational priorities?\nIOTOPS 2. How are you ensuring that newly provisioned devices have the required operational \nprerequisites?\nSecurity for IoT and data centers is similar in that both involve predominantly machine-to-machine \nauthentication. However, they di\ufb00er in that IoT devices are frequently deployed to environments that \ncannot be assumed to be physically secure. IoT applications also commonly require sensitive data \nto traverse the internet. Due to these considerations, it is vital for you to have an architecture that \ndetermines how devices will securely gain an identity, continuously prove their identity, be seeded with \nthe appropriate level of metadata, be organized and categorized for monitoring, and enabled with the \nright set of permissions.\nFor successful and scalable IoT applications, the management processes should be automated, data-\ndriven, and based on previous, current, and expected device behavior. IoT applications must support \nincremental rollout and rollback strategies. By having this as part of the operational e\ufb03ciency plan, you \nwill be equipped to launch a fault-tolerant, e\ufb03cient IoT application.\nIn AWS IoT, you can use multiple features to provision your individual device identities signed by your \nCA to the cloud. This path involves provisioning devices with identities and then using just-in-time-\nprovisioning (JITP), just-in-time-registration (JITR), \ufb02eet provisioning or multi-account registration to \nsecurely register your device certi\ufb01cates to the cloud. Using AWS services including Route\u00a053, Amazon \nAPI Gateway, Lambda, and DynamoDB, will create a simple API interface to extend the provisioning \nprocess with device bootstrapping.\nOperate\nIn IoT, operational health goes beyond the operational health of the cloud application and extends to \nthe ability to measure, monitor, troubleshoot, and remediate devices that are part of your application, \nbut are remotely deployed in locations that may be di\ufb03cult or impossible to troubleshoot locally. This \nrequirement of remote operations must be considered at design and implementation time to ensure your \nability to inspect, analyze, and act on metrics sent from these remote devices.\nIn IoT, you must establish the right baseline metrics of behavior for your devices, be able to aggregate \nand infer issues that are occurring across devices, and have a robust remediation plan that is not only \nperformed in the cloud, but also part of your device \ufb01rmware. You must implement a variety of device \nsimulation canaries that continue to test common device interactions directly against your production \nsystem. Device canaries assist in narrowing down the potential areas to investigate when operational \nmetrics are not met. Device canaries can be used to raise preemptive alarms when the canary metrics fall \nbelow your expected SLA.\nIn AWS, you can create an AWS IoT thing for each physical device in the device registry of AWS IoT Core. \nBy creating a thing in the registry, you can associate metadata to devices, group devices, and con\ufb01gure \nsecurity permissions for devices. An AWS IoT thing should be used to store static data in the thing \nregistry while storing dynamic device data in the thing\u2019s associated device shadow. A device's\u00a0shadow\u00a0is a \nJSON document that is used to store and retrieve state information for a device.\u00a0\nAlong with creating a virtual representation of your device in the device registry, as part of the \noperational process, you must create thing types that encapsulate similar static attributes that de\ufb01ne \n20", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a4210b08-d4aa-488a-9682-4ccd870e3d39": {"__data__": {"id_": "a4210b08-d4aa-488a-9682-4ccd870e3d39", "embedding": null, "metadata": {"page_label": "21", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5580f8fc08bf8911cfc12056be11f65ea2ed54b6ad1aba09263fc733a66c0473", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nyour IoT devices. A thing type is analogous to the product classi\ufb01cation for a device. The combination \nof thing, thing type, and device shadow can act as your \ufb01rst entry point for storing important metadata \nthat will be used for IoT operations.\nIn AWS IoT, thing groups allow you to manage devices by category. Groups can also contain other groups \n\u2014 allowing you to build hierarchies.\u00a0With organizational structure in your IoT application, you can \nquickly identify and act on related devices by device group. Leveraging the cloud allows you to automate \nthe addition or removal of devices from groups based on your business logic and the lifecycle of your \ndevices.\nIn IoT, your devices create telemetry or diagnostic messages that are not stored in the registry or the \ndevice\u2019s shadow. Instead, these messages are delivered to AWS IoT using a number of MQTT topics. To \nmake this data actionable, use the AWS IoT rules engine to route error messages to your automated \nremediation process and add diagnostic information to IoT messages. An example of how you would \nroute a message that contained an error status code to a custom work\ufb02ow is below. The rules engine \ninspects the status of a message and if it is an error, it starts the Step Function work\ufb02ow to remediate \nthe device based o\ufb00 the error message detail payload.\n{ \n    \"sql\": \"SELECT * FROM 'command/iot/response\u2019 WHERE code = 'error'\", \n    \"ruleDisabled\": false, \n    \"description\": \"Error Handling Workflow\", \n    \"awsIotSqlVersion\": \"2016-03-23\", \n    \"actions\": [{ \n        \"stepFunctions\": { \n            \"executionNamePrefix\": \"errorExecution\", \n            \"stateMachineName\": \"errorStateMachine\", \n            \"roleArn\": \"arn:aws:iam:: 123456789012 :role/aws_iot_step_functions\" \n        } \n    }]\n}\nTo support operational insights to your cloud application, generate dashboards for all metrics collected \nfrom the device broker of AWS IoT Core. These metrics are available through CloudWatch Metrics. In \naddition, CloudWatch Logs contain information such as total successful messages inbound, messages \noutbound, connectivity success, and errors.\nTo augment your production device deployments, implement IoT simulations on Amazon Elastic \nCompute Cloud (Amazon EC2) as device canaries across several AWS Regions. These device canaries are \nresponsible for mirroring several of your business use cases, such as simulating error conditions like long-\nrunning transactions, sending telemetry, and implementing control operations. The device simulation \nframework must output extensive metrics, including but not limited to successes, errors, latency, and \ndevice ordering and then transmit all the metrics to your operations system.\nIn addition to custom dashboards, AWS IoT provides \ufb02eet-level and device-level insights driven from \nthe thing registry and AWS IoT Device Shadow service through search capabilities such as AWS IoT \ufb02eet \nindexing. The ability to search across your \ufb02eet eases the operational overhead of diagnosing IoT issues, \nwhether they occur at the device-level or \ufb02eet-wide level.\nEvolve\nIOTOPS 3. How do you evolve your IoT application with minimum impact to downstream IoT \ndevices?\nIoT solutions frequently involve a combination of low-power devices, remote locations, low bandwidth, \nand intermittent network connectivity. Each of those factors poses communications challenges, \n21", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0e0386c5-6512-483d-8f25-118d3d4d6e21": {"__data__": {"id_": "0e0386c5-6512-483d-8f25-118d3d4d6e21", "embedding": null, "metadata": {"page_label": "22", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b4dee3f49ee8aeb45cc915ce230e7081ca6bc198821d83436c969c623939b0c3", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nincluding upgrading \ufb01rmware and edge applications. Therefore, it's important for you to incorporate \nand implement an IoT update process that minimizes the impact to downstream devices and operations. \nIn addition to reducing downstream impact, devices must be resilient to common challenges that exist \nin local environments, such as intermittent network connectivity and power loss. Use a combination of \ngrouping IoT devices for deployment and staggering \ufb01rmware upgrades over a period of time. Monitor \nthe behavior of devices as they are updated in the \ufb01eld, and proceed only after a percentage of devices \nhave upgraded successfully.\nUse AWS IoT Device Management for creating deployment groups of devices and delivering over-the-air \n(OTA) updates to speci\ufb01c device groups. During upgrades, continue to collect all of the CloudWatch Logs, \ntelemetry, and IoT device job messages and combine that information with the KPIs used to measure \noverall application health and the performance of any long-running canaries.\nBefore and after \ufb01rmware updates, perform a retrospective analysis of operations metrics with \nparticipants spanning the business to determine opportunities and methods for improvement. Services \nsuch as AWS IoT Analytics and AWS IoT Device Defender are used to track anomalies in overall device \nbehavior, and to measure deviations in performance that may indicate an issue in the updated \ufb01rmware.\nIOTOPS 4. How do you ensure that you are ready to support the operations of devices in your IoT \nworkload?\nOperating IoT workloads at scale is di\ufb00erent than testing and running prototypes. You need to ensure \nthat your team is prepared and trained to operate a widely distributed IoT data collection application. \nIoT workloads require your teams to learn new skills and competencies to deliver edge-to-cloud \noutcomes. Your team needs to be able to pinpoint key operational thresholds that indicate a high level \nof readiness.\nBest practice IOTOPS_4.1 \u2013 Train team members supporting your IoT workloads on the lifecycle of \nIoT applications and your business objectives\nKey team members responsible for IoT workloads are trained on major IoT lifecycle events: onboarding, \ncommand and control, security, data ingestion, integration, and analytics services. Team members \nshould be able to identify key operational metrics and know how to apply incident response measures. \nTraining team members on the basics of IoT lifecycles and how these align with business objectives \nprovides actionable context on failure scenarios, mitigation strategies, and de\ufb01ning lasting processes \nthat e\ufb00ectively contribute to fewer operational events and less severe impact during events.\nRecommendation IOTOPS_4.1.1 \u2013 Build IoT operational expertise by having team members and \narchitects\u2019 complete reviews of common IoT architectural patterns, best practices, and educational courses\n\u2022Introduce new team members to IoT lifecycles with onboarding checklists that include at least one \neducational course.\n\u2022Introduce new team members with onboarding checklists that include a step to review, validate, and \nsubmit updates to your IoT application architecture documentation and operational monitoring plan.\nRecommendation IOTOPS_4.1.2 \u2013 Author runbooks for each component of the architecture and train \nteam members on their use\n\u2022Include guidance for a response procedure for remote devices that are no longer online.\n\u2022Apply recovery commands for troubleshooting remote devices that are faulty but still online.\nIOTOPS 5. How do you assess whether your IoT application meets your operational goals?\n22", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9fa2f37b-cbdd-44f1-a7da-108152550a6a": {"__data__": {"id_": "9fa2f37b-cbdd-44f1-a7da-108152550a6a", "embedding": null, "metadata": {"page_label": "23", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "02cf11379a565ea43c8d9334edc63584b14d38be642ad7a07239ed1271e01705", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nEvaluating your operational goals enables you to \ufb01ne-tune and identify improvements throughout the \nlifecycle of your IoT application. Measuring and extracting operational and business value from your IoT \napplication allows you to e\ufb00ectively drive high-value initiatives.\nBest practice IOTOPS_5.1 \u2013 Enable appropriate responses to events\nKey operational data elements are those data points that convey some notion of operational health of \nyour application by classifying events. Detecting operational events early can uncover unforeseen risks \nin your application and give your operations team a head start to prevent or reduce signi\ufb01cant business \ninterruption. By de\ufb01ning a minimum set of logs, metrics, and alarms, your operations team can provide a \n\ufb01rst line of defense against signi\ufb01cant business interruption.\nRecommendation IOTOPS_5.1.1 \u2013 Con\ufb01gure logging to capture and store at least error-level events\n\u2022Use AWS IoT service logging options to capture error events in CloudWatch Logs\nRecommendation IOTOPS_5.1.2 \u2013 Create a dashboard for your responders to use in investigations of \noperational events to rapidly pinpoint the period of time when errors are logged\n\u2022Group clusters of error events into buckets of time to quickly identify when surges of errors were \ncaptured.\n\u2022Drill down into clusters of errors to identify any patterns to signal for triage response.\nRecommendation IOTOPS_5.1.3 \u2013 Review the default metrics emitted by your IoT services and con\ufb01gure \nalarms for metrics that might indicate business interruption\n\u2022For example:\n\u2022Your business deploys a thousand sensors across manufacturing plants and your operations team \nwants to be alerted if sensors can no longer connect to the cloud and send telemetry.\n\u2022Your IT team administering the AWS account reviews the \nAWS IoT Core metrics and notes the following metrics to \nmonitor:\u00a0Connect.AuthError ,\u00a0Connect.ClientError ,\u00a0Connect.ClientIDThrottle ,\u00a0Connect.ServerError ,\nConnect.Throttle . Activity in any of these metrics constitutes alerting and investigation.\n\u2022Your IT team uses CloudWatch to con\ufb01gure new alarms on these metrics when for any period the \nmetrics\u2019 SUM of Count is greater than zero.\n\u2022Your IT team con\ufb01gures an Amazon SNS topic to notify their paging tool when any of the new \nCloudWatch alarms changes status.\n\u2022For more information:\n\u2022Monitor AWS IoT alarms and metrics using Amazon CloudWatch\nRecommendation IOTOPS_5.1.4 \u2013 Con\ufb01gure an automated monitoring and alerting tool to detect \ncommon symptoms and warnings of operational impact\n\u2022For example:\n\u2022Con\ufb01gure AWS IoT Device Defender to run a daily audit on at least the high and critical checks.\n\u2022Con\ufb01gure an Amazon SNS topic to notify a team email list, paging tool, or operations channel when \nAWS IoT Device Defender reports non-compliant resources in an audit.\n\u2022For more information:\n\u2022AWS IoT Device Defender Audit\nIOTOPS 6. How do you govern device \ufb02eet provisioning process?\n23", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "be4c134a-3313-4b76-bc34-b315203c29a1": {"__data__": {"id_": "be4c134a-3313-4b76-bc34-b315203c29a1", "embedding": null, "metadata": {"page_label": "24", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "069fbbde475ebab13c94ce57429371fdd9c4d78f3d6a9125b5d5fbda989a3a50", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nIoT solutions can scale to millions of devices and this requires device \ufb02eets to be well planned from the \nperspectives of provisioning processes and metadata organization. De\ufb01ning how devices are provisioned \nmust include how the devices are manufactured and how they are registered. Maintain a full chain of \nsecurity controls over who or what processes can start device provisioning to decrease the likelihood of \ninviting unintended, or rogue, devices into your \ufb02eet.\nBest practice IOTOPS_6.1 \u2013 Document how devices join your \ufb02eet from manufacturing to \nprovisioning\nDocument the whole device provisioning process to clearly de\ufb01ne the responsibilities of di\ufb00erent actors \nat di\ufb00erent stages. The end-to-end device provisioning process involves multiple stages owned by \ndi\ufb00erent actors. Documenting the plan and processes by which devices onboard and join the \ufb02eet a\ufb00ords \nthe appropriate amount of review for potential gaps.\nRecommendation IOTOPS_6.1.1 \u2013 Document each step (manual and programmatic) of all the stages for \nthe corresponding actors of that stage and clearly de\ufb01ne the sequence\n\u2022Identify the steps at each stage and the corresponding actors.\n\u2022Device assembly by hardware manufacturer.\n\u2022Device registration by service and solution provider.\n\u2022Device activation by the end user of the service or solution provider.\n\u2022Clearly de\ufb01ne and document the dependencies and speci\ufb01c steps for each actor from device \nmanufacturer to the end user.\n\u2022Document whether devices can self-provision or are user-provisioned and how you can ensure that \nnewly provisioned devices are yours.\nRecommendation IOTOPS_6.1.2 \u2013 Assign device metadata to enable easy grouping and classi\ufb01cation of \ndevices in a \ufb02eet\n\u2022The metadata can be used to group the devices in groups to search and force common actions and \nbehaviors.\n\u2022For example, you can assign the following metadata at the time of manufacturing:\n\u2022Unique ID\n\u2022Manufacturer details\n\u2022Model number\n\u2022Version or generation\n\u2022Manufacturing date\n\u2022If a particular model of a device requires a security patch, then you can easily target the patch to \nall the devices that are part of the corresponding model number group. Similarly, you can apply \nthe patches to devices manufactured in a speci\ufb01c time frame or belonging to a particular version or \ngeneration.\nBest practice IOTOPS_6.2 \u2013 Use programmatic techniques to provision devices at scale\nScaling the onboarding and provisioning of a large device \ufb02eet can be a bottleneck if there is even \none manual step per device. Programmatic techniques de\ufb01ne patterns of behavior for automating \nthe provisioning process such that authenticated and authorized devices can onboard at any time. \nThis practice ensures a well-documented, reliable, and programmatic provisioning mechanism that is \nconsistent across all devices devoid of any human errors.\nRecommendation IOTOPS_6.2.1 \u2013 Embed provisioning claims into the devices that are mapped to \napproval authorities recognized by the provisioning service\n\u2022Generate a provisioning claim and embed it into the device at the time of manufacturing.\n24", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "794130ef-b676-469c-b0f6-0f9ed0fec89e": {"__data__": {"id_": "794130ef-b676-469c-b0f6-0f9ed0fec89e", "embedding": null, "metadata": {"page_label": "25", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f5e468d415af474f3f03c377c72f9004d3be693bb0dbfbc143fe6a51bfda49a8", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022AWS IoT Core can generate and securely deliver certi\ufb01cates and private keys to your devices when they \nconnect to AWS IoT for the \ufb01rst time, using AWS IoT \ufb02eet provisioning.\nRecommendation IOTOPS_6.2.2  \u2013 Use programmatic bootstrapping mechanisms if you are bringing your \nown certi\ufb01cates\n\u2022Determine if you will or won\u2019t have device information beforehand\n\u2022If you don\u2019t have device information beforehand, use just-in-time provisioning (JITP).\n\u2022Enable automatic registration and associate a provisioning template with the CA certi\ufb01cate used to \nsign the device certi\ufb01cate.\n\u2022For example, when a device attempts to connect to AWS IoT by using a certi\ufb01cate signed by a \nregistered CA certi\ufb01cate, AWS IoT loads the template from the certi\ufb01cate and initiates the JITP \nwork\ufb02ow.\n\u2022If you have device information beforehand, use bulk registration.\n\u2022Specify a list of single-thing provisioning template values that are stored in a \ufb01le in an S3 bucket.\n\u2022Run the start-thing-registration-task command to register things in bulk. Provide provisioning \ntemplate, S3 bucket name, a key name, and a role ARN to the command.\nBest practice IOTOPS_6.3 \u2013 Use device level features to enable re-provisioning\nA birth or bootstrap certi\ufb01cate is a low-privilege unique certi\ufb01cate that is associated with each device \nduring the manufacturing process. The certi\ufb01cate should have a policy to restrict devices to only allow \nconnecting to speci\ufb01c endpoints to initiate provisioning process and fetch the \ufb01nal certi\ufb01cate. Before a \ndevice is provisioned, it should be limited in functionality to prevent its misuse. Only after a provisioning \nprocess is invoked and approved, should the device be allowed to operate on the system as designed.\nRecommendation IOTOPS_6.3.1 \u2013 Use a certi\ufb01cate bootstrapping process to establish processes for device \nassembly, registration, and activation\n\u2022For example, AWS IoT Core o\ufb00ers a \ufb02eet provisioning interface to devices for upgrading a birth \ncerti\ufb01cate to long-lived credentials that enable normal runtime operations.\nRecommendation IOTOPS_6.3.2 \u2013 Obtain a list of allowed devices from the device manufacturer\n\u2022Check the allow list \ufb01le to validate that the device has been fully vetted by the supplier.\n\u2022Ensure that the list is encrypted, securely stored, and can only be accessed by necessary services and \nusers. Even if the list changes, keep the original list securely stored.\n\u2022Ensure that this list is securely transferred from the manufacturer to you, is encrypted, and is not \npublicly accessible.\n\u2022Ensure that any bootstrap certi\ufb01cate used is signed by a certi\ufb01cate authority (CA) you own or trust.\nBest practice IOTOPS_6.4 \u2013 Use data-driven auditing metrics to detect if any of your IoT devices \nmight have been broadly accessed\nMonitor and detect the abnormal usage patterns and possible misuse of devices and automate the \nquarantine steps. Programmatic methods to detect and quarantine devices from interacting with cloud \nresources enable teams to operate a \ufb02eet in a scalable way while minimizing a dependency on active \nhuman monitoring.\nRecommendation IOTOPS_6.4.1 \u2013 Use monitoring and logging services to detect anomalous behavior\nOnce you detect the compromised device, run programmatic actions to quarantine it.\n25", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a0c9ce45-f84d-447b-8d34-195b5443daca": {"__data__": {"id_": "a0c9ce45-f84d-447b-8d34-195b5443daca", "embedding": null, "metadata": {"page_label": "26", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "fd4e25940c98b179753b6f3d5dc27462a885c319a76ba42b75157af5042a0319", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022Disable the certi\ufb01cate for further investigation and revoke the certi\ufb01cate to prevent the device from \nany future use.\n\u2022Use AWS IoT CloudWatch metrics and logs to monitor for indications of misuse. If you detect misuse, \nquarantine the device so it does not impact the rest of the platform.\n\u2022Use AWS IoT Device Defender to identify security issues and deviations from best practices.\nIOTOPS 7. Do you organize the \ufb02eet to quickly identify devices?\nThe ability to quickly identify and interact with speci\ufb01c devices gives you the agility to troubleshoot \nand potentially isolate devices in case you encounter operational challenges. When operating large-\nscale device \ufb02eets, you need to deploy ways to organize, index, and categorize them. This is useful when \ntargeting new device software with updates and when you need to identify why some devices in your \n\ufb02eet behave di\ufb00erently than others.\nBest practice IOTOPS_7.1 \u2013 Use static and dynamic device hierarchies to support \ufb02eet operations\nUsing a software registry, devices can be categorized into static groups based on their \ufb01xed attributes \n(such as version or manufacturer) and into dynamic groups based on their changing attributes (such \nas battery percentage or \ufb01rmware version). Operationalizing devices in groups can help you manage, \ncontrol, and search for devices more e\ufb03ciently.\nRecommendation IOTOPS_7.1.1 \u2013 Manage several devices at once by categorizing them into static groups \nand hierarchy of groups\n\u2022Build a hierarchy of static groups for e\ufb03cient categorization and indexing of your devices.\n\u2022Use provisioning templates to assign devices to static groups as they are provisioned for the \ufb01rst time.\n\u2022For example, categorize all sensors of a car under a car group and all the cars under a vehicle group. \nChild groups inherit policies and permissions attached to their respective parent groups.\nRecommendation IOTOPS_7.1.2 \u2013 Build a device index to e\ufb03ciently search for devices, and aggregate \nregistry data, runtime data, and device connectivity data\n\u2022Use a \ufb02eet indexing service to index device and group data.\n\u2022Use a device index to search registry metadata, stateful metadata, and device connectivity status \nmetadata.\n\u2022Use a group index to search for groups based on group name, description, attributes, and all parent \ngroup names.\n\u2022For example, if you want to send over-the-air (OTA) updates only to devices that are su\ufb03ciently \ncharged, then de\ufb01ne a dynamic group for devices with more than 90% battery. Devices will \ndynamically be added to or removed from the group as their battery percentage crosses the threshold. \nSend OTA updates to all things under this dynamic group\nBest practice IOTOPS_7.2 \u2013 Use index and search services to enable rapid identi\ufb01cation of target \ndevices\nA large IoT deployment can have millions of sensors sending data to the cloud. A separate indexing \nand search service can make it easy to index and organize the device data, and search for any device \nby any attribute. Ingesting device data to a search service, for example, Amazon OpenSearch Service \n(OpenSearch Service), makes it easy to use powerful search, visualization, and analytics capabilities to \norganize and search for devices. You can ingest your device data and the state to OpenSearch Service \nseamlessly.\n26", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "16d6c94a-ab46-45e9-9274-ba1adda8b6ab": {"__data__": {"id_": "16d6c94a-ab46-45e9-9274-ba1adda8b6ab", "embedding": null, "metadata": {"page_label": "27", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "028521502b43f96f6d931691937d13186ea5f69935708efe4b01ed0702db6999", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nRecommendation IOTOPS_7.2.1 \u2013 Use an indexed data store to get, update, or delete device state\n\u2022Use messaging topics to enable applications and things to get, update, or delete the state information \nfor a Thing (Thing Shadow).\n\u2022Ingest the shadow data to Kinesis Data Firehose through the AWS IoT Core rules engine.\n\u2022Ingest the data from Kinesis Data Firehose to OpenSearch Service through built-in destination options.\n\u2022Con\ufb01gure search and visualizations on the data directly or through the OpenSearch Dashboards \nconsole.\n\u2022For more information:\n\u2022AWS IoT Core - Fleet indexing service\n\u2022AWS IoT Core - AWS IoT Device Shadow service\n\u2022What is Amazon OpenSearch Service?\n\u2022The Internet of Things on AWS \u2013 O\ufb03cial Blog: Archive AWS IoT Device Shadows in Amazon \nOpenSearch Service\n\u2022Analyze device-generated data with AWS IoT and Amazon OpenSearch Service\nIOTOPS 8. How do you monitor the status of your IoT devices?\nYou need to be able to track the status of your devices. This includes operational parameters and \nconnectivity. You need to know whether devices have disconnected intentionally or not. Monitoring \nthe status of your device \ufb02eet is important in helping troubleshoot device software operation and \nconnectivity disruptions.\nBest practice IOTOPS_8.1 \u2013 Collect lifecycle events from the device \ufb02eet\nDesign a state machine for the device connectivity states, from initialization and \ufb01rst connection, to \nfrequent communication (like keep-alive messages) and \ufb01nal state before going o\ufb04ine. Lifecycle events, \nsuch as connection and disconnection, can be used to observe and analyze device behavior over a period \nof time. Additionally, periodic keep-alive messages can track device connectivity status.\nRecommendation IOTOPS_8.1.1 \u2013 Subscribe to lifecycle events and monitor the connections using keep-\nalive messages:\n\u2022Capture messages from the IoT message broker whenever a device connects or disconnects. Being \nable to tell the di\ufb00erence between a clean and dirty disconnect is useful in many scenarios where the \ndevices don\u2019t maintain a constant connection to the broker.\n\u2022Based on the use case and device constraints, have the device send periodic keep-alive messages to \nAWS IoT Core and monitor, and analyze the keep-alive messages for anomalies.\n\u2022Ensure that the frequency of sending keep-alive messages is not causing any network storms (perhaps \nby introducing some jitter) in the network or causing rate limits.\nBest practice IOTOPS_8.2 \u2013 Con\ufb01gure your devices to communicate their status periodically.\nImplement Last Will and Testament (LWT) messages and periodic device keep-alive messages.\nRecommendation IOTOPS_8.2.1 \u2013 Implement a well-designed device connectivity state machine\n\u2022Ensure that the device communicates when it \ufb01rst comes online and just prior to going o\ufb04ine.\n\u2022Implement a wait state for lifecycle events. When a disconnect message is received, wait a period of \ntime and verify that the device is still o\ufb04ine before taking action.\n27", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "59fb1121-3299-4e31-83cb-4f6dfe910636": {"__data__": {"id_": "59fb1121-3299-4e31-83cb-4f6dfe910636", "embedding": null, "metadata": {"page_label": "28", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "fc62abe80fa4566fef2d253edb6acea1459c30f63595e7e799155e25175d77ee", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022Specify the interval with which each connection should be kept open if no messages are received. AWS \nIoT drops the connection after that interval unless the device sends a message or a ping.\nRecommendation IOTOPS_8.2.2 \u2013 Use device connection and disconnection status for anomaly detection\n\u2022Use connectivity data patterns from devices to detect anomalous behavior in their communication \npatterns.\n\u2022For more information:\n\u2022AWS IoT Now Supports WebSockets, Custom Keepalive Intervals, and Enhanced Console\n\u2022AWS IoT Device Defender Now Provides Statistical Anomaly Detection and Data Visualization\n\u2022AWS Solutions Library: Real-Time IoT Device Monitoring with Managed Service for Apache Flink\nBest practice IOTOPS_8.3 \u2013 Use device state management services to detect status and connectivity \npatterns\nEdge and cloud-side management services monitor and analyze parameters, such as device connectivity \nstatus and latency, to help in providing diagnostics and predicting anomalies.\nRecommendation IOTOPS_8.3.1 \u2013 Monitor device state and connectivity patterns\n\u2022Use (or develop as needed) device, gateway, edge, and cloud management tools that allow monitoring \nthe \ufb02eet of devices\n\u2022Use logging and monitoring features at all processing points\u2014device, gateway, edge, and cloud, to get \na complete picture of device connectivity patterns.\nFor more information:\n\u2022AWS IoT Core - Managing thing indexing\nIOTOPS 9. How do you segment your device operations in your IoT application?\nYou need to segment your device \ufb02eet to pinpoint operational challenges and direct incident response \nto the appropriate responder. Device \ufb02eet segmentation enables you to identify conditions under which \ndevices operate sub optimally and minimize response time to security events.\nBest practice IOTOPS_9.1 \u2013 Use static and dynamic device attributes to identify devices with \nanomalous behavior\nAnomalies in \ufb02eet operations might only surface when analyzing metrics that aggregate across the \nboundaries of your static and dynamic groups or attributes. For example, devices that are running \n\ufb01rmware version 2.0.10 and currently have a battery level over 50%. Static and dynamic groups allow for \nidentifying and pinpointing devices in unique ways to monitor, analyze, and take corrective actions on \ndevice behavior.\nRecommendation IOTOPS_9.1.1 \u2013 Pinpoint devices with unusual communication patterns\n\u2022Use a combination of static and dynamic groups of devices to perform \ufb02eet indexing to group devices \nand identify behavioral patterns\u2014connectivity status, message transmission, etc.\n\u2022Use lifecycle events, device connectivity, and data transmission patterns to detect anomalies and \npinpoint unusual behavior using techniques such as statistical anomaly detection (for large \ufb02eet of \ndevices).\n\u2022Once abnormal behavior has been identi\ufb01ed, move rogue and abnormal devices into a di\ufb00erent group \nso that remedial policies can be assigned and implemented on them.\n28", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "17328d74-0d1e-46bb-88fc-dbeef5027a26": {"__data__": {"id_": "17328d74-0d1e-46bb-88fc-dbeef5027a26", "embedding": null, "metadata": {"page_label": "29", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7a53fb4ff8ca2006918066d5c847f460f08babfd0661d3b766152e49e613539f", "text": "IoT Lens AWS Well-Architected Framework\nKey AWS services\nFor more information:\n\u2022AWS IoT Core - Authorization\n\u2022AWS IoT - Device Defender\nKey AWS services\nSeveral services can be used to drive operational excellence for your IoT application. The AWS Device \nQuali\ufb01cation Program for FreeRTOS helps you select hardware components that have been designed \nand tested for AWS IoT interoperability. Quali\ufb01ed hardware can get you to market faster and reduce \noperational friction. AWS IoT Core o\ufb00ers features used to manage the initial onboarding of a device. \nWith AWS IoT Greengrass, you can run any kind of custom compute, such as AWS Lambda functions \nand Docker containers on the device to respond quickly to local events, interact with local resources, \nand process data to minimize the cost of transmitting data to the cloud and simplify remote application \nmanagement. AWS IoT Device Management reduces the operational overhead of performing \ufb02eet-\nwide operations, such as device grouping and searching. In addition, Amazon CloudWatch is used for \nmonitoring IoT metrics, collecting logs, generating alerts, and triggering responses. Other services and \nfeatures that support the three areas of operational excellence are as follows:\n\u2022Preparation: AWS IoT Device Tester (IDT) for FreeRTOS and AWS IoT Greengrass is a test \nautomation tool for connected devices to determine if your devices running FreeRTOS or AWS IoT \nGreengrass can interoperate with AWS IoT Services.\n\u2022Preparation: AWS IoT Core supports provisioning and onboarding your devices in the \ufb01eld, including \nregistering the device identity using just-in-time provisioning, just-in-time registration, or multi-\naccount registration. Devices can then be associated with their metadata and device state using the \ndevice registry and the Device Shadow.\n\u2022Operations : AWS IoT thing groups and \ufb02eet indexing allow you to quickly develop an organizational \nstructure for your devices and search across the current metadata of your devices to perform recurring \ndevice operations. Amazon CloudWatch allows you to monitor the operational health of your devices \nand your application.\n\u2022Operations: AWS IoT Greengrass provides many pre-built capabilities on the device to help you focus \nmostly on their business logic and o\ufb00ers many foundational infrastructure and operation features such \nas remote application management.\n\u2022Responses: AWS IoT Jobs enables you to proactively push updates to one or more devices such as \n\ufb01rmware updates or device con\ufb01guration. AWS IoT rules engine allows you to inspect IoT messages \nas they are received by AWS IoT Core and immediately respond to the data, at the most granular \nlevel. AWS IoT Analytics and AWS IoT Device Defender enable you to proactively trigger noti\ufb01cations \nor remediation based on real-time analysis with AWS IoT Analytics, and real-time security and data \nthresholds with Device Defender.\nResources\nRefer to the following resources to learn more about our best practices for operations:\nDocumentation and blogs:\n\u2022Remote asset health monitoring\n\u2022Monitoring AWS IoT connections in near real time\n\u2022Managing IoT device certi\ufb01cate rotation\n\u2022Con\ufb01guring near real-time noti\ufb01cation for asset-based monitoring with AWS IoT Events\n\u2022Use AWS IoT service logging options to capture error events in CloudWatch Logs\n29", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "38a6fcc4-88a6-403a-8510-8126e7316530": {"__data__": {"id_": "38a6fcc4-88a6-403a-8510-8126e7316530", "embedding": null, "metadata": {"page_label": "30", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3b1bc9d0211c890df02b447dfd57c74d4f0ab01c05ee7e61a42d451b614277df", "text": "IoT Lens AWS Well-Architected Framework\nSecurity\nSecurity pillar\nThe security pillar includes the ability to protect information, systems, and assets while delivering \nbusiness value. This section provides in-depth, best-practice guidance for architecting secure IoT \nworkloads on AWS.\nTopics\n\u2022Design principles  (p. 30)\n\u2022Best practices (p. 31)\n\u2022Key AWS services (p. 49)\n\u2022Resources (p. 50)\nDesign principles\nIn addition to the overall Well-Architected Framework security design principles, there are speci\ufb01c design \nprinciples for IoT security:\n\u2022Manage device security lifecycle holistically: Device security starts at the design phase, and ends \nwith the retirement and destruction of the hardware and data. It is important to take an end-to-end \napproach to the security lifecycle of your IoT solution to maintain your competitive advantage and \nretain customer trust.\n\u2022Ensure least privilege permissions: Devices should all have \ufb01ne-grained access permissions that limit \nwhich topics a device can use for communication. By restricting access, one compromised device will \nhave fewer opportunities to impact any other devices.\n\u2022Secure device credentials at rest: Devices should securely store credential information at rest using \nmechanisms such as a dedicated crypto element or secure \ufb02ash.\n\u2022Implement device identity lifecycle management: Devices maintain a device identity from creation \nthrough end of life. A well-designed identity system will keep track of a device\u2019s identity, track the \nvalidity of the identity, and proactively extend or revoke IoT permissions over time.\n\u2022Take a holistic view of data security: IoT deployments involving a large number of remotely deployed \ndevices present a signi\ufb01cant attack surface for data theft and privacy loss. Use a model such as the\nOpen Trusted Technology Provider Standard to systemically review your supply chain and solution \ndesign for risk and then apply appropriate mitigations.\n\u2022Preserve safety and reliability in critical OT/IIoT environments: IIoT cybersecurity di\ufb00ers from \nthe IT cybersecurity model because it is not only concerned with data protection, but also with the \npreservation of safety and reliability of production systems and ensuring environmental health and \nsafety (EHS) in industrial facilities.\n\u2022Implement zero trust principles as per NIST SP 800-207: Zero trust isn\u2019t limited to traditional IT, \nand extends to IoT, operational technology (OT) and IIoT. A zero-trust model can signi\ufb01cantly improve \nyour organization\u2019s security posture by eliminating the sole reliance on perimeter-based protection. \nThis doesn\u2019t mean getting rid of perimeter security altogether. Where possible, use identity and \nnetwork capabilities together to protect core assets and apply zero trust principles working backwards \nfrom speci\ufb01c use cases with a focus on extracting business value and achieving measurable business \noutcomes.\n\u2022Establish secure connection with AWS via Site-to-Site VPN or Direct Connect from the industrial \nedge\nFor IIoT workloads, AWS o\ufb00ers multiple ways and design patterns to establish a secure connection to \nthe AWS environment from the industrial edge. Establish a secure VPN connection to AWS over the \ninternet or set up a dedicated private connection via Direct Connect. Use AWS VPN with Direct Connect\nto encrypt tra\ufb03c over Direct Connect.\n30", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "c7392cd3-f989-40f9-a962-e977c414b863": {"__data__": {"id_": "c7392cd3-f989-40f9-a962-e977c414b863", "embedding": null, "metadata": {"page_label": "31", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c6a1c6756e8dd77fc3c4b4151101f28cc3c740929959ca4c096a4053b8ee8fef", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022Use VPC Endpoints whenever possible\nFor IIoT workloads, after a secure connection to AWS has been established via VPN over the internet or \nDirect Connect, use VPC Endpoints  whenever possible. VPC Endpoints enables you to privately connect \nto supported regional services without requiring a public IP address. Endpoints also support endpoint \npolicies, which further allow to control and limit access to only the required resources.\n\u2022Use HTTP over TLS proxy and a \ufb01rewall for services connecting to AWS over the internet\nIf the VPC Endpoint for the required service is not available, you would have to establish a secure \nconnection over the internet. The best practice in such a scenario is to route these connections via a \nHTTP connection over a TLS proxy and a \ufb01rewall. Using a proxy allows the cloud tra\ufb03c to be inspected \nand monitored and enables threat and malware detection. It also allows the security policies to be \napplied at the network layer. Firewall rules can be established for HTTPS and MQTT tra\ufb03c to securely \nconnect to AWS IoT services over the public internet.\n\u2022Use secure protocols whenever possible and when using insecure protocols, convert insecure \nprotocols into standardized and secure protocols as close to the source as possible\nIn most environments, prefer to use secure protocols which support encryption. When using secure \nprotocols is not an option, tighten the trust boundaries as described in the next point.\n\u2022Use network segmentation and tighten trust boundaries\nFollow the micro segmentation approach, that is, build small islands of components within a single \nnetwork that communicate only with each other and control the network tra\ufb03c between segments. \nSelect the newer version of industrial protocols which o\ufb00er security features and con\ufb01gure the highest \nlevel of encryption available when using industrial control system (ICS) protocols such as CIP Security, \nModbus Secure, and OPC UA. When using secure industrial protocols is not an option, tighten the trust \nboundary using a protocol converter to translate the insecure protocol to a secure protocol as close to \nthe data source as possible.\nAlternatively, segregate the plant network into smaller cell or area zones by grouping ICS devices \ninto functional areas to limit the scope and area of insecure communications. Use unidirectional \ngateways and data diodes for one-way data \ufb02ow and specialized \ufb01rewall and inspection products \nthat understand ICS protocols to inspect tra\ufb03c entering and leaving cell/area zones and can detect \nanomalous behavior in the control network.\n\u2022Securely manage and access edge computing resources\nKeeping computing resources at the industrial edge up to-date, securely accessing to them for \ncon\ufb01guration and management, or automatically deploying changes can be challenging. AWS provides \noptions to securely manage edge compute resources (AWS System Manager), IoT resources (IoT Device \nManagement, AWS IoT Greengrass) and also provides a fully managed infrastructure service (AWS \nOutposts) to make it easy to consistently apply best practices to all resources.\nBest practices\nThere are \ufb01ve best practice areas for security:\nTopics\n\u2022Identity and access management (p. 32)\n\u2022Detective controls (p. 41)\n31", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "012abdf7-ad5a-4d9b-ac75-c5ab28111b2e": {"__data__": {"id_": "012abdf7-ad5a-4d9b-ac75-c5ab28111b2e", "embedding": null, "metadata": {"page_label": "32", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "add1285dda1e81d47eef0f5995eef82ae1576d24e55d5e81b4ab1083a3c96660", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022Infrastructure protection (p. 43)\n\u2022Data protection (p. 44)\n\u2022Incident response (p. 47)\nThese best practice areas encompass IoT device hardware, as well as the end-to-end solution. IoT \nimplementations require expanding your security model to ensure that devices implement hardware \nsecurity best practices and your IoT applications follow security best practices for factors such as \nadequately scoped device permissions and detective controls.\nThe security pillar focuses on protecting information and systems. Key topics include con\ufb01dentiality and \nintegrity of data, identifying and managing who can do what with privilege management, protecting \nsystems, and establishing controls to detect and respond to security events.\nIdentity and access management\nIoT devices are often a target because they are provisioned with a trusted identity, might store or have \naccess to strategic customer or business data (such as the \ufb01rmware itself), might be remotely accessible \nover the internet, and might be vulnerable to direct physical tampering. To provide protection against \nunauthorized access, you need to always begin with implementing security at the device level. From a \nhardware perspective, there are several mechanisms that you can implement to reduce the attack surface \nof tampering with sensitive information on the device such as:\n\u2022Hardware cryptographic modules\n\u2022Software-supported solutions including secure \ufb02ash\n\u2022Physical function modules that cannot be cloned\n\u2022Up-to-date cryptographic libraries and standards including PKCS #11 and TLS 1.2\nTo secure device hardware, you implement solutions such that private keys and sensitive identity are \nunique to, and only stored on the device in a secure hardware location. Implement hardware or software-\nbased modules that securely store and manage access to the device's private key corresponding to its \npublic key and X.509 certi\ufb01cate. FreeRTOS, AWS IoT Greengrass, and the AWS IoT Device SDKs support \nthis through the use of PKCS#11. In addition to hardware security, IoT devices must be given a valid \nidentity, which will be used for authentication and authorization in your IoT application.\nDuring the lifetime of a device, you will need to be able to manage certi\ufb01cate renewal and revocation, \nupdate device \ufb01rmware and software. To handle any of these changes, you must \ufb01rst have the ability \nto update a device in the \ufb01eld. The ability to perform \ufb01rmware updates, software updates and \ncon\ufb01guration updates on hardware is a vital underpinning to a well-architected IoT application. Through \nOTA updates, you can securely rotate device certi\ufb01cates before expiry including certi\ufb01cate authorities \nand update \ufb01rmware and software.\nFor example, with AWS IoT, you \ufb01rst provision X.509 certi\ufb01cate and then separately create the IoT \npermissions for connecting to IoT, publishing and subscribing to messages, and receiving updates. This \nseparation of identity and permissions provides \ufb02exibility in managing your device security. During the \ncon\ufb01guration of permissions, you can ensure that any device has the right level of identity as well as \nthe right level of access control by creating an IoT policy that restricts access to MQTT actions for each \ndevice.\nEnsure that each device has its own unique X.509 certi\ufb01cate in AWS IoT and that devices never share \ncerti\ufb01cates (one certi\ufb01cate for one device rule). In addition to using a single certi\ufb01cate per device, when \nusing AWS IoT, each device must have its own unique thing in the IoT registry, and the thing name is \nused as the basis for the MQTT ClientID for MQTT connect.\nDevices must support rotation and replacement of certi\ufb01cates to ensure continued operation as \ncerti\ufb01cates expire.\n32", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ce5607c5-b927-4759-bbb0-9a34b9895e96": {"__data__": {"id_": "ce5607c5-b927-4759-bbb0-9a34b9895e96", "embedding": null, "metadata": {"page_label": "33", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "1e261f054881938ab3d7fe8fb56d2e1b869cb1e341207a32345f30bd4981dfac", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nBy creating this association where a single certi\ufb01cate is paired with its own thing in AWS IoT Core, you \ncan ensure that one compromised certi\ufb01cate cannot inadvertently assume an identity of another device. \nIt also alleviates troubleshooting and remediation when the MQTT ClientID and the thing name match \nsince you can correlate any ClientID log message to the thing that is associated with that particular piece \nof communication.\nTo support device identity updates, use AWS IoT Jobs, which is a managed service for distributing OTA \ncommunication and binaries to your devices. AWS IoT Jobs is used to de\ufb01ne a set of remote operations \nthat are sent to and run on one or more devices connected to AWS IoT. AWS IoT Jobs by default \nintegrates several best practices, including mutual authentication and authorization, device tracking of \nupdate progress, and \ufb02eet-wide wide metrics for a given update.\nUse native provisioning mechanisms to onboard devices when they already have a device certi\ufb01cate (and \nassociated private key) on them. For example, you can use just-in-time provisioning (JITP) or just-in-time \nregistration (JITR) that provisions devices in bulk when they \ufb01rst connect to AWS IoT.\nIf the devices cannot use X.509 certi\ufb01cates, or you have an existing \ufb02eet of devices with a proprietary \naccess control mechanism, that requires use of bearer tokens such as OAuth over JWT or SAML tokens, \nuse custom auth mechanisms. For example, when a device attempts to connect to AWS IoT, it sends a \nJWT generated by their identity provider in the HTTP header or query string. The signature is validated \nby AWS IoT custom authorizer and the connection is established.\nIt is important to use a standard set of naming conventions when designing device name and MQTT \ntopics. For example, use the same client identi\ufb01er for the device as the IoT Thing Name. This will also \nallow to include any relevant routing information for the device in the topic namespace.\nEnable AWS IoT Device Defender audits to track device con\ufb01guration, device policies, and checking \nfor expiring certi\ufb01cates in an automated fashion. For example, Device Defender can run audits on a \nscheduled basis and trigger a noti\ufb01cation for expiring certi\ufb01cates. With the combination of receiving \nnoti\ufb01cations of any revoked certi\ufb01cates or pending expiry certi\ufb01cates, you can automatically schedule an \nOTA that can proactively rotate the certi\ufb01cate.\nIOTSEC 1. How do you associate IoT identities and permissions with your devices?\nYour application is responsible for managing how your devices authenticate and authorize their \ninteractions. By creating a process that ensures devices have identity-based permissions for accessing the \nIoT platform, you establish the greatest control for managing device interactions.\nBest practice IOTSEC_1.1 \u2013 Assign unique identities to each IoT device\nWhen a device connects to other devices or cloud services, it must establish trust by authenticating \nusing principals such as X.509 certi\ufb01cates, security tokens, or other credentials. You can \ufb01nd available \noptions from the IoT solution of your choice, and implement device registry and identity stores to \nassociate devices, metadata and user permissions. The solution should enable each device (or Thing) \nto have a unique name (or ThingName) in the device registry, and it should ensure that each device \nhas an associated unique identity principal, such as an X.509 certi\ufb01cate or security token. Identity \nprincipals, such as certi\ufb01cates, should not be shared between devices. When multiple devices use the \nsame certi\ufb01cate, this might indicate that a device has been compromised. Its identity might have been \ncloned to further compromise the system.\nRecommendation IOTSEC_1.1.1 \u2013 Use X.509 client certi\ufb01cates to authenticate over TLS 1.2\nWe recommend that each device be given a unique certi\ufb01cate to enable \ufb01ne-grained management, \nincluding certi\ufb01cate revocation. Devices must support rotation and replacement of certi\ufb01cates to ensure \ncontinued operation as certi\ufb01cates expire. For example, AWS IoT Core supports AWS IoT-generated X.509 \ncerti\ufb01cates or your own X.509 certi\ufb01cates for device authentication.\n33", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3d01798f-5c31-49b9-a74f-a8353d6a5556": {"__data__": {"id_": "3d01798f-5c31-49b9-a74f-a8353d6a5556", "embedding": null, "metadata": {"page_label": "34", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3d61e243e3223d3f63108f75c5305fea03425f978147cbe2e9bedf7a4883ac4d", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nRecommendation IOTSEC_1.1.2 \u2013 Choose the appropriate certi\ufb01cate vending mechanisms for your use \ncase\nWe recommend using native provisioning mechanisms to onboard devices when they already have \na device certi\ufb01cate (and associated private key) on them. For example, you can use just-in-time \nprovisioning (JITP) or just-in-time registration (JITR) that provisions devices in bulk when they \ufb01rst \nconnect to AWS IoT.\nRecommendation IOTSEC_1.1.3 \u2013 Use security bearer tokens for authorizing to the IoT broker\nIf the devices cannot use X.509 certi\ufb01cates, or you have an existing \ufb02eet of devices with a proprietary \naccess control mechanism, that requires use of bearer tokens such as OAuth over JWT or SAML tokens, \nuse custom auth mechanisms. For example, when a device attempts to connect to AWS IoT, it sends a \nJWT generated by their identity provider in the HTTP header or query string. The signature is validated \nby AWS IoT custom authorizer and the connection is established.\nRecommendation IOTSEC_1.1.4 \u2013 Use a consistent naming convention that maps your device identity to \nthe MQTT topics\nIt is important to use a standard set of naming conventions when designing device name and MQTT \ntopics. For example, use the same client identi\ufb01er for the device as the IoT Thing Name. This will also \nallow to include any relevant routing information for the device in the topic namespace.\nIOTSEC 2. How do you secure your devices and protect device credentials?\nYour IoT devices and identity principals (certi\ufb01cates, private keys, tokens, etc.) must be secured \nthroughout their lifecycle. To ensure device authenticity, your IoT hardware must securely store, manage, \nand restrict access to the identities that the device uses to authenticate itself with the cloud. By securing \nyour devices and storing your device credentials safely, you can reduce the risk of unauthorized users \nmisusing device credentials.\nBest practice IOTSEC_2.1 \u2013 Use a separate hardware or a secure area on your devices to store \ncredentials.\nA secure element is any hardware feature you can use to protect the device identity at rest. Secure \nstorage at rest helps reduce the risk of unauthorized use of the device identify. Never store or cache \ndevice credentials outside of the secure element. Generate private keys on the HSM, and generate the \nCerti\ufb01cate Signing Requests from the device. If this is not possible, generate and transmit the credentials \nto the HSM in a secure manufacturing facility with Common Criteria EAL certi\ufb01cation. Securely handling \na device\u2019s identity helps ensure that your hardware and application are resilient to potential security \nissues that occur in unprotected systems. A secure element provides encryption of private information \n(such as cryptographic keys) at rest and can be implemented as separate specialized hardware or as part \nof a system on a chip (SoC).\nRecommendation IOTSEC_2.1.1 \u2013 Use tamper-resistant hardware that o\ufb04oads the security encryption \nand communication from the IoT application.\nDevice credentials always reside in a secure element, which facilitates any usage of the credentials. Using \nthe secure element to facilitate the use of device credentials further limits the risk of unauthorize use. \nAs an example, AWS IoT Greengrass supports using a secure element to store AWS IoT certi\ufb01cates and \nprivate keys.\nRecommendation IOTSEC_2.1.2 \u2013 Use cryptographic API operations with the secure element hardware for \nprotecting the secrets on the device\nEnsure that any security modules are accessed using the latest security protocols. For example, in \nFreeRTOS, use the PKCS#11 APIs provided in the corePKCS11 library for protecting secrets.\n34", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3a53e92f-a683-4a17-ac37-47cc1322b365": {"__data__": {"id_": "3a53e92f-a683-4a17-ac37-47cc1322b365", "embedding": null, "metadata": {"page_label": "35", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "328130f90037e05adc3f4940e3f4a4cc480f9e0d9a5a31f32b1ed8f9172357fe", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nRecommendation IOTSEC_2.1.3 \u2013 Use the AWS Partner Device Catalog to \ufb01nd AWS Partners that o\ufb00er \nhardware security modules .\nIf you are getting devices that have not been deployed in the \ufb01eld, AWS recommends reviewing the \nAWS Partner Device Catalog to \ufb01nd AWS IoT hardware partners that either implement a TPM or a secure \nelement. Use AWS IoT Partners that o\ufb00er quali\ufb01ed secure elements for storing IoT device identities.\nBest practice IOTSEC_2.2 \u2013 Use a trusted platform module (TPM) to implement cryptographic \ncontrols\nGenerally, a TPM is used to hold, secure, and manage cryptographic keys and certi\ufb01cates for services \nsuch as disk encryption, Root of Trust booting, verifying the authenticity of hardware (as well as \nsoftware), and password management. The TPM has the following characteristics:\n1.TPM is a dedicated crypto-processor to help ensure the device boots into a secure and trusted state.\n2.The TPM chip contains the manufacturer\u2019s keys and software for device encryption.\n3.The Trusted Computing Group (TCG) de\ufb01nes hardware-roots-of-trust as part of the trusted platform \nmodule (TPM) speci\ufb01cation.\nA hardware identity refers to an immutable, unique identity for a platform that is inseparable from the \nplatform. A hardware embedded cryptographic key, also referred to as a hardware root of trust, can be \nan e\ufb00ective device identi\ufb01er. Vendors such as Microchip, Texas Instruments, and many others have TPM-\nbased hardware solutions.\nImplementation guidance\nRecommendation IOTSEC_2.2.1 \u2013 Perform cryptographic operations inside the TPM to avoid a third party \ngaining unauthorized access\nAll secret keys from the manufacturer required for secure boot, such as attestation keys, storage keys, \nand application keys, are stored in the secure enclave of the chip. For example, a device running AWS IoT \nGreengrass can be used with an In\ufb01neon OPTIGA TPM.\nRecommendation IOTSEC_2.2.2 \u2013 Use a trusted execution environment (TEE) along with a TPM to act as a \nbaseline defense against rootkits\nTEE is a separate execution environment that provides security services and isolates access to hardware \nand software security resources from the host operating system and applications. Various hardware \narchitectures support TEE such as:\n1.ARM TrustZone divides hardware into secure and non-secure worlds. TrustZone is a separate \nmicroprocessor from the non-secure microprocessor core.\n2.Intel Boot Guard is a hardware-based mechanism that provides a veri\ufb01ed boot, which \ncryptographically veri\ufb01es the initial boot block or uses a measuring process for validation.\nRecommendation IOTSEC_2.2.3 \u2013 Use physical unclonable function (PUF) technology for cryptographic \noperations\nA PUF technology is a physical object that provides a physically de\ufb01ned digital \ufb01ngerprint to serve \nas a unique identi\ufb01er for an IoT device. As a di\ufb00erent class of security primitive, PUFs normally have \na relatively simple structure. It makes them ideal candidates for a\ufb00ordable security solutions for IoT \nnetworks. Generally, a hardware root of trust based on PUF is virtually impossible to duplicate, clone, \nor predict. This makes them suitable for applications such as secure key generation and storage, device \nauthentication, \ufb02exible key provisioning, and chip asset management. For example, refer to AWS Partner \nDevice Catalog, that has various device solutions with PUFs such as LPC54018 IoT Solution by NXP.\nBest practice IOTSEC_2.3 \u2013 Use protected boot and persistent storage encryption\n35", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ce9f010e-2040-4132-8503-6e85612947b3": {"__data__": {"id_": "ce9f010e-2040-4132-8503-6e85612947b3", "embedding": null, "metadata": {"page_label": "36", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8d7c0e426242f1e6f6e57827d86dccead1824a71f738278ee7988009a7bf2392", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nWhen a device performs a secure boot, it validates that the device is not running unauthorized code from \nthe \ufb01lesystem. This helps ensure that the boot process starts from a trusted combination of hardware \nand software, and continues until the host operating system has fully booted and applications are \nrunning.\nChoose devices with TPM (or TEE) for new deployments. Secure boot also ensures that if even a single bit \nin the software boot-loader or application \ufb01rmware is modi\ufb01ed after deployment, the modi\ufb01ed \ufb01rmware \nwill not be trusted, and the device will refuse to run this untrusted code.\nFull disk encryption ensures that the storage and cryptographic elements are secured in absence of \na TPM or secure element. The disk controller needs to ensure that all read accesses to the disk are \ntransparently decrypted at-runtime.\nRecommendation IOTSEC_2.3.1 \u2013 Boot devices using a cryptographically veri\ufb01ed operating system image\nUse digitally signed binaries that have been veri\ufb01ed using an immutable root of trust, such as a master \nroot key (MRK) that\u2019s stored securely in a non-modi\ufb01able memory, to boot devices.\nRecommendation IOTSEC_2.3.2 \u2013 Create separate \ufb01lesystem partitions for the boot-loader and the \napplications\nAs an example, con\ufb01gure the device boot-loader to use a read-only partition, and applications to use a \nseparate writable partition for separation of concerns and reduce the surface area of the attack.\nRecommendation IOTSEC_2.3.3 \u2013 Use encryption utilities provided by the host operating system to \nencrypt the writable \ufb01lesystem\nFor example, use crypt utilities for Linux such as dm-crypt or GPG, and use BitLocker or Amazon Elastic \nFile System (Amazon EFS) for Microsoft Windows.\nRecommendation IOTSEC_2.3.4 \u2013 Use services that enable you to push signed application code from a \ntrusted source to the device\nYou can use AWS IoT Jobs to push signed software binaries from the cloud to the device. For \nmicrocontrollers using FreeRTOS, ensure that the \ufb01rmware images are signed before deployment.\nIOTSEC 3. How do you authenticate and authorize user access to your IoT application?\nAlthough many applications focus on the thing aspect of IoT, in almost all verticals of IoT, there is also \na human component that needs the ability to communicate to and receive noti\ufb01cations from devices. \nFor example, consumer IoT generally requires users to onboard their devices by associating them with an \nonline account. Industrial IoT typically entails the ability to analyze hardware telemetry in near real time. \nIn either case, it's essential to determine how your application will identify, authenticate, and authorize \nusers that require the ability to interact with particular devices.\nControlling user access to your IoT assets begins with identity. Your IoT application must have in place \na store (typically a database) that keeps track of a user's identity and also how a user authenticates \nusing that identity. The identity store might include additional user attributes that can be used at \nauthorization time (for example, user group membership).\nIoT device telemetry data is an example of a securable asset. By treating it as such, you can control the \naccess each user has and audit individual user interactions.\nWhen using AWS to authenticate and authorize IoT application users, you have several options to \nimplement your identity store and how that store maintains user attributes. For your own applications, \nuse Amazon Cognito for your identity store. Amazon Cognito provides a standard mechanism to express \nidentity, and to authenticate users, in a way that can be directly consumed by your app and other AWS \n36", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b02387c7-9b89-4ea3-a892-3edb7698d803": {"__data__": {"id_": "b02387c7-9b89-4ea3-a892-3edb7698d803", "embedding": null, "metadata": {"page_label": "37", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "249f6df74a59cab8922fd87e6e20b78070f4daebf0645b55de667461915956c4", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nservices to make authorization decisions.\u00a0 When using AWS IoT, you can choose from several identity and \nauthorization services including Amazon Cognito Identity Pools, AWS IAM, AWS IoT policies, and AWS IoT \ncustom authorizer to validate tokens (such as JWT, SAML, etc.) for authenticating users.\nFor implementing the decoupled view of telemetry for your users, use a mobile service such as AWS \nAppSync or Amazon API Gateway. With both of these AWS services, you can create an abstraction \nlayer that decouples your IoT data stream from your user\u2019s device data noti\ufb01cation stream. By creating \na separate view of your data for your external users in an intermediary datastore, for example. \nAmazon DynamoDB or Amazon OpenSearch Service, you can use AWS AppSync to receive user-speci\ufb01c \nnoti\ufb01cations based only on the allowed data in your intermediary store. In addition to using external \ndata stores with AWS AppSync, you can de\ufb01ne user speci\ufb01c noti\ufb01cation topics that can be used to push \nspeci\ufb01c views of your IoT data to your external users.\nIf an external user needs to communicate directly to an AWS IoT endpoint, ensure that the user identity \nis either an authorized Amazon Cognito Federated Identity that is associated to an authorized Amazon \nCognito role and a \ufb01ne-grained IoT policy, or uses AWS IoT custom authorizer, where the authorization \nis managed by your own authorization service. With either approach, associate a \ufb01ne-grained policy to \neach user that limits what the user can connect as, publish to, subscribe from, and receive messages from \nconcerning MQTT communication.\nBest practice IOTSEC_3.1 \u2013 Implement authentication and authorization for users accessing IoT \nresources\nIt enables end users with secure access to connected IoT devices and equipment via di\ufb00erent channels \nsuch as web or mobile devices. Without valid authentication and authorization, devices can be subjected \nto compromises or malicious attempts.\nRecommendation IOTSEC_3.1.1 \u2013 Implement an identity store to authenticate users of your IoT \napplication\nImplement an identity and access management solution for end users. This solution should allow end \nusers with temporary, role-based credentials to access the connected devices. For example, you can use \na service like Amazon Cognito to create user pools for authentication. Or, you can use Amazon Cognito \nintegration with SAML or OAuth2.0 compliant identity providers for authentication as well. If you host \nyour own identity store, use AWS IoT custom authorizers to validate tokens (such as JWT or SAML) for \nauthenticating users.\nRecommendation IOTSEC_3.1.2 \u2013 Enable users to be authorized with least privileged access\nAuthorization is the process of granting permissions to an authenticated identity. You grant permissions \nto your end users in AWS IoT Core using data plane and control plane IAM policies through the \nidentity broker. Control plane API allows you to perform administrative tasks like creating or updating \ncerti\ufb01cates, things, rules, and so on. Data plane API allows you send data to and receive data from AWS \nIoT Core. For example, if you are using Amazon Cognito, use federated identities for user authentication. \nIf you are using a di\ufb00erent Identity broker than Amazon Cognito, use AWS IoT custom authorizers to \ninvoke Lambda functions that will create the required IAM policies.\nRecommendation IOTSEC_3.1.3 \u2013 Adopt least privilege when assigning user permissions\nAdopt the least privilege principle and assign only the minimum required permissions to user roles. \nFor example, with Amazon Cognito this can be achieved, by setting up role-based access through IAM \npolicies for authenticated (think of consumers, admins) and unauthenticated users. Consumers or \nunauthenticated users should not be allowed to run destructive actions against IoT services, such as \ndetaching policies, deleting CA, or deleting certi\ufb01cate.\nBest practice IOTSEC_3.2 \u2013 Decouple access to your IoT infrastructure from the IoT applications\nBy decoupling the IoT infrastructure from the end-user IoT applications, you can build an additional layer \nof security and reliability.\n37", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "542252ad-b1ba-488b-8230-baf3f7e74d43": {"__data__": {"id_": "542252ad-b1ba-488b-8230-baf3f7e74d43", "embedding": null, "metadata": {"page_label": "38", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "cd0f461945621ace98c81e503c37a2cdad476c0d3c519b60081c9b4cdfa56c7f", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nRecommendation IOTSEC_3.2.1 \u2013 Use an API layer between the application and IoT layer\nBuild an application interface layer to reduce the blast radius of the IoT data plane from end users. \nFundamentally, the primary interface to IoT data plane is MQTT topics. Protecting the data plane \nessentially means protecting the MQTT topics from unwanted communication. For example, use Amazon \nAPI Gateway or AWS AppSync to provide a REST or GraphQL API interface between the end-user \napplication and the IoT layer. This helps reduce the blast radius of the IoT data plane from end users.\nIOTSEC 4. How do you ensure that least privilege is applied to principals that communicates to \nyour IoT application?\nAfter registering a device and establishing its identity, it might be necessary to seed additional device \ninformation needed for monitoring, metrics, telemetry, or command and control. Each resource requires \nits own assignment of access control rules. By reducing the actions that a device or user can take against \nyour application, and ensuring that each resource is secured separately, you limit the impact that can \noccur if any single identity or resource is used inadvertently.\nIn AWS IoT, create \ufb01ne-grained permissions by using a consistent set of naming conventions in the IoT \nregistry. The \ufb01rst convention is to use the same unique identi\ufb01er for a device as the MQTT ClientID and \nAWS IoT thing name. By using the same unique identi\ufb01er in all these locations, you can easily create an \ninitial set of IoT permissions that can apply to all of your devices using AWS IoT Thing Policy variables. \nThe second naming convention is to embed the unique identi\ufb01er of the device into the device certi\ufb01cate. \nContinuing with this approach, store the unique identi\ufb01er as the CommonName in the subject name of \nthe certi\ufb01cate to use Certi\ufb01cate Policy Variables to bind IoT permissions to each unique device credential.\nBy using policy variables, you can create a few IoT policies that can be applied to all of your device \ncerti\ufb01cates while maintaining least privilege. For example, the IoT policy below would restrict any device \nto connect only using the unique identi\ufb01er of the device (which is stored in the common name) as its \nMQTT ClientID and only if the certi\ufb01cate is attached to the device. This policy also restricts a device to \nonly publish on its individual shadow:\n{ \n    \"Version\": \"2012-10-17\", \n    \"Statement\":  [ \n        { \n            \"Effect\": \"Allow\", \n            \"Action\":  [ \n                \"iot:Connect\" \n            ], \n            \"Resource\":  [ \n                \"arn:aws:iot: us-west-2 :123456789012 :client/\n${iot:Certificate.Subject.CommonName}\" \n            ], \n            \"Condition\": { \n                \"Bool\": { \n                    \"iot:Connection.Thing.IsAttached\": [ \n                        \"true\" \n                    ] \n                } \n            } \n        }, \n        { \n            \"Effect\":\"Allow\", \n            \"Action\": [ \n                \"iot:Publish\" \n            ], \n            \"Resource\": [ \n                \"arn:aws:iot: us-west-2 :123456789012 :topic/$aws/things/\n${iot:Connection.Thing.ThingName}/shadow/update\" \n38", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "cc22a6cf-1ceb-4c37-8fd1-2c68bdc38c06": {"__data__": {"id_": "cc22a6cf-1ceb-4c37-8fd1-2c68bdc38c06", "embedding": null, "metadata": {"page_label": "39", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "08dcf9cda65d75798568d9b4986b89fb488621fa1cbfdb5c2e31f86e36911196", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n            ] \n        } \n    ]\n}\nAttach your device identity (certi\ufb01cate or Amazon Cognito Federated Identity) to the thing in the AWS \nIoT registry using AttachThingPrincipal .\nAlthough these scenarios apply to a single device communicating with its own set of topics and device \nshadows, there are scenarios where a single device needs to act upon the state or topics of other devices. \nFor example, you may be operating an edge appliance in an industrial setting, creating a home gateway \nto manage coordinating automation in the home, or allowing a user to gain access to a di\ufb00erent set of \ndevices based on their speci\ufb01c role. For these use cases, use a known entity, such as a group identi\ufb01er or \nthe identity of the edge gateway as the pre\ufb01x for all of the devices that communicate to the gateway. By \nmaking all of the endpoint devices use the same pre\ufb01x, you can make use of wildcards, \"*\", in your IoT \npolicies. This approach balances MQTT topic security with manageability.\n{ \n    \"Version\": \"2012-10-17\", \n    \"Statement\":  [ \n        { \n            \"Effect\":\"Allow\", \n            \"Action\": [ \n                \"iot:Publish\" \n            ], \n            \"Resource\": [ \n                \"arn:aws:iot: us-west-2 :123456789012 :topic/$aws/things/ edgegateway123-* /\nshadow/update\" \n            ] \n        } \n    ]\n}\nIn the preceding example, the IoT operator would associate the policy with the edge gateway with \nthe identi\ufb01er, edgegateway123 . The permissions in this policy would then allow the edge appliance \nto publish to other Device Shadows that are managed by the edge gateway. This is accomplished \nby enforcing that any connected devices to the gateway all have a thing name that is pre\ufb01xed with \nthe identi\ufb01er of the gateway. For example, a downstream motion sensor would have the identi\ufb01er,\nedgegateway123-motionsensor1 , and therefore can now be managed by the edge gateway while \nstill restricting permissions.\nBest practice IOTSEC_4.1 \u2013 Assign least privilege access to devices\nPermissions (or policies) allow an authenticated identity to perform various control and data plane \noperations against the IoT Broker, such as creating devices or certi\ufb01cates via the control plane, and \nconnecting, publishing, or subscribing via the data plane.\nRecommendation IOTSEC_4.1.1 \u2013 Grant least privileged access to reduce the scope of impact of the \npotential events\nWe recommend using granular device permissions to enable least privileged access, which can help limit \nthe impact of an error or miscon\ufb01guration. De\ufb01ne a mechanism so that devices can only communicate \nwith speci\ufb01c authorized resources, such as MQTT topics. If permissions are generated dynamically, ensure \nthat similar practices are followed. For example, create an AWS IoT policy as a JSON document that \ncontains a statement with the following:\n1.E\ufb00ect, which speci\ufb01es whether the action is allowed or denied.\n2.Action, which speci\ufb01es the action the policy is allowing or denying.\n3.Resource, which speci\ufb01es the resource or resources on which the action is allowed or denied.\n39", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "235bb362-f4f0-4e43-bc11-3b811ba4b893": {"__data__": {"id_": "235bb362-f4f0-4e43-bc11-3b811ba4b893", "embedding": null, "metadata": {"page_label": "40", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "1380408257b64086a5904eba8f6da7951175fa12b2d9db28a3b5aee3b7caf9df", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nRecommendation IOTSEC_4.1.2. \u2013 Consider scaling granular permissions across the IoT \ufb02eet\nWe recommend reusing permissions across principals rather than hardcoding for better manageability \nas it helps you avoid create redundant permissions per device. For example, an AWS IoT policy \nallows access based on various thing attributes such as ThingName , ThingTypeName , and\nThing Attributes . Thus, a device can connect with a client ID (such as foo), only if the \ndevice registry contains the matched device (aka ThingName), such as arn:aws:iot:us-\nwest-2:123456789012 :client/${iot:Connection.Thing.ThingName}  rather than\narn:aws:iot:us-west-2: 123456789012 :client/foo .\nAs another example, an AWS IoT policy also allows access based on various certi\ufb01cate attributes such \nas Subject , Issuer , Subject Alternate Name , Issuer Alternate Name , and Others . Thus, a \ndevice can only publish to a topic that matches with the Certi\ufb01cate ID associated with the device in the \nregistry like arn:aws:iot:us-west-2: 123456789012 :topic/${iot:CertificateId}  rather than\narn:aws:iot:us-west-2: 123456789012 :topic/xxxxxxxxxxx\nIOTSEC 5: How do you manage device certi\ufb01cates, including installation, validation, revocation, \nand rotation?\nTo protect and encrypt data in transit from an IoT device to the cloud, most IoT broker supports TLS-\nbased mutual authentication using X.509 certi\ufb01cates. Device makers must provision a unique identity, \nincluding a unique private key and X.509 certi\ufb01cate, into each device. Certi\ufb01cates are long-lived \ncredentials and managed using a customer-owned Certi\ufb01cate Authority (CA), a third-party CA, or AWS \nPrivate CA. Any hosted CA chosen must provide you the ability to validate, activate, deactivate, and \nrotate certi\ufb01cates.\nSecurity identities are the focal point of device trust and authorization to your IoT application. It's \nvital to be able to manage invalid identities, such as certi\ufb01cates, centrally. An invalid certi\ufb01cate can be \nrevoked, expired, or made inactive. As part of a well-architected application, you must have a process \nfor capturing all invalid certi\ufb01cates, and an automated response based on the state of the certi\ufb01cate \ntrigger. In addition to the ability of capturing the events of an invalid certi\ufb01cate, your devices should \nalso have a secondary means of establishing secure communications to your IoT platform. By enabling a \nbootstrapping pattern as described previously, where two forms of identity are used for a device, you can \ncreate a reliable fallback mechanism for detecting invalid certi\ufb01cates and providing a mechanism for a \ndevice or an administrator to establish trusted, secure communication for remediation.\nA well-architected IoT solution establishes a certi\ufb01cate revocation list (CRL) that tracks all revoked \ndevice certi\ufb01cates or certi\ufb01cate authorities (CAs). Use your own trusted CA for on-boarding devices \nand synchronize your CRL on a regular basis to your IoT application. Your IoT application must reject \nconnections from identities that are no longer valid.\nWith AWS, you do not need to manage your entire PKI on premises. Use AWS Private Certi\ufb01cate \nAuthority (AWS Private CA) to host your CA in the cloud. Or, you can work with an AWS Partner to add \nprecon\ufb01gured secure elements to your IoT device hardware speci\ufb01cation. ACM has the capability to \nexport revoked certi\ufb01cates to a \ufb01le in an S3 bucket. That same \ufb01le can be used to programmatically \nrevoke certi\ufb01cates against AWS IoT Core.\nAnother state for certi\ufb01cates is to be near their expiry date but still valid. The client certi\ufb01cate must \nbe valid for at least the service lifetime of the device. It\u2019s up to your IoT application to keep track of \ndevices near their expiry date and perform an OTA process to update their certi\ufb01cate to a new one with \na later expiry, along with logging information about why the certi\ufb01cate rotation was required for audit \npurposes.\nEnable AWS IoT Device Defender audits related to the certi\ufb01cate and CA expiry. Device Defender \nproduces an audit log of certi\ufb01cates that are set to expire within 30 days. Use this list to \nprogrammatically update devices before certi\ufb01cates are no longer valid. You may also choose to build \n40", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "042b1a07-c587-40ad-9d0b-708d5c8b47e6": {"__data__": {"id_": "042b1a07-c587-40ad-9d0b-708d5c8b47e6", "embedding": null, "metadata": {"page_label": "41", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c09051cca999a52e680a90010bdb9e7f8cf2f277b8a59186e0e8301c782063ab", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nyour own expiry store to manage certi\ufb01cate expiry dates and programmatically query, identify, and \ntrigger an OTA for device certi\ufb01cate replacement or renewal.\nBest practice IOTSEC_5.1 \u2013 Perform certi\ufb01cate lifecycle management\nA certi\ufb01cate lifecycle includes di\ufb00erent phases such as creation, activation, rotation, revocation or expiry. \nAn automated work\ufb02ow can be put in place to identify certi\ufb01cates that needs attention, along with \nremediation actions.\nRecommendation IOTSEC_5.1.1 \u2013 Document your plan for managing certi\ufb01cates\nAs explained previously, X.509 certi\ufb01cates help to establish the identity of devices and encrypts the \ntra\ufb03c from the edge to cloud. Thus, planning the lifecycle management of device certi\ufb01cates is essential. \nEnable auditing and monitoring for compromise or expiration of your device certi\ufb01cates. Determine \nhow frequently you need to rotate device certi\ufb01cates, audit cloud or device-related con\ufb01gurations and \npermissions to ensure that security measures are in place. For example, use AWS IoT Device Defender \nto monitor the health of the device certi\ufb01cates and di\ufb00erent con\ufb01gurations across your \ufb02eet. AWS \nIoT Device Defender can work in conjunction with AWS IoT Jobs to help enable rotate the expired or \ncompromised certi\ufb01cates.\nRecommendation IOTSEC_5.1.2 \u2013 Use certi\ufb01cates signed by your trusted intermediate CA for on-boarding \ndevices\nAs a best practice, the root CA needs to be locked and protected to secure the chain of trust. The device \ncerti\ufb01cates should be generated from an intermediate CA. De\ufb01ne a process to programmatically manage \nintermediate CA certi\ufb01cates as well. For example, enable AWS IoT Device Defender Audit to report on \nyour intermediate CAs that are revoked but device certi\ufb01cates are still active or if the CA certi\ufb01cate \nquality is low. You can thereafter use a security automation work\ufb02ow using mitigation actions in Device \ndefender to resolve the issues.\nRecommendation IOTSEC_5.1.3 \u2013 Secure provisioning claims private keys and disable the certi\ufb01cate in \ncase of misuse and record the event for further investigation\n\u2022Monitor provisioning claims for private keys at all times, including on the device.\nFor example:\n\u2022Use AWS IoT CloudWatch metrics and logs to monitor for indications of misuse. If you detect misuse, \ndisable the provisioning claim certi\ufb01cate so it cannot be used for device provisioning.\n\u2022Use AWS IoT Device Defender to identify security issues and deviations from best practices.\n\u2022For more information:\n\u2022https://docs.aws.amazon.com/iot/latest/developerguide/vulnerability-analysis-and-\nmanagement.html\n\u2022https://aws.amazon.com/blogs/iot/just-in-time-registration-of-device-certi\ufb01cates-on-aws-iot/\nDetective controls\nDue to the scale of data, metrics, and logs in IoT applications, aggregating and monitoring is an \nessential part of a well-architected IoT application. Unauthorized users will probe for bugs in your IoT \napplication and will look to take advantage of individual devices to gain further access into other devices, \napplications, and cloud resources. To operate an entire IoT solution, you will need to manage detective \ncontrols not only for an individual device but also for the entire \ufb02eet of devices in your application. You \nwill need to enable several levels of logging, monitoring, and alerting to detect issues at the device level \nas well as the \ufb02eet-wide level.\nIn a well-architected IoT application, each layer of the IoT application generates metrics and logs. At a \nminimum, your architecture should have metrics and logs related to the physical device, the connectivity \n41", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5024b8f8-3b99-42eb-b11d-3311b18e6df1": {"__data__": {"id_": "5024b8f8-3b99-42eb-b11d-3311b18e6df1", "embedding": null, "metadata": {"page_label": "42", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b3ebd598f19c872ad5ae122a9d99d73069b48a21b5b7c931006c5ec10882d52a", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nbehavior of your device, message input and output rates per device, provisioning activities, authorization \nattempts, and internal routing events of device data from one application to another.\nIOTSEC 6: How do you analyze application logs and device metrics to detect security issues?\nYour device logs and metrics play a critical role in monitoring security behavior of your IoT application. \nThe way you con\ufb01gure your operations, and how anomalies are surfaced in your system will determine \nhow quickly you can react to a security issue. By con\ufb01guring your IoT logs and metrics appropriately, you \ncan proactively mitigate potential security issues in your IoT application.\nIn AWS IoT, you can implement detective controls using AWS IoT Device Defender, CloudWatch Logs, \nAWS IoT Greengrass logs and CloudWatch Metrics. AWS IoT Device Defender processes logs and metrics \nrelated to device behavior and connectivity behaviors of your devices. AWS IoT Device Defender also lets \nyou continuously monitor security metrics from devices and AWS IoT Core for deviations from what you \nhave de\ufb01ned as appropriate behavior for each device or with ML detect to automatically learn normal \ndevice behaviors. Set a default set of thresholds when device behavior or connectivity behavior deviates \nfrom normal activity.\nAugment Device Defender metrics with Amazon CloudWatch Metrics, Amazon CloudWatch Logs \ngenerated by AWS IoT Core, AWS IoT Greengrass logs, and Amazon GuardDuty. These service-level logs \nprovide important insight into activity about not only activities related to AWS IoT Platform services and \nAWS IoT Core protocol usage, but also provide insight into the downstream applications running in AWS \nthat are critical components of your end-to-end IoT application. All Amazon CloudWatch Logs should be \nanalyzed centrally to correlate log information across all sources.\nBest practice IOTSEC_6.1 \u2013 Collect and analyze logs and metrics to capture authorization errors and \nfailures to enable appropriate response\nDevice logs and metrics can provide your organization with the insight to be operationally e\ufb03cient with \nyour IoT workloads by identifying security events, anomalies, and issues from device data. Record error-\nlevel messages from AWS IoT Core to provide operational visibility to potential security issues.\nRecommendation IOTSEC_6.1.1 \u2013 Enable metrics and create alarms that track authorization and error \nmetrics\n\u2022Observe the trends for these AWS IoT metrics: Connect.AuthError, PublishIn.AuthError, \nPublishOut.AuthError and Subscribe.AuthError.\n\u2022Con\ufb01gure CloudWatch alarms for each of the preceding metrics to alarm based on levels higher than \nnormal for your workload.\nBest practice IOTSEC 6.2 \u2013 Alert when on security events, miscon\ufb01guration, and behavior violations \nare detected\nAudit the con\ufb01guration of your devices and detect and alert when a device behavior di\ufb00ers from the \nexpected behavior. It provides visibility into operational data that can indicate potential security issues \nactive in the device \ufb02eet.\nRecommendation IOTSEC_6.2.1 \u2013 Enable metrics to detect security events from the data plane\nCreate a threat model to detect events from security vulnerabilities or device compromises. You can \ndetect events based on con\ufb01gured rules or machine learning (ML) models. For example, create a security \npro\ufb01le in AWS IoT Device Defender, that detects unusual device behavior that might be indicative of a \ncompromise by continuously monitoring high-value security metrics from the device and AWS IoT Core. \nYou can specify normal device behavior for a group of devices by setting up behaviors (rules) for these \n42", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "4cb7b0b5-9eec-4a7f-ae2f-da09ac6fbb69": {"__data__": {"id_": "4cb7b0b5-9eec-4a7f-ae2f-da09ac6fbb69", "embedding": null, "metadata": {"page_label": "43", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8072f9352afc59368307b98a13c4d9d4340816abddf042fae36537141b1008c6", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nmetrics. AWS IoT Device Defender monitors and evaluates each datapoint reported for these metrics \nagainst user-de\ufb01ned behaviors (rules) and alerts you if an anomaly is detected. When you use ML Detect, \nthe feature sets device behaviors automatically with machine learning to monitor device activities.\nRecommendation IOTSEC_6.2.2 \u2013 Enable auditing to check miscon\ufb01gurations\nAudit checks are necessary to determine that device stays con\ufb01gured with required best practices \nthroughout its lifecycle. For instance, its necessary to audit devices regularly on basic checks such \nas logging, shared certi\ufb01cates and unique device IDs. For example, AWS IoT Device Defender \ncan help you to continuously audit security con\ufb01gurations for compliance with security best \npractices and your own organizational security policies. Some of the auditing capabilities \nsupported natively are LOGGING_DISABLED_CHECK , IOT_POLICY_OVERLY_PERMISSIVE_CHECK ,\nDEVICE_CERTIFICATE_SHARED_CHECK , and CONFLICTING_CLIENT_IDS_CHECK .\nRecommendation IOTSEC_6.2.3 \u2013 Ensure alerting on a behavior violation\nEnable alarming or noti\ufb01cations when the device behavior is anomalous based on con\ufb01gured rules or \nML models. For example, AWS IoT Device Defender can alert you with the metric datapoint reported by \nthe device when an ML model \ufb02ags the datapoint as anomalous. This removes the need for you to de\ufb01ne \naccurate behaviors of your devices and helps you get started with monitoring more quickly and easily.\nBest practice IOTSEC_6.3 \u2013 Alert on non-compliant device con\ufb01gurations and remediate using \nautomation\nEnable auditing to continuously assess con\ufb01gurations and metrics on the device. security con\ufb01gurations \ncan be impacted by the passage of time and new threats are constantly emerging. For example, \ncryptographic algorithms once known to provide secure digital signatures for device certi\ufb01cates can be \nweakened by advances in the computing and cryptoanalysis methods.\nRecommendation IOTSEC_6.3.1 \u2013 Ensure regular auditing for identifying con\ufb01guration issues\nAudit checks are necessary to determine that device stays con\ufb01gured with required best practices \nthroughout its lifecycle. For instance, its necessary to audit devices regularly on basic checks such \nas logging, shared certi\ufb01cates and unique device IDs. For example, AWS IoT Device Defender \ncan help you to continuously audit security con\ufb01gurations for compliance with security best \npractices and your own organizational security policies. Some of the auditing capabilities supported \nnatively are LOGGING_DISABLED_CHECK , IOT_POLICY_OVERLY_PERMISSIVE_CHECK ,\nDEVICE_CERTIFICATE_SHARED_CHECK , and CONFLICTING_CLIENT_IDS_CHECK .\nRecommendation IOTSEC_6.3.2 \u2013 Use automation to remediate issues\nInvestigate issues by providing contextual and historical information about the device such as device \nmetadata, device statistics, and historical alerts for the device. For example, you can use AWS IoT Device \nDefender built-in mitigation actions to perform mitigation steps on Audit and Detect alarms such as \nadding things to a thing group, replacing default policy version and updating device certi\ufb01cate. Or you \ncan enable a mitigation action to re-enable logging and publish the \ufb01nding to Amazon SNS should the \nLOGGING_DISABLED_CHECK \ufb01nd that logging is not enabled.\nInfrastructure protection\nDesign time is the ideal phase for considering security requirements for infrastructure protection \nacross the entire lifecycle of your device and solution. By considering your devices as an extension of \nyour infrastructure, you can take into account how the entire device lifecycle impacts your design for \ninfrastructure protection. From a cost standpoint, changes made in the design phase are less expensive \nthan changes made later. From an e\ufb00ectiveness standpoint, data loss mitigations implemented at design \ntime are likely to be more comprehensive than mitigations retro\ufb01tted. Therefore, planning the device \nand solution security lifecycle at design time reduces business risk and provides an opportunity to \nperform upfront infrastructure security analysis before launch.\n43", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6fd73020-5820-4d26-96d5-470c72eeafc1": {"__data__": {"id_": "6fd73020-5820-4d26-96d5-470c72eeafc1", "embedding": null, "metadata": {"page_label": "44", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8395239158f20c9cc36dc8381e08e3a768ee78712863851868b2622205da7a39", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nOne way to approach the device security lifecycle is through supply chain analysis. The IoT supply chain \nincludes the actors, processes and assets that participate in the realization (for example, development, \ndesign, maintenance, patch management) of any IoT device. For example, even a modestly sized IoT \ndevice manufacturer or solution integrator has a large number of suppliers that make up its supply chain, \nwhether directly or indirectly. To maximize solution lifetime and reliability, ensure that you are receiving \nauthentic components.\nSoftware is also part of the supply chain. The production \ufb01rmware image for a device includes drivers \nand libraries from many sources including silicon partners, open-source aggregation sites such as GitHub \nand SourceForge, previous \ufb01rst-party products, and new code developed by internal engineering.\nTo understand the downstream maintenance and support for \ufb01rst-party \ufb01rmware and software, you \nmust analyze each software provider in the supply chain to determine if it o\ufb00ers support and how it \ndelivers patches. This analysis is especially important for connected devices: software bugs are inevitable, \nand represent a risk to your customers because a vulnerable device can be exploited remotely. Your IoT \ndevice manufacturer or solution engineering team must learn about and patch bugs in a timely manner \nto reduce these risks.\nAlthough there is no cloud infrastructure to manage when using AWS IoT services, there are integration \npoints where AWS IoT Core interacts on your behalf with other AWS services. For example, the AWS \nIoT rules engine consists of rules that are analyzed that can trigger downstream actions to other AWS \nservices based on the MQTT topic stream. Since AWS IoT communicates to your other AWS resources, \nyou must ensure that the right service role permissions are con\ufb01gured for your application. The same \napplies for connected devices with AWS IoT Greengrass for cloud services the device needs to talk to.\nAWS o\ufb00ers \ufb02exible ways and design patterns to establish a secure connection to the AWS environment \nfrom the edge. When choosing a secure connection to the AWS environment, take into consideration the \nuse case requirements such as latency and data locality to ensure that the chosen connection solution \nmeets the performance and compliance requirements. Use AWS Systems Manager to carry out routine \nmanagement tasks on edge computing resources, Secure Tunneling for AWS IoT Device Management to \naccess IoT devices behind restricted \ufb01rewalls at remote sites for troubleshooting, con\ufb01guration updates, \nand other operational tasks and AWS IoT Greengrass for secure remote application management. \nTake advantage of on-premises managed infrastructure solutions such as AWS Outposts, AWS Storage \nGateway, AWS Snow Family to simplify management and monitoring.\nData protection\nBefore architecting an IoT application, data classi\ufb01cation, governance, and controls must be designed \nand documented to re\ufb02ect how the data can be persisted in the cloud, and how data should be \nencrypted, whether on a device or between the devices and the cloud. Unlike traditional cloud \napplications, data sensitivity and governance extend to the IoT devices that are deployed in remote \nlocations outside of your network boundary. These techniques are important because they support \nprotecting personally identi\ufb01able data transmitted from devices and complying with regulatory \nobligations.\nDuring the design process, determine how hardware, \ufb01rmware, and data are handled at device end-of-\nlife. Store long-term historical data in the cloud. Store a portion of current sensor readings locally on a \ndevice, namely only the data required to perform local operations. By only storing the minimum data \nrequired on the device, the risk of unintended access is limited.\nIn addition to reducing data storage locally, there are other mitigations that must be implemented at \nthe end of life of a device. First, the device should o\ufb00er a reset option which can reset the hardware and \n\ufb01rmware to a default factory version. Second, your IoT application can run periodic scans for the last \nlogon time of every device. Devices that have been o\ufb04ine for too long a period of time, or are associated \nwith inactive customer accounts, can be revoked. Third, encrypt sensitive data that must be persisted on \nthe device using a key that is unique to that particular device.\nIn IIoT environments, to allow one-way data \ufb02ow, access controls can be applied at the connectivity layer \nusing security appliances such as \ufb01rewalls and data diodes.\n44", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0d7273c6-cb5d-4907-b15d-d142af2291db": {"__data__": {"id_": "0d7273c6-cb5d-4907-b15d-d142af2291db", "embedding": null, "metadata": {"page_label": "45", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "03f46485fad8cb1d70ca2a3410d1fb6106aa9b078dd13ea6dc4e0a8ec8551467", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nIOTSEC 7: How do you ensure that device data is protected at rest and in transit?\nAll tra\ufb03c to and from AWS IoT must be encrypted using Transport Layer Security (TLS). In AWS IoT, \nsecurity mechanisms protect data as it moves between AWS IoT and other devices or AWS services. In \naddition to AWS IoT, you must implement device-level security to protect not only the device\u2019s private \nkey but also the data collected and processed on the device.\nFor embedded development, AWS has several services that abstract components of the application \nlayer while incorporating AWS security best practices by default on the edge. For microcontrollers, AWS \nrecommends using FreeRTOS. FreeRTOS has libraries for Bluetooth LE, TCP/IP, and other protocols. In \naddition, FreeRTOS contains a set of security APIs that allow you to create embedded applications that \nsecurely communicate with AWS IoT.\nFor Linux-based devices, AWS IoT Greengrass can be used to accelerate the development and operations \nof connected device software to extend cloud functionality to the edge of your network. AWS \nIoT Greengrass implements several security features, including mutual X.509 certi\ufb01cate-based \nauthentication with connected devices, AWS IAM policies and roles to manage communication \npermissions between AWS IoT Greengrass and cloud applications, and subscriptions, which are used to \ndetermine how and if data can be routed between connected devices and AWS IoT Greengrass core.\nProtect your data at rest by de\ufb01ning your requirements and implementing controls, including \nencryption, to reduce the risk of unauthorized access or loss. Protect your data in transit by de\ufb01ning your \nrequirements and implementing controls, including encryption, reduces the risk of unauthorized access \nor exposure. By providing the appropriate level of protection for your data in transit, you protect the \ncon\ufb01dentiality and integrity of your IoT data.\nFollow these best practices and check if your workload is well architected.\nBest practice IOTSEC_7.1 \u2013 Use encryption to protect IoT data in transit and at rest\nFor data at rest, the Storage Networking Industry Association (SNIA) de\ufb01nes storage security as \n\u201cTechnical controls, which may include integrity, con\ufb01dentiality and availability controls that protect \nstorage resources and data from unauthorized users and uses.\u201d Thus, it\u2019s required to protect the \ncon\ufb01dentiality of sensitive data, such as the device identity, secrets, or user data, by encrypting it at \nrest. For data in transit, use a secure transport mechanism such as TLS to protect the con\ufb01dentiality and \nintegrity of all data transmitted to and from your devices.\nRecommendation IOTSEC_7.1.1 \u2013 Require the use of device SDKs or client libraries for the device to \ncommunicate to cloud\nCon\ufb01gure the IoT devices to communicate to cloud endpoints only over TLS. For example, use AWS IoT \nGreengrass or FreeRTOS SDKs to secure connectivity from your devices to AWS IoT Core over TLS 1.2.\nRecommendation IOTSEC_7.1.2 \u2013 Encrypt data at rest or secrets on IoT devices\nAs explained previously in section IOTSEC_2.3.3, take advantage of encryption utilities provided by \nthe host operating system to encrypt the data stored at rest in the local \ufb01lesystem. In addition, take \nadvantage of Secure Elements and TPMs. TEEs can add storage protections as well.\nBest practice IOTSEC_7.2 \u2013 Use data classi\ufb01cation strategies to categorize data access based on levels \nof sensitivity\nData classi\ufb01cation and governance is the customer\u2019s responsibility.\n1.Identify and classify data based on sensitivity collected throughout your IoT workload and learn their \ncorresponding business use case.\n45", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a8c8b567-6928-4ab7-b873-9d01340684e5": {"__data__": {"id_": "a8c8b567-6928-4ab7-b873-9d01340684e5", "embedding": null, "metadata": {"page_label": "46", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "9d8542f1c0ef4d76c6edb5cf53d00c4848bf297caa4d48f43857e8034995007a", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n2.Identify and act on opportunities to stop collecting unused data, or adjusting data granularity and \nretention time.\n3.Consider a defense in depth approach and reduce human access to device data.\nSee the following for more details:\n\u2022AWS IoT Greengrass Developer Guide: Manage data streams on the AWS IoT Greengrass core\n\u2022The Internet of Things on AWS \u2013 O\ufb03cial Blog: Designing data\ufb02ows for multi-schema messages in AWS \nIoT Analytics\nRecommendation IOTSEC_7.2.1 \u2013 Implement data classi\ufb01cation strategies for all data stored on devices \nor in the cloud, as well as all data sent over the network. Process data based on the level of sensitivity (for \nexample, highly classi\ufb01ed, or personally identi\ufb01able data.)\nBefore architecting an IoT application, data classi\ufb01cation, governance, and controls must be designed \nand documented to re\ufb02ect how the data can be persisted on the edge or in the cloud, and how data \nshould be encrypted throughout its lifecycle. For example:\n\u2022By using AWS IoT Greengrass stream manager, you can de\ufb01ne policies for storage type, size, and data \nretention on a per-stream basis. For highly classi\ufb01ed data, you can de\ufb01ne a separate data stream.\n\u2022By using AWS IoT Analytics, you can create di\ufb00erent work\ufb02ows for storing classi\ufb01ed data. For highly \nclassi\ufb01ed data, you can de\ufb01ne a separate pipeline and data store.\nBest practice IOTSEC_7.3 \u2013 Protect your IoT data in compliance with regulatory requirements\nData governance is the rules, processes, and behavior that a\ufb00ect the way in which data is used, \nparticularly as it regards openness, participation, accountability, e\ufb00ectiveness, and coherence. Data \ngovernance practices for IoT is important as it enables protecting classi\ufb01ed data and complying with \nregulatory obligations. It helps to determine what data needs protection, or which data needs access \ncontrol.\nSee the following for more information:\n\u2022AWS Cloud Enterprise Strategy Blog: Using a Cloud Center of Excellence (CCOE) to Transform the \nEntire Enterprise\nRecommendation IOTSEC_7.3.1 \u2013 De\ufb01ne speci\ufb01c roles for personnel responsible for implementing IoT \ndata governance\nFor example, there might be a need for new roles to monitor security, from both the functional and \npolicy perspectives, to control data when it moves from IoT environments to the cloud.\nRecommendation IOTSEC_7.3.2 \u2013 De\ufb01ne data governance policies to monitor compliance with approved \nstandards\nFor example, you might de\ufb01ne a policy that requires security credentials to never be hardcoded, even \non edge devices. Thus, only services such as AWS Secrets Manager can retrieve secrets in an encrypted \nmanner.\nRecommendation IOTSEC_7.3.3  \u2013 De\ufb01ne clear responsibilities to drive the IoT data governance process\nMultiple administrative roles can exist for a single system. For instance, you might de\ufb01ne roles for users \nwho can replace defective devices, and separate roles for users who can apply security patches and \nupgrade device \ufb01rmware. Note that roles and responsibilities might change over the lifecycle of your IoT \nsystems.\n46", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b662809d-35e3-4044-9bfc-5b074abaa5ba": {"__data__": {"id_": "b662809d-35e3-4044-9bfc-5b074abaa5ba", "embedding": null, "metadata": {"page_label": "47", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0263aa5b97edfb2ac5c00167ec772f41d2e9198a75cf48db7c5ce51ccd856d28", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nIncident response\nBeing prepared for incident response in IoT requires planning on how you will deal with two types of \nincidents in your workload. The \ufb01rst incident type is an attack against an individual IoT device in an \nattempt to disrupt the performance or impact the device\u2019s behavior. The second incident type is a larger \nscale IoT event, such as network outages and DDoS event. In both scenarios, the architecture of your \nIoT application plays a large role in determining how quickly you will be able to diagnose incidents, \ncorrelate the data across the incident, and then subsequently apply runbooks to the a\ufb00ected devices in \nan automated, reliable fashion.\nFor IoT applications, follow the following best practices for incident responses:\n\u2022IoT devices are organized in di\ufb00erent groups based on device attributes such as location and hardware \nversion.\n\u2022IoT devices are searchable by dynamic attributes, such as connectivity status, \ufb01rmware version, \napplication status, and device health.\n\u2022OTA updates can be staged for devices and deployed over a period of time. Deployment rollouts are \nmonitored and can be automatically aborted if devices fail to maintain the appropriate KPIs.\n\u2022Any update process is resilient to errors, and devices can recover and roll back from a failed software \nupdate.\n\u2022Detailed logging, metrics, and device telemetry are available that contain contextual information \nabout how a device is currently performing and has performed over a period of time.\n\u2022Fleet-wide metrics monitor the overall health of your \ufb02eet and alert when operational KPIs are not \nmet for a period of time.\n\u2022Any individual device that deviates from expected behavior can be quarantined, inspected, and \nanalyzed for potential compromise of the \ufb01rmware and applications.\n\u2022Test incident response procedures on a periodic basis.\nImplement a strategy in which your InfoSec team can quickly identify the devices that need remediation. \nEnsure that the InfoSec team has runbooks that consider \ufb01rmware versioning and patching for device \nupdates. Create automated processes that proactively apply security patches to vulnerable devices as \nthey come online.\nImplement a monitoring solution in the OT, IoT, and IIoT environments to create an industrial network \ntra\ufb03c baseline and monitor anomalies and adherence to the baseline. Collect security logs and analyze \nthem in real-time using dedicated tools, for example, security information and event management \n(SIEM) class solutions such as within a security operation center (SOC). AWS works with a number of OT \nIntrusion Detection System (IDS) and SIEM partners that can be found on AWS Marketplace.\nAt a minimum, your security team should be able to detect an incident on a speci\ufb01c device based on the \ndevice logs and current device behavior. After an incident is identi\ufb01ed, the next phase is to quarantine \nthe device. To implement this with AWS IoT services, you can use AWS IoT thing groups with more \nrestrictive IoT policies along with enabling custom group logging for those devices. This allows you \nto only enable features that relate to troubleshooting, as well as gather more data to understand \nroot cause and remediation. Lastly, after an incident has been resolved, you must be able to deploy a \n\ufb01rmware update to the device to return it to a known state.\nIOTSEC 8: How do you plan the security lifecycle of your IoT devices?\nThe security lifecycle of your IoT devices includes everything, from how you choose your suppliers, \ncontract manufacturers, and other outsourced relationships to how you manage security in your third-\n47", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6bbb7b79-b119-4de8-b320-c0309bed4a66": {"__data__": {"id_": "6bbb7b79-b119-4de8-b320-c0309bed4a66", "embedding": null, "metadata": {"page_label": "48", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "55183d9cbb5e898f54ed430d8bb4674ed496010d036219fd8cbfb2b4cb220e76", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nparty \ufb01rmware and manage security events over time. With visibility into the full spectrum of actors \nand activities in your hardware and software supply chain, you can be better prepared to respond to \ncompliance questions, detect and mitigate events, and avoid common security risks related to third-party \ncomponents.\nBest practice IOTSEC_8.1 \u2013 Build incident response mechanisms to address security events at scale\nThere are several formalized incident management methodologies in common use. The processes \ninvolved in monitoring and managing incident response can be extended to IoT devices. For instance, \nAWS IoT Device Management capabilities provide \ufb02eet analysis and activity tracking to identify potential \nissues, in addition to mechanisms to enable an e\ufb00ective response.\nRecommendation IOTSEC_8.1.1 \u2013 Ensure that IoT devices are searchable by using a device management \nsolution\nDevices should be grouped by dynamic attributes, such as connectivity status, \ufb01rmware version, \napplication status, and device health.\nRecommendation IOTSEC_8.1.2 \u2013 Quarantine any device that deviates from expected behavior\nInspect the device for potential compromise of the con\ufb01gurations, \ufb01rmware or applications using \ndevice logs or metrics. If a compromise is detected, the device can be diagnosed remotely provided \nthat capability exists. For example, con\ufb01gure AWS IoT Secure Tunneling to remotely diagnose a \ufb02eet of \ndevices.\nIf remote diagnosis is not su\ufb03cient or available, the other option is to push a security patch, application \nor \ufb01rmware upgrade to quarantine the device. When sending code to devices, the best practice is to sign \nthe code \ufb01le. This allows devices to detect if the code has been modi\ufb01ed in transit. For example, With \ncode signing for AWS IoT, you can sign code that you create for IoT devices supported by FreeRTOS and \nAWS IoT device management. In addition, the signed code can be valid for a limited amount of time to \navoid further manipulation.\nRecommendation IOTSEC_8.1.3 \u2013 Over-the-air (OTA) updates should be con\ufb01gured and staged for \ndeployment activation during regular maintenance\nWhether it\u2019s a security patch or a \ufb01rmware update, an update to a con\ufb01guration \ufb01le on a device, or a \nfactory reset, you need to know which devices in your \ufb02eet have received and processed any of your \nupdates, either successfully or unsuccessfully. In addition, a staged rollout is recommended to reduce the \nblast radius along with rollout and abort criterias for a failsafe solution. For example, you can use AWS \nIoT Jobs for OTA updates of security patch and device con\ufb01gurations in a staged manner with required \nrollout and abort con\ufb01gurations.\nPractice IOTSEC_8.2 \u2013 Require timely vulnerability noti\ufb01cations and software updates from your \nproviders\nComponents in a device bill of materials (BOM), such as secure elements for certi\ufb01cate storage or \na trusted platform module (TPM), can make use of updatable software components. Some of this \nsoftware might be contained in the Board Support Package (BSP) assembled for your device. You \ncan help to mitigate device-side security issues quickly by knowing where the security-sensitive \nsoftware components are within your device software stack, and by understanding what to expect from \ncomponent suppliers with regard to security noti\ufb01cations and updates.\nRecommendation IOTSEC_8.2.1 \u2013 Ensure that your IoT device manufacturer provides security-related \nnoti\ufb01cations to you, and provides software updates in a timely manner to reduce the associated risks of \noperating hardware or software with known security vulnerabilities\nAsk your suppliers about their product conformance to the Common Criteria for Information Technology \nSecurity Evaluation. In addition, consider using the AWS Partner Device Catalog where you can \ufb01nd \ndevices and hardware to help you explore, build, and go to market with your IoT solutions.\n48", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9b2b4a82-184b-4cad-a3d0-8d3742e8f812": {"__data__": {"id_": "9b2b4a82-184b-4cad-a3d0-8d3742e8f812", "embedding": null, "metadata": {"page_label": "49", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8c5711fcfb095de997a446472710e9f62b0f81e1bbd9362b59dfea4ba1dac504", "text": "IoT Lens AWS Well-Architected Framework\nKey AWS services\nKey AWS services\nThe essential AWS security services in IoT are the AWS IoT registry, AWS IoT Device Defender, AWS \nIdentity and Access Management (IAM), and Amazon Cognito. In combination, these services along \nwith other AWS security services allow you to securely control access to IoT devices, AWS services, IoT \napplications, and resources for your users. The following services and features support IoT security:\nDesign : The AWS Device Quali\ufb01cation Program provides IoT endpoint and edge hardware that has been \npre-tested for interoperability with AWS IoT. Tests include mutual authentication and OTA support for \nremote patching.\nAsset inventory: AWS IoT Device Management can be used as an inventory for IoT devices and AWS \nSystems Manager Inventory can be used to provide visibility into on premises computing resources and \nedge gateways.\nAWS Identity and Access Management (IAM): Device credentials (X.509 certi\ufb01cates, IAM, Amazon \nCognito identity pools and Amazon Cognito user pools, or custom authorization tokens) enable you \nto securely control device and external user access to AWS resources. AWS IoT policies add the ability \nto implement \ufb01ne grained access to IoT devices. ACM Private CA provides a cloud-based approach to \ncreating and managing device certi\ufb01cates. Use AWS IoT thing groups to manage IoT permissions at the \ngroup level instead of individually.\nDetective controls: AWS IoT Device Defender records device communication and cloud side metrics \nfrom AWS IoT Core. AWS IoT Device Defender can automate security responses by sending noti\ufb01cations \nthrough Amazon Simple Noti\ufb01cation Service (Amazon SNS) to internal systems or administrators. \nAWS CloudTrail logs provide administrative actions of your IoT application. Amazon CloudWatch is a \nmonitoring service with integration with AWS IoT Core and can trigger CloudWatch Events to automate \nsecurity responses. CloudWatch captures detailed logs related to connectivity and security events \nbetween IoT edge components and cloud services.\nInfrastructure protection: AWS IoT Core is a cloud service that lets connected devices easily and securely \ninteract with cloud applications and other devices. The AWS IoT rules engine in AWS IoT Core uses IAM \npermissions to communicate with other downstream AWS services. AWS has created a wide selection of \nindustry leading IoT silicon vendors, device manufacturers, and gateway partners who have integrated \nAWS IoT Greengrass into their software and hardware o\ufb00erings. You have the option to store your device \nprivate key on a hardware secure element and store sensitive device information at the edge with AWS \nIoT Greengrass Secrets Manager and encrypt secrets using private keys for root of trust security.\nData protection: AWS IoT includes encryption capabilities for devices over TLS to protect your data in \ntransit. AWS IoT integrates directly with services, such as Amazon S3 and Amazon DynamoDB, which \nsupport encryption at rest. In addition, AWS Key Management Service (AWS KMS) supports the ability for \nyou to create and control keys used for encryption. On devices, you can use AWS edge o\ufb00erings such as \nFreeRTOS, AWS IoT Greengrass, or the AWS IoT Embedded C SDK to support secure communication.\nPatch management: Implement patch management to \ufb01x device vulnerabilities and de\ufb01ne appropriate \nupdate mechanisms for software and \ufb01rmware updates using AWS IoT Device Management Jobs service \nand AWS Systems Manager Patch Manager. Perform deployment of patches only after testing the \npatches in a test environment before implementing them in production and verify the integrity of the \nsoftware before starting to run it ensuring that it comes from a reliable source (signed by the vendor) \nand that it is obtained in a secure manner.\nIncident response : AWS IoT Device Defender allows you to create security pro\ufb01les that can be used to \ndetect deviations from normal device behavior and trigger automated responses including AWS Lambda. \nAWS IoT Device Management should be used to group devices that need remediation and then using \nAWS IoT Jobs to deploy \ufb01xes to devices. AWS Security Hub can be used to aggregate security alerts \nfrom various AWS services and partner products to help you analyze your security trends and identify \nthe highest priority security issues. AWS Security Hub provides you with a comprehensive view of your \nsecurity state within AWS and your compliance with security standards and best practices and enables \n49", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1aea3e2d-7d3c-4ece-977c-064d428bca0f": {"__data__": {"id_": "1aea3e2d-7d3c-4ece-977c-064d428bca0f", "embedding": null, "metadata": {"page_label": "50", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "96a587fe5adf0ee1a0ecd6927e852edf00caed597dd8e697f5187fb99c109dab", "text": "IoT Lens AWS Well-Architected Framework\nResources\nautomated remediation. Security Hub has out-of-the-box integrations with ticketing, chat, Security \nInformation and Event Management (SIEM), Security Orchestration Automation and Response (SOAR), \nthreat investigation, Governance Risk and Compliance (GRC), and incident management tools to provide \nusers with a complete security operations work\ufb02ow.\nBusiness continuity and recovery\nTo backup IoT data at the edge and in the cloud, you can use AWS IoT Greengrass stream manager to \nlocally bu\ufb00er data and send data to local storage destinations and other life cycle management features \navailable in AWS IoT Greengrass to support your data resiliency and backup needs. AWS Backup can be \nused to centrally manage and automate backups across AWS services and on premise IoT systems.\nResources\nRefer to the following resources to learn more about our best practices for security:\nDocumentation and blogs\n\u2022AWS IoT Device Management\n\u2022IoT Security Identity\n\u2022AWS IoT Device Defender\n\u2022IoT Authentication Model\n\u2022MQTT on port 443\n\u2022Assessing OT and IIoT cybersecurity risk\n\u2022Detect Anomalies with Device Defender\n\u2022Implement security monitoring across OT, IIoT and Cloud\n\u2022AWS IoT secure tunneling\n\u2022AWS Systems Manager\n\u2022Plant network to Amazon VPC connectivity options\n\u2022Ten security golden rules for Industrial IoT solutions\n\u2022AWS Security Incident Response Guide\n\u2022AWS Backup\nWhitepapers\n\u2022MQTT Topic Design\n\u2022Security Best Practices in Manufacturing OT\n\u2022Securing Internet of Things (IoT) with AWS\n\u2022Device Manufacturing and Provisioning with X.509 Certi\ufb01cates in AWS IoT Core\nReliability pillar\nThe reliability pillar focuses on the ability to prevent and quickly recover from failures to meet \nbusiness and customer demand. Key topics include foundational elements around setup, cross-project \nrequirements, recovery planning, and change management.\nTopics\n\u2022Design principles  (p. 51)\n\u2022Best practices (p. 51)\n50", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "fc6f3aa7-2ce8-4d7f-bd50-739c4c0860aa": {"__data__": {"id_": "fc6f3aa7-2ce8-4d7f-bd50-739c4c0860aa", "embedding": null, "metadata": {"page_label": "51", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "4f5644a50fed7fc8c18c25d7383b1d3d01fb3b776a398af4bbda897a5d5f3fdd", "text": "IoT Lens AWS Well-Architected Framework\nDesign principles\n\u2022Key AWS services (p. 62)\n\u2022Resources (p. 63)\nDesign principles\nIn addition to the overall Well-Architected Framework design principles, there are three design principles \nfor reliability for IoT:\n\u2022Simulate device behavior at production scale: Create a production-scale test environment that \nclosely mirrors your production deployment. Use a multi-step simulation plan that allows you to test \nyour applications with a more signi\ufb01cant load before your go-live date. During development, ramp \nup your simulation tests over a period of time starting with 10% of overall tra\ufb03c for a single test and \nincrementing over time (that is, 25%, 50%, then 100% of day one device tra\ufb03c). During simulation \ntests, monitor performance and review logs to ensure that the entire solution behaves as expected.\n\u2022Bu\ufb00er message delivery from the IoT rules engine with streams or queues: Use managed services \nto enable high throughput telemetry. By injecting a queuing layer behind high throughput topics, IoT \napplications can manage failures, aggregate messaging, and scale other downstream services.\n\u2022Design for failure and resiliency: It\u2019s essential to plan for resiliency on the device itself. Depending \non your use case, resiliency might entail robust retry logic for intermittent connectivity, ability to roll \nback \ufb01rmware updates, ability to fail over to a di\ufb00erent networking protocol or communicate locally \nfor critical message delivery, running redundant sensors or edge gateways to be resilient to hardware \nfailures, and the ability to perform a factory reset.\nBest practices\nThere are three best practice areas for reliability:\nTopics\n\u2022Foundations (p. 51)\n\u2022Change management  (p. 57)\n\u2022Failure management (p. 59)\nTo achieve reliability, a system must have a well-planned foundation and monitoring in place, with \nmechanisms for handling changes in demand, requirements, or potentially defending a denial of service \nevent. The system should be designed to detect the failure and automatically heal itself.\nFoundations\nIoT devices must continue to operate in some capacity in the face of network or cloud errors. Design \ndevice \ufb01rmware to handle intermittent connectivity or loss in connectivity in a way that is sensitive \nto memory and power constraints. IoT cloud applications must also be designed to handle remote \ndevices that frequently transition between being online and o\ufb04ine to maintain data coherency and scale \nhorizontally over time. Monitor overall IoT utilization and create a mechanism to automatically increase \ncapacity to ensure that your application can manage peak IoT tra\ufb03c.\nTo prevent devices from creating unnecessary peak tra\ufb03c, device \ufb01rmware must be implemented that \nprevents the entire \ufb02eet of devices from attempting the same operations at the same time. For example, \nif an IoT application is composed of alarm systems and all the alarm systems send an activation event at \n9am local time, the IoT application is inundated with an immediate spike from your entire \ufb02eet. Instead, \nyou should incorporate a randomization factor into those scheduled activities, such as timed events \nand exponential back o\ufb00, to permit the IoT devices to more evenly distribute their peak tra\ufb03c within a \nwindow of time.\n51", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8a391d8a-d60b-4a53-971f-91b142dd98f6": {"__data__": {"id_": "8a391d8a-d60b-4a53-971f-91b142dd98f6", "embedding": null, "metadata": {"page_label": "52", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "dccb44db360e8e4972c65a181d910f33e38fceaf0c0249f9e98daee58214ce31", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nIOTREL 01. How do you handle AWS service limits for peaks in your IoT application?\nAWS IoT provides a set of soft and hard limits for di\ufb00erent dimensions of usage. AWS IoT outlines all of \nthe data plane limits on the IoT limits page . Data plane operations (for example, MQTT Connect, MQTT \nPublish, and MQTT Subscribe) are the primary driver of your device connectivity. Therefore, it's important \nto review the IoT limits and ensure that your application adheres to any soft limits related to the data \nplane, while not exceeding any hard limits that are imposed by the data plane.\nThe most important part of your IoT scaling approach is to ensure that you architect around any hard \nlimits because exceeding limits that are not adjustable results in application errors, such as throttling and \nclient errors. Hard limits are related to throughput on a single IoT connection. If you \ufb01nd your application \nexceeds a hard limit, we recommend redesigning your application to avoid those scenarios. This can \nbe done in several ways, such as restructuring your MQTT topics, or implementing cloud-side logic to \naggregate or \ufb01lter messages before delivering the messages to the interested devices.\nSoft limits in AWS IoT traditionally correlate to account-level limits that are independent of a single \ndevice. For any account-level limits, you should calculate your IoT usage for a single device and then \nmultiply that usage by the number of devices to determine the base IoT limits that your application will \nrequire for your initial product launch. AWS recommends that you have a ramp-up period where your \nlimit increases align closely to your current production peak usage with an additional bu\ufb00er. To ensure \nthat the IoT application is not under provisioned:\n\u2022Consult published AWS IoT CloudWatch metrics for all of the limits.\n\u2022Monitor CloudWatch metrics in AWS IoT Core.\n\u2022Alert on CloudWatch throttle metrics, which would signal if you need a limit increase.\n\u2022Set alarms for all thresholds in IoT, including MQTT connect, publish, subscribe, receive, and rule \nengine actions.\n\u2022Ensure that you request a limit increase in a timely fashion, before reaching 100% capacity.\nIn addition to data plane limits, the AWS IoT service has a control plane for administrative APIs. The \ncontrol plane manages the process of creating and storing IoT policies and principals, creating the \nthing in the registry, and associating IoT principals including certi\ufb01cates and Amazon Cognito federated \nidentities. Because bootstrapping and device registration is critical to the overall process, it's important \nto plan control plane operations and limits. Control plane API calls are based on throughput measured \nin requests per second. Control plane calls are normally in the order of magnitude of tens of requests \nper second. It\u2019s important for you to work backward from peak expected registration usage to determine \nif any limit increases for control plane operations are needed. Plan for sustained ramp-up periods for \nonboarding devices so that the IoT limit increases align with regular day-to-day data plane usage.\nTo protect against a burst in control plane requests, your architecture should limit the access to these \nAPIs to only authorized users or internal applications. Implement back-o\ufb00 and retry logic, and queue \ninbound requests to control data rates to these APIs.\nIOTREL 02. What is the strategy for managing ingestion and processing throughput of IoT data to \nother applications?\nAlthough IoT applications have communication that is only routed between other devices, there will \nbe messages that are processed and stored in your application. In these cases, the rest of your IoT \napplication must be prepared to respond to incoming data. All internal services that are dependent upon \nthat data need a way to seamlessly scale the ingestion and processing of the data. In a well-architected \nIoT application, internal systems are decoupled from the connectivity layer of the IoT platform through \n52", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "108aaa77-e612-4ac5-bfbe-b787362e6ed7": {"__data__": {"id_": "108aaa77-e612-4ac5-bfbe-b787362e6ed7", "embedding": null, "metadata": {"page_label": "53", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a22ce92464a99fe8ec383a54193a45b6f5a4146490722e67db50027dd79f1006", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nthe ingestion layer. The ingestion layer is composed of queues and streams that enable durable short-\nterm storage while allowing compute resources to process data independent of the rate of ingestion.\nTo optimize throughput, use AWS IoT rules to route inbound device data to services such as Amazon \nKinesis Data Streams, Amazon Kinesis Data Firehose, or Amazon Simple Queue Service before \nperforming any compute operations. Ensure that all the intermediate streaming points are provisioned \nto handle peak capacity. This approach creates the queueing layer necessary for upstream applications to \nprocess data resiliently.\nIOTREL 03. How do you implement your IoT workload to withstand component and system faults?\nUnderstanding and predicting the fault scenarios in the system helps you to architect for failure \nconditions and use service features to handle them. Therefore, the handling of such predicted system \nfaults and recovering from them should be architected into the system.\nBest practice IOTREL_3.1 \u2013 Use the services provided by your vendors for integration and error \nhandling to withstand component failure\nAn IoT design consists of device software, connectivity and control services, and analytics services. Test \nthe entire IoT environment for resiliency, starting with device \ufb01rmware, data \ufb02ow, the cloud services \nused, and error handling. Vendors have services integrated with each other to provide a simpli\ufb01ed \nintegration and fault handling.\nRecommendation IOTREL_3.1.1 \u2013 Understand and apply the standard libraries available to manage your \ndevice \ufb01rmware\n\u2022Devices can be built on FreeRTOS, which provides connectivity, messaging, power management and \ndevice management libraries that are tested for reliability and designed for ease of use.\nRecommendation IOTREL_3.1.2 \u2013 Use log levels appropriate to the lifecycle stage of your workload\n\u2022AWS IoT logs can be set up per region and per account with the logging level set to DEBUG during \nproduct development phase to provide insights on data \ufb02ow and resources used. This data can be used \nto improve the IoT system security and performance.\n\u2022AWS IoT Secure Tunneling can be used to test and debug devices that are behind a restrictive \ufb01rewall \nin the \ufb01eld.\nIOTREL 04. How do you ensure that all IoT messages are processed?\nData sent from devices should be processed and stored without excessive loss. Services that queue and \ndeliver IoT data to compute and database services should be used to ensure the processing of data. IoT \ndevices send lots of data in small sizes without order, and the cloud application should be able to handle \nthis.\nBest practice IOTREL_4.1 \u2013 Dynamically scale cloud resources with utilization\nThe elastic nature of the cloud can be used to increase and decrease resources on demand. Use the \nability to increase and decrease cloud resources based on data, number of messages and size of \nmessages and number of devices.\nRecommendation IOTREL_4.1.1 \u2013 Know the mechanisms that can be used to monitor cloud resource \nusage and methods to scale the resources\n53", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d7364d04-8a29-460d-86f9-2725a0064930": {"__data__": {"id_": "d7364d04-8a29-460d-86f9-2725a0064930", "embedding": null, "metadata": {"page_label": "54", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7f61596ec1bce624a0ae631b7338c1a3a3f405620f07adf65639bc813f342d71", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022Use Amazon CloudWatch Logs to trigger based on rate of data \ufb02ow to auto-scale cloud resources as \nneeded.\n\u2022Use AWS IoT Rules engine error actions to provision additional cloud resources and message retries as \nneeded.\n\u2022Examine IoT logs for errors in communicating to resources and provision resources based on that data.\n\u2022Use AWS Lambda to automatically scale your application by running code in response to each event.\n\u2022Use automatic scaling where possible. Kinesis Data Streams and Amazon DynamoDB are two services \nthat provide automatic scaling.\nIOTREL 05. How do you ensure that your IoT device operates with intermittent connectivity to the \ncloud?\nIoT solution reliability must also encompass the device itself. Devices are deployed in remote locations \nand deal with intermittent connectivity, or loss in connectivity, due to a variety of external factors that \nare out of your IoT application\u2019s control. For example, if an ISP is interrupted for several hours, how \nwill the device behave and respond to these long periods of potential network outage? Implement \na minimum set of embedded operations on the device to make it more resilient to the nuances of \nmanaging connectivity and communication to AWS IoT Core.\nYour IoT device must be able to operate without internet connectivity. You must implement robust \noperations in your \ufb01rmware to provide the following capabilities:\n\u2022Store important messages durably o\ufb04ine and, once reconnected, send those messages to AWS IoT \nCore.\n\u2022Implement exponential retry and back-o\ufb00 logic when connection attempts fail.\n\u2022If necessary, have a separate failover network channel to deliver critical messages to AWS IoT. This can \ninclude failing over from Wi-Fi to standby cellular network, or failing over to a wireless personal area \nnetwork protocol (such as Bluetooth LE) to send messages to a connected device or gateway.\n\u2022Have a method to set the current time using an NTP client or low-drift real-time clock. A device should \nwait until it has synchronized its time before attempting a connection with AWS IoT Core. If this isn\u2019t \npossible, the system provides a way for a user to set the device\u2019s time so that subsequent connections \ncan succeed.\n\u2022Send error codes and overall diagnostics messages to AWS IoT Core.\n\u2022Con\ufb01gure a AWS IoT Greengrass group to write logs to the local \ufb01le system and to CloudWatch Log\nConnection to the cloud can be intermittent and devices should be designed to handle this. Choose \ndevices with \ufb01rmware designed for intermittent cloud connection and that have the ability to store data \non the device if you cannot a\ufb00ord to lose the data.\nBest practice IOTREL_5.1 \u2013 Synchronize device states upon connection to the cloud\nIoT devices are not always connected to the cloud. Design a mechanism to synchronize device states \nevery time the device has access to the cloud. Synchronizing the device state to the cloud allows the \napplication to get and update device state easily, as the application doesn\u2019t have to wait for the device to \ncome online.\nRecommendation IOTREL_5.1.1 \u2013 Use a digital devices state representation to synchronize device state \nusing the below capabilities:\n\u2022AWS provides device shadow capabilities that can be used to synchronize device state when the device \nconnects to the cloud. The AWS IoT Device Shadow service maintains a shadow for each device that \n54", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8bab5b0a-b53d-4bd2-9321-0532e3e1ef9f": {"__data__": {"id_": "8bab5b0a-b53d-4bd2-9321-0532e3e1ef9f", "embedding": null, "metadata": {"page_label": "55", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f5193e74b37411654695793ba0beacb97e8797e5e0e899257d76fe0321a32972", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nyou connect to AWS IoT and is supported by the AWS IoT Device SDK, AWS IoT Greengrass core, and \nFreeRTOS.\n\u2022Synchronizing device shadows\u00a0\u2013 Device SDKs and the AWS IoT Core take care of synchronizing \nproperty values between the connected device and its device shadow in AWS IoT Core.\n\u2022AWS IoT Greengrass\u00a0\u2013 AWS IoT Greengrass core software provides local shadow synchronization of \ndevices and these shadows can be con\ufb01gured to sync with cloud.\n\u2022FreeRTOS\u00a0\u2013 The FreeRTOS device shadow API operations de\ufb01ne functions to create, update, and delete \nAWS IoT Device Shadows.\nBest practice IOTREL_5.2 \u2013 Use device hardware with su\ufb03cient capacity to meet your data retention \nrequirements while disconnected\nStore important messages durably o\ufb04ine and, once reconnected, send those messages to the cloud. \nDevice hardware should have capabilities to store data locally for a \ufb01nite period of time to prevent any \nloss of information.\nRecommendation IOTREL_5.2.1 \u2013 You can leverage the device edge software capabilities for storing data \nlocally.\n\u2022Using AWS IoT Greengrass for device software can help collect, process, and export data streams, \nincluding when devices are o\ufb04ine.\n\u2022Messages collected on the device are queued and processed in FIFO order.\n\u2022By default, the AWS IoT Greengrass Core stores unprocessed messages destined for AWS Cloud \ntargets in memory.\n\u2022Con\ufb01gure AWS IoT Greengrass to cache messages to the local \ufb01le system so that they persist across \ncore restarts.\n\u2022AWS IoT Greengrass stream manager makes it easier and more reliable to transfer high-volume IoT \ndata to the AWS Cloud.\n\u2022Con\ufb01gure AWS IoT Greengrass core\n\u2022Manage data streams on AWS IoT Greengrass Core\n\u2022AWS IoT Greengrass Developer Guide\n\u2022Run Lambda on AWS IoT Greengrass Core for preprocessing\n\u2022The\u00a0ETL with AWS IoT Extract, Transform, Load with AWS IoT Greengrass Solution Accelerator\u00a0helps to \nquickly set up an edge device with AWS IoT Greengrass to perform extract, transform, and load (ETL) \nfunctions on data gathered from local devices before being sent to AWS.\n\u2022ETL with AWS IoT Greengrass solution accelerator\n\u2022Consider using AWS IoT SiteWise for data coming from disparate industrial equipment\n\u2022The AWS IoT SiteWise connector sends local equipment data in AWS IoT SiteWise. You can use this \nconnector to collect data from multiple OPC Uni\ufb01ed Architecture (UA) servers and publish it to AWS \nIoT SiteWise.\n\u2022AWS IoT SiteWise connector with AWS IoT Greengrass can cache data locally in the event of \nintermittent network connectivity.\n\u2022You can con\ufb01gure the maximum disk bu\ufb00er size used for caching data. If the cache size exceeds the \nmaximum disk bu\ufb00er size, the connector discards the earliest data from the queue.\n\u2022AWS IoT Greengrass: AWS IoT SiteWise connectors\nBest practice IOTREL_5.3 \u2013 Down sample data to reduce storage requirements and network \nutilization\nData should be down sampled where possible to reduce storage in the device and lower transmission \ncosts and reduce network pressure.\n55", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f6f17138-2e2e-4f8c-b654-f5ed779b482c": {"__data__": {"id_": "f6f17138-2e2e-4f8c-b654-f5ed779b482c", "embedding": null, "metadata": {"page_label": "56", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a2aeddc03fc35532ba32cac90340c24027b73d55504121f68a8d712043896f30", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nRecommendation IOTREL_5.3.1 \u2013 Use device edge software capabilities for down sampling\n\u2022Using AWS IoT Greengrass for device software to down sample data.\n\u2022Local Lambda functions can be used on AWS IoT Greengrass to down sample the data before \nsending it to the cloud.\n\u2022ETL with AWS IoT Extract, Transform, Load with AWS IoT Greengrass Solution Accelerator helps to \nquickly set up an edge device with AWS IoT Greengrass to perform extract, transform, and load (ETL) \nfunctions on data gathered from local devices before being sent to AWS.\nBest practice IOTREL_5.4 \u2013 Use an exponential backo\ufb00 with jitter and retry logic to connect remote \ndevices to the cloud\nConsider implementing a retry mechanism for IoT device software. The retry mechanism should have \nexponential backo\ufb00 with a randomization factor built in to avoid retries from multiple devices occurring \nsimultaneously. Implementing retry logic with exponential backo\ufb00 with jitter allows the IoT devices to \nmore evenly distribute their tra\ufb03c and prevent them from creating unnecessary peak tra\ufb03c.\nRecommendation IOTREL_5.4.1 \u2013 Implement logic in the cloud to notify the device operator if a device \nhas not connected for an extended period of time\n\u2022AWS IoT Events can be used to monitor devices remotely.\n\u2022Remote monitoring using AWS IoT Events\nRecommendation IOTREL_5.4.2 \u2013 Use device edge software and the SDK to leverage built-in exponential \nback o\ufb00 logic\n\u2022Exponential backo\ufb00 logic is included in the AWS SDK, including the AWS IoT Device SDK, and edge \nsoftware, such as AWS IoT Greengrass Core and FreeRTOS.\n\u2022AWS SDK handles the exponential back o\ufb00\n\u2022AWS IoT Device SDK for C uses \u201cIOT_MQTT_RETRY_MS_CEILING\u201d for setting maximum retry interval \nlimit.\nRecommendation IOTREL_5.4.3 \u2013 Establish alternate network channels to meet requirements\n\u2022Have a separate failover network channel to deliver critical messages to AWS IoT. Failover channels can \ninclude Wi-Fi, cellular networks, or a wireless personal network.\n\u2022For low latency workload, use AWS Wavelength for 5G devices and AWS Local Zones to keep your \ncloud services closer to the user.\nIOTREL 06. How do you control the frequency of message delivery to the device?\nDevices can be restricted in message processing capacity and messages from the cloud might need to \nbe throttled. The cloud-side message delivery rate might need to be architected based on the type of \ndevices that are connected.\nBest practice IOTREL_6.1 \u2013 Target messages to relevant devices\nDevices receive information from shadow updates, or from messages published to topics they subscribe \nto. Some data are relevant only to speci\ufb01c devices. In those cases, design your workload to send \nmessages to relevant devices only, and to remove any data that is not relevant to those devices.\n56", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "cd276a77-0bfd-4287-836b-a79de8c02bfd": {"__data__": {"id_": "cd276a77-0bfd-4287-836b-a79de8c02bfd", "embedding": null, "metadata": {"page_label": "57", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b3ef7379eed9bdd7e3575eece05e733f3a22ede7ece04e272f8c387aed7d1dd6", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nRecommendation IOTREL_6.1.1 \u2013 Preprocess data to support the speci\ufb01c needs of the device\n\u2022Use AWS Lambda to pre-process the data and hone-in speci\ufb01cally to attributes and variables that are \nneeded by the device to act upon\nBest practice IOTREL_6.2 \u2013 Implement retry and backo\ufb00 logic to support throttling by device type\nRetry and backo\ufb00 logic should be implemented in a controlled manner so that when you need to alter \nthrottling settings per device type, you can easily do it. Using data storage of any chosen kind gives you \n\ufb02exibility on what data to publish down to the device.\nRecommendation IOTREL_6.2.1 \u2013 Use storage mechanisms that enable retry mechanisms\n\u2022Using DynamoDB, you can hold data in key value format where device ID is the key. Retry logic can be \napplied to only certain device IDs.\n\u2022Using Amazon Relational Database Service (Amazon RDS), you have the \ufb02exibility to use a variety of \ndatabase engines. The retry messages can have new real-time data augmented with historic data from \nprevious device interactions stored in Amazon RDS.\n\u2022AWS IoT Events provides state machines with built-in timers to hold back data and retry based on \ntimers.\nChange management\nIOTREL 07. How do you ensure that you can reliably update device \ufb01rmware from your IoT \napplication?\nIt is important to implement the capability to revert to a previous version of your device \ufb01rmware or your \ncloud application in the event of a failed rollout. If your application is well architected, you will capture \nmetrics from the device, as well as metrics generated by AWS IoT Core, AWS IoT Greengrass and AWS IoT \nDevice Defender. You will also be alerted when your device canaries deviate from expected behavior after \nany cloud-side changes. Based on any deviations in your operational metrics, you need the ability to:\n\u2022Version all of the device \ufb01rmware using Amazon S3.\n\u2022Version the manifest or execution steps for your device \ufb01rmware.\n\u2022Implement a known-safe default \ufb01rmware version for your devices to fall back to in the event of an \nerror.\n\u2022Implement an update strategy using cryptographic code-signing, version checking, and multiple non-\nvolatile storage partitions, to deploy software images and rollback.\n\u2022Version all IoT rules engine con\ufb01gurations in CloudFormation.\n\u2022Version all downstream AWS Cloud resources using CloudFormation.\n\u2022Implement a rollback strategy for reverting cloud side changes using CloudFormation and other \ninfrastructure as code tools.\nTreating your infrastructure as code on AWS allows you to automate monitoring and change \nmanagement for your IoT application. Version all of the device \ufb01rmware artifacts and ensure that \nupdates can be veri\ufb01ed, installed, or rolled back when necessary.\nDevices will need new features over time for better user experience and the \ufb01rmware will need to \nbe updated remotely. Devices should be designed to receive and update their \ufb01rmware and the IoT \napplication should be designed to send \ufb01rmware updates and monitor the success of such an update \nsend.\n57", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "02520605-6a51-4736-af7a-f2904f6d12c8": {"__data__": {"id_": "02520605-6a51-4736-af7a-f2904f6d12c8", "embedding": null, "metadata": {"page_label": "58", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3a50265bdb365d74fad1708236b28747d75d49732f914cb7da8e31f24f6cfcc7", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nBest practice IOTREL_7.1 \u2013 Use a mechanism to deploy and monitor \ufb01rmware updates\nWhen performing over-the-air (OTA) updates to remote devices\u2019 \ufb01rmware, we should always ensure that \nthe updates are controlled and reversible to avoid functional impact of the device to the user, or the \ndevice entering a non-recoverable state. Use tools that allow you to deploy and track management tasks \nin your device \ufb02eet.\nRecommendation IOTREL_7.1.1 \u2013 Use a cloud-based update orchestrator to deploy your \ufb01rmware\n\u2022You can use AWS IoT Jobs to send remote actions to one or many devices at once, control the \ndeployment of jobs to your devices, and track the current and past status of job executions for each \ndevice.\n\u2022Using FreeRTOS OTA using AWS IoT Jobs: By using AWS IoT Jobs for FreeRTOS, you have reliability \nand security provided out of the box where OTA update job will send \ufb01rmware to your end device over \nsecure MQTT or HTTPS and system reserved topics are provided to keep track on the status of the job \nschedule.\n\u2022Using custom IoT jobs with AWS IoT connected devices: By using AWS IoT Jobs with one or more \ndevices connected to AWS IoT gives you the ability to track the full roll out of the update.\nBest practice IOTREL_7.2 \u2013 Implement \ufb01rmware rollback capabilities in devices\nAugment hardware with software to hold two versions of \ufb01rmware and the ability to switch between \nthem. Devices can rapidly roll back to older \ufb01rmware if the new \ufb01rmware has issues.\nRecommendation IOTREL_7.2.1 \u2013 Leverage an RTOS with functionality to roll back device \ufb01rmware\nBy combining OTA agents provided by FreeRTOS or using AWS IoT Device SDK, you can create \ufb02exibility \nto hold two versions of \ufb01rmware with the hardware that is capable of storing it.\nBest practice IOTREL_7.3 \u2013 Implement support for incremental updates to target device groups\nIt\u2019s a good practice to test new \ufb01rmware on a small group of devices. Using a smaller group of devices for \n\ufb01rmware updates helps ensure that the \ufb01rmware as well as the upgrade process is well tested before the \nentire \ufb02eet is updated.\nRecommendation IOTREL_7.3.1 \u2013 Use a cloud orchestrator in conjunction with device settings \naugmentation. Cloud services can help you control and manage jobs in tandem with the devices running the \njobs.\n\u2022The AWS IoT Jobs API provides a granular level of control from the cloud to the device for carrying out \n\ufb01rmware update incrementally and roll back as needed.\n\u2022A job document created as part of AWS IoT job details the remote operations the device needs to \nperform. This includes shutting down rollouts based on timeouts, number of updates per device \namong other things. Devices can use this information to reject or accept \ufb01rmware updates.\nBest practice IOTREL_7.4 \u2013 Implement dynamic con\ufb01guration management for devices\nDeploying software changes to devices constitutes a high-risk operation due to the recovery cost \nassociated with remotely deployed devices. When possible, prefer mechanisms for making changes \nusing command-and-control channels to reduce the risk that comes with software deployments and \n\ufb01rmware upgrades. This approach enables you to push some changes to devices while minimizing the \nrisk of entering fault states that require on-premises recovery actions. Con\ufb01guration changes reduces the \namount of bandwidth compared to \ufb01rmware updates.\nRecommendation IOTREL_7.4.1 \u2013 Use cloud tools to command-and-control devices. Changing \ncon\ufb01guration of devices is less error prone and easier to trace back than updating \ufb01rmware.\n58", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "eed1b0f4-d126-4221-b0c3-4bafb995fc79": {"__data__": {"id_": "eed1b0f4-d126-4221-b0c3-4bafb995fc79", "embedding": null, "metadata": {"page_label": "59", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "fdcb31c456ee2205df9d7ffc6bcc5481ac1fa727d51839d49aa0c8926fbc415e", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022Use Secure Tunneling or AWS Systems Manager to facilitate patching of the operating system instead \nof pushing a new image to be loaded on the device.\n\u2022Use Device Shadows to command-and-control devices rather than sending commands directly to \ndevice.\n\u2022Use AWS IoT Device Defender and AWS IoT Device Management jobs to rotate expiring device \ncerti\ufb01cates instead of pushing a new image with updated certi\ufb01cates.\n\u2022Secure Tunneling\n\u2022Device Shadows\n\u2022Device Defender\nFailure management\nIOTREL 08. How do you implement cloud-side mechanisms to control and modify the message \nfrequency to the device?\nBecause IoT is an event-driven workload, your application code must be resilient to handling known and \nunknown errors that can occur as events are permeated through your application. A well-architected IoT \napplication has the ability to log and retry errors in data processing. An IoT application will archive all \ndata in its raw format. By archiving all data, valid and invalid, an architecture can more accurately restore \ndata to a given point in time.\nWith the IoT rules engine, an application can enable an IoT error action. If a problem occurs when \ninvoking an action, the rules engine will invoke the error action. This allows you to capture, monitor, \nalert, and eventually retry messages that could not be delivered to their primary IoT action. We \nrecommend that an IoT error action is con\ufb01gured with a di\ufb00erent AWS service from the primary action. \nUse durable storage for error actions such as Amazon SQS or Amazon Kinesis\nBeginning with the rules engine, your application logic should initially process messages from a queue \nand validate that the schema of that message is correct. Your application logic should catch and log \nany known errors and optionally move those messages to their own dead letter queue (DLQ) for further \nanalysis. Have a catch-all IoT rule that uses Amazon Kinesis Data Firehose and AWS IoT Analytics \nchannels to transfer all raw and unformatted messages into long-term storage in Amazon S3, AWS IoT \nAnalytics data stores, and Amazon Redshift for data warehousing.\nIoT implementations must allow for multiple types of failure at the device level. Failures can be due to \nhardware, software, connectivity, or unexpected adverse conditions. One way to plan for thing failure is \nto deploy devices in pairs, if possible, or to deploy dual sensors across a \ufb02eet of devices deployed over \nthe same coverage area (meshing).\nRegardless of the underlying cause for device failures, if the device can communicate to your cloud \napplication, it should send diagnostic information about the hardware failure to AWS IoT Core using a \ndiagnostics topic. If the device loses connectivity because of the hardware failure, use Fleet Indexing with \nconnectivity status to track the change in connectivity status. If the device is o\ufb04ine for extended periods \nof time, trigger an alert that the device may require remediation.\nDevices can be restricted in message processing capacity and messages from the cloud might need to \nbe throttled. The cloud-side message delivery rate might need to be architected based on the type of \ndevices that are connected to control the frequency of message delivery to the device.\nIOTREL 09. How do you plan for disaster recovery (DR) in your IoT workloads?\n59", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3c772d1a-02fa-4653-b6dc-1a6d90fe8fcd": {"__data__": {"id_": "3c772d1a-02fa-4653-b6dc-1a6d90fe8fcd", "embedding": null, "metadata": {"page_label": "60", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "fbf976f479d19422fc02dc59f507777f9fdde370822d121014a9f7082f2d2021", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nWhen companies run their core production operations and cybersecurity functions in the cloud, it is \nimportant to design resilience at the edge and cloud in IoT systems. IoT implementations must allow for \nloss of internet connectivity, local data storage and processing.\nBest practice IOTREL_9.1 \u2013 Design server software to initiate communication only with devices that \nare online\nCommunication should be server initiated with devices that are online rather than client-server requests. \nThis enables you to design client software to accept commands from the server.\nRecommendation IOTREL_9.1.1 \u2013 Design client software to accept commands from the server\n\u2022FreeRTOS provides pub/sub and shadow library to connected devices.\n\u2022AWS IoT Core provides device shadow capability to persist device states.\n\u2022AWS IoT Device Registry contains a list of devices connected to AWS IoT Core. AWS IoT Device Registry \nlets you manage devices by grouping them.\nBest practice IOTREL_9.2 \u2013 Implement multi-region support for IoT applications and devices\nCloud service providers have the same service in multiple regions. This architecture enables you to divert \ndevice data to a regional endpoint that is in not down. Data consumers should be enabled in all regions \nthat consume the diverted device data.\nRecommendation IOTREL_9.2.1 \u2013 Architect device software to reach multiple regions in case one is not \navailable\n\u2022AWS IoT is available in multiple Regions with di\ufb00erent endpoints. If an endpoint is not available, divert \ndevice tra\ufb03c to a di\ufb00erent endpoint.\n\u2022AWS IoT con\ufb01gurable endpoints can be used with Amazon Route\u00a053 to divert IoT tra\ufb03c to a new \nregional endpoint.\n\u2022AWS IoT Con\ufb01gurable Endpoints\nRecommendation IOTREL_9.2.2 \u2013 Enable device authentication certi\ufb01cates in multiple regions\n\u2022AWS IoT provides devices with authentication certi\ufb01cates to verify on connection. Deploy the device \ncerti\ufb01cates in the Regions where the device will connect.\n\u2022Setup the cloud side IoT data consumers to accept and process data in multiple regions.\n\u2022AWS IoT device registration\nRecommendation IOTREL_9.2.3 \u2013 Use device services in all the regions the device connects to\n\u2022AWS IoT Rules Engine diverts device data to use multiple services. Set up AWS IoT Rules Engine in the \nrespective Regions to divert tra\ufb03c to the appropriate services.\n\u2022Rules for AWS IoT\nBest practice IOTREL_9.3 \u2013 Use edge devices to store and analyze data\nEdge storage can provide additional storage for device data. Data can be stored at the edge during large-\nscale network events and streamed later, when network is available.\nRecommendation IOTREL_9.3.1 \u2013 Use an edge device as a connection point to store and analyze data\n\u2022AWS IoT Greengrass can be used for local processing for serverless functions, containers, messaging, \nstorage, and machine learning inference.\n\u2022Data can be stored in AWS IoT Greengrass and sent to the network when it\u2019s available.\n60", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3524ca56-3321-417f-881f-c3fe0acb0375": {"__data__": {"id_": "3524ca56-3321-417f-881f-c3fe0acb0375", "embedding": null, "metadata": {"page_label": "61", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "94754be6e7e69c528f1826c11b0b93e90082b4097ceba850ef046781dde8f0e5", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022AWS IoT Greengrass Features\nIOTREL 10. How do you provision reliable storage for IoT data that has been sent to the cloud?\nIoT devices send a lot of small messages with no guarantee of delivery order. This data might not be \nimmediately useful, but the data volume is typically low enough to economically store against a future \nneed. It will be bene\ufb01cial to store the data so that the data can processed in order. Stored data can be \nreprocessed as new requirements are developed.\nBest practice IOTREL_10.1 \u2013 Store data before processing\nEnsure that the data from the devices is stored before processing. As new requirements and capabilities \nare added, stored data can be analyzed to meet the new requirements.\nRecommendation IOTREL_10.1.1 \u2013 Use IoT Core Rules Engine to send data to Kinesis Data Firehose to \nbatch and store data on Amazon Simple Storage Service (Amazon S3)\n\u2022IoT Rules Engine can send data to Kinesis Data Firehose to batch and store data on Amazon Simple \nStorage Service (Amazon S3). Intelligent tiering can be enabled on Amazon S3 to reduce storage costs.\n\u2022Understand the latency to access data and choose the Region to store the data in based on device \nlocation.\n\u2022If data will be processed in Amazon EC2 instances, consider using the highly available and low-latency \nAmazon Elastic Block Store (Amazon EBS).\n\u2022NoSQL data can be stored in Amazon DynamoDB, which is a key-value and document database that \ndelivers single-digit millisecond performance at any scale.\nBest practice IOTREL_10.2 \u2013 Have mechanisms in place to compensate when the primary storage \nlocation is unavailable\nThere should be recovery plans for failures in storing and accessing device data in the cloud. Understand \nthe recovery point objective (RPO) and recovery time objective (RTO) needed by your application to \naccess data to be used for analysis.\nRecommendation IOTREL_10.2.1 \u2013 Know how to monitor and take action on cloud storage failures for IoT \ndata\n\u2022AWS Health Dashboard provides noti\ufb01cation and remediation guidance when AWS is experiencing \nevents that might impact you. Storage and access of data can be modi\ufb01ed based on the noti\ufb01cation.\n\u2022Use Amazon CloudWatch Logs to trigger on events on writing and reading data and take appropriate \nerror handling action.\n\u2022Use AWS IoT rules engine error actions to provision data storage to other locations if primary \nstorage is unavailable.\nIOTREL 11. How do you ensure that your device accurately determines UTC?\nA secure device should have a valid certi\ufb01cate. IoT devices use a server certi\ufb01cate to communicate to the \ncloud and the certi\ufb01cate presented uses time for certi\ufb01cate validity. Having reliable and accurate time \nis compulsory to be able to validate certi\ufb01cates. Because IoT data is not ordered, including an accurate \ntimestamp with the data will enhance your analytic capabilities.\n61", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e51cf2c3-e0e1-48c1-b3ec-38991aa3bfe9": {"__data__": {"id_": "e51cf2c3-e0e1-48c1-b3ec-38991aa3bfe9", "embedding": null, "metadata": {"page_label": "62", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0d745b3d48fa3e1a1313e0b562fae8b44bcc6f68d51805927cbeb2775595fc9b", "text": "IoT Lens AWS Well-Architected Framework\nKey AWS services\nBest practice IOTREL_11.1 \u2013 Use NTP to maintain time synchronization on devices\nIoT devices need to have a client to keep track of time\u2014either using Real Time Clock (RTC) or Network \nTime Protocol (NTP) to set the RTC on boot. Failure to provide accurate time to an IoT device could \nprevent it from being able to connect to the cloud.\nRecommendation IOTREL_11.1.1 \u2013 Prefer NTP to RTC when NTP synchronization is available\nMany computers have an RTC peripheral that helps in keeping time. Consider that RTC is prone to \nclock drift of about one second a day, which can result in the device going o\ufb04ine because of certi\ufb01cate \ninvalidity.\nRecommendation IOTREL_11.1.2 \u2013 Use Network Time Protocol for connected applications\n\u2022Select a safe, reliable NTP pool to use, and a one that addresses your security design.\n\u2022Many operating systems include an NTP client to sync with an NTP server\n\u2022If the IoT device is using GNU/Linux, it\u2019s likely to include the ntpd daemon\n\u2022You can import an NTP client to your platform if using FreeRTOS\n\u2022The device\u2019s software needs to include an NTP client and should wait until it has synchronized with an \nNTP server before attempting a connection with AWS IoT Core\n\u2022The system should provide a way for a user to set the device\u2019s time so that subsequent connections \ncan succeed.\n\u2022Use NTP to synchronize RTC on the device to prevent the device from deviating from UTC\n\u2022Chrony is a di\ufb00erent implementation of NTP than what ntpd uses and it\u2019s able to synchronize the \nsystem clock faster and with better accuracy than ntpd. Chrony can be set up as a client and server.\n\u2022https://chrony.tuxfamily.org/\nBest practice IOTREL_11.2 \u2013 Provide devices access to NTP servers\nAn NTP server should be available for clients to use for local time. NTP servers are required by NTP \nclients to synchronize device time and function properly\nRecommendation IOTREL_11.2.2 \u2013 Provide access to NTP services\n\u2022ntp.org \u2013 can be used to synchronize your computer clocks.\n\u2022Amazon Time Sync Service \u2013 a time synchronization service delivered over NTP, which uses a \ufb02eet of \nredundant satellite-connected and atomic clocks in each Region to deliver a highly accurate reference \nclock. This is natively accessible from Amazon EC2 instances and this can be pushed to edge devices.\n\u2022Chrony is a di\ufb00erent implementation of NTP than what ntpd uses and it\u2019s able to synchronize the \nsystem clock faster and with better accuracy than ntpd. Chrony can be set up as a server and client.\nKey AWS services\nUse Amazon CloudWatch to monitor runtime metrics and ensure reliability. Other services and features \nthat support the three areas of reliability are as follows:\nFoundations: AWS IoT Core enables you to scale your IoT application without having to manage the \nunderlying infrastructure. You can scale AWS IoT Core by requesting account level limit increases.\nChange management:  AWS IoT Device Management enables you to update devices in the \ufb01eld \nwhile using Amazon S3 to version all \ufb01rmware, software, and update manifests for devices. AWS \n62", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "65163188-181d-41ce-9f9d-a0b0d242a93b": {"__data__": {"id_": "65163188-181d-41ce-9f9d-a0b0d242a93b", "embedding": null, "metadata": {"page_label": "63", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "cbde89d4c14eb0c416245f68292a327d09c50d76982d54c8f3fa5c58b5b2a5a0", "text": "IoT Lens AWS Well-Architected Framework\nResources\nCloudFormation lets you document your IoT infrastructure as code and provision cloud resources using a \nCloudFormation template.\nFailure management:  Amazon S3 allows you to durably archive telemetry from devices. The AWS IoT \nrules engine Error action enables you to fall back to other AWS services when a primary AWS service is \nreturning errors.\nResilience at the edge: AWS IoT Greengrass o\ufb00ers several features to help support data resiliency and \nbackup needs with features which allow devices to communicate over the local network even after loss \nin internet connectivity, allowing the core to receive messages sent while the core is o\ufb04ine and using \nstream manager to process data locally until the connection is restored and send data to cloud or local \nstorage destinations.\nResources\nRefer to the following resources to learn more about our best practices related to reliability:\nDocumentation and blogs\n\u2022Using Device Time to Validate AWS IoT Server Certi\ufb01cates\n\u2022AWS IoT Core Limits\n\u2022IoT Error Action\n\u2022Fleet Indexing\n\u2022IoT Atlas\n\u2022Resilience in AWS IoT Greengrass\nPerformance e\ufb03ciency pillar\nThe performance e\ufb03ciency pillar focuses on using resources e\ufb03ciently. Key topics include selecting the \nright resource types and sizes based on workload requirements, monitoring performance, and making \ninformed decisions to maintain e\ufb03ciency as business and technology needs evolve. The performance \ne\ufb03ciency pillar focuses on the e\ufb03cient use of resources to meet the requirements and the maintenance \nof that e\ufb03ciency as demand changes and technologies evolve.\nTopics\n\u2022Design principles  (p. 63)\n\u2022Best practices (p. 64)\n\u2022Key AWS services (p. 74)\n\u2022Resources (p. 74)\nDesign principles\nIn addition to the overall Well-Architected Framework performance e\ufb03ciency design principles, there are \nthree design principles for performance e\ufb03ciency for IoT:\n\u2022Use managed services: AWS provides several managed services across databases, compute, and \nstorage which can assist your architecture in increasing the overall reliability and performance.\n\u2022Decouple ingestion and processing: Decouple the connectivity portion of IoT applications from the \ningestion and processing portion in IoT. By decoupling the ingestion layer, your IoT application can \nhandle data in aggregate and can scale more seamlessly by processing multiple IoT messages at once.\n\u2022Use event-driven architectures: IoT systems publish events from devices and permeate those \nevents to other subsystems in your IoT application. Design mechanisms that cater to event-driven \n63", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "38833b59-b4ed-48d0-83a9-4cd209baf87a": {"__data__": {"id_": "38833b59-b4ed-48d0-83a9-4cd209baf87a", "embedding": null, "metadata": {"page_label": "64", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "db0a4055e6b8e36e4de75fe653fc1d43bc3b57e8568e3433f238da4dbcedfb66", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\narchitectures include using queues, message handling, idempotency, dead-letter queues, and state \nmachines.\nBest practices\nThere are four best practice areas for performance e\ufb03ciency:\nTopics\n\u2022Selection (p. 64)\n\u2022Review (p. 66)\n\u2022Monitoring  (p. 66)\n\u2022Tradeo\ufb00s (p. 71)\nUse a data-driven approach when selecting a high-performance architecture. Gather data on all \naspects of the architecture, from the high-level design to the selection and con\ufb01guration of resource \ntypes. By reviewing your choices on a cyclical basis, you will ensure that you are taking advantage \nof the continually evolving AWS services. Monitoring ensures that you are aware of any deviation \nfrom expected performance and allows you to act. Your architecture can make tradeo\ufb00s to improve \nperformance, such as using compression or caching, or relaxing consistency requirements.\nSelection\nWell-Architected IoT solutions are made up of multiple systems and components such as devices, \nconnectivity, databases, data processing, and analytics. In AWS, there are several IoT services, database \no\ufb00erings, and analytics solutions that enable you to quickly build solutions that are well architected \nwhile allowing you to focus on business objectives. AWS recommends that you use a mix of managed \nAWS services that best \ufb01t your workload. The following questions focus on these considerations for \nperformance e\ufb03ciency.\nIOTPERF 01. How do you ensure your IoT application\u2019s performance and have the capabilities to \nmeasure it?\nWhen you select the implementation for your architecture, use a data-driven approach based on the \nlong-term view of your operation. IoT applications align naturally to event driven architectures. Your \narchitecture will combine services that integrate with event-driven patterns such as noti\ufb01cations, \npublishing and subscribing to data, stream processing, and event-driven compute. In the following \nsections, we look at the \ufb01ve main IoT resource types that you should consider (devices, connectivity, \ndatabases, compute, and analytics).\nDevices\nThe optimal embedded software for a particular system will vary based on the hardware footprint of \nthe device. For example, network security protocols, while necessary for preserving data privacy and \nintegrity, can have a relatively large RAM footprint. For intranet and internet connections, use TLS \nwith a combination of a strong cipher suite and minimal footprint. AWS IoT\u00a0supports Elliptic Curve \nCryptography (ECC) for devices connecting to AWS IoT using TLS. A secure software and hardware \nplatform on device should take precedence during the selection criteria for your devices. AWS also has a \nnumber of IoT partners that provide hardware solutions that can securely integrate to AWS IoT.\nIn addition to selecting the right hardware partner, you might choose to use a number of software \ncomponents to run your application logic on the device, including FreeRTOS and AWS IoT Greengrass. \n64", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d75d8e54-13fe-4671-9043-f34c342f8d88": {"__data__": {"id_": "d75d8e54-13fe-4671-9043-f34c342f8d88", "embedding": null, "metadata": {"page_label": "65", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8757ea326c8597264c812c42cb057996e561ed4cd6d0aa5317b43794f39fe014", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nYou can orchestrate native OS processes on speci\ufb01c hardware to improve performance and you also can \nrun containerized workloads for isolation.\nDe\ufb01ning and analyzing key performance metrics for your IoT applications helps you to understand the \nperformance characteristics for your application. Logging and end-to-end application monitoring are key \nto measuring, evaluating, and optimizing the performance of your IoT applications.\nBest practice IOTPERF_1.1 \u2013 Analyze the runtime performance of your application\nApplication performance in production can be di\ufb00erent from what you observe in a controlled test \nenvironment. Actively analyzing the performance of your application based on device health, network \nlatency, and payload size provides insight on how to obtain performance improvements. By using \ndi\ufb00erent types of metrics, the health of each device in a multi-device setting can be obtained.\nRecommendation IOTPERF_1.1.1 \u2013 Analyze connection patterns, sensor data and set up a device security \npro\ufb01le to detect anomalies\n\u2022Measuring changes in connection patterns of devices might indicate some devices having a jittery \nnetwork connection.\n\u2022Comparing device-side timestamps from multiple devices to arrival times on the cloud-side might \nindicate local network latency or additional hops in device path.\n\u2022AWS IoT Device Defender Detect\n\u2022Anomaly detection using AWS IoT\n\u2022Detect anomalies in device metrics\nBest practice IOTPERF_1.2 \u2013 Add timestamps to each message published\nTimestamps (ideally in UTC time) help in determining delays that might occur during the transmission \nof a message from the device to the application. Timestamps can be associated with the message and to \n\ufb01elds contained in the message. If a timestamp is included, the sent timestamp, along with the sensor or \nevent data, is recorded on the cloud-side.\nRecommendation IOTPERF_1.2.1 \u2013 Add timestamps on the server side\n\u2022If the devices lack the capability to add timestamps to the messages, consider using server-side \nfeatures to enrich the messages with timestamps that correspond to receiving the message.\n\u2022For example, AWS IoT Rules SQL language provides a\u00a0timestamp()\u00a0function to generate a timestamp \nwhen the message is received.\nRecommendation IOTPERF_1.2.2 \u2013 Have a reliable time source on the device\n\u2022Without a reliable time source, the timestamp can only be used relative to the speci\ufb01c device. For \nexample:\n\u2022Devices should use the Network Time Protocol (NTP) to obtain a reliable time when connected.\n\u2022Real Time Clock (RTC) devices can be used to maintain an accurate time while the device lacks \nnetwork connectivity.\n\u2022Depending on the application, timestamps can be added at the message level or at the single payload \n\ufb01eld level. Delta encoding can be used to reduce the size of the message when multiple timestamps \nare included. Choosing the right approach is a trade-o\ufb00 between accuracy, energy e\ufb03ciency, and \npayload size.\n\u2022Developer Guide \u2013 timestamp()\n\u2022Time series compression algorithms\n65", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "4b10c00e-57b2-40db-b7a4-8fb11f199cb6": {"__data__": {"id_": "4b10c00e-57b2-40db-b7a4-8fb11f199cb6", "embedding": null, "metadata": {"page_label": "66", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "26598c9c5c4bebf7e87cec27f4ad6649e853e2899f7b5428ade5c48a5837345a", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022Delta encoding\nBest practice IOTPERF_1.3 \u2013 Load test your IoT applications\nApplications can be complex and have multiple dependencies. Testing the application under load helps \nidentify problems before going into production. Load testing your IoT applications ensures that you \nunderstand the cloud-side performance characteristics and failure modes of your IoT architecture. \nTesting helps you understand how your application architecture operates under load, identify any \nperformance bottlenecks, and apply mitigating strategies prior to releasing changes to your production \nsystems.\nRecommendation IOTPERF_1.3.1 \u2013 Simulate the real device behavior\n\u2022A device simulator should implement the device behavior as closely as possible. Test not only message \npublishing, but also connections, reconnections, subscriptions, enrollment and other environmental \ndisruptive events. Start testing at a lower load, and progressively increase to 100%.\n\u2022Start the load test at a low percent of your estimated total device \ufb02eet, for example, 10%.\n\u2022Evaluate the performance of your application using operational dashboards created to measure end-\nto-end delivery of device telemetry data and automated device commands.\n\u2022Make any necessary changes to the application architecture to achieve desired performance goals.\n\u2022Iterate these steps increasing the load until you get to 100%.\n\u2022IoT Device Simulator\n\u2022From testing to scaling\nReview\nWhen building complex IoT solutions, you can devote a large percentage of time on e\ufb00orts that do not \ndirectly impact your business outcome. These e\ufb00orts include managing IoT protocols, securing device \nidentities, and transferring telemetry between devices and the cloud. Although these aspects of IoT are \nimportant, they do not directly lead to di\ufb00erentiating value. The pace of innovation in IoT can also be a \nchallenge.\nAWS regularly releases new features and services based on the common challenges of IoT. Perform \na periodic review of your data to see if new AWS IoT services can solve a current IoT gap in your \narchitecture, or if they can replace components of your architecture that are not core business \ndi\ufb00erentiators. Use services built to aggregate your IoT data, store your data, and then later visualize \nyour data to implement historical analysis. You can use a combination of sending timestamp information \nfrom your IoT device using services, such as AWS IoT Analytics, and time-based indexing to archive your \ndata with associated timestamp information. Data in AWS IoT Analytics can be stored in an S3 bucket \nalong with additional IT or OT operational and e\ufb03ciency logs from your devices. By combining this \narchival state of data in IoT with visualization tools, you can make data driven decisions about how new \nAWS services can provide additional value and measure how those services improve e\ufb03ciency across \nyour \ufb02eet.\nMonitoring\nIoT applications can be simulated using production devices set up as test devices (with a speci\ufb01c test \nMQTT namespace), or by using simulated devices. All incoming data captured using the IoT rules engine \nis processed using the same work\ufb02ows that are used for production.\nThe frequency of end-to-end simulations must be driven by your speci\ufb01c release cycle or device \nadoption. You should test failure pathways (code that is only run during a failure) to ensure that the \nsolution is resilient to errors. You should also continually run device canaries against your production \nand pre-production accounts. The device canaries act as key indicators of the system performance during \n66", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1ace74c1-a0db-4332-87fb-bfb1562dab76": {"__data__": {"id_": "1ace74c1-a0db-4332-87fb-bfb1562dab76", "embedding": null, "metadata": {"page_label": "67", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "85619f928dd5a51fe1015272949ee5a49bbdf8cd4e67dbf8f26dcff995a4a999", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nsimulation tests. Outputs of the tests should be documented and remediation plans should be drafted. \nUser acceptance tests should be performed.\nThere are several key types of performance monitoring related to IoT deployments including device, \ncloud performance, and storage/analytics. Create appropriate performance metrics using data collected \nfrom logs with telemetry and command data. Start with basic performance tracking and build on those \nmetrics as your business core competencies expand.\nUse CloudWatch Logs metric \ufb01lters to transform your IoT application standard output into custom \nmetrics through regex (regular expressions) pattern matching. Create CloudWatch alarms based on your \napplication\u2019s custom metrics to gain quick insight into your IoT application\u2019s behavior.\nSet up \ufb01ne-grained logs to track speci\ufb01c thing groups. During IoT solution development, enable DEBUG\nlogging for a clear understanding of the progress of events about each IoT message as it passes from \nyour devices through the message broker and the rules engine. In production, change the logging to\nERROR  and WARN .\nIn addition to cloud instrumentation, you must run instrumentation on devices prior to deployment \nto ensure that the devices make the most e\ufb03cient use of their local resources, and that \ufb01rmware code \ndoes not lead to unwanted scenarios such as memory leaks. Deploy code that is highly optimized for \nconstrained devices and monitor the health of your devices using device diagnostic messages published \nto AWS IoT from your embedded application.\nIoT connectivity\nIOTPERF 02. How do you ensure your IoT device\u2019s performance and have mechanisms to measure \nit?\nBefore \ufb01rmware is developed to communicate to the cloud, implement a secure, scalable connectivity \nplatform to support the long-term growth of your devices over time. Based on the anticipated volume \nof devices, an IoT platform must be able to scale the communication work\ufb02ows between devices and the \ncloud, whether that is simple ingestion of telemetry or command and response communication between \ndevices.\nYou can build your IoT application using AWS services such as Amazon EC2, but you take on the \nundi\ufb00erentiated heavy lifting for building unique value into your IoT o\ufb00ering. Therefore, AWS \nrecommends that you use AWS IoT Core for your IoT platform.\nAWS IoT Core supports HTTP, WebSockets, LoRaWAN, and MQTT. MQTT is a lightweight communication \nprotocol designed to tolerate intermittent connections, minimize the code footprint on devices, and \nreduce network bandwidth requirements.\nDe\ufb01ning and analyzing key performance metrics for your hardware devices helps you to understand \nthe performance characteristics of the devices and how they relate to the application performances. \nCapturing device logs and device metrics are key to measuring, evaluating, and optimizing the \nperformance of your IoT devices.\nBest practice IOTPERF_2.1 \u2013 Capture device diagnostic data into the IoT platform\nAs the number of devices increases, watch out for performance bottlenecks when all the devices connect \nto the cloud-side. These devices could generate a large aggregate amount of data, and obtaining device \ndiagnostics is critical for ensuring the understanding of the area of improvement. Using di\ufb00erent types \nof device diagnostics, the immediate health of a device and those in proximity to that device can be \nobtained.\nRecommendation IOTPERF_2.1.1 \u2013 Deploy an agent to the device to start capturing the relevant \ndiagnostic data\n67", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ddcba91a-faca-4059-bbc3-46b2236e4f63": {"__data__": {"id_": "ddcba91a-faca-4059-bbc3-46b2236e4f63", "embedding": null, "metadata": {"page_label": "68", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "6b32d26e272229809e9c20942e90924645fc54db06a0bac788fdbb3e241dcc6e", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022For microprocessor-based applications, consider deploying the AWS Systems Manager Agent (SSM \nAgent) so that you can continuously monitor your device\u2019s performance metrics.\n\u2022There are sample agents provided to use on the device-side (device or gateway). If device-side \ndiagnostic metrics cannot be obtained, then it is possible to obtain limited cloud-side metrics. Below \nare some sample metrics:\n\u2022TCP connections\n\u2022TCP_connections\n\u2022Connections\n\u2022Local_interface\n\u2022Listening TCP/UDP ports\n\u2022Listening_TCP/UDP_ports\n\u2022Interface\n\u2022Network statistics\n\u2022Bytes_in/out\n\u2022Packets_in/out\n\u2022Network_statistics\n\u2022Use custom metrics  to de\ufb01ne and monitor metrics that are unique to your \ufb02eet or use case.\nBest practice IOTPERF_2.2 \u2013 Measure, evaluate, and optimize \ufb01rmware updates\nFirmware updates are critical to ensure that the IoT devices remain performant over time, but might not \nalways have the expected impact. As you deploy \ufb01rmware updates to your devices, monitoring your KPIs \nwill ensure that the updates do not have any unintended impacts to the performance of your hardware \ndevices or to your IoT applications.\nRecommendation IOTPERF_2.2.1 \u2013 Implement canary deployment for device \ufb01rmware\n\u2022Deploy new \ufb01rmware to a limited set of devices and monitor the impact on performance before rolling \nthe update out to the entire \ufb02eet. Abort deployment if degradation is detected.\n\u2022Use AWS IoT Jobs to manage OTA updates and con\ufb01gure it to deploy to a limited set of devices.\n\u2022After the update, evaluate end-to-end performance of the system using your previously identi\ufb01ed \nKPIs.\n\u2022If performance characteristics appear to have been impacted after the \ufb01rmware release, use AWS IoT \nSecure Tunneling, a feature of AWS IoT Device Management, to remotely troubleshoot the device.\n\u2022Release additional \ufb01rmware updates to remediate identi\ufb01ed issues.\n\u2022For more information:\n\u2022The Internet of Things on AWS \u2013 O\ufb03cial Blog \u2013 Using Continuous Jobs with AWS IoT Device \nManagement\n\u2022The Internet of Things on AWS \u2013 O\ufb03cial Blog \u2013 Using Device Jobs for Over-the-Air Updates\n\u2022The Internet of Things on AWS \u2013 O\ufb03cial Blog \u2013 Introducing Secure Tunneling for AWS IoT Device \nManagement, a new secure way to troubleshoot IoT devices\nBest practice IOTPERF_2.3 \u2013 Limit the number of messages that devices receive and \ufb01lter out\nFirmware updates are critical, and \ufb01ltering messages at the edge might subject the devices to \nunnecessary load. This result could be counterproductive from a power and memory consumption \nperspective. Sending only messages that the device makes use of reduces the load on the resources and \nensures better performances.\nRecommendation IOTPERF_2.3.1 \u2013 Structure the topics using the scope/verb approach.\n68", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b1da7218-e574-4f34-8005-8ccb7247dc28": {"__data__": {"id_": "b1da7218-e574-4f34-8005-8ccb7247dc28", "embedding": null, "metadata": {"page_label": "69", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d357246352d8bd0522f3de6da123b0b6f31ccffc28d55393b0c2f1cabef4bec7", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nIn this way, you can subscribe to all messages for a given scope (for example, a device) or re\ufb01ne the \nsubscription on a given scope and verb.\nResources\nRelated documents\n\u2022Designing MQTT Topics for AWS IoT Core\nIOTPERF 03. How do you ensure that your application operates within the limits set by the AWS \nservice?\nDatabases\nYou will have multiple databases in your IoT application, each selected for attributes such as the write \nfrequency of data to the database, the read frequency of data from the database, and how the data is \nstructured and queried. There are other criteria to consider when selecting a database o\ufb00ering:\n\u2022Volume of data and retention period.\n\u2022Intrinsic data organization and structure.\n\u2022Users and applications consuming the data (either raw or processed) and their geographical location \nand dispersion.\n\u2022Advanced analytics needs, such as machine learning or real-time visualizations.\n\u2022Data synchronization across other teams, organizations, and business units.\n\u2022Security of the data at the row, table, and database levels.\n\u2022Interactions with other related data-driven events such as enterprise applications, drill-through \ndashboards, or systems of interaction.\nAWS has several database o\ufb00erings that support IoT solutions. For structured data, you should use \nAmazon Aurora, a highly scalable relational interface to organizational data. For semi-structured data \nthat requires low latency for queries and will be used by multiple consumers, use Amazon DynamoDB, \na fully managed, multi-Region, multi-master database that provides consistent single-digit millisecond \nlatency, and o\ufb00ers built-in security, backup and restore, and in-memory caching.\nFor storing raw, unformatted event data, use AWS IoT Analytics. AWS IoT Analytics \ufb01lters, transforms, \nand enriches IoT data before storing it in a time series data store for analysis.\u00a0Use Amazon SageMaker \nto build, train, and deploy machine learning models, based o\ufb00 of your IoT data, in the cloud and on the \nedge using AWS IoT services, such as machine learning inference in AWS IoT Greengrass. Consider storing \nyour raw formatted time series data in a data warehouse solution such as Amazon Redshift. Unformatted \ndata can be imported to Amazon Redshift using Amazon S3 and Amazon Kinesis Data Firehose. By \narchiving unformatted data in a scalable, managed data storage solution, you can begin to gain business \ninsights, explore your data, and identify trends and patterns over time.\nIn addition to storing and leveraging the historical trends of your IoT data, you must have a system that \nstores the current state of the device and provides the ability to query against the current state of all of \nyour devices. This supports internal analytics and customer facing views into your IoT data.\nThe AWS IoT Device Shadow service is an e\ufb00ective mechanism to store a virtual representation of your \ndevice in the cloud. AWS IoT Device Shadow service is best suited for managing the current state of each \ndevice. In addition, for internal teams that need to query against the shadow for operational needs, \nleverage the managed capabilities of \ufb02eet indexing, which provides a searchable index incorporating \nyour IoT registry and shadow metadata. If there is a need to provide index-based searching or \ufb01ltering \ncapability to a large number of external users, such as for a consumer application, dynamically archive \n69", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e21b6fd7-d52b-4f46-88a9-ba5b129f2e08": {"__data__": {"id_": "e21b6fd7-d52b-4f46-88a9-ba5b129f2e08", "embedding": null, "metadata": {"page_label": "70", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "355bf0139d3d3a4a98b2c1fcf7c214a5c97704e02f102ed60d9698d55dff483c", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nthe shadow state using a combination of the IoT rules engine, Kinesis Data Firehose, and Amazon \nOpenSearch Service to store your data in a format that allows \ufb01ne grained query access for external \nusers.\nIOTPERF 04. How do you bootstrap devices to use the endpoint with least latency?\nIn IoT, bootstrapping refers to the process of assigning identity to the device and enabling \ncommunications with an endpoint. Devices in a global \ufb02eet should be provisioned in the regional data \ncenter nearest to its physical location for minimum latency. Each device should get its regional endpoint \nand certi\ufb01cate no later than the time of bootstrapping. Each device is provisioned nearest to its physical \nlocation and gets the certi\ufb01cate and IoT endpoint at the time of bootstrapping. This ensures best \npossible latency for bidirectional communications.\nCompute\nIoT applications lend themselves to a high \ufb02ow of ingestion that requires continuous processing over the \nstream of messages. Therefore, an architecture must choose compute services that support the steady \nenrichment of stream processing and the execution of business applications during and prior to data \nstorage.\nThe most common compute service used in IoT is AWS Lambda, which allows actions to be invoked when \ntelemetry data reaches AWS IoT Core or AWS IoT Greengrass. AWS Lambda can be used at di\ufb00erent \npoints throughout IoT. The location where you elect to launch your business logic with AWS Lambda is \nin\ufb02uenced by the time that you want to process a speci\ufb01c data event.\nAmazon EC2 instances can also be used for a variety of IoT use cases. They can be used for managed \nrelational databases systems and for a variety of applications, such as web, reporting, or hosting existing \non-premises solutions.\nAnalytics\nThe primary business case for implementing IoT solutions is to respond more quickly to how devices are \nperforming and being used in the \ufb01eld. By acting directly on incoming telemetry, businesses can make \nmore informed decisions about which new products or features to prioritize, or how to more e\ufb03ciently \noperate work\ufb02ows within their organization. Analytics services must be selected in such a way that gives \nyou varying views on your data based on the type of analysis you are performing. AWS provides several \nservices that align with di\ufb00erent analytics work\ufb02ows including time-series analytics, real-time metrics, \narchival, and data lake use cases.\nWith IoT data, your application can generate time-series analytics in addition to the steaming data \nmessages. You can calculate metrics over time windows and then stream values to other AWS services.\nIn addition, IoT applications that use AWS IoT Analytics can implement a managed AWS Data Pipeline \nconsisting of data transformation, enrichment, and \ufb01ltering before storing data in a time series data \nstore. Additionally, with AWS IoT Analytics, visualizations and analytics can be performed natively using \nQuickSight and Jupyter Notebooks.\nIOTPERF 05. How do you ensure that your applications operate within the limits set by the AWS \nservice?\nBeing aware of the soft and hard quotas of the AWS service and continuously monitoring the key \nperformance indicators enables you to anticipate when actions must be taken to request increases in \nthe service quotas and re-evaluate your architecture. Ensuring that your application operates within the \nquotas of the services that you are building on is key to providing the optimal performance to your users.\n70", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2b6772e8-5e09-4481-ac10-a60bd84aea3d": {"__data__": {"id_": "2b6772e8-5e09-4481-ac10-a60bd84aea3d", "embedding": null, "metadata": {"page_label": "71", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "51bbb31ba5601ac655022b1678a630814ba7cb10e05e57cb139c6fe5f83ad47c", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nBest practice IOTPERF_5.1 \u2013 Monitor and manage your IoT service quotas using available tools and \nmetrics\nMonitoring enables you to be aware of which service quotas you might be reaching, allowing you to \nchange your application to cope with the hard quotas or to request the increase of a soft quota with \nsu\ufb03cient lead time.\nRecommendation IOTPERF_5.1.1 \u2013 Familiarize yourself with the service quotas of the di\ufb00erent IoT \nservices\n\u2022Pay attention to which limits are soft quotas and which are hard quotas as they require di\ufb00erent \napproaches.\n\u2022For example:\n\u2022A hard quota, such a control plane request rate, would require changes in the application behavior \nto avoid the event repeating too often. Workarounds for hard quotas might require di\ufb00erent design \ndecisions, such as using multiple accounts. It\u2019s good to know the hard and soft quotas in advance so \nthat you can make these design decisions as early as possible in the development process.\n\u2022Soft quotas should be monitored to anticipate the need for additional capacity and provide \nsu\ufb03cient notice so that a request for a limit increase can be made well ahead of time.\n\u2022For example:\n\u2022For AWS IoT Core, alert \non\u00a0RulesMessageThrottles ,\u00a0Connect.ClientIDThrottle ,\u00a0Connect.Throttle ,\u00a0PublishIn.Throttle ,\u00a0Subscribe.Throttle ,\u00a0Unsubscribe.Throttle .\n\u2022For AWS IoT Analytics, alert \non\u00a0ActionExecutionThrottled ,\u00a0PipelineConcurrentExecutionCount\n\u2022For AWS IoT Device Management, monitor active continuous jobs, and active snapshot jobs in \nService Quotas\n\u2022For AWS IoT SiteWise, monitor the quotas in Service Quotas.\n\u2022For more information:\n\u2022AWS IoT Core\n\u2022AWS IoT Device Defender\n\u2022AWS IoT Device Management\n\u2022AWS IoT Events\n\u2022AWS IoT Greengrass\n\u2022AWS IoT SiteWise\n\u2022AWS IoT Things Graph\n\u2022AWS IoT Analytics\n\u2022AWS IoT 1-Click\n\u2022AWS IoT Analytics CloudWatch\n\u2022AWS IoT Core monitoring with Amazon CloudWatch\n\u2022Service Quotas for AWS IoT SiteWise\n\u2022Service Quotas for AWS IoT Device Management\n\u2022Amazon CloudWatch dashboards\n\u2022AWS IoT Monitoring tools\n\u2022Logging AWS IoT API calls with AWS CloudTrails\nTradeo\ufb00s\nIoT solutions drive rich analytics capabilities across vast areas of crucial enterprise functions, such as \noperations, customer care, \ufb01nance, sales, and marketing. At the same time, they can be used as e\ufb03cient \nexit points for edge gateways. Careful consideration must be given to architecting highly e\ufb03cient IoT \n71", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "4e89613c-a0dd-4abe-b993-ca89bd0b0fa4": {"__data__": {"id_": "4e89613c-a0dd-4abe-b993-ca89bd0b0fa4", "embedding": null, "metadata": {"page_label": "72", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0a1957e72de03f10f0339d672134415394cd9939e8ea4d7fadef05ca7a56b233", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nimplementations where data and analytics are pushed to the cloud by devices, and where machine \nlearning algorithms are pulled down to the device gateways from the cloud.\nIndividual devices will be constrained by the throughput supported over a given network. The frequency \nwith which data is exchanged must be balanced with the transport layer and the ability of the device \nto optionally store, aggregate, and then send data to the cloud. Send data from devices to the cloud at \ntimed intervals that align to the time required by backend applications to process and take action on the \ndata. For example, if you need to see data at a one-second increment, your device must send data at a \nmore frequent time interval than one second. Conversely, if your application only reads data at an hourly \nrate, you can make a trade-o\ufb00 in performance by aggregating data points at the edge and sending the \ndata every half hour.\nIOTPERF 06. How do you optimize the ingestion of telemetry data?\nThe speed with which enterprise applications, business, and operations need to gain visibility into \nIoT telemetry data determines the most e\ufb03cient point to process IoT data. In network constrained \nenvironments where the hardware is not limited, use edge solutions such as AWS IoT Greengrass to \noperate and process data o\ufb04ine from the cloud. In cases where both the network and hardware are \nconstrained, look for opportunities to compress message payloads by using binary formatting and \ngrouping similar messages together into a single request.\nFor visualizations, Amazon Managed Service for Apache Flink enables you to quickly author SQL code \nthat continuously reads, processes, and stores data in near-real-time. Using standard SQL queries on the \nstreaming data allows you to construct applications that transform and provide insights into your data. \nWith Managed Service for Apache Flink, you can expose IoT data for streaming analytics.\nEvaluating and optimizing your IoT application for its speci\ufb01c needs, whether telemetry data ingestion \nor controlling devices in the \ufb01eld, ensures that you get the best outcomes in balancing performances and \ncost. Separating the way that your application handles data collected through sensors or device probes \nfrom command-and-control \ufb02ows helps achieve better performance.\nBest practice IOTPERF_6.1 \u2013 Identify the ingestion mechanisms that best \ufb01t your use case\nIdentify which data ingestion method best \ufb01ts with your use case to obtain the best performance and \noperational complexity tradeo\ufb00. Multiple mechanisms might be needed. This method provides the \noptimal ingestion path for the data generated by your devices to obtain the best trade-o\ufb00s between \nperformance and cost.\nRecommendation IOTPERF_6.1.1 \u2013 Evaluate ingestion mechanism for telemetry data\n\u2022Determine if the communication pattern is unidirectional (device to backend) or bi-directional. For \nexample:\n\u2022HTTPS should be considered if your device is acting as an aggregator and needs to send more than \n100 messages per second instead of opening multiple MQTT connections. Use multiple threads and \nmultiple HTTP connections to maximize the throughput for high delay networks as HTTP calls are \nsynchronous.\n\u2022Consider the APIs provided by the destination for your data and adopt them if you can securely access \nthem. For example:\n\u2022AWS IoT Analytics provides an HTTP API that is capable of batching several messages and is suitable \nfor high-rate data ingestion when the data is consumed in near-real-time fashion and a service-\nintegrated data storage, data processing and data retention and replay are desired.\n\u2022AWS IoT SiteWise provides an HTTP API to ingest operational data from industrial applications \nwhich needs to be stored for a limited period of time and processed as a time series with hierarchical \naggregation capabilities.\n72", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "c92bc4a8-c51b-4167-81ea-f07af5a0c90b": {"__data__": {"id_": "c92bc4a8-c51b-4167-81ea-f07af5a0c90b", "embedding": null, "metadata": {"page_label": "73", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b3230a6db053b312c9b3738743e8af6a092661cb10df18da55c5cf8c05670515", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022Real-time video (for example, video surveillance cameras) has speci\ufb01c characteristics that makes it \nmore suitable to ingest in a dedicated service, such as Amazon Kinesis Video Streams.\n\u2022Consider the need for data to be bu\ufb00ered locally while the device is disconnected and the transmission \nresumed as soon as the connection is re-established. For example:\n\u2022AWS IoT Greengrass stream manager provides a managed stream service with local persistence, local \nprocessing pipelines and exporters to Amazon Kinesis Data Streams, AWS IoT Analytics, AWS IoT \nSiteWise and Amazon S3.\n\u2022Consider the latency, throughput, and ordering characteristics of the data you want to ingest. For \nexample:\n\u2022For applications with a high ingestion rate (high-frequency sensor data) and where message \nordering is important, Amazon Kinesis Data Streams provides stream-oriented processing \ncapabilities and the ability to act as temporary storage.\n\u2022For applications that do not have any real time requirements (such as logging, large images) and \nwhen the devices have the possibility to store data locally, uploading data directly to Amazon S3 can \nbe both performant and cost e\ufb03cient.\n\u2022AWS IoT Core supported protocols\n\u2022AWS IoT Analytics\n\u2022AWS IoT SiteWise\n\u2022Amazon Kinesis Data Streams\n\u2022Amazon Kinesis Video Streams\n\u2022Amazon S3\n\u2022Amazon S3 pre-signed URLs\n\u2022AWS IoT Greengrass stream manager\nBest practice IOTPERF_6.2 \u2013 Evaluate network connectivity and data freshness requirements\nEvaluating these requirements enable you to make the right assumptions on the local data storage \nand data transmission needed to satisfy the requirements of your workload. It also provides a clear \nunderstanding of the requirements of the workload and allows you to determine the hardware and \nsoftware needs of the devices and the platform.\nRecommendation IOTPERF_6.2.1 \u2013 Choose the right Quality of Service (QoS) for publishing the messages\n\u2022QoS 0 should be the default choice for all telemetry data that can cope with message loss and where \ndata freshness is more important than reliability.\n\u2022QoS 1 provides reliable message transmission at the expense of increased latency, ordered ingestion \nin case of retries, and local memory consumption. It requires a local bu\ufb00er for all unacknowledged \nmessages.\n\u2022QoS 2 provides once and only once delivery of messages but increases the latency.\nRecommendation IOTPERF_6.2.2 \u2013 Right size the o\ufb04ine persistent storage to ensure that your application \nobjective can be obtained without wasting resources\n\u2022The AWS IoT Greengrass message spooler can be con\ufb01gured with an o\ufb04ine message queue for \nmessages that need to be sent to the AWS IoT Core. The size and type of storage should be con\ufb01gured \naccording to the needs of the workload.\nResources\nRelated documents\n\u2022MQTT QoS\n73", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ceca8eaf-78ad-4897-b5dd-76b2c6481cba": {"__data__": {"id_": "ceca8eaf-78ad-4897-b5dd-76b2c6481cba", "embedding": null, "metadata": {"page_label": "74", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "10f8abe9d47c7ab1e4cfc01dfe3f03ccf51e9ea0822cf18e71507e7a4fbba7bb", "text": "IoT Lens AWS Well-Architected Framework\nKey AWS services\n\u2022Publish/subscribe AWS IoT Core MQTT messages\nBest practice IOTPERF_6.3 \u2013 Optimize data sent from devices to backend services\nOptimizing the amount of data sent by the devices at the edge allows the backend to better meet the \nprocessing targets set by the business. Detailed data generated at the edge might have little value for \nyour application in its raw form.\nRecommendation IOTPERF_6.3.1 \u2013 Aggregate or compress data at the edge\n\u2022You can aggregate data points at the edge before sending it to the cloud, such as performing \nstatistical aggregation, frequency histograms, signal processing.\n\u2022For example, if you are using AWS IoT Greengrass, you can implement data processing at the edge with \na combination of streams and Lambda functions.\n\u2022Run Lambda functions on the AWS IoT Greengrass core\n\u2022Industrial OEE workshop\n\u2022AWS IoT Greengrass stream manager\nKey AWS services\nThe key AWS service for performance e\ufb03ciency is Amazon CloudWatch, which integrates with several IoT \nservices including AWS IoT Core, AWS IoT Device Defender, AWS IoT Device Management, AWS Lambda, \nand DynamoDB. Amazon CloudWatch provides visibility into your application\u2019s overall performance and \noperational health. The following services also support performance e\ufb03ciency:\nDevices: AWS hardware partners provide production ready IoT devices that can be used as part of you \nIoT application. FreeRTOS is an operating system with software libraries for microcontrollers. AWS IoT \nGreengrass allows you to run local compute, messaging, data caching, synchronization, and ML at the \nedge.\nConnectivity: AWS IoT Core is a managed IoT platform that supports MQTT, a lightweight publish and \nsubscribe protocol for device communication.\nDatabase:  Amazon DynamoDB is a fully managed NoSQL datastore that supports single digit millisecond \nlatency requests to support quick retrieval of di\ufb00erent views of your IoT data.\nCompute:  AWS Lambda is an event driven compute service that lets you run application code without \nprovisioning servers. Lambda integrates natively with IoT events initiated from AWS IoT Core or services \nsuch as Amazon Kinesis and Amazon SQS.\nAnalytics: AWS IoT Analytics is a managed service that operationalizes device level analytics while \nproviding a time series data store for your IoT telemetry.\nReview: The AWS IoT Blog section on the AWS website is a resource for learning about what is newly \nlaunched as part of AWS IoT.\nMonitoring:  Amazon CloudWatch Metrics and Amazon CloudWatch Logs provide metrics, logs, \ufb01lters, \nalarms, and noti\ufb01cations that you can integrate with your existing monitoring solution. These metrics \ncan be augmented with device telemetry to monitor your application.\nTradeo\ufb00: AWS IoT Greengrass and Amazon Kinesis are services that allow you to aggregate and batch \ndata at di\ufb00erent locations of your IoT application, providing you more e\ufb03cient compute performance.\nResources\nRefer to the following resources to learn more about our best practices related to performance \ne\ufb03ciency:\n74", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "36b59e84-4ff4-4b11-92b1-0c48cc82d8a5": {"__data__": {"id_": "36b59e84-4ff4-4b11-92b1-0c48cc82d8a5", "embedding": null, "metadata": {"page_label": "75", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "bd57ac700701c3ae60429f143c932ebaf60a5729920bb0e0d6c6e77cbc2de445", "text": "IoT Lens AWS Well-Architected Framework\nCost optimization\nDocumentation and blogs\n\u2022AWS Lambda Getting Started\n\u2022DynamoDB Getting Started\n\u2022AWS IoT Analytics User Guide\n\u2022FreeRTOS Getting Started\n\u2022AWS IoT Greengrass Getting Started\n\u2022AWS IoT Blog\nCost optimization pillar\nThe cost optimization pillar includes the continual process of re\ufb01nement and improvement of a system \nover its entire lifecycle. From the initial design of your \ufb01rst proof of concept to the ongoing operation \nof production workloads, adopting the practices in this paper will enable you to build and operate cost-\naware systems that achieve business outcomes and minimize costs, allowing your business to maximize \nits return on investment.\nTopics\n\u2022Design principles  (p. 75)\n\u2022Best practices (p. 75)\n\u2022Key AWS services (p. 83)\n\u2022Resources (p. 83)\nDesign principles\nIn addition to the overall Well-Architected Framework cost optimization design principles, there are \nthree design principle for cost optimization for IoT:\n\u2022Manage manufacturing cost tradeo\ufb00s: Business partnering criteria, hardware component selection, \n\ufb01rmware complexity, and distribution requirements all play a role in manufacturing cost. Minimizing \nthat cost helps determine whether a product can be brought to market successfully over multiple \nproduct generations. However, taking shortcuts in the selection of your components and manufacturer \ncan increase downstream costs. For example, partnering with a reputable manufacturer helps minimize \ndownstream hardware failure and customer support cost. Selecting a dedicated crypto component \ncan increase bill of material (BOM) cost, but reduce downstream manufacturing and provisioning \ncomplexity, since the part may already come with an onboard private key and certi\ufb01cate.\n\u2022Avoid unnecessary data access, storage, and transmission: Identify and classify data collected \nthroughout your IoT environment and learn their corresponding business use-case. Then identify and \nexecute on opportunities to stop collecting unused data or adjusting their\u00a0granularity and retention \ntime.\n\u2022Process data at the edge whenever possible: Processing data at the edge can help to save costs. \nProcess large volumes of data locally, upload only relevant insights and high-value data to the cloud.\nBest practices\nThere are \ufb01ve best practice areas for cost optimization:\nTopics\n\u2022Practice Cloud Financial Management (p. 76)\n75", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "fdb66548-1ccb-4b87-b3ff-2436fec1b957": {"__data__": {"id_": "fdb66548-1ccb-4b87-b3ff-2436fec1b957", "embedding": null, "metadata": {"page_label": "76", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "727c0c5769b45c21cd3762b943ad2002036c33a0300e4923223e8753fb741840", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\n\u2022Expenditure and usage awareness (p. 76)\n\u2022Cost-e\ufb00ective resources (p. 76)\n\u2022Manage demand and supplying resources (p. 81)\n\u2022Optimize over time (p. 81)\nThere are tradeo\ufb00s to consider. For example, do you want to optimize for speed to market or cost? In \nsome cases, it's best to optimize for speed\u2014going to market quickly, shipping new features, or meeting \na deadline\u2014rather than investing in upfront cost optimization. Design decisions are sometimes guided \nby haste as opposed to empirical data, as the temptation always exists to overcompensate rather than \nspend time benchmarking for a cost-optimal deployment. This leads to over-provisioned and under-\noptimized deployments. The following sections provide techniques and strategic guidance for your \ndeployment\u2019s initial and ongoing cost optimization.\nPractice Cloud Financial Management\nThere are no Cloud Financial Management best practices speci\ufb01c to the IoT Lens.\nExpenditure and usage awareness\nThere are no expenditure and usage awareness best practices speci\ufb01c to the IoT Lens.\nCost-e\ufb00ective resources\nGiven the scale of devices and data that can be generated by an IoT application, using the appropriate \nAWS services for your system is key to cost savings. In addition to the overall cost for your IoT solution, \nIoT architects often look at connectivity through the lens of bill of materials (BOM) costs. For BOM \ncalculations, you must predict and monitor what the long-term costs will be for managing the \nconnectivity to your IoT application throughout the lifetime of that device. Leveraging AWS services will \nhelp you calculate initial BOM costs, make use of cost-e\ufb00ective services that are event driven, and update \nyour architecture to continue to lower your overall lifetime cost for connectivity.\nThe most straightforward way to increase the cost-e\ufb00ectiveness of your resources is to group IoT events \ninto batches and process data collectively. By processing events in groups, you are able to lower the \noverall compute time for each individual message. Aggregation can help you save on compute resources \nand enable solutions when data is compressed and archived before being persisted. This strategy \ndecreases the overall storage footprint without losing data or compromising the query ability of the \ndata.\nIOTCOST 01. How do you choose cost-e\ufb03cient tools for data aggregation of your IoT workloads?\nAWS IoT is best suited for streaming data for either immediate consumption or historical analyses. There \nare several ways to batch data from AWS IoT Core to other AWS services and the di\ufb00erentiating factor \nis driven by batching raw data (as is) or enriching the data and then batching it. Enriching, transforming, \nand \ufb01ltering IoT telemetry data during (or immediately after) ingestion is best performed by creating an \nAWS IoT rule that sends the data to Kinesis Data Streams, Kinesis Data Firehose, AWS IoT Analytics, or \nAmazon Simple Queue Service (Amazon SQS). These services allow you to process multiple data events \nat once.\nWhen dealing with raw device data from this batch pipeline, you can use AWS IoT Analytics and Amazon \nKinesis Data Firehose to transfer data to S3 buckets and Amazon Redshift. To lower storage costs in \nAmazon S3, an application can use lifecycle policies that archive data to lower cost storage, such as \nAmazon S3 Glacier.\n76", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f79335f6-322e-4ad3-9c65-b6797ce9c556": {"__data__": {"id_": "f79335f6-322e-4ad3-9c65-b6797ce9c556", "embedding": null, "metadata": {"page_label": "77", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5c813f26914b6dd1a3d80a9dbf431fee6ceafb6c3ea151cb2ed336675f9b99cf", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nRaw data from devices can also be processed at the edge using AWS IoT Greengrass thus eliminating the \nneed to send all the data to the cloud for storage and processing. This can result in lower network cost \nand lower cost in cloud services. You can dynamically change or update that logic, as well as frequency \nof transmission using AWS IoT Greengrass since it's not hardcoded and can be adjusted as needed by the \nuse case. This gives you added \ufb02exibility for cost optimization.\nIn addition, observe the following general practice recommendations:\nMethods and tools for how data is acquired, validated, categorized, and stored impacts the overall cost \nof your application. Focusing on tools that can automatically vary in scale and cost with demand and \nsupport your data with a minimum of administrative overhead can help you achieve lowest cost for \nyour application. By considering the data pipeline from origination to archival, you can make informed \ndecisions and examine tradeo\ufb00s among technical and business requirements to identify the most \ne\ufb00ective solution.\nBest practice IOTCOST_1.1 \u2013 Use a data lake for raw telemetry data\nA data lake brings di\ufb00erent data sources together and provides a common management framework \nfor browsing, viewing, and extracting the sources. An e\ufb00ective data lake enables IoT cost management \nby storing data in the right format for the right use case. With a data lake, storage and interaction \ncharacteristics can be aligned to a speci\ufb01c dataset format and required interfaces.\nRecommendation IOTCOST_1.1.1 \u2013 Categorize telemetry types and map to storage capabilities\n\u2022For each telemetry stream, identify key features of telemetry using the 4Vs of big data\u2014velocity, \nvolume, veracity, and variety.\n\u2022Map each stream into the appropriate storage capability. For example, a stream that sends an \nMQTT message with a JSON payload every second would be an ideal candidate for being batched, \ncompressed then stored in Amazon S3.\n\u2022For more information:\n\u2022AWS storage types\n\u2022AWS re:Invent 2018: Building with AWS Databases: Match Your Workload to the Right Database \n(DAT301)\nBest practice IOTCOST_1.2 \u2013 Provide a self-service interface for end users to search, extract, manage, \nand update IoT data\nWith inexpensive cloud computing resources, pay-as-you-go pricing, and strong identity and encryption \ncontrols, your organization should allow groups to de\ufb01ne and share data models in the format that \nmakes the most sense for them. Self-service interfaces will encourage experimentation and speed up \nchange by removing barriers for teams to gain access to the data they need to make decisions.\nRecommendation IOTCOST_1.2.1 \u2013 Use an architecture that allows various end users to easily \ufb01nd, \nobtain, enhance, and share data\nRecommendation IOTCOST_1.2.2 \u2013 Use a subscriber model, which allows teams to subscribe to data feeds \nand receive noti\ufb01cation of updates, to reduce the need for active polling and re-synching with data sources\nFor more information:\n\u2022Creating a data lake from a JDBC source in AWS Lake Formation\n\u2022AWS Data Lake Quick Start\n\u2022AWS Data Exchange o\ufb00ers subscriptions to third-party data sources with noti\ufb01cation on updates\nBest practice IOTCOST_1.3 \u2013 Track and manage the utilization of data sources\n77", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "cd822cf7-8fc5-4862-95f8-6a9be92ea497": {"__data__": {"id_": "cd822cf7-8fc5-4862-95f8-6a9be92ea497", "embedding": null, "metadata": {"page_label": "78", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a856a2e2dab99d46f3c560cb8e25c6ffd0c0be7ff251ea882b01be464fe7524c", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nApplications and users evolve over time, and IoT solutions can generate large volumes of data quickly. \nAs your application matures, it\u2019s important for cost management of your IoT workload to track that data \ncollected is still being used. Consistent tracking and review of data utilization provides an objective basis \nfor cost optimization decisions.\nRecommendation IOTCOST_1.3.1 \u2013 Track and manage the utilization of data sources to identify hot and \ncold spots to assess value of data\n\u2022Track access rates and storage trends for your data lake sources.\n\u2022Use automated guidance tools, such as AWS Cost Explorer and AWS Trusted Advisor, to identify under-\nutilized or resizable components of your workload. AWS Cost Explorer has a forecast feature that \npredicts how much you will use AWS services over the forecast time period you selected.\n\u2022Use AWS Budgets and AWS Cost Anomaly Detection to prevent surprise bills.\n\u2022For more information:\n\u2022Monitoring Amazon S3 metrics with Amazon CloudWatch\n\u2022Find cost of your S3 buckets using AWS Cost Explorer\n\u2022Forecast your spend using Cost explorer\n\u2022Best practices for AWS Budget\nBest practice IOTCOST_1.4 \u2013 Aggregate data at the edge where possible\nData aggregation is an architectural decision that can have impacts on data \ufb01delity. Aggregations \nshould be thoroughly reviewed with engineering and architectural teams before implementation. If the \ndevice can aggregate data before sending for processing using methods such as combining messages \nor removing duplicate or repeating values, that can reduce the amount of processing, the number of \nassociated resources, and associated expense.\nRecommendation IOTCOST_1.4.1 \u2013 Examine device telemetry for opportunities to batch and aggregate \ndata\n\u2022A common mechanism includes combining multiple status updates to a \ufb01nal status, or combining a \nseries of measurements generated by the device into a single message.\n\u2022For example, 10 KB of device telemetry data might be packaged as one 10-KB message, two 5-KB \nmessages, or 10 1-KB messages. Each packaging format has implications outside of cost such as \nnetwork tra\ufb03c (10 1-KB messages will each add their own header messaging as opposed to a single \n10-KB message with one header) and the impact of a lost or delayed message. Optimizing message \nsize should consider how a lost message impacts the functional or non-functional characteristics of the \nsystem.\nRecommendation IOTCOST_1.4.2 \u2013 Use cost calculators  to model di\ufb00erent approaches for message size \nand count\n\u2022The AWS Pricing Calculator can estimate IoT costs for speci\ufb01c message sizes, tra\ufb03c, and operations.\nIOTCOST 02. How do you optimize the cost of raw telemetry data?\nRaw telemetry is an original source for analytics but can also be a major component of cost. Analyze \nthe \ufb02ow and usage of your telemetry to identify the right service and handling process required. Select \nstorage and processing mechanisms that match the needs of your speci\ufb01c telemetry case.\nBest practice IOTCOST_2.1 \u2013 Use lifecycle policies to archive your data\n78", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a8feecca-a381-4c12-b2f4-33d6d2c267f3": {"__data__": {"id_": "a8feecca-a381-4c12-b2f4-33d6d2c267f3", "embedding": null, "metadata": {"page_label": "79", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "85e2c8dc529359b28e2131bced2885fa5d1128c8d20abfcf8b22a3d77de44ddc", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nWhen selecting an automated lifecycle policy for data, there are tradeo\ufb00s to consider. For example, do \nyou want to optimize for speed to market or cost? In some cases, it's best to optimize for speed\u2014going \nto market quickly, shipping new features, or meeting a deadline\u2014rather than investing in upfront cost \noptimization. Use your organization\u2019s data classi\ufb01cation strategies to de\ufb01ne a lifecycle policy to take \nraw telemetry measurements through various services. Setting milestones by time sets expectations and \nencourages aggregation and production of data over mere collection.\nRecommendation IOTCOST_2.1.1 \u2013 Evaluate your organization\u2019s data retention and handling \nrequirements and con\ufb01gure your AWS services to support them\n\u2022Check your organization\u2019s data management policy for requirements on retention, deletion, and \nencryption and align your retention policies and tools with those guidelines.\n\u2022S3 Lifecycle policies or S3 Intelligent-Tiering can move the data to the most cost-e\ufb00ective Amazon S3 \nstorage class or Amazon S3 Glacier for long-term storage.\nBest practice IOTCOST_2.2 \u2013 Evaluate storage characteristics for your use case and align with the \nright services\nNot all data needs to be stored in the same way, and data storage needs change through a data item\u2019s \nlifecycle. A growing \ufb02eet of devices can exponentially scale its messaging rate and device operation \ntra\ufb03c. This scaling of message volumes can also mean an increase in storage costs.\nRecommendation IOTCOST_2.2.1 \u2013 Evaluate velocity and the volume of data coming from IoT devices \nwhen selecting storage services\n\u2022For data at high scale of devices, time, or other characteristics\u2014Consider a data warehouse such as \nAmazon Redshift or Amazon S3 with Amazon Athena. The data partitioning and tiering features of \nAWS storage services can help reduce storage costs.\n\u2022For data at lower scale of time, devices, or other characteristics\u2014Consider Amazon DynamoDB, \nAmazon OpenSearch Service (OpenSearch Service), or Amazon Aurora for short-term historical data. \nUse your data lifecycle policies to optimize what is kept in the short-term storage.\nBest practice IOTCOST_2.3 \u2013 Store raw archival data on cost e\ufb00ective services\nUsing the right storage solution for a speci\ufb01c data type will align costs with usage.\nRecommendation IOTCOST_2.3.1 \u2013 Use an object store for archival storage\n\u2022Use an object store, such as Amazon S3, for raw archival storage. Object stores are immutable and \noften more e\ufb03cient and cost-e\ufb00ective than block storage, especially for data which doesn\u2019t require \nediting.\n\u2022Avoid costs by using a schema-on-read service, such as Amazon Athena, to query the data in its native \nform. Using Athena can help reduce the need for large-scale storage arrays or always-on databases to \nread raw archival data.\nIOTCOST 03. How do you optimize the cost of interactions between devices and your IoT cloud \nsolution?\nInteractions to and from devices can be a signi\ufb01cant driver of your workload\u2019s overall cost. \nUnderstanding and optimizing interactions between devices and cloud solution can be a signi\ufb01cant \nfactor of cost management.\nBest practice IOTCOST_3.1 \u2013 Select services to optimize cost\n79", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "35888876-ac0a-4092-a389-29012c1b3ede": {"__data__": {"id_": "35888876-ac0a-4092-a389-29012c1b3ede", "embedding": null, "metadata": {"page_label": "80", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "027b9e3150bb343e688dcce0bb0e1b867dae187c85d943f0c689fd0cc3334336", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nUnderstand how services use and charge for messaging, as well as operating modes that o\ufb00er cost \nbene\ufb01ts. Understanding service billing characteristics can help you identify ways to optimize messaging, \nwhich could result in considerable cost savings at scale.\nRecommendation IOTCOST_3.1.1 \u2013 Select services to optimize cost\n\u2022Review your IoT architecture to \ufb01nd communication patterns and scenarios that could map to service \ndiscount features.\n\u2022With AWS IoT Core Rules Engine Basic Ingest, you can publish directly to a rule without messaging \ncharges.\n\u2022Use your registry of things only for primarily immutable data, such as\u00a0serialNumber.\n\u2022For your device\u2019s shadow, minimize the frequency of reads and writes to reduce the total metered \noperation and your operating costs.\n\u2022For more information:\n\u2022AWS IoT Rules Engine Basic Ingest\n\u2022AWS IoT Pricing\nBest practice IOTCOST_3.2 \u2013 Implement and con\ufb01gure telemetry to reduce data transfer costs\nMatching the precision of telemetry data, such as the number of decimal places, to the precision of the \nrequired calculation can help address both the overall message size and the precision of calculations.\nRecommendation IOTCOST_3.2.1 \u2013 Reduce string lengths and decimal precision where feasible\n\u2022For example, strings sent regularly such as \"POWER \" or \"CHARGE\" could be reduced to the strings \"P\" \nor \"C\". Similarly, decimal values such as \u201c21.25 \u201d or \u201c71.86\u201d could be reduced to \u201c21\u201d or \u201c72\u201d if the \nadditional precision is not required for the application. This is common in room temperature readings \nwhere precision beyond a whole number is rarely required. Across many millions of messages, the \nsavings from removing a few characters can make a signi\ufb01cant di\ufb00erence in message size and cost.\nBest practice IOTCOST_3.3 \u2013 Use shadow only for slow changing data\nShadow is used in IoT applications as a persistence mechanism of device state. The shadow maintains \ndata that remains consistent across multiple points in time. Device shadow operations can be billed and \nmetered di\ufb00erently than publish/subscribe messages. Reducing the shadow update frequency from \nthe device can reduce the number of billed operations while maintaining an acceptable level of data \nfreshness.\nRecommendation IOTCOST_3.3.1 \u2013 Avoid using shadows as a guaranteed-delivery mechanism or for \ncontinuously \ufb02uctuating data\n\u2022As a workload scales up, the cost of frequent shadow updates could exceed the value of the data.\n\u2022Consider MQTT Last Will and Testament (LWT) as a mitigation for the risk of loss of device \ncommunication instead of using shadow.\n\u2022Use the AWS Pricing Calculator to compare device shadow interactions versus telemetry messages \nunderstand cost implications.\n\u2022For more information:\n\u2022Last Will and Testament (LWT) Lifecycle Event\nBest practice IOTCOST_3.4 \u2013 Group and tag IoT devices and messages for cost allocation\nAn IoT billing group enables you to tag devices by categories related to your IoT application. You should \ncreate tags that represent business categories, such as cost centers. Visibility into devices and messages \nby category makes cost dimensions easier to understand and visualize.\n80", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e54ade80-4ede-479a-8eca-33a92e0b11cb": {"__data__": {"id_": "e54ade80-4ede-479a-8eca-33a92e0b11cb", "embedding": null, "metadata": {"page_label": "81", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a5148cbbb6cadc1b54b44b7dca5cbb1540c1018bdc0d43294cdd306d10cc30c8", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nRecommendation IOTCOST_3.4.1 \u2013 Use AWS IoT Core Billing Groups to tag IoT devices for cost allocation\n\u2022Add tracking elements to messages and devices to help trace source such as product model and serial \nnumber.\n\u2022Ensure that your system can group and organize data by both technical and business entity.\n\u2022For more information:\n\u2022Tagging IoT Billing Groups\nBest practice IOTCOST_3.5 \u2013 Implement and con\ufb01gure device messaging to reduce data transfer costs\nCharges for di\ufb00erent cloud and data transporter providers can vary based on speci\ufb01cs of message size \nand frequency. IoT workloads can cross multiple communication, such as cell networks, and each layer \ncan have its own metering and pricing standards.\nRecommendation IOTCOST_3.5.1 \u2013 Evaluate tradeo\ufb00s between message size and number of messages\n\u2022Frequency optimization is performed with payload optimization to both accurately assess the network \nload and identify adequate trade-o\ufb00s between frequency and payload size.\n\u2022For example, your devices might send one message per second. If you could aggregate those messages \non the device and send \ufb01ve observations in a single message every \ufb01ve seconds, that could drastically \nreduce your message count and cost.\nRecommendation IOTCOST_3.5.2 \u2013 Evaluate cost of streaming services versus IoT messaging services\n\u2022Use the AWS Cost Calculator to compare the cost of using messaging services like Kinesis and API \nGateway to o\ufb04oad components of your IoT workload.\nManage demand and supplying resources\nOptimally matching supply to demand delivers the lowest cost for a system. However, given the \nsusceptibility of IoT workloads to data bursts, solutions must be dynamically scalable and consider \npeak capacity when provisioning resources. With the event driven \ufb02ow of data, you can choose to \nautomatically provision your AWS resources to match your peak capacity and then scale up and down \nduring known low periods of tra\ufb03c.\nIOTCOST 04. How do you optimize cost by matching the supply of resources with device demand?\nServerless technologies, such as AWS Lambda and API Gateway, help you create a more scalable and \nresilient architecture, and you only pay for when your application utilizes those services. AWS IoT Core, \nAWS IoT Device Management, AWS IoT Device Defender, AWS IoT Greengrass, and AWS IoT Analytics \nare also managed services that are pay per usage and do not charge you for idle compute capacity. The \nbene\ufb01t of managed services is that AWS manages the automatic provisioning of your resources. If you \nuse managed services, you are responsible for monitoring and setting alerts for quota increases for AWS \nservices.\nWhen architecting to match supply against demand, proactively plan your expected usage over time, and \nthe limits that you are most likely to exceed. Factor those limit increases into your future planning.\nOptimize over time\nEvaluating new AWS features allows you to optimize cost by analyzing how your devices are performing \nand make changes to how your devices communicate with your IoT.\n81", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "7d86cf0a-bf4a-4153-b2a0-bd9ca24615fb": {"__data__": {"id_": "7d86cf0a-bf4a-4153-b2a0-bd9ca24615fb", "embedding": null, "metadata": {"page_label": "82", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "1b9807546f252f7a714839bbcee40dc7783de4473819c20078c1d7f37729ed30", "text": "IoT Lens AWS Well-Architected Framework\nBest practices\nTo optimize the cost of your solution through changes to device \ufb01rmware, you should review the \npricing components of AWS services, such as AWS IoT, determine where you are below billing metering \nthresholds for a given service, and then weigh the trade-o\ufb00s between cost and performance.\nIOTCOST 05. How do you optimize payload size between devices and your IoT platform to save \ncost?\nIoT applications must balance the networking throughput that can be realized by end devices with \nthe most e\ufb03cient way that data should be processed by your IoT application. We recommend that IoT \ndeployments initially optimize data transfer based on the device constraints. Begin by sending discrete \ndata events from the device to the cloud, making minimal use of batching multiple events in a single \nmessage. Later, if necessary, you can use serialization frameworks to compress the messages prior to \nsending them to your IoT platform.\nFrom a cost perspective, the MQTT payload size is a critical cost optimization element for AWS IoT Core. \nAn IoT message is billed in 5-KB increments, up to 128 KB. For this reason, each MQTT payload size \nshould be as close to possible to any 5 KB. For example, a payload that is currently sized at 6 KB is not as \ncost e\ufb03cient as a payload that is 10 KB because the overall costs of publishing that message is identical \ndespite one message being larger than the other.\nTo take advantage of the payload size, look for opportunities to either compress data or aggregate data \ninto messages:\n\u2022You should shorten values while keeping them legible. If \ufb01ve digits of precision are su\ufb03cient, then you \nshould not use 12 digits in the payload.\n\u2022If you do not require IoT rules engine payload inspection, you can use serialization frameworks to \ncompress payloads to smaller sizes.\n\u2022You can send data less frequently and aggregate messages together within the billable increments. For \nexample, sending a single 2-KB message every second can be achieved at a lower IoT message cost by \nsending two 2-KB messages every other second.\nThis approach has tradeo\ufb00s that should be considered before implementation. Adding complexity or \ndelay in your devices may unexpectedly increase processing costs. A cost optimization exercise for IoT \npayloads should only happen after your solution has been in production and you can use a data-driven \napproach to determine the cost impact of changing the way data is sent to AWS IoT Core.\nIOTCOST 06. How do you optimize the costs of storing the current state of your IoT device?\nWell-Architected IoT applications have a virtual representation of the device in the cloud. This virtual \nrepresentation is composed of a managed data store or specialized IoT application data store. In both \ncases, your end devices must be programmed in a way that e\ufb03ciently transmits device state changes \nto your IoT application. For example, your device should only send its full device state if your \ufb01rmware \nlogic dictates that the full device state might be out of sync and would be best reconciled by sending all \ncurrent settings. As individual state changes occur, the device should optimize the frequency it transmits \nthose changes to the cloud.\nIn AWS IoT, device shadow and registry operations are metered in 1 KB increments and billing is per \nmillion access/modify operations. The shadow stores the desired or actual state of each device and the \nregistry is used to name and manage devices.\nCost optimization processes for device shadows and registry focus on managing how many operations \nare performed and the size of each operation. If your operation is cost sensitive to shadow and registry \n82", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "45e9509c-785d-407d-aa11-30a27cc8cba2": {"__data__": {"id_": "45e9509c-785d-407d-aa11-30a27cc8cba2", "embedding": null, "metadata": {"page_label": "83", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "cc7cf5643a6e7ef9ba9897a870f5a5207368460bd86086dd6f8be62ef2c0a5fb", "text": "IoT Lens AWS Well-Architected Framework\nKey AWS services\noperations, you should look for ways to optimize shadow operations. For example, for the shadow you \ncould aggregate several reported \ufb01elds together into one shadow message update instead of sending \neach reported change independently. Grouping shadow updates together reduces the overall cost of the \nshadow by consolidating updates to the service.\nKey AWS services\nThe key AWS feature supporting cost optimization is cost allocation tags, which help you to understand \nthe costs of a system. The following services and features are important in the three areas of cost \noptimization:\n\u2022Cost-e\ufb00ective resources: Amazon Kinesis, AWS IoT Analytics, and Amazon S3 are AWS services that \nenable you to process multiple IoT messages in a single request to improve the cost e\ufb00ectiveness of \ncompute resources.\n\u2022Matching supply and demand:  AWS IoT Core is a managed IoT platform for managing connectivity, \ndevice security to the cloud, messaging routing, and device state.\n\u2022Optimizing over time: The AWS IoT Blog section on the AWS website is a resource for learning about \nwhat is newly launched as part of AWS IoT.\nResources\nRefer to the following resources to learn more about AWS best practices for cost optimization.\nDocumentation and blogs\n\u2022AWS IoT Blogs\nSustainability pillar\nThe sustainability pillar includes the ability to continually improve sustainability impacts by reducing \nenergy consumption and increasing e\ufb03ciency across all components of a workload by maximizing the \nbene\ufb01ts from the provisioned resources and minimizing the total resources required.\nThere are no sustainability practices unique to this lens. For information on Sustainability, refer to the\nSustainability Pillar whitepaper.\n83", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "73353ec2-8cdc-458a-8cf2-958154eef334": {"__data__": {"id_": "73353ec2-8cdc-458a-8cf2-958154eef334", "embedding": null, "metadata": {"page_label": "84", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "fb3bf0c382ba5f04f84cd883ed00e7db872f05543230ba739f715004c722c523", "text": "IoT Lens AWS Well-Architected Framework\nConclusion\nThe AWS Well-Architected Framework provides architectural best practices across the pillars for \ndesigning and operating reliable, secure, e\ufb03cient, cost-e\ufb00ective, and sustainable systems in the cloud \nfor IoT applications. The framework provides a set of questions that you can use to review an existing \nor proposed IoT architecture, and also a set of AWS best practices for each pillar. Using the framework \nin your architecture helps you produce stable and e\ufb03cient systems, which allows you to focus on your \nfunctional requirements.\n84", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "df7283cb-6c32-4e1e-af44-13738cd2792d": {"__data__": {"id_": "df7283cb-6c32-4e1e-af44-13738cd2792d", "embedding": null, "metadata": {"page_label": "85", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f01fded20d721a48e43532bcf326e8fb5873da598a43e82a2f0b09856e421bfa", "text": "IoT Lens AWS Well-Architected Framework\nContributors\nThe following individuals and organizations contributed to this document:\n\u2022Olawale Oladehin, Solutions Architect Specialist, IoT\n\u2022Dan Gri\ufb03n, Software Development Engineer, IoT\n\u2022Catalin Vieru, Solutions Architect Specialist, IoT\n\u2022Brett Francis, Product Solutions Architect, IoT\n\u2022Craig Williams, Partner Solutions Architect, IoT\n\u2022Philip Fitzsimons, Sr. Manager Well-Architected, Amazon Web Services\n\u2022Harish Rajagopalan, Senior Solutions Architect, IoT\n\u2022Ryan Dsouza, Principal Solutions Architect, IoT\n85", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0fb08bd3-40f0-4a84-b716-6731b03a558c": {"__data__": {"id_": "0fb08bd3-40f0-4a84-b716-6731b03a558c", "embedding": null, "metadata": {"page_label": "86", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "ea74e2059127c23abccb56c8432cf1ecea52e049b25588707476831c8fdc277f", "text": "IoT Lens AWS Well-Architected Framework\nDocument revisions\nTo be noti\ufb01ed about updates to this whitepaper, subscribe to the RSS feed.\nChange Description Date\nMajor update  (p. 86) Updated to include Lens \nChecklist, industrial IoT (IIoT), \nand new AWS IoT services and \nfeatures.March 31, 2023\nMinor update  (p. 86) Updated link. March 10, 2021\nWhitepaper updated  (p. 86) Updated to include additional \nguidance on IoT SDK usage, \nbootstrapping, device lifecycle \nmanagement, and IoTDecember 23, 2019\nInitial publication  (p. 86) IoT Lens \ufb01rst published. November 1, 2018\n86", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "902a9643-32f6-4ebc-a634-17db05a66160": {"__data__": {"id_": "902a9643-32f6-4ebc-a634-17db05a66160", "embedding": null, "metadata": {"page_label": "87", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e7c9fe8366b687b420d3b7684cd5b7b545c9cbfff51bac8a1ee5aa11ccaf24df", "text": "IoT Lens AWS Well-Architected Framework\nAWS glossary\nFor the latest AWS terminology, see the AWS glossary in the AWS Glossary Reference.\n87", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8f11be0d-f5a9-4835-896e-984d850f63b6": {"__data__": {"id_": "8f11be0d-f5a9-4835-896e-984d850f63b6", "embedding": null, "metadata": {"page_label": "88", "file_name": "wellarchitected-iot-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "2dac463985d363bd9996010a9d99fdc25a1467434d8c3794f014797ba6eee06f", "text": "IoT Lens AWS Well-Architected Framework\nNotices\nCustomers are responsible for making their own independent assessment of the information in this \ndocument. This document: (a) is for informational purposes only, (b) represents current AWS product \no\ufb00erings and practices, which are subject to change without notice, and (c) does not create any \ncommitments or assurances from AWS and its a\ufb03liates, suppliers or licensors. AWS products or services \nare provided \u201cas is\u201d without warranties, representations, or conditions of any kind, whether express or \nimplied. The responsibilities and liabilities of AWS to its customers are controlled by AWS agreements, \nand this document is not part of, nor does it modify, any agreement between AWS and its customers.\n\u00a9 2023 Amazon Web Services, Inc. or its a\ufb03liates. All rights reserved.\n88", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f00ee21b-07f9-4877-9ce4-f172d6d95f00": {"__data__": {"id_": "f00ee21b-07f9-4877-9ce4-f172d6d95f00", "embedding": null, "metadata": {"page_label": "i", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d3c5dac87f017d3e3be6a895b22b0b07b16cbd9e7b02720142064c1c9e37a871", "text": "Machine Learning Lens\nAWS Well-Architected Framework", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "69df6054-de20-4b9b-940d-196ce38c4b44": {"__data__": {"id_": "69df6054-de20-4b9b-940d-196ce38c4b44", "embedding": null, "metadata": {"page_label": "ii", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "670beac227b8c536564b581afe10a193104370362256329c1b6754b52c30ca79", "text": "Machine Learning Lens AWS Well-Architected Framework\nMachine Learning Lens: AWS Well-Architected Framework\nCopyright \u00a9 2023 Amazon Web Services, Inc. and/or its a\ufb03liates. All rights reserved.\nAmazon's trademarks and trade dress may not be used in connection with any product or service that is not \nAmazon's, in any manner that is likely to cause confusion among customers, or in any manner that disparages or \ndiscredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may \nor may not be a\ufb03liated with, connected to, or sponsored by Amazon.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "84226ca7-d12c-4f87-9c57-3d731f448746": {"__data__": {"id_": "84226ca7-d12c-4f87-9c57-3d731f448746", "embedding": null, "metadata": {"page_label": "iii", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e53257c9b245ceb0a832e8a8bf6dcf4f8e96f338f8d8479533232cdc8c4ce30c", "text": "Machine Learning Lens AWS Well-Architected Framework\nTable of Contents\nAbstract and introduction....................................................................................................................i\nIntroduction..............................................................................................................................1\nRun a Machine Learning Lens review............................................................................................1\nWell-Architected Framework pillars......................................................................................................3\nWell-Architected machine learning lifecycle...........................................................................................4\nWell-Architected machine learning design principles...............................................................................7\nWell-Architected machine learning.......................................................................................................8\nBusiness goal identi\ufb01cation lifecycle phase....................................................................................8\nOperational excellence pillar best practices...........................................................................9\nSecurity pillar best practices..............................................................................................11\nReliability pillar best practices............................................................................................12\nPerformance e\ufb03ciency pillar best practices.........................................................................13\nCost optimization pillar best practices.................................................................................13\nSustainability pillar best practices.......................................................................................16\nML problem framing lifecycle phase...........................................................................................16\nOperational excellence pillar best practices..........................................................................17\nSecurity pillar best practices..............................................................................................24\nReliability pillar best practices............................................................................................24\nPerformance e\ufb03ciency pillar best practices.........................................................................26\nCost optimization pillar best practices.................................................................................28\nSustainability pillar best practices.......................................................................................30\nLifecycle architecture diagram....................................................................................................32\nData processing lifecycle phase..................................................................................................34\nData collection.................................................................................................................35\nData preparation..............................................................................................................37\nOperational excellence pillar best practices..........................................................................39\nSecurity pillar best practices..............................................................................................41\nReliability pillar best practices............................................................................................46\nPerformance e\ufb03ciency pillar best practices.........................................................................49\nCost optimization pillar best practices.................................................................................50\nSustainability pillar best practices.......................................................................................53\nModel development lifecycle phase............................................................................................56\nModel training and tuning .................................................................................................56\nModel evaluation ..............................................................................................................58\nOperational excellence pillar best practices..........................................................................59\nSecurity pillar best practices..............................................................................................61\nReliability pillar best practices............................................................................................64\nPerformance e\ufb03ciency pillar best practices.........................................................................67\nCost optimization pillar best practices.................................................................................72\nSustainability pillar best practices.......................................................................................83\nDeployment lifecycle phase.......................................................................................................87\nOperational excellence pillar best practices..........................................................................89\nSecurity pillar best practices\u00a0.............................................................................................91\nReliability pillar best practices............................................................................................92\nPerformance e\ufb03ciency pillar best practices.........................................................................94\nCost optimization pillar best practices\u00a0................................................................................96\nSustainability pillar best practices.....................................................................................100\nMonitoring lifecycle phase.......................................................................................................103\nOperational excellence pillar best practices........................................................................104\nSecurity pillar best practices............................................................................................107\nReliability pillar best practices..........................................................................................108\nPerformance e\ufb03ciency pillar best practices........................................................................111\nCost optimization pillar best practices...............................................................................116\nSustainability pillar best practices....................................................................................118\niii", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a7629223-7b14-49d8-ae29-72684880bd1f": {"__data__": {"id_": "a7629223-7b14-49d8-ae29-72684880bd1f", "embedding": null, "metadata": {"page_label": "iv", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d57eb5e747ffe338ee9710db669cbd1c47f76750dcaf35575fefda98a8beda1c", "text": "Machine Learning Lens AWS Well-Architected Framework\nConclusion .....................................................................................................................................120\nContributors ...................................................................................................................................121\nSME reviewers........................................................................................................................121\nReferences.....................................................................................................................................122\nDocument history...........................................................................................................................123\nBest practices arranged by pillar......................................................................................................124\nOperational excellence pillar....................................................................................................124\nSecurity pillar.........................................................................................................................124\nReliability pillar......................................................................................................................125\nPerformance e\ufb03ciency pillar....................................................................................................125\nCost optimization pillar ...........................................................................................................125\nSustainability pillar.................................................................................................................126\nBest practices by ML lifecycle phase.................................................................................................127\nBusiness goal identi\ufb01cation phase ............................................................................................127\nOperational excellence pillar............................................................................................124\nSecurity pillar.................................................................................................................124\nReliability pillar..............................................................................................................125\nPerformance e\ufb03ciency pillar............................................................................................125\nCost optimization pillar ...................................................................................................125\nSustainability pillar.........................................................................................................126\nML problem framing phase......................................................................................................127\nOperational excellence pillar............................................................................................124\nSecurity pillar.................................................................................................................124\nReliability pillar..............................................................................................................125\nPerformance e\ufb03ciency pillar............................................................................................125\nCost optimization pillar ...................................................................................................125\nSustainability pillar.........................................................................................................126\nData processing phase............................................................................................................128\nOperational excellence pillar............................................................................................124\nSecurity pillar.................................................................................................................124\nReliability pillar..............................................................................................................125\nPerformance e\ufb03ciency pillar............................................................................................125\nCost optimization pillar ...................................................................................................125\nSustainability pillar.........................................................................................................126\nModel development phase.......................................................................................................129\nOperational excellence pillar............................................................................................124\nSecurity pillar.................................................................................................................124\nReliability pillar..............................................................................................................125\nPerformance e\ufb03ciency pillar............................................................................................125\nCost optimization pillar ...................................................................................................125\nSustainability pillar.........................................................................................................126\nModel deployment phase........................................................................................................130\nOperational excellence pillar............................................................................................124\nSecurity pillar.................................................................................................................124\nReliability pillar..............................................................................................................125\nPerformance e\ufb03ciency pillar............................................................................................125\nCost optimization pillar ...................................................................................................125\nSustainability pillar.........................................................................................................126\nModel monitoring phase .........................................................................................................131\nOperational excellence pillar............................................................................................124\nSecurity pillar.................................................................................................................124\nReliability pillar..............................................................................................................125\nPerformance e\ufb03ciency pillar............................................................................................125\nCost optimization pillar ...................................................................................................125\nSustainability pillar.........................................................................................................126\nNotices..........................................................................................................................................133\nAWS glossary.................................................................................................................................134\niv", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "eff56bdd-bbbc-47f3-9b42-dbf47a54bb6c": {"__data__": {"id_": "eff56bdd-bbbc-47f3-9b42-dbf47a54bb6c", "embedding": null, "metadata": {"page_label": "1", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "bdfb9ff57d27706e64adcfc64813cbb90c50458215e6b8706f10cbfdb6703872", "text": "Machine Learning Lens AWS Well-Architected Framework\nIntroduction\nMachine Learning Lens\nPublication date: July 5th, 2023  (Document history (p. 123))\nIn recent years, machine learning (ML) has moved from research and development to the mainstream, \ndriven by the increasing number of data sources and scalable cloud-based compute resources. AWS\u2019 \ncustomers currently use AI/ML for a wide variety of applications such as call center operations, \npersonalized recommendations, identifying fraudulent activities, social media content moderation, \naudio and video content analysis, product design services, and identity veri\ufb01cation. Industries using \nAI/ML include healthcare and life sciences, industrial and manufacturing, \ufb01nancial services, media and \nentertainment, and telecom.\nMachine learning, through its use of algorithms to \ufb01nd patterns in data, can bring considerable power \nto its customers and thus recommends responsibility in its use. AWS is committed to developing fair and \naccurate AI and ML services and providing you with the tools and guidance needed to build AI and ML \napplications responsibly. For more information on this important topic, refer to AWS' Responsible AI.\nThis whitepaper provides you with a set of proven best practices. You can apply this guidance and \narchitectural principles when designing your ML workloads, and after your workloads have entered \nproduction as part of continuous improvement. Although the guidance is cloud- and technology-\nagnostic, the paper also includes guidance and resources to help you implement these best practices on \nAWS.\nIntroduction\nThe AWS Well-Architected Framework helps you understand the bene\ufb01ts and risks of decisions you make \nwhile building workloads on AWS. By using the Framework, you learn operational and architectural best \npractices for designing and operating workloads in the cloud. It provides a way to consistently measure \nyour operations and architectures against best practices and identify areas for improvement.\nYour ML models depend on the quality of input data to generate accurate results. As data changes \nwith time, monitoring is required to continually detect, correct, and mitigate issues with accuracy and \nperformance. This monitoring step might require you to retrain your model over time using the latest \nre\ufb01ned data.\nWhile application workloads rely on step-by-step instructions to solve a problem, ML workloads enable \nalgorithms to learn from data through an iterative and continuous cycle. The ML Lens complements \nand builds upon the Well-Architected Framework to address this di\ufb00erence between these two types of \nworkloads.\nThis paper is intended for those in a technology role, such as chief technology o\ufb03cers (CTOs), architects, \ndevelopers, data scientists, and ML engineers. After reading this paper, you will understand the best \npractices and strategies to use when you design and operate ML workloads on AWS.\nRun a Machine Learning Lens review in your AWS \naccount\nA common request from our customers has been to enable them to run a self service Machine Learning \n(ML) Lens review in the AWS Well-Architected Tool (AWS WA Tool).\n1", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1b398117-3447-4f3c-9c39-fa4eb40da539": {"__data__": {"id_": "1b398117-3447-4f3c-9c39-fa4eb40da539", "embedding": null, "metadata": {"page_label": "2", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7e8f2e8034308327a68ae146fc9f3657ac319a5279ec0dfe341aee05f6b47044", "text": "Machine Learning Lens AWS Well-Architected Framework\nRun a Machine Learning Lens review\nThe ML Lens is now available as a custom lens for the AWS Well-Architected Tool in the AWS \nManagement Console. Custom lenses, such as the ML Lens, are de\ufb01ned in a JSON \ufb01le and allow you to \ntailor your workload reviews to particular technologies, help you meet governance needs, and extend the \nguidance already provided by the Well-Architected Framework and the AWS lenses.\nTo add the ML Lens to the AWS Well-Architected Tool:\n1.Download the ML Lens JSON \ufb01le. This \ufb01le is used in Step 5.\n2.Sign in to the AWS Management Console and open the AWS Well-Architected Tool console at https:// \nconsole.aws.amazon.com/wellarchitected/.\n3.In the left navigation pane, choose Custom lenses.\n4.Choose Create custom lens.\n5.Choose Choose \ufb01le and select the JSON \ufb01le you downloaded in Step 1.\n6.(Optional) In the Tags section, add any tags you want to associate with the ML Lens.\n7.Choose Submit & Preview  to preview the ML Lens, or Submit  to create the lens without previewing.\nIf you choose to Submit & Preview , you can select Next to navigate through the ML Lens preview, or \nselect Exit Preview  to go back to Custom lenses.\n8.Select the ML Lens and choose Publish lens.\n9.In the Version name box, enter a unique identi\ufb01er for the version change. This value can be up to 32 \ncharacters and must only contain alphanumeric characters and periods (\".\").\n10.Choose Publish custom lens.\nAfter the ML Lens has been published, it's in PUBLISHED  status.\nThe ML Lens can now be applied to workloads in your AWS account, and shared with other AWS accounts \nand users. If your account is managed by AWS Organizations, you can share the lens with all accounts in \nthe organization or in an OU without having to enumerate each account.\nAs you work through the ML Lens checklist, risks can be identi\ufb01ed and comments can be captured. A \nworkload report is available in PDF format for sharing with stakeholders to document risks and future \nrecommendations. Open risks can be managed and assigned in the tool and periodic milestone reviews \ncan be performed.\nFor more information on using the AWS WA Tool, custom lenses, reports, and the risk dashboard, see the\nAWS Well-Architected Tool User Guide.\n2", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "518576d6-d2b3-4fed-a57e-d1f69aca13c8": {"__data__": {"id_": "518576d6-d2b3-4fed-a57e-d1f69aca13c8", "embedding": null, "metadata": {"page_label": "3", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "99bdcc0f2a4b41d00013966cfd81d5dc55ab27badb0a8d8dc21a8d9700d50e1f", "text": "Machine Learning Lens AWS Well-Architected Framework\nWell-Architected Framework pillars\nThe AWS Well-Architected Framework provides architectural best practices for designing and operating \nworkloads in the cloud. The Framework consists of six pillars:\n\u2022Operational excellence - Includes the ability to run, monitor, and gain insights into workloads. It \nenables delivering business value and improves supporting processes and procedures. Best practice \nfocus areas include: organization, prepare, operate, and evolve.\n\u2022Security - Includes the ability to protect information, systems, and assets. It enables delivering \nbusiness value through risk assessments and mitigation strategies. Best practice focus areas include: \nsecurity foundations, identity and access management, detection, infrastructure protection, data \nprotection, incident response, and application security.\n\u2022Reliability - Includes the ability of a workload to recover from infrastructure or service disruptions. \nEnsures a workload performs its intended function correctly and consistently when it\u2019s expected to. \nIt enables dynamically acquiring computing resources to meet demand, and mitigating disruptions \nsuch as miscon\ufb01gurations and transient network issues. Best practice focus areas include: foundations, \nworkload architecture, change management, and failure management.\n\u2022Performance e\ufb03ciency - Focuses on the e\ufb03cient use of computing resources to meet requirements. It \nenables maintaining e\ufb03ciency as demand changes and technologies evolve. Best practice focus areas \ninclude: selection, review, monitoring, and trade-o\ufb00s.\n\u2022Cost optimization  - Includes the continuous process of re\ufb01nement and improvement of a system \nover its entire lifecycle. It enables building and operating cost-aware systems that minimize costs, \nmaximize return on investment, and achieve business outcomes. Best practice focus areas include: \nCloud Financial Management, expenditure and usage awareness, resource cost-e\ufb00ectiveness, resource \ndemand and supply management, and optimization.\n\u2022Sustainability - Focuses on environmental impacts, especially energy consumption and e\ufb03ciency, \nsince they are important levers for architects to inform direct action to reduce resource usage. Best \npractice focus areas include: Region selection, alignment to demand, software and architecture, data, \nhardware and services, and process and culture.\nWhile this paper focuses on the details speci\ufb01c to ML workloads, refer to the AWS Well-Architected \nFramework whitepaper for more information on the Framework and its pillars.\n3", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "13810b55-9a83-4cb0-b07f-9d7d6fe0d093": {"__data__": {"id_": "13810b55-9a83-4cb0-b07f-9d7d6fe0d093", "embedding": null, "metadata": {"page_label": "4", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "cc1e35ce81590b670e5eea4741e142a1129b58282fd4bd834bc14545ca68f925", "text": "Machine Learning Lens AWS Well-Architected Framework\nWell-Architected machine learning \nlifecycle\nThe ML lifecycle is the cyclic iterative process with instructions and best practices to use across de\ufb01ned \nphases while developing an ML workload. The ML lifecycle adds clarity and structure for making a \nmachine learning project successful. The end-to-end machine learning lifecycle process illustrated in \nFigure 1 includes the following phases:\n\u2022Business goal identi\ufb01cation\n\u2022ML problem framing\n\u2022Data processing (data collection, data preprocessing, feature engineering)\n\u2022Model development (training, tuning, evaluation)\n\u2022Model deployment (inference, prediction)\n\u2022Model monitoring\nThe phases of the ML lifecycle are not necessarily sequential in nature and can have feedback loops, a \nfew of which are illustrated in Figure 1, to interrupt the cycle across the lifecycle phases.\n4", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b630b5f2-6fe3-4288-b22b-7330bb5cb398": {"__data__": {"id_": "b630b5f2-6fe3-4288-b22b-7330bb5cb398", "embedding": null, "metadata": {"page_label": "5", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "50ea64edac860fa5c41368045e0968dd54a42a2b231d497dc51e7a8e85002820", "text": "Machine Learning Lens AWS Well-Architected Framework\nFigure 1: ML lifecycle\nThe following is a quick introduction to each phase, which will be expanded upon later in this paper.\nBusiness goal\nAn organization considering ML should have a clear idea of the problem, and the business value to be \ngained by solving that problem. You must be able to measure business value against speci\ufb01c business \nobjectives and success criteria.\nML problem framing\nIn this phase, the business problem is framed as a machine learning problem: what is observed and \nwhat should be predicted (known as a label or target variable). Determining what to predict and how \nperformance and error metrics must be optimized is a key step in this phase.\nData processing\nTraining an accurate ML model requires data processing to convert data into a usable format. Data \nprocessing steps include collecting data, preparing data, and feature engineering that is the process of \ncreating, transforming, extracting, and selecting variables from data.\n5", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "183bb781-2d0e-4917-8533-5889925a6cde": {"__data__": {"id_": "183bb781-2d0e-4917-8533-5889925a6cde", "embedding": null, "metadata": {"page_label": "6", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "540237dd2341ee77628615292d75c0014d7a33feda048a279cf850acd20f154e", "text": "Machine Learning Lens AWS Well-Architected Framework\nModel development\nModel development consists of model building, training, tuning, and evaluation. Model building \nincludes creating a CI/CD pipeline that automates the build, train and release to staging and production \nenvironments.\nDeployment\nAfter a model is trained, tuned, evaluated and validated, you can deploy the model into production. You \ncan then make predictions and inferences against the model.\nMonitoring\nModel monitoring system ensures your model is maintaining a desired level of performance through \nearly detection and mitigation.\nThe Well-Architected ML lifecycle, shown in Figure 2, takes the machine learning lifecycle just described, \nand applies the Well-Architected Framework pillars to each of the lifecycle phases.\nFigure 2: Well-Architected ML lifecycle\n6", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "c8133105-b3c9-4b0b-a078-2ba031ee1bd3": {"__data__": {"id_": "c8133105-b3c9-4b0b-a078-2ba031ee1bd3", "embedding": null, "metadata": {"page_label": "7", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "cbfc11dde72394ba716d0ed9d140f165858e77e3c476387440dd5b9c5e298800", "text": "Machine Learning Lens AWS Well-Architected Framework\nWell-Architected machine learning \ndesign principles\nWell-Architected ML design principles are a set of considerations used as the basis for a well-architected \nML workload.\nFollowing the Well-Architected Framework guidelines, use these general design principles to facilitate \ngood design in the cloud for ML workloads:\n\u2022Assign ownership- Apply the right skills and the right number of resources along with accountability \nand empowerment to increase productivity.\n\u2022Provide protection - Apply security controls to systems and services hosting model data, algorithms, \ncomputation, and endpoints. This ensures secure and uninterrupted operations.\n\u2022Enable resiliency - Ensure fault tolerance and the recoverability of ML models through version control, \ntraceability, and explainability.\n\u2022Enable reusability - Use independent modular components that can be shared and reused. This helps \nenable reliability, improve productivity, and optimize cost.\n\u2022Enable reproducibility - Use version control across components, such as infrastructure, data, models, \nand code. Track changes back to a point-in-time release. This approach enables model governance and \naudit standards.\n\u2022Optimize resources - Perform trade-o\ufb00 analysis across available resources and con\ufb01gurations to \nachieve optimal outcome.\n\u2022Reduce cost - Identify the potentials for reducing cost through automation or optimization, analyzing \nprocesses, resources, and operations.\n\u2022Enable automation - Use technologies, such as pipelining, scripting, and continuous integration (CI), \ncontinuous delivery (CD), and continuous training (CT), to increase agility, improve performance, \nsustain resiliency, and reduce cost.\n\u2022Enable continuous improvement - Evolve and improve the workload through continuous monitoring, \nanalysis, and learning.\n\u2022Minimize environmental impact - Establish sustainability goals and understand the impact of \nML models. Use managed services and adopt e\ufb03cient hardware and software and maximize their \nutilization.\n7", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "c00d6022-3042-4b49-9262-16e773fd6c34": {"__data__": {"id_": "c00d6022-3042-4b49-9262-16e773fd6c34", "embedding": null, "metadata": {"page_label": "8", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5b9663158a043337cb693c2f0dbfa06a8d4658b4385e9b2b99644b6fb2159626", "text": "Machine Learning Lens AWS Well-Architected Framework\nBusiness goal identi\ufb01cation lifecycle phase\nWell-Architected machine learning\nThis section introduces ML speci\ufb01c Well-Architected best practices. For each of the ML lifecycle phases, \nWell-Architected best practices are examined across each of the six pillars of operational excellence, \nsecurity, reliability, performance e\ufb03ciency, cost optimization, and sustainability. Best practices for each \nML lifecycle phase follow an introductory background on each phase.\nThe six phases for the ML lifecycle referenced in this paper are illustrated in Figure 3 in a sequence.\nFigure 3: ML Lifecycle phases\nThe following sections describe the Well-Architected machine learning best practices for each of the \nlifecycle phases.\nNote\nWhen there is a best practice that applies to multiple pillars or phases, it is described in the \npillar or phase where it makes the most impact. A complete list of the ML Lens best practices \nordered by pillar instead of by ML lifecycle phase can be found in Best practices arranged by \npillar  (p. 124).\nLifecycle phases\n\u2022ML lifecycle phase - Business goal  (p. 8)\n\u2022ML lifecycle phase - ML problem framing (p. 16)\n\u2022ML lifecycle architecture diagram  (p. 32)\n\u2022ML lifecycle phase - Data processing (p. 34)\n\u2022ML lifecycle phase - Model development (p. 56)\n\u2022ML lifecycle phase - Deployment (p. 87)\n\u2022ML lifecycle phase \u2013 Monitoring  (p. 103)\nML lifecycle phase - Business goal\nBusiness goal identi\ufb01cation is the most important phase of the ML lifecycle. An organization considering \nML should have a clear idea of the problem to be solved, and the business value to be gained. You must \nbe able to measure business value against speci\ufb01c business objectives and success criteria. While this \nholds true for any technical solution, this step is particularly challenging when considering ML solutions \nbecause ML is a constantly evolving technology.\u00a0\nAfter you determine your criteria for success, evaluate your organization's ability to move toward that \ntarget. The target should be achievable and provide a clear path to production. Involve all relevant \nstakeholders from the beginning to align them to this target and any new business processes that result \nfrom this initiative.\nStart the review by determining if ML is the appropriate approach for delivering your business goal. \nEvaluate all of the options that you have available for achieving the goal. Determine how accurate the \nresulting outcomes would be, while considering the cost and scalability of each approach.\nFor an ML-based approach to be successful, ensure that enough relevant, high-quality training data is \navailable to the algorithm. Carefully evaluate the data to make sure that the correct data sources are \navailable and accessible.\n8", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f9a09b09-9a91-4ee1-bd72-0081a582fe64": {"__data__": {"id_": "f9a09b09-9a91-4ee1-bd72-0081a582fe64", "embedding": null, "metadata": {"page_label": "9", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "fff69c96bf632aaddabe7d0fc0e05ca8c98ed9e9d0fb99675ecfc52edd32114b", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\nSteps in this phase:\nThe following work steps should be followed to establish your business goals.\n\u2022Business considerations\n\u2022Understand business requirements.\n\u2022Align a\ufb00ected stakeholders with this initiative.\n\u2022Form a business question.\n\u2022Identify critical, must-have features.\n\u2022Consider new business processes that might come out of this implementation.\n\u2022Consider how business value can be measured using business metrics that the ML model can help to \nimprove.\n\u2022Frame the ML problem\n\u2022De\ufb01ne the machine learning task based on the business question.\n\u2022Review proven or published works in similar domains, if available.\n\u2022Design small, focused POCs to validate those aspects of the approach where inadequate con\ufb01dence \nexists.\n\u2022Determine the optimization objective\n\u2022Determine key business performance metrics for the ML use case, such as uplift in new business \nacquisition, fraud detection rate, and anomaly detection. Increase CSAT according to the business \nneeds.\n\u2022Review data requirements\n\u2022Review the project\u2019s ML feasibility and data requirements.\n\u2022Cost and performance optimization\n\u2022Evaluate the cost of data acquisition, training, inference, and wrong predictions.\n\u2022Evaluate whether bringing in external data sources might improve model performance.\n\u2022Production considerations\n\u2022Review how to handle ML-generated errors.\n\u2022Establish pathways to production.\nBest practices\n\u2022Operational excellence pillar - Best practices (p. 9)\n\u2022Security pillar - Best practices (p. 11)\n\u2022Reliability pillar - Best practices (p. 12)\n\u2022Performance e\ufb03ciency pillar - Best practices (p. 13)\n\u2022Cost optimization pillar - Best practices (p. 13)\n\u2022Sustainability pillar - Best practices (p. 16)\nOperational excellence pillar - Best practices\nThe operational excellence pillar includes the ability to run and monitor systems to deliver business value \nand to continually improve supporting processes and procedures. This section includes best practices to \nconsider while identifying the business goal.\nBest practices\n\u2022MLOE-01: Develop the right skills with accountability and empowerment (p. 10)\n\u2022MLOE-02: Discuss and agree on the level of model explainability (p. 10)\n\u2022MLOE-03: Monitor model compliance to business requirements (p. 11)\n9", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "bc854b50-ff5d-40d6-8113-ae91cad563e2": {"__data__": {"id_": "bc854b50-ff5d-40d6-8113-ae91cad563e2", "embedding": null, "metadata": {"page_label": "10", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b30297225f7d2a34de611e7fd6a6f4a0d6a1390f8299a7e9ebc96855c15aafc1", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\nMLOE-01: Develop the right skills with accountability and \nempowerment\nArti\ufb01cial intelligence (AI) has many di\ufb00erent and growing branches, such as machine learning, deep \nlearning, and computer vision. Given the complexity and fast-growing nature of ML technologies, plan to \nhire specialists with the understanding that additional training will be needed as ML evolves. Keep teams \nlearning new skills, engaged, and motivated while encouraging accountability and empowerment at all \ntimes. Building ML models is a complex and iterative process that can infuse bias or unfair predictions \nagainst a certain entity. It\u2019s important to promote and enforce the ethical use of AI across enterprises. \nAWS provides clear guidance to customers for responsible AI practices.\nImplementation plan\nDevelop skills - A key element in any organization\u2019s strategy for employee engagement and business \ngrowth must be ongoing learning and development. Consider strategies to grow your ML-driven business \noutcomes through intentional workforce skills development. Building a successful ML workforce includes \nproviding training on ML concepts and algorithms, end-to-end ML lifecycle processes (such as model \ntraining, tuning, and deployment on Amazon SageMaker), and e\ufb03cient use of ML infrastructure with \nSageMaker and automation with MLOps tools, such as SageMaker Pipelines. Training people in di\ufb00erent \nspecialty areas of ML, such as computer vision, NLP, and reinforcement learning based on your business \nneeds, can increase productivity.\n\u2022Develop accountability and empowerment -AI applied through ML transforms the way business is \nrun by tackling some of humanity\u2019s most challenging problems, augmenting human performance, and \nmaximizing productivity. Promoting responsible use of these technologies is key to fostering continued \ninnovation. Eliminating bias in datasets and model predictions by using Amazon SageMaker Clarify can \nhelp you build fair and explainable models.\nDocuments\n\u2022Responsible use of Arti\ufb01cial Intelligence and Machine Learning\nBlogs\n\u2022Learn how SageMaker Clarify can detect bias\nMLOE-02: Discuss and agree on the level of model explainability\nDiscuss and agree with the business stakeholders on the acceptable level of model explainability required \nfor the use case. Use the agreed level as a metric for evaluations and tradeo\ufb00 analysis  across the ML \nlifecycle. Explainability can help with understanding the cause of a prediction, auditing, and meeting \nregulatory requirements. It can be useful for building trust ensuring that the model is working as \nexpected.\nImplementation plan\n\u2022Understand business requirements  - The adoption of AI systems in regulated domains requires trust. \nThis can be built by providing reliable explanations on the deployed predictions. Model explainability \ncan be particularly important to reliability, safety, and compliance requirements. Use SageMaker \nClarify to create explainability reports and detect dataset or model bias.\n\u2022Agree on an acceptable level of explainability - Communicate with stakeholders across the project \nabout the level of explainability that is required for the project. Agree to a level that helps you meet \nbusiness requirements.\n10", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f7e2f8e4-865b-4ac2-a9bb-d2e1f11d9b53": {"__data__": {"id_": "f7e2f8e4-865b-4ac2-a9bb-d2e1f11d9b53", "embedding": null, "metadata": {"page_label": "11", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f9e93d535398fe31e961d5cfc0b91898830ade6f400ca0f6000721363fab224d", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\n\u2022Choose good baselines \u2013  Shapley values determine the contribution that each feature made to \nmodel prediction. SHAP Baselines for Explainability are crucial to building fair and explainable ML \nmodels. Choose the baseline carefully since model explanations are based on deviations from the \nbaseline (the baseline, in the ML context, is a hypothetical instance). You can choose a baseline with \na \u2018low information content\u2019 (e.g., by constructing an average instance from the training dataset by \ntaking either the median or average for numerical features and the mode for categorical features) \nor a baseline with \u2018high information content\u2019 (e.g., an instance which represents a particular class of \ninstances that you are interested in). SageMaker Clarify, which uses Shapley Additive exPlanations \n(SHAP), calculates baselines automatically in the input dataset by using clustering methods such as K-\nmeans or K-prototypes. \u00a0For more on SHAP baselines and parameters, please see the documents listed \nbelow.\nDocuments\n\u2022What Is Fairness and Model Explainability for Machine Learning Predictions?\n\u2022Model Explainability\n\u2022SHAP Baselines\nMLOE-03: Monitor model compliance to business requirements\nMachine learning models degrade over time due to changes in the real world, such as data drift and\nconcept drift. If not monitored, these changes could lead to models becoming inaccurate or even \nobsolete over time. It\u2019s important to have a periodic monitoring process in place to make sure that your \nML models continue to comply to your business requirements, and that deviations are captured and \nacted upon promptly.\u00a0\nImplementation plan\n\u2022Agree on the metrics to monitor -  Clearly establish the metrics that you want to capture from your \nmodel monitoring process. These metrics should be tied to your business requirements and should \ncover your dataset-related statistics and model inference metrics.\n\u2022Have an action plan on a drift \u2013 If an unacceptable drift is detected in a dataset or the model output, \nhave an action plan to mitigate it based on the type of drift and the metrics associated. This mitigation \ncould include kicking o\ufb00 a retraining pipeline, updating the model, augmenting your dataset with \nmore instances, or enriching your feature engineering process.\nDocuments\n\u2022Monitor models for data and model quality using SageMaker Model Monitor\nBlogs\n\u2022Model monitoring at scale for production models\nSecurity pillar - Best practices\nThe security pillar encompasses the ability to protect data, systems, and assets to take advantage of \ncloud technologies to improve your security posture. This section includes best practices to consider \nwhile identifying the business goal.\nBest practices\n11", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "da8bdd5d-301f-45f5-8f8f-97fe3062a15c": {"__data__": {"id_": "da8bdd5d-301f-45f5-8f8f-97fe3062a15c", "embedding": null, "metadata": {"page_label": "12", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "4907b2a5f46c4fc7b27274b3efa349d2da1332712b09d035d3318c2756eae1da", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\n\u2022MLSEC-01: Validate ML data permissions, privacy, software, and license terms (p. 12)\nMLSEC-01: Validate ML data permissions, privacy, software, and \nlicense terms\nML libraries and packages handle data processing, model development, training, and hosting. Establish \na process to review the privacy and license agreements for all software and ML libraries needed \nthroughout the ML lifecycle. Ensure these agreements comply with your organization\u2019s legal, privacy, \nand security terms and conditions. These terms should not add any limitations on your organization\u2019s \nbusiness plans.\nImplementation plan\n\u2022Ensure data permissions for ML  - Verify whether the intended data can be used for machine learning, \nthat it\u2019s a legitimate purpose, and whether you require additional consent from the data owner or \ndata subjects. Have a plan to handle data subjects that subsequently withdraw their consent. Ensure \ndocumentation of data permissions is maintained for compliance purposes.\n\u2022Bootstrap instances with lifecycle management policies - Create a lifecycle con\ufb01guration with a \nreference to your package repository, and a script to install required packages.\n\u2022Evaluate package integrations that require external lookup services - Based on your data privacy \nrequirements, opt out of data collection when necessary. Minimize data exposure through trusted \nrelationships. Evaluate the privacy policies and the license terms for ML packages that might collect \ndata.\n\u2022Use prebuilt containers - Start with pre-packaged and veri\ufb01ed containers to quickly provide support \nfor commonly used dependencies. For example,\u00a0AWS Deep Learning Containers contain several deep \nlearning framework libraries and tools including TensorFlow, PyTorch, and Apache MXNet.\nDocuments\n\u2022Amazon Well-Architected Security Pillar for Software Integrity\n\u2022AWS Deep Learning Containers\n\u2022Installing External Libraries and Kernels on Notebook Instances\n\u2022AWS License Manager\n\u2022Lifecycle Con\ufb01guration Best Practices\nBlogs\n\u2022Private package installation in Amazon SageMaker running in internet-free mode\n\u2022Create a hosting VPC for PyPi package mirroring and consumption of approved packages\n\u2022Machine Learning Best Practices in Financial Services\nVideos\n\u2022Machine Learning Best Practices in Financial Services\nReliability pillar - Best practices\nThe reliability pillar encompasses the ability of a workload to perform its intended function correctly and \nconsistently when it\u2019s expected to. There are no reliability best practices to consider while identifying the \nbusiness goal.\n12", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "193111f3-8368-4c37-9e51-617a9ab50fc1": {"__data__": {"id_": "193111f3-8368-4c37-9e51-617a9ab50fc1", "embedding": null, "metadata": {"page_label": "13", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8bd1e0fdbcce20a452b50aa5108563eec1729de00089a141e395427c7d4c251a", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nPerformance e\ufb03ciency pillar - Best practices\nThe performance e\ufb03ciency pillar focuses on the e\ufb03cient use of computing resources to meet \nrequirements and the maintenance of that e\ufb03ciency as demand changes and technologies evolve. This \nsection includes best practices to consider while identifying the business goal.\nBest practices\n\u2022MLPER-01: Determine key performance indicators (p. 13)\nMLPER-01: Determine key performance indicators\nUse guidance from business stakeholders to capture key performance indicators (KPIs) relevant to \nthe business use case. The KPIs should be directly linked to business value to guide acceptable model \nperformance. Consider that machine learning inferences are probabilistic and will not provide exact \nresults. Identify a minimum acceptable accuracy and maximum acceptable error in the KPIs. This helps \nenable achieving the required business value and manage the risk of variable results.\nImplementation plan\n\u2022Quantify the value of machine learning for the business - Consider measures of how machine \nlearning and automation will impact the business:\n\u2022How much will machine learning reduce costs?\n\u2022How many more users will be reached by increasing scale?\n\u2022How much time will the business save by being able to respond faster to changes, such as in demand \nand supply disruptions?\n\u2022How many hours of manual e\ufb00ort will be eliminated by automating with machine learning?\n\u2022How much will machine learning be able to change user behavior, such as reducing churn?\n\u2022Evaluate risks and the tolerance for error -Quantify the impact of machine learning on the business. \nRank order the value of impacts to identify the primary KPIs to optimize with machine learning. \nDe\ufb01ne the cost of error for automated inferences that will be performed by ML models in the use \ncase. Determine the tolerance of the business for error. For example, determine how far o\ufb00 a cost \nreduction estimate would have to be to negatively impact the business goals. Finally, evaluate the risks \nof machine learning for the business, and whether the bene\ufb01ts of ML solutions are of high enough \nvalue to outweigh those risks.\nDocuments\n\u2022Improve Business Outcomes with Machine Learning\nBlogs\n\u2022Building the Business Case for Machine Learning in the Real World\nCost optimization pillar - Best practices\nThe cost optimization pillar includes the continual process of re\ufb01nement and improvement of a system \nover its entire lifecycle. From the initial design of your very \ufb01rst proof of concept to the ongoing \noperation of production workloads, adopting the practices in this document can enable you to build \nand operate cost-aware systems that achieve business outcomes and minimize costs, thus allowing your \nbusiness to maximize its return on investment. This section includes best practices to consider while \nidentifying the business goal.\n13", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "741ac371-44b9-4fd2-b844-06b296929a79": {"__data__": {"id_": "741ac371-44b9-4fd2-b844-06b296929a79", "embedding": null, "metadata": {"page_label": "14", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "23165fb0d41c4f41267e0f4c20bf08cd17f38c74a67074bfb5cb014e12b88a5b", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nBest practices\n\u2022MLCOST-01: De\ufb01ne overall return on investment (ROI) and opportunity cost (p. 14)\n\u2022MLCOST-02: Use managed services to reduce total cost of ownership (TCO) (p. 15)\nMLCOST-01: De\ufb01ne overall return on investment (ROI) and \nopportunity cost\nEvaluate the opportunity cost of ML for each use case to solve the business problem. Ensure cost \ne\ufb00ective decisions are made with respect to long-term resource allocation. Minimize the possible future \nrisks and failures through upfront understanding of the ML development process and its resource \nrequirements. Adopt automation and optimization that can result in reduced cost and improved \nperformance.\nImplementation plan\n\u2022Specify the objectives of the ML project as research or development. A research project is intended \nto discover the value that could be achieved from an untested ML use case, and the returns will be \nlong-term. A development project is intended for speci\ufb01c production improvements, and is expected \nto deliver a faster return on investment. Both business management and data scientists should agree \non whether the project is research-oriented, or development that applies well-understood methods to \na well-known use case.\n\u2022Use Tagging so that costs can be tracked by project and business unit to give clear sight of ROI.\n\u2022Evaluate and assess the data pipeline, the ML model, and the expected quality of production \ninferences to estimate the costs of data and errors.\n\u2022Develop a cost-bene\ufb01t model, and reassess that model as changes occur throughout the project. For \nexample, changes in the external business environment, or the addition of expensive data sources, can \nrequire modi\ufb01cations to the initial cost-bene\ufb01t model.\n\u2022Understand, evaluate, and monitor  project risks.\n\u2022Estimate the cost of resources needed, such as data engineers and data scientists, to maintain a \nproduction model.\nDocuments\n\u2022Pricing for Amazon ML\n\u2022AWS Application Cost Pro\ufb01ler\n\u2022Managing costs with AWS Budgets\n\u2022AWS Cost Explorer\n\u2022AWS Cost and Usage Report\u00a0\nBlogs\n\u2022Building the Business Case for Machine Learning in the Real World\nVideos\n\u2022APIs: ROI from arti\ufb01cial intelligence\n14", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "90d3a658-a007-4b76-b406-1e3f701861af": {"__data__": {"id_": "90d3a658-a007-4b76-b406-1e3f701861af", "embedding": null, "metadata": {"page_label": "15", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5bac155873f440405f7f375b70cbdf2c2a40bf28149be4ca5b0425b94b060e95", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nMLCOST-02: Use managed services to reduce total cost of \nownership (TCO)\nEvaluate adopting managed services and pay-per-usage. Using managed services enables organizations \nto operate more e\ufb03ciently with reduced resources and reduced cost.\nImplementation plan\n\u2022Use Amazon managed ML services - Use Amazon SageMaker as a fully managed machine learning \nservice to build, train, and deploy models at scale and at signi\ufb01cantly lower costs. The total cost\u00a0of \nownership (TCO) of SageMaker over a three-year period is much lower than other self-managed \ncloud-based ML options, such as Amazon Elastic Compute Cloud (Amazon EC2) and Amazon Elastic\nKubernetes Service (Amazon EKS). SageMaker includes technologies such as Autopilot , Feature Store,\nClarify, DataWrangler, Debugger , Studio , Training, Model deployment, Monitoring , and Pipelines .\n\u2022Use Amazon managed AI services - AWS pre-trained AI services provide ready-made intelligence for \nyour applications and work\ufb02ows. AI services integrate with your applications to address common use \ncases, such as personalized recommendations, modernizing your contact center, improving safety and \nsecurity, and increasing customer engagement. AI services on AWS don't require machine learning \nexperience. They are fully managed, complete solutions with pay-as-you-go pricing and no upfront \ncommitment.\n\u2022Perform pricing model analysis - Analyze each component of the workload. Determine if the \ncomponent and resources will be running for extended periods and eligible for commitment discounts, \nsuch as AWS Savings Plans. You can use\u00a0Savings Plans\u00a0to save on AWS usage in exchange for a \ncommitment to a consistent amount of usage.\u00a0Amazon SageMaker Savings Plans\u00a0o\ufb00er \ufb02exible \nattributes such as instance family, instance size, AWS Region, and component for your SageMaker \ninstance usage.\nDocuments\n\u2022Amazon SageMaker Total Cost of Ownership (TCO)\n\u2022AWS Pricing Calculator for SageMaker\n\u2022Amazon managed AI services\n\u2022AWS Savings Plans\nBlogs\n\u2022Lowering total cost of ownership for machine learning and increasing productivity with Amazon\nSageMaker\n\u2022Decrease Your Machine Learning Costs with Instance Price Reductions and Savings Plans for Amazon\nSageMaker\n\u2022Amazon SageMaker Continues to Lead the Way in Machine Learning and Announces up to 18% Lower\nPrices on GPU Instances\nVideos\n\u2022Optimizing your Machine Learning costs on Amazon SageMaker with Savings Plans (April 2021)\n15", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b8a5a6cb-2f04-47fb-8c27-1fd58e1c42ef": {"__data__": {"id_": "b8a5a6cb-2f04-47fb-8c27-1fd58e1c42ef", "embedding": null, "metadata": {"page_label": "16", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0de181ecfe090c26e38c26740843a5924e03f79d4c869b59307c437c79777e68", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\nSustainability pillar - Best practices\nThe sustainability pillar focuses on environmental impacts, especially energy consumption and e\ufb03ciency, \nsince they are important levers for architects to guide direct action on how to reduce resource usage. \nThis section includes best practices to consider while identifying the business goal.\nBest practices\n\u2022MLSUS-01: De\ufb01ne the overall environmental impact or bene\ufb01t (p. 16)\nMLSUS-01: De\ufb01ne the overall environmental impact or bene\ufb01t\nMeasure your workload\u2019s impact and its contribution to the overall sustainability goals of the \norganization.\u00a0\nImplementation plan\n\u2022Ask probing questions  - How does this workload support our overall sustainability mission? How \nmuch data will we have to store and process? What is the impact of training the model? How often will \nwe have to re-train? What are the impacts resulting from customer use of this workload? What will be \nthe productive output compared with this total impact? Asking these questions will help you establish \nspeci\ufb01c sustainability objectives and success criteria to measure against in the future.\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 1, identify business goals, validate ML use, and \nprocess data\n\u2022New \u2013 Customer Carbon Footprint Tool\nML lifecycle phase - ML problem framing\nIn this phase, the business problem is framed as a machine learning problem: what is observed and \nwhat should be predicted (known as a label or target variable). Determining what to predict and \nhow performance must be optimized is a key step in ML. For example, consider a scenario where a \nmanufacturing company wants to maximize pro\ufb01ts. There are several possible approaches including \nforecasting sales demand for existing product lines to optimize output, forecasting the required input \nmaterials and components required to reduce capital locked up in stock, and predicting sales for new \nproducts to prioritize new product development.\nIt's necessary to work through framing the ML problems in line with the business challenge.\nSteps in this phase:\n\u2022De\ufb01ne criteria for a successful outcome of the project.\n\u2022Establish an observable and quanti\ufb01able performance metric for the project, such as accuracy.\n\u2022De\ufb01ne the relationship between the technical metric (for example, accuracy) and the business outcome \n(for example, sales).\n\u2022Help ensure business stakeholders understand and agree with the de\ufb01ned performance metrics.\n\u2022Formulate the ML question in terms of inputs, desired outputs, and the performance metric to be \noptimized.\n\u2022Evaluate whether ML is the right approach. Some business problems don\u2019t need ML as simple business \nrules can do a much better job. For other business problems, there might not be su\ufb03cient data to \napply ML as a solution.\n16", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ed4fe457-628b-416b-8740-a1a876b21295": {"__data__": {"id_": "ed4fe457-628b-416b-8740-a1a876b21295", "embedding": null, "metadata": {"page_label": "17", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d1acd3b2687a7c4591a07a51c4b5426d385fb7fa00fc2770277ca8b58b46c2cc", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\n\u2022Create a strategy to achieve the data sourcing and data annotation objective.\n\u2022Start with a simple model that is easy to interpret, and makes debugging more manageable.\n\u2022Map the technical outcome to a business outcome.\n\u2022Iterate on the model by gathering more data, optimizing the parameters, or increasing the complexity \nas needed to achieve the business outcome.\nBest practices\n\u2022Operational excellence pillar - Best practices (p. 17)\n\u2022Security pillar - Best practices (p. 24)\n\u2022Reliability pillar - Best practices (p. 24)\n\u2022Performance e\ufb03ciency pillar - Best practices (p. 26)\n\u2022Cost optimization pillar \u2013 Best practices (p. 28)\n\u2022Sustainability pillar - Best practices (p. 30)\nOperational excellence pillar - Best practices\nThe operational excellence pillar includes the ability to run and monitor systems to deliver business value \nand to continually improve supporting processes and procedures. This section includes best practices to \nconsider while framing the ML problem.\nBest practices\n\u2022MLOE-04: Establish ML roles and responsibilities (p. 17)\n\u2022MLOE-05: Prepare an ML pro\ufb01le template (p. 19)\n\u2022MLOE-06: Establish model improvement strategies (p. 20)\n\u2022MLOE-07: Establish a lineage tracker system (p. 21)\n\u2022MLOE-08: Establish feedback loops across ML lifecycle phases (p. 22)\n\u2022MLOE-09: Review fairness and explainability (p. 23)\nMLOE-04: Establish ML roles and responsibilities\nUnderstand the roles, responsibilities, ownership, and required interactions across teams to maximize \noverall e\ufb00ectiveness. An ML project typically consists of multiple roles, with de\ufb01ned tasks and \nresponsibilities for each. In many cases, the separation of roles and responsibilities is not clear and there \nis overlap.\nImplementation plan\n\u2022Establish cross-functional teams with roles and responsibilities - Enterprises often struggle getting \nstarted with their \ufb01rst enterprise-grade ML platform. This is partly due to the ML platform architecture \nhaving many components. Complexities around data science, data management, and model and \noperational governance also contribute to this struggle. Building an enterprise ML platform requires \nthe collaboration of di\ufb00erent cross-functional teams. The di\ufb00erent personas from the di\ufb00erent teams \nshould each have a di\ufb00erent role and responsibilities. They all should contribute in the build-out, \nusage, and operation of an ML platform. Structure your ML organization to support your de\ufb01ned \nbusiness outcomes. Examples of ML technical roles and responsibilities with their de\ufb01nitions include:\n\u2022Domain expert - Has valuable functional knowledge and understanding of the environment that \nthe ML problem must be framed in. Helps ML engineers and data scientists with developing and \nvalidating assumptions and hypotheses. Engages early in the ML lifecycle and stays in close contact \nwith the engineering owners throughout the evaluation phase.\n17", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f301b346-e266-46ea-8f4a-9d0f95773d3c": {"__data__": {"id_": "f301b346-e266-46ea-8f4a-9d0f95773d3c", "embedding": null, "metadata": {"page_label": "18", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "1d3e78cb2f7e35485f53dea21fe488dab4c53b1301848dfcc59a2d14c44391d8", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\n\u2022Data engineer  - Transforms data into a consumable format for machine learning and data science \nanalysis.\n\u2022Data scientist  - Employs machine learning, statistical modeling, and arti\ufb01cial intelligence to derive \ninsights from the data.\n\u2022ML engineer  - Turns reference implementations of ML models developed by data scientists into \nproduction-ready software.\n\u2022MLOps engineer - Builds and manages automation pipelines to operationalize the ML platform and \nML pipelines for fully or partially automated CI/CD pipelines. These pipelines automate building \nDocker images, model training, and model deployment. MLOps engineers also have a role in \noverall platform governance such as data and model lineage, as well as infrastructure and model \nmonitoring.\n\u2022IT auditor  - Responsible for analyzing system access activities, identifying anomalies and violations, \npreparing audit reports for audit \ufb01ndings, and recommending remediations.\n\u2022Model risk manager  - Responsible for ensuring machine learning models meet various external and \ninternal control requirements. These requirements include: model inventory, model explainability, \nmodel performance monitoring, and model lifecycle management.\n\u2022Cloud security engineer - Responsible for creating, con\ufb01guring, and managing the cloud accounts, \nand the resources in the accounts. Works with other security functions, such as identity and access \nmanagement, to set up the required users, roles, and policies to grant users and services permissions \nto perform various operations in the cloud accounts. On the governance front, cloud security \nengineer implements governance controls such as resource tagging, audit trail, and other preventive \nand detective controls to meet both internal requirements and external regulations.\n\u2022Enable easy mechanisms to control access and grant permissions for various ML roles \u2013 Appropriate \nuser access controls are essential for governance; they enable practitioners to access the tools they \nneed to do their jobs, while ensuring data privacy and security.\n\u2022Avoid the use of one-time methods for managing access policies for large teams which contain \nmultiple roles for performing various ML activities, such as data preparation, training, and model \nmonitoring.\n\u2022Use Amazon SageMaker Role Manager to make it easier for administrators to control access and \nde\ufb01ne permissions for users. Administrators can select and edit prebuilt templates based on various \nuser roles and responsibilities. The tool then automatically creates the access policies with the \nnecessary permissions within minutes, reducing the time and e\ufb00ort to onboard and manage users \nover time.\nDocuments\n\u2022Personas for an ML platform\n\u2022AWS MLOps Framework\n\u2022Why should you use MLOps?\n\u2022Amazon SageMaker Role Manager\nBlogs\n\u2022Architecting Persona-centric Data Platform with on-premises Data Sources\n\u2022De\ufb01ne customized permissions in minutes with Amazon SageMaker Role Manager\n\u2022New ML Governance Tools for Amazon SageMaker \u2013 Simplify Access Control and Enhance \nTransparency Over Your ML Projects\n18", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f5dc0537-af8b-4886-95fe-35a947ad0792": {"__data__": {"id_": "f5dc0537-af8b-4886-95fe-35a947ad0792", "embedding": null, "metadata": {"page_label": "19", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "485dfba03a89517d8c615632c155e694fd5bf43a88c7cd2a43407fffb87f259c", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\nMLOE-05: Prepare an ML pro\ufb01le template\nPrepare an ML pro\ufb01le template to capture workload artifacts across ML lifecycle phases. The template \nhelps enable evaluating the current maturity status of a workload and plan for improvements \naccordingly. Artifact examples to capture for the deployment phase include: model instance size, \nmodel update schedule, and model deployment location. This template should have artifact metrics \nwith thresholds to evaluate and rank the level of maturity. Enable the ML pro\ufb01le template to \nre\ufb02ect workload maturity status with snapshots of existing pro\ufb01les, and alternative target pro\ufb01les. \nProvide documentation with rationale for choosing one option over another that meets the business \nrequirements.\nImplementation plan\n\u2022Capture ML workload deployment characteristics - Capture the most impactful deployment \ncharacteristics of your ML workload. In this paper, we will highlight the characteristics as a sample \npro\ufb01le template on AWS. The collected design and provisioning characteristics will help identify the \noptimal deployment architecture, including computing and inference instance types and sizes.\n\u2022Map ML workload characteristics across a spectrum from lower to higher ranges -Ideally, there \nshould be at least two pro\ufb01le templates generated for each workload characteristic. One ML \npro\ufb01le template gives a snapshot of the current workload pro\ufb01le. Another pro\ufb01le template can be \ninstantiated to capture the target or future characteristics of the ML workload.\n\u00a0 Documentation should provide the rationale for justifying the characteristic values in the target pro\ufb01le.\nSample design, architecture, and provisioning characteristics include:\n\u2022Model deployment sample characteristics include:\n\u2022Model size (model.tar.gz) in bytes\n\u2022Number of models deployed per endpoint\n\u2022Instance size (for example, r5dn.4x.large) as suggested by the inference recommender\n\u2022Retraining and model endpoint update frequency (hourly, daily, weekly, monthly, or per-event)\n\u2022Model deployment location (on premises,\u00a0Amazon EC2, container, serverless, or edge)\n\u2022Architectural deployment sample characteristics for the internal underlying algorithm or neural \narchitecture includes:\n\u2022Inference pipeline architecture (single endpoint, or chained endpoints)\n\u2022Neural architecture (single framework (Scikit-learn), or multi-framework (PyTorch+ Scikit-learn + \nTensorFlow))\n\u2022Containers ( SageMaker prebuilt container, bring your own container)\n\u2022Location of the containers and models (on premises, cloud, or hybrid)\n\u2022Serverless inferencing (pay as you go)\u00a0\n\u2022Tra\ufb03c pattern deployment sample characteristics include:\n\u2022Tra\ufb03c pattern (steady, or spiky)\n\u2022Input size (number of bytes)\n\u2022Latency (low, medium, high, or batch)\n\u2022Concurrency (single thread, or multi-thread)\n\u2022Cold start tolerance characteristics - Determine and document the tolerance of the various aspects of \ncold start in milliseconds.\n\u2022Network deployment characteristics - Check for the applicability of network deployment \ncharacteristics including AWS KMS encryption, multi-variant endpoints, network isolation, and third-\nparty Docker repositories.\n\u2022Cost considerations - Discuss and document the cost considerations for elements, such as Amazon \nEC2 Spot Instances.\n19", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "899b42d6-d9c2-414f-9bcf-09c2709eb703": {"__data__": {"id_": "899b42d6-d9c2-414f-9bcf-09c2709eb703", "embedding": null, "metadata": {"page_label": "20", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a675bb030543abdb40ac80170db4d45bbe991b3985759705219d9668dd225472", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\n\u2022Determine provisioning matrix - Critical ML workloads might be vying for resources from cloud \nproviders. For staging and production environments, include a matrix of the expected capacity \nrequirements. This matrix consists of the number of instance types per AWS Region across training, \nbatch interference, real-time inference, and notebooks.\nMLOE-06: Establish model improvement strategies\nPlan improvement drivers for optimizing model performance before ML model development starts. \nExamples of improvement drivers include: collecting more data, cross-validation, feature engineering, \ntuning hyperparameters, and ensemble methods.\nImplementation plan\n\u2022Use Amazon SageMaker Experiments - Improvement strategies for ML experimentation follow a \nsequence from simple to more complex. Begin with minimal data cleaning and the most obvious \ndata. Train a simple classical model using algorithms, such as linear regression or logistic regression, \nfor classi\ufb01cation tasks. Iterate by increasing the data processing and model complexity to improve \nmetrics related to business value. Amazon SageMaker Experiments can help to organize multiple tests \nto compare di\ufb00erent con\ufb01gurations and algorithms. A few sample approaches to experiment with \ninclude:\n\u2022Use e\ufb00ective feature selection - Work with subject matter experts to gain insight into the most \nsigni\ufb01cant features that will be related to the target values. Iteratively add more complex features, and \nremove less important features to improve model accuracy and robustness.\n\u2022Use deep learning - For a large volume training data, consider deep learning models to \ufb01nd previously \nunknown features and improve the model accuracy.\n\u2022Consider ensemble methods - Ensemble methods can add further improvements to accuracy \nby combining the best characteristics of various algorithms. However, there is a trade-o\ufb00 with \ncomputational performance and maintenance di\ufb03culty that should be considered for each speci\ufb01c \nbusiness use case.\n\u2022Consider AutoML  - Automatic machine learning, known as AutoML, removes the tedious, iterative, \nand time-consuming work across the machine learning work\ufb02ow from data acquisition to model \noperationalization, so you can spend less time on low level details and more time on using ML to \nimprove business outcomes. AutoML tools take care of sourcing and preparing data, engineering \nfeatures, training and tuning models, deploying models, and ongoing model monitoring and updating. \nAmazon SageMaker Autopilot is an AutoML solution for tabular data.\n\u2022Optimize hyperparameters - Optimize hyperparameters for each algorithm to obtain the top \nperformance before selection of the most appropriate. Amazon SageMaker Hyperparameter\nOptimization  automates this process of selecting the top performance.\nDocuments\n\u2022Manage Machine Learning with Amazon SageMaker Experiments\n\u2022Perform Automatic Model Tuning with SageMaker\n\u2022Automate the experimental trials into SageMaker Pipelines by leveraging the native SageMaker \nPipelines integration with experiments\n\u2022Automate model development with Amazon SageMaker Autopilot\nBlogs\n\u2022Developing a business strategy by combining machine learning with sensitivity analysis\n20", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "937fa38a-c5d6-45f7-8b4f-981fffc75952": {"__data__": {"id_": "937fa38a-c5d6-45f7-8b4f-981fffc75952", "embedding": null, "metadata": {"page_label": "21", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e1bcd7496ad3b9b58a980adff0b22d2fa0025db1ebee1915e1ecacd4e762f2fb", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\n\u2022Amazon SageMaker Experiments \u2013 Organize, Track And Compare Your Machine Learning Trainings\n\u2022Code-free machine learning: AutoML with AutoGluon, Amazon SageMaker, and AWS Lambda\nVideos\n\u2022Hyperparameter Tuning with Amazon SageMaker's Automatic Model Tuning\nExamples\n\u2022Ensemble Predictions from Multiple Models\nMLOE-07: Establish a lineage tracker system\nMaintain a system that tracks changes for each release. These changes include documentation, \nenvironment, model, data, code, and infrastructure. Having this system allows you to go back and quickly \nreproduce a problem on a prior release, allowing rollbacks and reproducibility.\nImplementation plan\n\u2022Identify artifacts needed for tracking - Tracking all the artifacts used for a production model is an \nessential requirement for reproducing the model to meet regulatory and control requirements. Data\nand artifacts lineage tracking includes the list of artifacts needed for tracking.\n\u2022Use SageMakerML Lineage Tracking - SageMaker ML Lineage Tracking creates and stores information \nabout the steps of an ML work\ufb02ow from data preparation to model deployment. With the tracking \ninformation, you can reproduce the work\ufb02ow steps, track model and data set lineage, and establish \nmodel governance and audit standards.\n\u2022Use SageMaker Studio - Use SageMaker Studio to track the lineage of a SageMaker ML pipeline.\n\u2022Use SageMaker Feature Store \u2013 Amazon SageMaker Feature Store is a purpose-built repository where \nyou can store and access features so it\u2019s much easier to name, organize, and reuse them across teams. \nSageMaker Feature Store provides a uni\ufb01ed store for features during training and real-time inference \nwithout the need to write additional code or create manual processes to keep features consistent\n\u2022Use SageMaker Model Registry - Use SageMaker Model Registry to catalog models for production, \nmanage model versions, and associate metadata with a model. Model Registry enables lineage \ntracking.\n\u2022Use SageMaker Pipelines for model building -With SageMaker Pipelines you can track the history of \nyour data within the pipeline. SageMaker ML Lineage Tracking lets you analyze input data, its source, \nand the outputs generated.\nDocuments\n\u2022SageMaker ML Lineage Tracking\n\u2022Data and artifacts lineage tracking\n\u2022SageMaker Model Building Pipelines\n\u2022Track the Lineage of a SageMaker ML Pipeline\n\u2022SageMaker Studio\n\u2022SageMaker Model Registry\n\u2022SageMaker Feature Store\n21", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "08a97c44-395d-4c76-9f59-7760c317aa0c": {"__data__": {"id_": "08a97c44-395d-4c76-9f59-7760c317aa0c", "embedding": null, "metadata": {"page_label": "22", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "46be9a7a4053d194c2b38f9942a3e3d250b16ade6277d4e444ac7f5bb0b3aec9", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\nBlogs\n\u2022Using model attributes to track your training runs on Amazon SageMaker\nExamples\n\u2022Controlling and auditing data exploration activities with SageMakerStudio and AWS Lake Formation\nMLOE-08: Establish feedback loops across ML lifecycle phases\nEstablish a feedback mechanism to share and communicate successful development experiments, \nanalysis of failures, and operational activities. This facilitates continuous improvement on future \niterations of the ML workload. ML feedback loops are driven by model drifts and requires ML \npractitioners to analyze and revisit monitoring and retraining strategies over time. ML feedback loops \nallow experimentation with data augmentation, and di\ufb00erent algorithms and training approaches until \nan optimal outcome is achieved. Document your \ufb01ndings to identify key learnings and improve processes \nover time.\nImplementation plan\n\u2022Establish SageMaker Model Monitoring - The accuracy of ML models can deteriorate over time, a \nphenomenon known as model drift. Many factors can cause model drift, such as changes in model \nfeatures. The accuracy of ML models can also be a\ufb00ected by concept drift, the di\ufb00erence between data \nused to train models and data used during inference. Amazon SageMaker Model Monitor continually \nmonitors machine learning models for concept drift and model drift. SageMaker Model Monitor alerts \nyou if there are any deviations so that you can take remedial action.\n\u2022Use Amazon CloudWatch - Con\ufb01gure Amazon CloudWatch to receive noti\ufb01cations if a drift in model \nquality is observed. Monitoring jobs can be scheduled to run at a regular cadence (for example, \nhourly or daily) and push reports as well as metrics to Amazon CloudWatch and Amazon S3.\n\u2022Use Amazon SageMaker Model Dashboard as the central interface to track models, monitor \nperformance, and review historical behavior\n\u2022Automate retraining pipelines  - Create a CloudWatch Events rule that alerts on a events emitted \nby the SageMaker Model Monitoring system. The event rule can detect the drifts or anomalies, and \nstart a retraining pipeline.\n\u2022Use Amazon Augmented AI (A2I) - Check accuracy by having human reviews to establish the ground \ntruth , using tools such as Amazon A2I, against which model performance can be compared.\nDocuments\n\u2022Amazon SageMaker Model Monitor\n\u2022Creating a CloudWatch Events Rule That Triggers on an Event\n\u2022SageMaker Model Dashboard\n\u2022Monitoring Amazon ML with Amazon CloudWatch Metrics\nBlogs\n\u2022Automated monitoring of your machine learning models with Amazon SageMakerModel Monitor and \nsending predictions to human review work\ufb02ows using Amazon A2I\n\u2022Automating model retraining and deployment using the AWS Step Functions Data Science SDK for\nAmazon SageMaker\n\u2022Monitoring in-production ML models at large scale using Amazon SageMaker Model Monitor\n22", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "c2818042-2ad7-4abd-b138-89a5db55e495": {"__data__": {"id_": "c2818042-2ad7-4abd-b138-89a5db55e495", "embedding": null, "metadata": {"page_label": "23", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c9c629199f70982ea0eb7596732505daebe776f6438b6ec7fbde4d1ecfb7bbe3", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\n\u2022Human-in-the-loop review of model explanations with Amazon SageMaker Clarify and Amazon A2I\n\u2022Amazon SageMaker Model Monitor now supports new capabilities to maintain model quality in\nproduction\nVideos\n\u2022Easily Implement Human in the Loop into Your Machine Learning Predictions with Amazon A2I\nMLOE-09: Review fairness and explainability\nConsider fairness and explainability during each stage of the ML lifecycle. Compile a list of questions to \nreview for each stage including:\n\u2022Problem framing - Is an algorithm an ethical solution to the problem?\n\u2022Data management  - Is the training data representative of di\ufb00erent groups? Are there biases in labels \nor features? Does the data need to be modi\ufb01ed to mitigate bias?\n\u2022Training and evaluation - Do fairness constraints need to be included in the objective function? Does \nchanging the number of models to train needed to mitigate bias? Has the model been evaluated using \nrelevant fairness metrics?\n\u2022Deployment - Is the model deployed on a population for which it was not trained or evaluated?\n\u2022Monitoring  - Are there unequal e\ufb00ects across users?\nImplementation plan\n\u2022Use Amazon SageMaker Clarify - Understand model characteristics, debug predictions, and explain \nhow ML models make predictions with Amazon SageMaker Clarify. Amazon SageMaker Clarify uses \na model-agnostic feature attribution approach that includes an e\ufb03cient implementation of SHAP\n(Shapley Additive Explanations). SageMaker Clarify allows you to:\n\u2022Understand the compliance requirements for fairness and explainability.\n\u2022Determine whether training data is biased in its classes or population segments, particularly \nprotected groups.\n\u2022Develop a strategy for monitoring for bias in data when the model is in production.\n\u2022Consider the trade-o\ufb00s between model complexity and explainability, and select simpler models if \nexplainability is required.\nDocuments\n\u2022What Is Fairness and Model Explainability for Machine Learning Predictions?\n\u2022Amazon SageMaker Clarify: Detect bias in ML models and understand model predictions\n\u2022Feature Attributions that Use Shapley Values\n\u2022Amazon SageMaker Clarify: Machine Learning Bias Detection and Explainability in the Cloud\nBlogs\n\u2022ML model explainability with Amazon SageMaker Clarify and the SK Learn pre-built container\n\u2022Explaining Amazon SageMaker Autopilot models with SHAP\n23", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "4df77e7e-d40c-45dc-8258-7dde380c090a": {"__data__": {"id_": "4df77e7e-d40c-45dc-8258-7dde380c090a", "embedding": null, "metadata": {"page_label": "24", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b610f420b513883b80c45ae7eb31f305a87de9ef912dc1f6a5bb5ca656f5b6a3", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\nVideos\n\u2022Machine learning and society: Bias, fairness, and explainability\n\u2022How Clarify helps machine learning developers detect unintended bias\n\u2022Interpretability and explainability in machine learning\nSecurity pillar - Best practices\nThe security pillar encompasses the ability to protect data, systems, and assets to take advantage of \ncloud technologies to improve your security. This section includes best practices to consider while \nframing the ML problem.\nBest practices\n\u2022MLSEC-02: Design data encryption and obfuscation\u00a0 (p. 24)\nMLSEC-02: Design data encryption and obfuscation\u00a0\nConsider how personal data should be protected. Field level encryption or obfuscation can be used to \nprotect personally identi\ufb01able data.\u00a0\nImplementation plan\n\u2022Audit data for attributes requiring special treatment - Identify \ufb01elds containing data requiring \nspecial treatment, such as \ufb01eld level encryption, data masking or obfuscation\nBlogs\n\u2022Introducing PII Data Identi\ufb01cation and Handling Using AWS Glue Databrew\n\u20227 ways to improve security of your machine learning work\ufb02ows\n\u2022Secure deployment of Amazon SageMaker resources\nReliability pillar - Best practices\nThe reliability pillar encompasses the ability of a workload to perform its intended function correctly and \nconsistently when it\u2019s expected to. This section includes best practices to consider while framing the ML \nproblem.\nBest practices\n\u2022MLREL-01: Use APIs to abstract change from model consuming applications (p. 24)\n\u2022MLREL-02: Adopt a machine learning microservice strategy (p. 25)\nMLREL-01: Use APIs to abstract change from model consuming \napplications\nUse a \ufb02exible application and API design to abstract change from model consuming applications. Ensure \nthat changes to an ML model are introduced with minimal or no interruption to existing workload \ncapabilities. Minimize the changes across other downstream applications.\n24", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2dcc83d2-ee7a-4cf9-bd52-5bbf83e9acfe": {"__data__": {"id_": "2dcc83d2-ee7a-4cf9-bd52-5bbf83e9acfe", "embedding": null, "metadata": {"page_label": "25", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0a2184014331961e9c6781c1abb1e5b6911309608f9cdcce4dd18ff7217c4a59", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nImplementation plan\n\u2022Adopt best practices in use of APIs -Expose your ML endpoints through APIs so that changes to \nthe model can be introduced without disrupting upstream communications. Document your API in a \ncentral repository or documentation site so that any calling services can easily understand your API \nroutes and \ufb02ags. Ensure that any changes to your API are communicated with any calling services.\n\u2022Deploy a model in Amazon SageMaker- After you train your model, you can deploy it using Amazon\nSageMaker to get predictions. To establish a persistent endpoint to get one prediction at a time, use \nSageMaker hosting services. To get predictions for an entire dataset, use SageMaker batch transform.\n\u2022Use Amazon API Gateway to create APIs - Amazon API Gateway is a fully managed service that \nenables developers to create, publish, maintain, monitor, and secure APIs. Using API Gateway, you can \ncreate RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. \nAPI Gateway supports containerized and serverless workloads, as well as web applications.\nDocuments\n\u2022Deploy a Model in Amazon SageMaker\n\u2022What is Amazon API Gateway?\n\u2022API Gateway Pattern\nBlogs\n\u2022Build a serverless frontend for an Amazon SageMaker endpoint\n\u2022Creating a machine learning-powered REST API with Amazon API Gateway mapping templates and\nAmazon SageMaker\n\u2022Deploying machine learning models with serverless templates\nVideos\n\u2022Deploy Your ML Models to Production at Scale with Amazon SageMaker\nExamples\n\u2022AWS Solutions Constructs aws-apigateway-sagemaker endpoint\n\u2022AWS MLOps Framework\n\u2022Amazon SageMaker Safe Deployment Pipeline\n\u2022Amazon SageMaker Inference Client Application\nMLREL-02: Adopt a machine learning microservice strategy\nWhere appropriate, a complex business problem can be usefully decomposed into a series of machine \nlearning models with a loosely coupled implementation. This can be accomplished by adopting a \nmicroservice instead of a monolithic architecture. This approach replaces one large resource with \nmultiple small resources and can reduce the impact of a single failure on the overall workload. This \nstrategy enables distributed development and improves scalability, enabling easier change management.\nImplementation plan\n\u2022Adopt a microservice strategy - Service-oriented architecture (SOA) is the practice of making software \ncomponents reusable using service interfaces. Instead of building a monolithic application, where \n25", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "29638380-0374-44e4-8a06-8a388d363e94": {"__data__": {"id_": "29638380-0374-44e4-8a06-8a388d363e94", "embedding": null, "metadata": {"page_label": "26", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c81c513f9a6c0b24793cd413f79b9a5eb4f7f90334be13f6ac90a79bcf8c3300", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nall functionality is contained in a single runtime, the application is instead broken into separate \ncomponents. Microservices extend this by making components that are single-purpose and reusable. \nWhen building your architecture, divide components along business boundaries or logical domains. \nAdopt a philosophy that favors single-purpose applications that can be composed in di\ufb00erent ways to \ndeliver di\ufb00erent end-user experiences.\n\u2022Use AWS services in developing microservices - Two popular approaches for developing \nmicroservices are using AWS Lambda and Docker containers with AWS Fargate. With AWS Lambda, \nyou can run code for virtually any type of application or backend service with zero administration. \nYou pay only for the compute time you consume, and there is no charge when your code is not \nrunning. A common approach to reduce operational e\ufb00orts for deployment is using a container- \nbased deployment. AWS Fargate is a container management service that allows you to run serverless \ncontainers so you don\u2019t have to worry about provisioning, con\ufb01guring, and scaling clusters of virtual \nmachines to run containers.\nDocuments\n\u2022Implementing Microservices on AWS\n\u2022Microservices on AWS\n\u2022Break a Monolith Application into Microservices\n\u2022AWS Lambda Documentation\n\u2022What is AWS Fargate?\nBlogs\n\u2022Deploying Python Flask microservices to AWS using open-source tools\n\u2022Deploying machine learning models as serverless APIs\n\u2022Integrating machine learning models into your Java-based microservices\n\u2022Adopting machine learning in your microservices with DJL (Deep Java Library) and Spring Boot\n\u2022Building, deploying, and operating containerized applications with AWS Fargate\nVideos\n\u2022Breaking the Monolith Using AWS Container Services\n\u2022AWS New York Summit 2019: Migrating Monolithic Applications with the Strangler Pattern (FSV303)\nExamples\n\u2022Run a Serverless \u201cHello, World\u201d with AWS Lambda\nPerformance e\ufb03ciency pillar - Best practices\nThe performance e\ufb03ciency pillar focuses on the e\ufb03cient use of computing resources to meet \nrequirements and the maintenance of that e\ufb03ciency as demand changes and technologies evolve. This \nsection includes best practices to consider while framing the ML problem.\nBest practices\n\u2022MLPER-02: Use purpose-built AI and ML services and resources (p. 27)\n\u2022MLPER-03: De\ufb01ne relevant evaluation metrics (p. 27)\n26", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8b3f79f2-2e30-4626-b112-7e77d02e1114": {"__data__": {"id_": "8b3f79f2-2e30-4626-b112-7e77d02e1114", "embedding": null, "metadata": {"page_label": "27", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "441b23d46a0097e09e3f1dd8e48e0ffa73ec3cd84177957cd10ca782cfb843d6", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nMLPER-02: Use purpose-built AI and ML services and resources\nConsider how part or all of the workload could be handled by pre-built AI services or ML resources. \nBetter performance can often be delivered more e\ufb03ciently by using pre-optimized components included \nin AI and ML managed services. Select an optimal mix of bespoke and pre-built components to\u00a0meet the \nworkload requirements.\nImplementation plan\n\u2022Learn about AWS AI services - Determine whether AWS managed AI services are applicable to the \nbusiness use case. Understand how managed AWS AI services can relieve the burden of training \nand\u00a0maintaining an ML pipeline. Use Amazon SageMaker to develop in the cloud and understand \nthe roles and responsibilities needed to maintain the ML workload. Consider combining managed \nAI services with custom ML models built on Amazon SageMaker. This approach allows balancing the \ntradeo\ufb00s between ML workload management, and solutions speci\ufb01city for the business use case.\n\u2022Learn about  SageMaker JumpStart \u2013 This service provides pre-trained, open-source models for a wide \nrange of problem types to help you get started with machine learning.\n\u2022Learn about  SageMaker Algorithms and Models in AWS Marketplace, a curated digital catalog that \nmakes it easy for you to \ufb01nd, buy, deploy, and manage third-party software and services that can help \nyou build solutions and run their businesses.\nDocuments\n\u2022Overview of Amazon Web Services: Machine Learning\n\u2022Machine Learning on AWS\n\u2022Architecture Best Practices for Machine Learning\nVideos\n\u2022An Overview of AI and Machine Learning Services From AWS\nMLPER-03: De\ufb01ne relevant evaluation metrics\nTo validate and monitor model performance, establish numerical metrics that directly relate to the KPIs. \nThese KPIs are established in the business goal identi\ufb01cation phase. Evaluate whether the performance \nmetrics accurately re\ufb02ect the business\u2019 tolerance for the error. For instance, false positives might lead to \nexcessive maintenance costs in predictive maintenance use cases. Numerical metrics, such as precision \nand recall, would help di\ufb00erentiate the business requirements and be closer aligned to business value. \nConsider developing custom metrics that tune the model directly for the business objectives. Examples \nof standard metrics for ML models include:\n\u2022Classi\ufb01cation\n\u2022Confusion matrix (precision, recall, accuracy, F1 score)\n\u2022Receiver operating characteristic-area under curve (AUC)\n\u2022Logarithmic loss (log-loss)\n\u2022Regression\n\u2022Root mean square error (RMSE)\n\u2022Mean absolute percentage error (MAPE)\n27", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9916cf39-c9b2-440f-814b-251d39fd1ca7": {"__data__": {"id_": "9916cf39-c9b2-440f-814b-251d39fd1ca7", "embedding": null, "metadata": {"page_label": "28", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d5e2913dc5188ff698c625b22a7833bf04f1f1153853802c6dae340718fcfd6f", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nImplementation plan\n\u2022Optimize business-related metrics - Identify performance metrics relevant to use-case and model \ntype. Implement the metric as a loss function or use the loss function included in Amazon SageMaker. \nUse Amazon SageMaker Experiments to evaluate the metrics with consideration to the business use \ncase to maximize business value. Track model and concept drift in real time with Amazon SageMaker\nModel Monitor  to estimate errors.\n\u2022Calculate the maximum probability of error that will be required for the ML model to produce results \nconsidering the tolerance set by the business.\n\u2022Select and train ML models on the available data to make prediction within the probability bounds. \nOrganize tests on di\ufb00erent models with Amazon SageMaker Experiments.\nDocuments\n\u2022Monitor and Analyze Training Jobs Using Metrics\n\u2022Manage Machine Learning with Amazon SageMaker Experiments\nBlogs\n\u2022Training models with unequal economic error costs using Amazon SageMaker\n\u2022Amazon SageMaker Experiments \u2013 Organize, Track, and Compare Your Machine Learning Trainings\nVideos\n\u2022Organize, Track, and Evaluate ML Training Runs with Amazon SageMaker Experiments\nExamples\n\u2022Scikit-Learn Data Processing and Model Evaluation\nCost optimization pillar \u2013 Best practices\nThe cost optimization pillar includes the continual process of re\ufb01nement and improvement of a system \nover its entire lifecycle. From the initial design of your very \ufb01rst proof of concept to the ongoing \noperation of production workloads, adopting the practices in this document can enable you to build \nand operate cost-aware systems that achieve business outcomes and minimize costs, thus allowing your \nbusiness to maximize its return on investment. This section includes best practices to consider while \nframing the ML problem.\nBest practices\n\u2022MLCOST-03: Identify if machine learning is the right solution (p. 28)\n\u2022MLCOST-04: Tradeo\ufb00 analysis on custom versus pre-trained models (p. 29)\nMLCOST-03: Identify if machine learning is the right solution\nEvaluate if there are alternatives, such as a simple rule-based approach, that could do a better job than \nML. Weigh the cost of adopting ML against the opportunity cost of not leaning on ML transformation. \nSpecialized resources, such as data scientist time or model time-to-market, might be the most expensive \nand constrained resources. The most cost-e\ufb00ective hardware choice might not be cost optimized if it \nconstrains experimentation and development speed.\n28", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0eee301e-92cb-45e7-a1cd-33a76354ecc7": {"__data__": {"id_": "0eee301e-92cb-45e7-a1cd-33a76354ecc7", "embedding": null, "metadata": {"page_label": "29", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0219871bdb0054aa43776a8eee44bd8d3876af38974e9a4ff7a28e364b079632", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nImplementation plan\n\u2022Start simple:\n\u2022Articulate your problem.\n\u2022Identify your data sources.\n\u2022Think about cost involved in:\u00a0\n\u2022Designing or preparing your data for the model.\n\u2022Data storage cost for ML.\n\u2022Model training cost depending on the hardware. choice\n\u2022Data labeling cost, if required.\n\u2022Potential bias resulting in iterative model re-training leading to higher cost.\n\u2022Potential cost of hosting the ML model.\n\u2022Model maintenance costs.\n\u2022Consider these data points to weigh the cost of adopting ML against the opportunity cost of not \nleaning on ML transformation.\n\u2022Use Amazon SageMaker Autopilot and SageMaker Clarify to validate that ML is the right solution.\n\u2022Baseline the solution  by reviewing how the problem is solved today. If a rules-based solution is \navailable, then use it as a baseline.\u00a0Selecting a simple ML model for baselining can also be done \nusing JumpStart or AWS Marketplace. AWS also provides many pre-built solutions with one-click \ndeploy for most common business use cases.\n\u2022Build a machine learning model using SageMaker or SageMaker Autopilot and compare the metrics \nof this solution against the baseline.\n\u2022Use SageMaker Clarify to explain the model that you have built using SageMaker or Autopilot.\n\u2022Identify if the ML model is performing better than your existing solution or a rules-based approach \nbefore investing on an ML-based solution.\nDocuments\n\u2022Amazon SageMaker\n\u2022Amazon SageMaker Autopilot\n\u2022Amazon SageMaker Jumpstart\n\u2022Amazon SageMaker Clarify\n\u2022Machine Learning solutions in AWS Marketplace\nMLCOST-04: Tradeo\ufb00 analysis on custom versus pre-trained \nmodels\nOptimize the cost through tradeo\ufb00 analysis based on custom versus pre-trained models. This tradeo\ufb00 \nanalysis should keep the security and performance e\ufb03ciency in perspective and within the acceptable \nthresholds.\nImplementation plan\n\u2022Use Amazon SageMaker built-in algorithms and AWS Marketplace - Amazon SageMaker provides \na suite of built-in algorithms to help data scientists and machine learning practitioners get started \non training and deploying machine learning models. Pre-trained ML models are ready-to-use models \nthat can be quickly deployed on Amazon SageMaker. By pre-training the ML models for you, solutions \nin the AWS Marketplace take care of the heavy lifting, helping you deliver AI- and ML-powered \nfeatures faster and at a lower cost. Evaluate the cost of your data scientists\u2019 time and other resource \n29", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3197d148-a31f-4a9d-ba86-7eea55e3e93b": {"__data__": {"id_": "3197d148-a31f-4a9d-ba86-7eea55e3e93b", "embedding": null, "metadata": {"page_label": "30", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "4ad2f0a28b0c19450ee5712e8cb7051bc68232fd16d58f8dbdbc6ceeda9781ea", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\nrequirements to develop your own custom model vs. bringing a pre-trained model and deploying it on \nSageMaker for inferencing. The advantage of a custom model is the \ufb02exibility to \ufb01ne-tune it to match \nthe needs of your business use case. A pre-trained model can be di\ufb03cult to modify and you might \nhave to use it as is.\n\u2022Use Amazon SageMaker Jumpstart to access pre-trained models and accelerate the ML development \nprocess. SageMaker JumpStart provides a set of solutions for the most common use cases that can be \ndeployed readily with just a few clicks. The solutions are fully customizable and showcase the use of \nAWS CloudFormation templates and reference architectures so you can accelerate your ML journey. \nAmazon SageMaker JumpStart also supports one-click deployment and \ufb01ne-tuning of more than \n150 popular open-source models such as natural language processing, object detection, and image \nclassi\ufb01cation models.\nDocuments\n\u2022Pre-trained machine learning models available in AWS Marketplace\n\u2022Amazon SageMaker Jumpstart\nBlogs\n\u2022Bring your own pre-trained MXNet or TensorFlow models into Amazon SageMaker\n\u2022How Startups Deploy Pretrained Models on Amazon SageMaker\n\u2022Amazon SageMaker JumpStart Simpli\ufb01es Access to Pre-built Models and Machine Learning Solutions\n\u2022Amazon SageMaker JumpStart models and algorithms now available via API\n\u2022Machine Learning algorithms and model packages now available in AWS Marketplace\n\u2022Using Amazon Augmented AI with AWS Marketplace machine learning models\n\u2022Save costs by automatically shutting down idle resources within Amazon SageMaker Studio\nSustainability pillar - Best practices\nThe sustainability pillar focuses on environmental impacts, especially energy consumption and e\ufb03ciency, \nsince they are important levers for architects to inform direct action to reduce resource usage. This \nsection includes best practices to consider while framing the ML problem.\nBest practices\n\u2022MLSUS-02: Consider AI services and pre-trained models (p. 30)\n\u2022MLSUS-03: Select sustainable Regions (p. 31)\nRelated best practices\n\u2022Identify if machine learning is the right solution (MLCOST-03) - Always ask if AI or ML is right for \nyour workload. There is no need to use computationally intensive AI when a simpler, more sustainable \napproach might be just as successful. For example, using ML to route Internet of Things (IoT) messages \nmight be unwarranted. Instead, you might be able to express the logic with a rules engine.\nMLSUS-02: Consider AI services and pre-trained models\nConsider whether the workload needs to be developed as a custom model. Many workloads can use \nmanaged AI services accessible through an API. Using these services means that you won\u2019t need to \nprovision your own resources to collect, store, and process training data and to prepare, train, tune, and \ndeploy an ML model.\n30", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "db92fdab-9433-434a-9b56-e0347c9c4f70": {"__data__": {"id_": "db92fdab-9433-434a-9b56-e0347c9c4f70", "embedding": null, "metadata": {"page_label": "31", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "08c30eeb511ace41f2bfd60f33520ab5dcae5f9647333eba94bf15cbbb0d9310", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\nIf adopting a fully managed AI service is not appropriate, evaluate if you can use pre-existing datasets, \nalgorithms, or models. You can also \ufb01ne-tune an existing model starting from a pre-trained model. Using \npre-trained models from third parties can reduce the resources needed for data preparation and model \ntraining.\nImplementation plan\n\u2022Use pre-trained AWS AI services - AWS AI services integrate with applications through APIs to address \ncommon use cases such as personalized recommendations, image recognition, language analysis and \ntranslation, modernizing contact centers, improving safety and security, and increasing customer \nengagement.\u00a0\n\u2022Use pre-trained models from AWS Marketplace - AWS Marketplace o\ufb00ers over 1,400 ML-related \nassets that you can subscribe to.\n\u2022Use pre-trained models from SageMaker JumpStart - SageMaker JumpStart provides pre-trained, \nopen-source models for a wide range of problem types to help you get started with machine learning. \nYou can incrementally train and tune these models before deployment.\nDocuments\n\u2022Explore AWS AI services\n\u2022Pre-trained machine learning models available in AWS Marketplace\n\u2022Use Hugging Face with Amazon SageMaker\n\u2022Use SageMaker JumpStart algorithms with pre-trained models\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 1, identify business goals, validate ML use, and \nprocess data\n\u2022Fine-tune and host Hugging Face BERT models on Amazon SageMaker\nVideos\n\u2022Introduction to Hugging Face on Amazon SageMaker\nMLSUS-03: Select sustainable Regions\nChoose the Regions where you implement your workloads based on both your business requirements \nand sustainability goals.\nImplementation plan\n\u2022Select an AWS Region with sustainable energy sources - When regulations and legal aspects allow, \nchoose Regions near Amazon renewable energy projects and Regions where the grid has low published \ncarbon intensity to host your data and workloads.\nResources\n\u2022Renewable energy projects on Amazon Around the Globe\n\u2022Renewable Energy Methodology\n31", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ce365f7f-61f1-4612-bed6-80dbe0d8d38a": {"__data__": {"id_": "ce365f7f-61f1-4612-bed6-80dbe0d8d38a", "embedding": null, "metadata": {"page_label": "32", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3ca7db017d3428a192e9e569ea325401876a0cb3b2d741ad6ec6ab07618a82d2", "text": "Machine Learning Lens AWS Well-Architected Framework\nLifecycle architecture diagram \nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 1, identify business goals, validate ML use, and \nprocess data\n\u2022How to select a region for your workload based on sustainability goals\nML lifecycle architecture diagram\nFigure 4 shows the ML lifecycle phases with the \u201cdata processing phase\u201d (for example, \u201cProcess Data\u201d) \nexpanded into a \u201cdata collection sub-phase\u201d (\u201cCollect Data\u201d) and a \u201cdata preparation sub-phase\u201d (\u201cPre-\nprocess Data\u201d and \u201cEngineer Features\u201d). These sub-phases are discussed in more detail in this section.\nFigure 4: ML lifecycle with data processing sub-phases included\nFigure 5 illustrates the details of all the ML lifecycle phases that occur following the problem framing \nphase and shows how the data-processing sub-phases interact with the subsequent phases, that is, the \n\u201cmodel development phase\u201d, the \u201cmodel monitoring phase\u201d, and the \u201cmodel monitoring phase\u201d.\nThe model development phase includes training, tuning, and evaluation. The model deployment phase \nincludes the staging environment for model validation for security and robustness. Monitoring is key \nin timely detection and mitigation of drifts. Feedback loops across the ML lifecycle phases are key \nenablers for monitoring. Feature stores (both online and o\ufb04ine) provide consistent and reusable features \nacross model development and deployment phases. The model registry enables the version control and \nlineage tracking for model and data components. This \ufb01gure also emphasizes the lineage tracking and its \ncomponents that are discussed in this section in more detail.\nThe cloud agnostic architecture diagrams in this paper provide high-level best practices with the \nfollowing assumptions:\n\u2022All concepts presented here are cloud and technology agnostic.\n\u2022Solid black lines are indicative of process \ufb02ow.\n\u2022Dashed color lines are indicative of input and output \ufb02ow.\n\u2022Architecture diagram components are color-coded for ease of communication across this document.\n32", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f3dc674e-88fa-479b-bc1d-920110da24e5": {"__data__": {"id_": "f3dc674e-88fa-479b-bc1d-920110da24e5", "embedding": null, "metadata": {"page_label": "33", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "455779039ed8705b91083ceb502c2fee1dcea1d2e8ef4b5d2f6aa04862af4d06", "text": "Machine Learning Lens AWS Well-Architected Framework\nLifecycle architecture diagram \nFigure 5: ML lifecycle with detailed phases and expanded components\nThe components of the sub-phases of the ML lifecycle shown in Figure 5 are as follows:\n\u2022Online/O\ufb04ine feature store  - Reduces duplication and the need to rerun feature engineering code \nacross teams and projects. An online store with low-latency retrieval capabilities is ideal for real-time \ninference. On the other hand, an o\ufb04ine store is designed for maintaining a history of feature values \nand is suited for training and batch scoring.\n\u2022Model registry - A repository for storing ML model artifacts including trained model and related \nmetadata (such as data, code, and model). It enables the tracking of the lineage of ML models as it can \nact as a version control system.\n\u2022Performance feedback loop - Informs the iterative data preparation phase based on the evaluation of \nthe model during the model development phase.\n\u2022Model drift feedback loop - Informs the iterative data preparation phase based on the evaluation of \nthe model during the production deployment phase.\n\u2022Alarm manager  - Receives alerts from the model monitoring system. It then publishes noti\ufb01cations to \nthe services that can deliver alerts to target applications. The model update re-training pipeline is one \nsuch target application.\n\u2022Scheduler - Initiates a model re-training at business-de\ufb01ned intervals.\n\u2022Lineage tracker - Enables reproducible machine learning experiences. It enables the re-creation of the \nML environment at a speci\ufb01c point in time, re\ufb02ecting the versions of all resources and environments at \nthat time.\nThe ML lineage tracker collects references to traceable data, model, and infrastructure resource changes. \nIt consists of the following components:\n\u2022System architecture (infrastructure as code to address environment drift)\n33", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "57c7777d-09d7-4dca-bf74-d793262d391e": {"__data__": {"id_": "57c7777d-09d7-4dca-bf74-d793262d391e", "embedding": null, "metadata": {"page_label": "34", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3c5fb6152eddc94b8c0fb64ecbf60b07a2fc272c0fa9da8daf566492f0ffaead", "text": "Machine Learning Lens AWS Well-Architected Framework\nData processing lifecycle phase\n\u2022Data (metadata, values, and features)\n\u2022Model (algorithm, features, parameters, and hyperparameters)\n\u2022Code (implementation, modeling, and pipeline)\nThe lineage tracker collects changed references through alternative iterations of ML lifecycle phases. \nAlternative algorithms and feature lists are evaluated as experiments for \ufb01nal production deployment.\nFigure 6 includes machine learning components and their information that the lineage tracker collects \nacross di\ufb00erent releases. The collected information enables going back to a speci\ufb01c point-in-time release \nand re-creating it.\nFigure 6: Lineage tracker\nLineage tracker components include:\n\u2022Infrastructure as code (IaC) - Modeling, provisioning, and managing cloud computing resources \n(compute, storage, network, and application services) can be automated using infrastructure as code. \nCloud computing takes advantage of virtualization to enable the on-demand provisioning of resources. \nIaC eliminates con\ufb01guration drift through automation, while increasing the speed and agility of \ninfrastructure deployments. IaC code changes are committed to version-controlled repository.\n\u2022Data  - Store data schemes and metadata in version control systems. Store the data in a storage media, \nsuch as a data lake. The location or link to the data can be in a con\ufb01guration \ufb01le and stored in code \nversion control media.\n\u2022Implementation code - Changes to any implementation code at any point-in-time can be stored in \nversion control media.\n\u2022Model feature list  - A \u201cfeature store\u201d, discussed earlier in this section (Figure 5), maintains the details \nof the features as well as their previous versions for any point-in-time changes.\n\u2022Model algorithm code - Changes to any model algorithm code at any point-in-time can be stored in \nversion control media.\n\u2022Model container image - Versions of model container images for any point-in-time changes can be \nstored in container repositories managed by container registry.\nML lifecycle phase - Data processing\nIn ML workloads, the data (inputs and corresponding desired output) serves important functions \nincluding:\n34", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "544f9be2-44b6-44c8-b57f-73296e2ae042": {"__data__": {"id_": "544f9be2-44b6-44c8-b57f-73296e2ae042", "embedding": null, "metadata": {"page_label": "35", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c0a9d5a7effeb63bcbbc2b7576d060d890b5675e21dae34d8d1f81c0f04846da", "text": "Machine Learning Lens AWS Well-Architected Framework\nData collection\n\u2022De\ufb01ning the goal of the system: the output representation and the relationship of each output to each \ninput, by means of the input and output pairs.\n\u2022Training the algorithm that associates inputs to outputs.\n\u2022Measuring the performance of the model against changes in data distribution or data drift.\n\u2022Building a baseline dataset to capture data drift.\nAs shown in Figure 7, data processing consists of data collection and data preparation. Data preparation \nincludes data preprocessing and feature engineering. It mainly uses data wrangling for interactive data \nanalysis and data visualization for exploratory data analysis (EDA). EDA focuses on understanding data, \nsanity checks, and validation of data quality.\u00a0\nIt is important to note that the same sequence of data processing steps that is applied to the training \ndata needs to also be applied to the inference requests.\nFigure 7: Data processing components\nBest practices\n\u2022Data collection (p. 35)\n\u2022Data preparation (p. 37)\n\u2022Operational excellence pillar - Best practices (p. 39)\n\u2022Security pillar - Best practices (p. 41)\n\u2022Reliability pillar - Best practices (p. 46)\n\u2022Performance e\ufb03ciency pillar - Best practices (p. 49)\n\u2022Cost optimization pillar - Best practices (p. 50)\n\u2022Sustainability pillar - Best practices (p. 53)\nData collection\nImportant steps in the ML lifecycle are to identify the data needed, followed by the evaluation of the \nvarious means available for collecting that data to train your model.\n35", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f36210f0-cb96-4c10-87f2-fe8c3967031b": {"__data__": {"id_": "f36210f0-cb96-4c10-87f2-fe8c3967031b", "embedding": null, "metadata": {"page_label": "36", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e1dd9e1568c8824daa667a571bc175e3ecda737a17abaab9549864b9c1b495c2", "text": "Machine Learning Lens AWS Well-Architected Framework\nData collection\nFigure 8: The main components of data collection\nThe main components of the data collection phase (shown in Figure 8) are as follows:\n\u2022Label  - Labeled data  is a group of samples that have been tagged with one or more labels. If labels are \nmissing, then some e\ufb00ort is required to label it (either manual or automated).\n\u2022Ingest and aggregate  - Data collection includes ingesting and aggregating data from multiple data \nsources.\nFigure 9: Data sources, data ingestion, and data technologies\nThe sub-components of the ingest and aggregate  component (shown in Figure 9) are as follows:\n\u2022Data sources - Data sources include time-series, events, sensors, IoT devices, and social networks, \ndepending on the nature of the use case. You can enrich your data sources by using the geospatial \ncapability of Amazon SageMaker to access a range of geospatial data sources from AWS (for example, \nAmazon Location Service), open-source datasets (for example, Open Data on AWS), or your own \n36", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2f192f00-e7a9-4ac7-8b1e-495167475469": {"__data__": {"id_": "2f192f00-e7a9-4ac7-8b1e-495167475469", "embedding": null, "metadata": {"page_label": "37", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "ffc34dd37791721c2a9c79fa1170a703668c41518b389715b3eeda8a879f0d31", "text": "Machine Learning Lens AWS Well-Architected Framework\nData preparation\nproprietary data including from third-party providers (such as Planet Labs). To learn more about the \ngeospatial capability in Amazon SageMaker, visit Geospatial ML with Amazon SageMaker (Preview).\n\u2022Data ingestion - Data ingestion processes and technologies capture and store data on storage media. \nData ingestion can occur in real-time using streaming technologies or historical mode using batch \ntechnologies.\n\u2022Data technologies - Data storage technologies vary from transactional (SQL) databases, to data \nlakes and data warehouses. Extract, transform, and load (ETL) pipeline technology automates and \norchestrates the data movement and transformations across cloud services and resources. A data lake \ntechnology enables storing and analyzing structured and unstructured data.\nData preparation\nML models are only as good as the data that is used to train them. Ensure that suitable training data is \navailable and is optimized for learning and generalization. Data preparation includes data preprocessing \nand feature engineering.\nA key aspect to understanding data is to identify patterns. These patterns are often not evident with \ndata in tables. Exploratory data analysis (EDA) with visualization tools can help in quickly gaining a \ndeeper understanding of data. Prepare data using data wrangler tools for interactive data analysis \nand model building. Employ no-code/low-code, automation, and visual capabilities to improve the \nproductivity and reduce the cost for interactive analysis.\nData preprocessing\nData preprocessing puts data into the right shape and quality for training. There are many data \npreprocessing strategies including: data cleaning, balancing, replacing, imputing, partitioning, scaling, \naugmenting, and unbiasing.\nFigure 10: Data processing main components\nThe data preprocessing strategies listed in Figure 10 can be expanded as the following:\n\u2022Clean (replace, impute, remove outliers and duplicates) - Remove outliers and duplicates, replace \ninaccurate or irrelevant data, and correct missing data using imputation techniques that will minimize \nbias as part of data cleaning.\n\u2022Partition - To prevent ML models from over\ufb01tting and to evaluate a trained model accurately, \nrandomly split data into train, validate, and test sets. Data leakage can happen when information \n37", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5c38c906-eaa5-4d08-b233-384e670d078c": {"__data__": {"id_": "5c38c906-eaa5-4d08-b233-384e670d078c", "embedding": null, "metadata": {"page_label": "38", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "2942804e18ebf86bc0e7cc37d57f58c5d2041e9b2646384fa848125750fb74a4", "text": "Machine Learning Lens AWS Well-Architected Framework\nData preparation\nfrom hold-out test dataset leaks into the training data. One way to avoid data leakage is to remove \nduplicates before splitting the data.\n\u2022Scale (normalize, standardize) - Normalization is a scaling technique in machine learning that is \napplied during data preparation to change the values of numeric columns in the dataset to use a \ncommon scale. This technique helps ensure that each feature of the machine learning model has equal \nfeature importance when they have di\ufb00erent ranges. Normalized numeric features will have values in \nthe range of [0,1]. Standardized numeric features will have a mean of 0 and standard deviation of 1. \nStandardization helps in handling outliers.\n\u2022Unbias, balance (detection & mitigation) - Detecting and mitigating bias helps avoid inaccurate \nmodel results. Biases are imbalances in the accuracy of predictions across di\ufb00erent groups, such as age \nor income bracket. Biases can come from the data or algorithm used to train your model.\n\u2022Augment  - Data augmentation increases the amount of data arti\ufb01cially by synthesizing new data from \nexisting data. Data augmentation can help regularize and reduce over\ufb01tting.\nFeature engineering\nEvery unique attribute of the data is considered a \u201cfeature\u201d (also known as \u201cattribute\u201d). For example, \nwhen designing a solution for predicting customer churn, the data used typically includes features such \nas customer location, age, income level, and recent purchases.\nFigure 11: Feature engineering main components\nFeature engineering is a process to select and transform variables when creating a predictive model \nusing machine learning or statistical modeling. Feature engineering typically includes feature creation, \nfeature transformation, feature extraction, and feature selection as listed in Figure 11. With deep \nlearning, feature engineering is automated as part of the algorithm learning.\n\u2022Feature creation refers to the creation of new features from existing data to help with better \npredictions. Examples of feature creation include: one-hot-encoding, binning, splitting, and calculated \nfeatures.\n\u2022Feature transformation and imputation include steps for replacing missing features or features \nthat are not valid. Some techniques include: forming Cartesian products of features, non-linear \ntransformations (such as binning numeric variables into categories), and creating domain-speci\ufb01c \nfeatures.\n\u2022Feature extraction involves reducing the amount of data to be processed using dimensionality \nreduction techniques. These techniques include: Principal Components Analysis (PCA), Independent \nComponent Analysis (ICA), and Linear Discriminant Analysis (LDA). This reduces the amount of memory \nand computing power required, while still accurately maintaining original data characteristics.\n38", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5d05ab0f-e72f-4e03-bb58-71877e3b09d8": {"__data__": {"id_": "5d05ab0f-e72f-4e03-bb58-71877e3b09d8", "embedding": null, "metadata": {"page_label": "39", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "01b15a0d624aaaacc101999927d5357fffd1612a5e91795154401aa1e4e803cd", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\n\u2022Feature selection is the process of selecting a subset of extracted features. This is the subset that is \nrelevant and contributes to minimizing the error rate of a trained model. Feature importance score and \ncorrelation matrix can be factors in selecting the most relevant features for model training.\nOperational excellence pillar - Best practices\nThe operational excellence pillar includes the ability to run and monitor systems to deliver business value \nand continually improve supporting processes. This section includes best practices to consider while \nprocessing data.\nBest practices\n\u2022MLOE-10: Pro\ufb01le data to improve quality (p. 39)\n\u2022MLOE-11: Create tracking and version control mechanisms (p. 40)\nMLOE-10: Pro\ufb01le data to improve quality\nPro\ufb01le data to use data characteristics like distribution, descriptive statistics, data types, and data \npatterns. Review source data for content and quality. Filter out or correct any data not passing the \nreviews. This will contribute to quality improvement.\nImplementation plan\n\u2022Use the built-in data preparation capability of Amazon SageMaker Studio Notebook - This allows \nyou to visually review data characteristics and remediate data-quality problems directly in your \nnotebook environment. When you display a data frame (that is, a tabular representation of data) in \nyour notebook, Amazon SageMaker Studio Notebook automatically generates charts to help users \nidentify data-quality issues and suggests data transformations to help \ufb01x common problems. After \nyou select a data transformation, Amazon SageMaker Studio Notebook generates the corresponding \ncode within the notebook so that it can be repeatedly applied every time the notebook is run.\n\u2022Use Amazon SageMaker Data Wrangler - Import, prepare, transform, visualize, and analyze data with\nSageMaker Data Wrangler. You can integrate Data Wrangler into your ML work\ufb02ows to simplify and \nstreamline data pre-processing and feature engineering with little to no coding. You can also add your \nown Python scripts and transformations to customize your data preparation work\ufb02ow. Import data \nfrom Amazon S3, Amazon Redshift, or other data sources, and then query the data using Amazon\nAthena . Use Data Wrangler to create sophisticated machine learning data preparation work\ufb02ows with \nbuilt-in and custom data transformations and analysis features. These features include feature target \nleakage and quick modeling.\n\u2022Create an automatic data pro\ufb01le and a reporting system - Use AWS Glue Crawler to crawl the data \nsources and create a data schema. Use AWSAWS Glue Data Catalog to list all the tables and schemas. \nUse Amazon Athena for serverless SQL querying to constantly pro\ufb01le data and then use Amazon\nQuickSight  dashboards for visualization of the data.\n\u2022Create a baseline dataset with SageMaker Model Monitor \u2013 The training dataset used to train the \nmodel is usually a good baseline dataset. The training dataset data schema and the inference dataset \nschema should exactly match (the number and order of the features).\nDocuments\n\u2022Amazon SageMaker Notebooks\n\u2022Data Wrangler \u2013 Getting Started\n\u2022SageMaker Model Monitor \u2013 Create baseline\n39", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e651d47c-bd35-4235-b2bd-8176c6e90a8e": {"__data__": {"id_": "e651d47c-bd35-4235-b2bd-8176c6e90a8e", "embedding": null, "metadata": {"page_label": "40", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b123d97734f60d53364734e03c7f8b09b9438f08d8fd9679f9cb25a3af4a8a3b", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\nBlogs\n\u2022Next Generation SageMaker Notebooks \u2013 Now with Built-in Data Preparation, Real-Time Collaboration, \nand Notebook Automation\n\u2022Introducing Amazon SageMaker Data Wrangler, a Visual Interface to Prepare Data for Machine \nLearning\n\u2022Exploratory data analysis, feature engineering, and operationalizing your data \ufb02ow into your ML with \nAmazon SageMaker Data Wrangler\n\u2022Prepare data for predicting credit risk using Amazon SageMaker Data Wrangler and Amazon \nSageMaker Clarify\n\u2022Prepare data from Snow\ufb02ake for machine learning with Amazon SageMaker Data Wrangler\n\u2022Develop and deploy ML models using Amazon SageMaker Data Wrangler and Amazon SageMaker \nAutopilot\n\u2022Build an automatic data pro\ufb01ling and reporting solution with Amazon EMR, AWS Glue, and Amazon \nQuickSight\n\u2022Prepare image data with Amazon SageMaker Data Wrangler\nMLOE-11: Create tracking and version control mechanisms\nDue to its exploratory and iterative nature, it\u2019s easy to lose track of ML model development and its \nevolution. You need to experiment with multiple combinations of data, algorithms, and parameters, \nall while observing the impact of incremental changes on model accuracy. Log and track your model \nexperiments with con\ufb01guration settings and hyperparameters. Document and version control any data \nprocessing-related \ufb01ndings, processes, and improvement to enable easier future referencing and reuse. \nUse a model registry to register and version control your ML models. Automate your model deployment \nwith CI/CD processes. To learn more about knowledge management, refer the best practice documented \nin OPS11-BP04 .\nImplementation plan\n\u2022Track your ML experiments with SageMaker Experiments - Amazon SageMaker Experiments \nlets you create, manage, analyze, and compare your machine learning experiments. SageMaker \nExperiments automatically tracks the inputs, parameters, con\ufb01gurations, and results of your iterations \nas\u00a0runs. You can assign, group, and organize these runs into\u00a0experiments. SageMaker Experiments is \nintegrated with Amazon SageMaker Studio, providing a visual interface to browse your active and past \nexperiments, compare runs on key performance metrics, and identify the best performing models\n\u2022Associate notebook instances with Git repositories - To analyze data, document its processing, \nand evaluate ML models on Amazon SageMaker, you can use Amazon SageMaker Processing. \nSageMaker Processing can be used for feature engineering, data validation, model evaluation, and \nmodel interpretation. SageMaker notebook instances can be associated with Git repositories. This \nenables saving notebooks in a source control environment that persists after stopping or deleting \nthe notebook instance. The notebooks hold the data processing code and its documentation. You can \nassociate a default repository and up to three additional repositories with a notebook instance. The \nrepositories can be hosted in AWS CodeCommit, GitHub, or on any other Git server.\n\u2022Use SageMaker Model Registry - Catalog, manage, and deploy models using SageMaker Model \nRegistry. Create a model group and, for each run of your ML pipeline, create a model version that you \nregister in the model group.\nDocuments\n\u2022Amazon SageMaker \u2013 Process Data\n\u2022Associate Git Repositories with SageMaker Notebook Instances\n40", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2cab20c4-d93f-4267-9109-1b0caa0b7ebd": {"__data__": {"id_": "2cab20c4-d93f-4267-9109-1b0caa0b7ebd", "embedding": null, "metadata": {"page_label": "41", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d2e16aab215340dd41b22acdeb03f4eed02adec1dc3bafa64d2dce8c019eb904", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\nBlogs\n\u2022Amazon SageMaker notebooks now support Git integration for increased persistence, collaboration, \nand reproducibility\n\u2022How to manage Amazon SageMaker code with AWS CodeCommit\n\u2022Track your ML experiments end to end with Data Version Control and Amazon SageMaker Experiments\nExamples\n\u2022Amazon SageMaker processing\nSecurity pillar - Best practices\nThe security pillar encompasses the ability to protect data, systems, and assets to take advantage of \ncloud technologies to improve\u00a0security.\nBest practices\n\u2022MLSEC-03: Ensure least privilege access (p. 41)\n\u2022MLSEC-04: Secure data and modeling environment (p. 42)\n\u2022MLSEC-05: Protect sensitive data privacy (p. 44)\n\u2022MLSEC-06: Enforce data lineage (p. 45)\n\u2022MLSEC-07: Keep only relevant data (p. 45)\nMLSEC-03: Ensure least privilege access\nProtect all resources across various phases of the ML lifecycle using the principle of least privilege. These \nresources include: data, algorithms, code, hyperparameters, trained model artifacts, and infrastructure. \nProvide dedicated network environments with dedicated resources and services to operate any individual \nproject.\u00a0\nImplementation plan\n\u2022Restrict access based on business roles for individuals - Identify roles that need to explore data \nto build models, features, and algorithms. Map those roles to access patterns using role-based \nauthentication. This approach helps you achieve least privilege access to sensitive data, assets, and \nservices on a project-by-project basis.\n\u2022Use account separation and AWS Organizations - Establish tagging and role-based access grants. \nUnderstand work\ufb02ows of the di\ufb00erent user types. Use Service Catalog to create pre-provisioned \nenvironments for quick deployment including a multi-account architecture that segregates workloads \nbetween development, test, and production with appropriate governance based on data sensitivity \nand compliance requirements. Tag data and buckets that contain sensitive\u00a0workloads. Use these tags \nto grant granular access to individuals.\n\u2022Break out ML workloads by access pattern and structure organizational units - Delegate speci\ufb01c \naccess to each group, such as administrators or data analysts, as required. Use guardrails and service \ncontrol policies (SCPs) to enforce best practices for each access type and group. Limit infrastructure \naccess to administrators. Verify all sensitive data is accessed through restricted, dedicated, and isolated \nenvironments.\nDocuments\n\u2022Amazon SageMaker with Guardrails on AWS\n41", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9703f8bf-31c8-4c5d-b1ac-da455972a874": {"__data__": {"id_": "9703f8bf-31c8-4c5d-b1ac-da455972a874", "embedding": null, "metadata": {"page_label": "42", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "cd2b1c45e5e6a0e9f07b1926614b6701fbd49c25ce24784a42e03527910dbc0c", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\n\u2022Service Catalog\n\u2022Build a Secure Enterprise Machine Learning Platform on AWS\n\u2022AWS Well Architected Framework Security Pillar : Protecting Data at Rest\nBlogs\n\u2022Building secure Amazon SageMaker access URLs with Service Catalog\n\u2022Setting up secure, well-governed machine learning environments on AWS - for detailed guidance on\nSCP and OU strategies\nVideos\n\u2022AWS re:Invent 2020: Architectural best practices for machine learning applications\n\u2022AWS re:Invent 2020: Secure and compliant machine learning for regulated industries\n\u2022AWSre:Inforce 2019: Amazon SageMaker Model Development in a Highly Regulated Environment\n(SDD315)\nExamples\n\u2022Build your own Anomaly Detection ML Pipeline\n\u2022AWS MLOps Framework\nMLSEC-04: Secure data and modeling environment\nSecure any system or environment that hosts data or enables model development. Store training data \nin secured storage and repositories. Run data preparation in a secure cloud. Tightly control access to the \ndestination compute instances as data moves from the data repositories to the instances. Encrypt data at \nrest in the storage infrastructure and in transit to the compute infrastructure.\nImplementation plan\n\u2022Build a secure analysis environment - During the data preparation and feature engineering phases, \nthere are multiple options for secure data exploration on AWS. Data can be explored in an Amazon\nSageMaker managed notebook environment, or in an Amazon EMR notebook. You can also use \nmanaged services, such as Amazon Athena and AWS Glue, or a combination of the two, to explore the \ndata without moving the data out of your data lake. Use an Amazon SageMaker Jupyter notebook \ninstance to explore, visualize, and feature engineer a small subset of data. Scale up the feature \nengineering using a managed ETL service, such as Amazon EMR or AWS Glue.\n\u2022Create dedicated  AWS IAM and AWS KMS resources \u2013 This approach limits the scope of impact \nof credentials and keys. Create a private S3 bucket and enable version control for the data and \nintellectual property (IP). In AWS, a centralized data lake is implemented using AWS Lake Formation \non Amazon S3. Securing and monitoring a data lake on Amazon S3 is achieved using a combination of \nservices and capabilities to encrypt data in transit and at rest. Monitor access using granular AWS IAM \npolicies , S3 bucket policies, S3 Access Logs , Amazon CloudWatch, and AWS CloudTrail.\u00a0\n\u2022Use Secrets Manager and Paramater Store to protect credentials - Secrets Manager enables you to \nreplace hard-coded secrets in your code, such as credentials, with an API call to decrypt and retrieve \nthe secret programmatically. Parameter Store was designed for wider use cases than secrets or \npasswords, but allows you to store application con\ufb01guration variables such as AMI IDs or license \nkeys. With AWS Secrets Manager and Parameter Store, you can store your credentials, and then grant \npermissions to your SageMaker IAM role to access Secrets Manager from your notebook.\n42", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0e5acad5-179c-428b-b900-4e5b917298c4": {"__data__": {"id_": "0e5acad5-179c-428b-b900-4e5b917298c4", "embedding": null, "metadata": {"page_label": "43", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "85e522a1368d9ed63a016a0b395847820584c01c2bd21469dfa8b208b2e7d47d", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\n\u2022Automate managing con\ufb01guration - Use lifecycle con\ufb01gurations scripts to manage Jupyter notebook \ninstances. The scripts run when the notebook instance is \ufb01rst created, or every time it starts. They \nenable you to install custom packages, preload datasets, and set up source code repositories. Lifecycle \ncon\ufb01gurations can be changed and reused across multiple notebook instances. You can make a change \nonce and apply the updated con\ufb01guration by restarting the managed notebook instances. This gives \nIT, operations, and security teams the \ufb02exibility and control they need, while supporting the needs of \nyour developers and data scientists. Use AWS CloudFormation infrastructure as code, as well as Service \nCatalog  to simplify con\ufb01guration for end users.\n\u2022Create private, isolated, network environments - Use Amazon Virtual Private Cloud (Amazon VPC) to \nenable connectivity to only the services and users you need. Deploy the Amazon SageMaker notebook \ninstance in an Amazon VPC to enable network level controls to limit communication to the hosted \nnotebook. Additionally, network calls into and out of the notebook instance can be captured in VPC \nFlow Logs to enable additional visibility and control at the network level. By deploying the notebook \nin your VPC, you will also be able to query data sources and systems accessible from within your VPC, \nsuch as relational databases in Amazon RDS or Amazon Redshift data warehouses. Using IAM, you can \nfurther restrict access to the web-based UI of the notebook instance so that it can only be accessed \nfrom within your VPC. Use AWS PrivateLink to privately connect your SageMaker notebook instance \nVPC with supported AWS services. This ensures secure communication between your notebook \ninstance and Amazon S3 within the AWS network. Use AWS KMS to encrypt data on the EBS volumes \nattached to SageMaker notebook instances.\n\u2022Restrict access - The Jupyter notebook server provides web-based access to the underlying operating \nsystem on an EC2 instance. This gives you the ability to install additional software packages or Jupyter \nkernels to customize your environment. The access is granted by default to a user with root access or \nsuper user on the operating system, giving them total control of the underlying EC2 instance. This \naccess should be restricted to remove the user's ability to assume root permissions but still give them \ncontrol over their local user's environment.\n\u2022Secure ML algorithms - Amazon SageMaker uses container technology to train and host algorithms \nand models. When creating your own containers, publish them to a private container registry hosted \non Amazon Elastic Container Repository (Amazon ECR). Encrypt containers that are hosted on Amazon \nECR at rest using AWS KMS.\n\u2022Enforce code best practices - Use secure git repositories through fully managed AWS CodeCommit for \nstoring code.\n\u2022Implement a package mirror for consuming approved packages - Evaluate the license terms to \ndetermine which ML packages are appropriate for your business across the phases of the ML lifecycle. \nExamples of ML Python packages include: Pandas, PyTorch, Keras, NumPy, and Scikit-learn. Once \nyou\u2019ve determined the set and criteria, build a validation mechanism and automate it where possible. \nA sample automated mechanism can include a script that runs the download, installation, and package \nversion and dependency checks. Only download packages from approved and private repos. Validate \nwhat is in the packages downloaded. This will enable importing safely and con\ufb01rming the validity \nof packages. Amazon SageMaker notebook instances come with multiple environments already \ninstalled. These environments contain Jupyter kernels and Python packages. You can also install your \nown environments that contain your choice of packages and kernels. SageMaker enables modifying \npackage channel paths to a private repository. Where appropriate, use an internal repository as a \nproxy for public repositories to minimize the network and time overhead.\nDocuments\n\u2022Amazon Sagemaker Workshop - Using Secure Environments\n\u2022Storage Best Practices for Data and Analytics Applications\n\u2022What is AWS CodeCommit?\n\u2022Security in Amazon SageMaker\n\u2022Amazon Well-Architected Security Pillar for Software Integrity\n\u2022Installing External Libraries and Kernels on Notebook Instances\n43", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9e509368-b40c-462e-a062-06b751c38e29": {"__data__": {"id_": "9e509368-b40c-462e-a062-06b751c38e29", "embedding": null, "metadata": {"page_label": "44", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "fa69c171c5b508b216838c788576aa05a10e2e37ae7f09d538be24376e5e3b30", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\n\u2022AWS Well Architected Framework Security Pillar : Protecting Data in Transit\nBlogs\n\u20227 ways to improve security of your machine learning\n\u2022Building secure machine learning environments with Amazon SageMaker\n\u2022Setting up secure, well-governed machine learning environments on AWS\n\u2022Private package installation in Amazon SageMaker running internet-free mode\n\u2022Secure Deployment of Amazon SageMaker resource\n\u2022Create a hosting VPC for PyPi package mirroring and consumption of approved packages\n\u2022Apply \ufb01ne-grained data access controls with AWS Lake Formation and Amazon EMR from Amazon \nSageMaker Studio\nVideos\n\u2022Security for AI/ML Models in AWS\n\u2022AWS re:Invent 2020: Security best practices the AWS Well-Architected way\nExamples\n\u2022Secure Data Science Reference Architecture\nMLSEC-05: Protect sensitive data privacy\nProtect sensitive data used in training against unintended disclosure. Identify and classify the sensitive \ndata. Handle the sensitive data using strategies including: removing, masking, tokenizing, and principal \ncomponent analysis (PCA). Document best governance practices for future reuse and references.\nImplementation plan\n\u2022Use automated mechanisms to classify data where possible - Use automated sensitive data \ndiscovery in Amazon Macie that provides continual, cost e\ufb03cient, organization-wide visibility \ninto where sensitive data resides across your Amazon S3 environment. Macie automatically and \nintelligently inspects your S3 buckets for sensitive data such as personally identi\ufb01able information \n(PII), \ufb01nancial data, and AWS credentials. Macie then builds and continuously maintains an interactive \ndata map of the locations in Amazon S3 where your sensitive data resides, and provides a sensitivity \nscore for each bucket.\n\u2022Use tagging  \u2013 Tag resources and models that are made from sensitive elements to quickly di\ufb00erentiate \nbetween resources requiring protection and those that do not.\n\u2022Encrypt sensitive data - Encrypt sensitive data using services such as AWS KMS, the AWS Encryption\nSDK, or client-side encryption.\n\u2022Reduce data sensitivity - Evaluate and identify data for anonymization or de-identi\ufb01cation to reduce \nsensitivity.\nDocuments\n\u2022Running sensitive data discovery jobs in Amazon Macie\n\u2022Categorizing your storage using tags\n\u2022AWS Key Management Service best practices\n\u2022Getting started with the AWS Encryption SDK\n44", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8f7696e3-2176-4c13-b597-2be241ceb431": {"__data__": {"id_": "8f7696e3-2176-4c13-b597-2be241ceb431", "embedding": null, "metadata": {"page_label": "45", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "2c6545be91d9b69646cb033cc473413456fefe607143d9ec3de39324eb421a79", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\nBlogs\n\u20227 ways to improve security of your machine learning work\ufb02ows\n\u2022Macie for Data Classi\ufb01cation\n\u2022Building a Serverless Tokenization Solution to Mask Sensitive Data\nExamples\n\u2022Amazon SageMaker Solution for Privacy in Natural Language Processing\n\u2022How Amazon is advancing privacy-aware data processing\nMLSEC-06: Enforce data lineage\nMonitor and track data origins and transformations over time. Strictly control data access. Perform \npreventative controls, auditing, and monitoring to demonstrate data lineage. Implement integrity checks \nagainst training data to detect any unexpected deviances caused by loss, corruption, or manipulation. \nData lineage enables visibility and helps tracing root cause of data processing errors.\u00a0\nImplementation plan\n\u2022Track records for any update - Create and store information about the steps of a ML work\ufb02ow from \ndata preparation to model deployment using Amazon SageMaker ML Lineage Tracker. With the \ntracking information you can:\n\u2022Reproduce the work\ufb02ow steps, track model and dataset lineage, and establish model governance \nand audit standards.\n\u2022Consider origin data to be the source of truth.\n\u2022Ingest and process derived datasets and retain mappings throughout the process. Iterate from the \nend result back to the original data element.\n\u2022Apply these concepts not just to data, but also the code, models, pipelines, and infrastructure. \nValidate that you can trace and audit any activity against data, pipeline actions, or machine learning \nmodels.\u00a0\nDocuments\n\u2022Amazon SageMaker ML Lineage Tracking\nBlogs\n\u2022Using model attributes to track your training runs on Amazon SageMaker\nExamples\n\u2022LAB 04: DevOps WorkFlow\nMLSEC-07: Keep only relevant data\nPreserve data across computing environments (such as development and staging) and only store \nuse-case relevant data to reduce data exposure risks. Implement mechanisms to enforce a lifecycle \nmanagement process across the data. Decide when to automatically remove stale data.\n45", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "715527b6-c851-47ef-98ba-bab6c16b03bf": {"__data__": {"id_": "715527b6-c851-47ef-98ba-bab6c16b03bf", "embedding": null, "metadata": {"page_label": "46", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a0a39d258a655bc2db9f9efe1c667731d62813f87cebf28d27431ab67c1f8ab3", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nImplementation plan\n\u2022Establish a data lifecycle plan - Understand usage patterns and requirements for debugging and \noperational tasks. Establish a data lifecycle plan to reduce data sprawl over time.\n\u2022Design for privacy - Remove sensitive elements that are not needed for the ML work\ufb02ow. Detect \nand redact personally identi\ufb01able information (PII), while maintaining data usability. Determine what \nfeatures are required to solve the business problem and valuable for future iterations. \u00a0 \nDocuments\n\u2022Reference Guide: Extract More Value from your Data\nBlogs\n\u2022Building a data analytics practice across the data lifecycle\n\u2022Detecting and redacting PII using Amazon Comprehend\n\u2022Now available in Amazon Transcribe: Automatic Redaction of Personally Identi\ufb01able Information\n\u2022Machine learning models that act on encrypted data\n\u2022Redacting sensitive information with user-de\ufb01ned functions in Amazon Athena\nVideos\n\u2022AWS re:Invent 2020: Privacy-preserving machine learning\n\u2022AWS re:Invent 2019: Best practices for Amazon S3\nExamples\n\u2022Field Notes: Redacting Personal Data from Connected Cars Using Amazon Rekognition\n\u2022How to Create a Modern CPG Data Architecture with Data Mesh\nReliability pillar - Best practices\nThe reliability pillar encompasses the ability of a workload to perform its intended function correctly and \nconsistently when it\u2019s expected to. This section includes best practices to consider while processing data.\nBest practices\n\u2022MLREL-03: Use a data catalog (p. 46)\n\u2022MLREL-04: Use a data pipeline (p. 47)\n\u2022MLREL-05: Automate managing data changes (p. 48)\nMLREL-03: Use a data catalog\nProcess data across multiple data stores using data catalog technology. An advanced data catalog service \ncan enable ETL process integration. This approach enables more reliability and e\ufb03ciency.\nImplementation plan\n\u2022Use AWS Glue Data Catalog - The AWS Glue Data Catalog provides a way to track the data assets \nthat have been loaded into your ML workload. Data catalogs also describe how data is transformed \n46", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b583f095-788a-427b-b3c2-1dfde255a1cd": {"__data__": {"id_": "b583f095-788a-427b-b3c2-1dfde255a1cd", "embedding": null, "metadata": {"page_label": "47", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "256f23a8d69ed773cff4dbb9a587638813a2ebfaed2ba65c45557c2168cd3f13", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nas it is loaded into the data lake and data warehouse. AWS Glue is a fully managed ETL (extract, \ntransform, and load) service. It enables a simple and cost-e\ufb00ective approach to categorize your data, \nclean it, enrich it, and move it reliably between various data stores and data streams. AWS Glue \nconsists of a central metadata repository known as the AWS Glue Data Catalog. It also has an ETL \nengine that automatically generates Python or Scala code. With a \ufb02exible scheduler, AWS Glue handles \ndependency resolution, job monitoring, and retries.\nDocuments\n\u2022Data Cataloging\n\u2022Populating the AWSAWS Glue Data Catalog\nBlogs\n\u2022Moving from notebooks to automated ML pipelines using Amazon SageMaker and AWS Glue\n\u2022How Genworth built a serverless ML pipeline on AWS using Amazon SageMaker and AWS Glue\nVideos\n\u2022Getting Started with AWS Glue Data Catalog\n\u2022AWS re:Invent 2018: How Bill.com Uses Amazon SageMaker & AWS Glue to Enable Machine Learning -\nSTP10\n\u2022AWS re:Invent 2018: Build and Govern Your Data Lakes with AWS Glue (ANT309)\nExamples\n\u2022Explaining Credit Decisions with Amazon SageMaker\n\u2022How to build an end-to-end Machine Learning pipeline using AWS Glue, Amazon S3, Amazon\nSageMaker and Amazon Athena.\nMLREL-04: Use a data pipeline\nAutomate the processing, movement, and transformation of data between di\ufb00erent compute and \nstorage services. This automation enables data processing that is fault tolerant, repeatable, and highly \navailable.\nImplementation plan\n\u2022Use Amazon SageMaker Data Wrangler and Pipelines - SageMaker Data Wrangler simpli\ufb01es \nthe preparation of machine learning data. It enables data selection, cleansing, exploration, \nand\u00a0visualization using a single visual interface. After you\u2019ve created a work\ufb02ow, export it to\nSageMaker Pipelines  to automate model deployment and management. Data pipelines provide an \nautomated way to move and transform data in your ML workload. Manually moving and transforming \ndata can lead to errors and inconsistencies. Use AWS Data Pipeline to save time and decrease errors.\nDocuments\n\u2022Prepare ML Data with Amazon SageMaker Data Wrangler\n\u2022Amazon SageMaker Model Building Pipelines\n47", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "7b338443-b567-48c4-b538-995e98a73746": {"__data__": {"id_": "7b338443-b567-48c4-b538-995e98a73746", "embedding": null, "metadata": {"page_label": "48", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a1918097ce666729532c0858a8bfc464e4b66017eb60ef76d9052f29a7e3ce22", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nBlogs\n\u2022Building, automating, managing, and scaling ML work\ufb02ows using Amazon SageMaker Pipelines\n\u2022Develop and deploy ML models using Amazon SageMaker Data Wrangler and Amazon SageMaker\nAutopilot\nVideos\n\u2022AWS re:Invent 2020: Accelerate data preparation with Amazon SageMaker Data Wrangler\n\u2022Amazon SageMaker Data Wrangler Deep Dive Demo\nExamples\n\u2022Amazon SageMaker Data Wrangler and Feature Store\n\u2022SageMaker Pipelines\nMLREL-05: Automate managing data changes\nAutomate managing changes to training data using version control technology. This will enable \nreproducibility to re-create the exact version of a model in the event of a failure.\nImplementation plan\n\u2022Use AWS MLOps Framework - AWS MLOps Framework provides a standard interface for managing \nML pipelines for Amazon Machine Learning services and third-party services. The solution\u2019s template \nallows you to upload your trained models (also referred to as\u00a0bring your own model ). It con\ufb01gures the \norchestration of the pipeline, and monitors the pipeline's operations. This solution increases agility \nand e\ufb03ciency by allowing repeating of successful processes at scale. One of the key components of \nMLOps pipeline in SageMaker is Model Registry. SageMaker Model Registry tracks the model versions \nand respective artifacts, including the lineage and metadata.\nDocuments\n\u2022AWS MLOps Framework\n\u2022Register and Deploy Models with Model Registry\nBlogs\n\u2022Amazon SageMaker Pipelines Brings DevOps Capabilities to your Machine Learning Projects\nVideos\n\u2022Solving with AWS Solutions: AWS MLOps Framework\nExamples\n\u2022Amazon SageMaker secure MLOps\n48", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "63208d30-bf3e-493b-8e04-1397e4aa3ba5": {"__data__": {"id_": "63208d30-bf3e-493b-8e04-1397e4aa3ba5", "embedding": null, "metadata": {"page_label": "49", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "720528e5dced5b70d0bf7c5af8e8309ce94b7af186370558d1a70cf0de175ca6", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nPerformance e\ufb03ciency pillar - Best practices\nThe performance e\ufb03ciency pillar focuses on the e\ufb03cient use of computing resources to meet \nrequirements and the maintenance of that e\ufb03ciency as demand changes and technologies evolve. This \nsection includes best practices to consider while processing data.\nBest practices\n\u2022MLPER-04: Use a modern data architecture (p. 49)\nMLPER-04: Use a modern data architecture\nGet the best insights from exponentially growing data using a modern data architecture. This \narchitecture enables easy movement of data between a data lake and purpose-built stores including a \ndata warehouse, relational databases, non-relational databases, ML and big data processing, and log \nanalytics. A data lake provides a single place to run analytics across mixed data structures collected from \ndisparate sources. Purpose-built analytics services provide the speed required for speci\ufb01c use cases like \nreal-time dashboards and log analytics.\nImplementation plan\n\u2022Unify data governance and access - Integrate a data lake, a data warehouse, and purpose-built stores. \nThis will enable uni\ufb01ed governance and easy data movement. With a Modern Data Architecture on \nAWS, you can store data in a data lake and use data services around it. Use AWS Lake Formation to \nbuild a scalable and secure data lake. Build a high-speed analytic layer with purpose-built services, \nsuch as Amazon Redshift, Amazon Kinesis, and Amazon Athena. Integrate data across services and \ndata stores with AWS Glue. Apply governance policies to manage security, access control, and audit \ntrails across all the data stores using AWS IAM.\nDocuments\n\u2022Data Lake on AWS\n\u2022AWS Lake Formation\n\u2022Derive Insights from Modern Data\nBlogs\n\u2022Build a Lake House Architecture on AWS\n\u2022Moving from notebooks to automated ML pipelines using Amazon SageMaker and AWS Glue\n\u2022Data preprocessing for machine learning on Amazon EMR made easy with AWS Glue DataBrew\u00a0\nVideos\n\u2022Build and Govern Your Data Lakes with AWS Glue\n\u2022The lake house approach to data warehousing with Amazon Redshift\nExamples\n\u2022Predictive Data Science with Amazon SageMaker and a Data Lake on AWS\n49", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6a4bcb81-3b60-4c9c-b3b4-cc3c3f27ede8": {"__data__": {"id_": "6a4bcb81-3b60-4c9c-b3b4-cc3c3f27ede8", "embedding": null, "metadata": {"page_label": "50", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e3771897030152d78201a51788f7b7baeb3b1d8bf5e6a1e978dc014e380de76c", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nCost optimization pillar - Best practices\nThe cost optimization pillar includes the continual process of re\ufb01nement and improvement of a system \nover its entire lifecycle. From the initial design of your very \ufb01rst proof of concept to the ongoing \noperation of production workloads, adopting the practices in this document can enable you to build \nand operate cost-aware systems that achieve business outcomes and minimize costs, thus allowing your \nbusiness to maximize its return on investment. This section includes best practices to consider while \nprocessing data.\nBest practices\n\u2022MLCOST-05: Use managed data labeling (p. 50)\n\u2022MLCOST-06: Use data wrangler tools for interactive analysis (p. 51)\n\u2022MLCOST-07: Use managed data processing capabilities (p. 52)\n\u2022MLCOST-08: Enable feature reusability (p. 52)\nMLCOST-05: Use managed data labeling\nChoose a managed labeling tool that provides automation and access to cost-e\ufb00ective teams of human \ndata labelers . It should also provide \ufb02exibility to choose a variable number of labelers for a given input. \nThe tool should have a user interface, and learn to label data by itself over time.\nImplementation plan\n\u2022Use Amazon SageMaker Ground Truth - To train a machine learning model, you need a large, high \nquality, labeled dataset. Amazon SageMaker Ground Truth helps you build high-quality training \ndatasets for your ML models. With Ground Truth, you can use ML along with workers from Amazon \nMechanical Turk, a vendor company that you choose, or an internal, private workforce to create a \nlabeled dataset. You can use the labeled dataset output from Ground Truth to train your own models. \nYou can also use the output as a training data set for an Amazon SageMaker model.\n\u2022Use Amazon SageMaker Ground Truth Plus \u2013 Ground Truth Plus is a turn-key service that uses \nan expert workforce to deliver high-quality training datasets fast, and reduces costs by up to 40 \npercent. Amazon SageMaker Ground Truth Plus enables you to easily create high-quality training \ndatasets without having to build labeling applications and manage the labeling workforce on your \nown. By using this approach, you don\u2019t need to have deep ML expertise or extensive knowledge of \nwork\ufb02ow design and quality management. You simply provide data along with labeling requirements \nand Ground Truth Plus sets up the data labeling work\ufb02ows and manages them on your behalf in \naccordance with your requirements.\nDocuments\n\u2022Use Amazon SageMaker Ground Truth to Label Data\n\u2022Use Amazon SageMaker Ground Truth Plus to Label Data\nBlogs\n\u2022Real-time data labeling pipeline for ML work\ufb02ows using Amazon SageMaker Ground Truth\n\u2022Implementing a custom labeling GUI with built-in processing logic with Amazon SageMaker Ground\nTruth\n\u2022Amazon SageMaker Ground Truth Plus \u2013 Create Training Datasets Without Code or In-house Resources\n\u2022Get Started with Amazon SageMaker Ground Truth Plus\n50", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b5a22cd2-7b1c-47aa-9532-b626e7cb7976": {"__data__": {"id_": "b5a22cd2-7b1c-47aa-9532-b626e7cb7976", "embedding": null, "metadata": {"page_label": "51", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "824b959b6633ddf1c30c2eb603f6487fb4c127cb157b8f55227a523ded8bc383", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nVideos\n\u2022Amazon SageMaker Ground Truth Plus\u00a0\nExamples\n\u2022Bring your own model for SageMaker labeling work\ufb02ows with active learning\n\u2022SageMaker Ground Truth recipe\n\u2022How to setup and use SageMaker Ground Truth\nMLCOST-06: Use data wrangler tools for interactive analysis\nPrepare data through data wrangler tools for interactive data analysis and model building. The no-\ncode/low-code, automation, and visual capabilities improve the productivity and reduce the cost for \ninteractive analysis.\nImplementation plan\n\u2022Use Amazon SageMaker Data Wrangler - Amazon SageMaker Data Wrangler, part of SageMaker\nStudio , provides an end-to-end solution to import, prepare, transform, analyze data and select \nfeatures. You can integrate a Data Wrangler data \ufb02ow into your ML work\ufb02ows to simplify and \nstreamline data pre-processing and feature engineering using little to no coding. You can also add your \nown Python scripts and transformations to customize work\ufb02ows.\nDocuments\n\u2022Amazon SageMaker Data Wrangler\nBlogs\n\u2022Introducing Amazon SageMaker Data Wrangler, a Visual Interface to Prepare Data for Machine\nLearning\n\u2022Develop and deploy ML models using Amazon SageMaker Data Wrangler and Amazon SageMaker\nAutopilot\n\u2022Prepare time series data with Amazon SageMaker Data Wrangler\n\u2022Accelerate data preparation with data quality and insights in Amazon SageMaker Data Wrangler\n\u2022Balance your data for machine learning with Amazon SageMaker Data Wrangler\n\u2022Process larger and wider datasets with Amazon SageMaker Data Wrangler\nVideos\n\u2022Amazon SageMaker Data Wrangler Deep Dive Demo\nExamples\n\u2022Prepare ML Data with Amazon SageMaker Data Wrangler\n51", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1591cbc1-fb00-4328-a689-90933a9bffbf": {"__data__": {"id_": "1591cbc1-fb00-4328-a689-90933a9bffbf", "embedding": null, "metadata": {"page_label": "52", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7d2cecd3721f173047411d028a77b9035ba6d7fbede398bf140fbcbf492d2719", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nMLCOST-07: Use managed data processing capabilities\nWith managed data processing, you can use a simpli\ufb01ed, managed experience to run your data \nprocessing workloads, such as feature engineering, data validation, model evaluation, and model \ninterpretation.\u00a0\nImplementation plan\n\u2022Use Amazon SageMaker Processing \u2013 With Amazon SageMaker Processing, you can run processing \njobs for data processing steps in your machine learning pipeline. Processing jobs accept data from \nAmazon S3 as input and store data into Amazon S3 as output. The processing container image can \neither be an Amazon SageMaker built-in image or a custom image that you provide. The underlying \ninfrastructure for a Processing job is fully managed by Amazon SageMaker. Cluster resources are \nprovisioned for the duration of your job, and cleaned up when a job completes. SageMaker Processing \nhas simpli\ufb01ed running machine learning preprocessing and postprocessing tasks with popular \nframeworks such as scikit-learn, Apache Spark, PyTorch, TensorFlow, Hugging Face, MXNet, and \nXGBoost.\nDocuments\n\u2022Process Data with SageMaker Processing\nBlogs\n\u2022Amazon SageMaker Processing \u2013 Fully Managed Data Processing and Model Evaluation\n\u2022Use deep learning frameworks natively in Amazon SageMaker Processing\n\u2022Building machine learning work\ufb02ows with Amazon SageMaker Processing jobs and AWS Step \nFunctions\n\u2022Process Amazon Redshift data and schedule a training pipeline with Amazon SageMaker Processing \nand Amazon SageMaker Pipelines\nExamples\n\u2022Amazon SageMaker Processing jobs\nMLCOST-08: Enable feature reusability\nReduce duplication and the rerunning of feature engineering code across teams and projects by using \nfeature storage. The store should have online and o\ufb04ine storage, and data encryption capabilities. \nAn online store with low-latency retrieval capabilities is ideal for real-time inference. An o\ufb04ine store \nmaintains a history of feature values and is suited for training and batch scoring.\nImplementation plan\n\u2022Use Amazon SageMaker Feature Store - Amazon SageMaker Feature Store is a fully managed, \npurpose-built repository to store, update, retrieve, and share ML features. Feature Store makes it easy \nfor data scientists, machine learning engineers, and general practitioners to create, share, and manage \nfeatures for ML development. The online store is used for low latency, real-time inference use cases. \nThe o\ufb04ine store is used for training and batch inference. The Feature Store reduces the repetitive data \nprocessing and curation work required to convert raw data into features for training an ML algorithm.\nYou can use Feature Store in the following modes:\n52", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3dddcb76-7492-4eb9-a1e9-1e1a8bf8d81d": {"__data__": {"id_": "3dddcb76-7492-4eb9-a1e9-1e1a8bf8d81d", "embedding": null, "metadata": {"page_label": "53", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8b804316fa7c2b0d7c44a7d4919b6874ab00c71e2125142b4c3a8eabfe281c62", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\n\u2022Online  - Features are read with low latency reads (milliseconds) and used for high throughput \npredictions.\u00a0\n\u2022O\ufb04ine  - Large streams of data are fed to an o\ufb04ine store, which is used for training and batch \ninference. This mode requires a feature group to be stored in an o\ufb04ine store. The o\ufb04ine store uses \nyour S3 bucket for storage and can also fetch data using Amazon Athena queries.\n\u2022Online and o\ufb04ine  - This includes both online and o\ufb04ine modes.\nDocuments\n\u2022Create, Store, and Share Features with Amazon SageMaker Feature Store\nBlogs\n\u2022Getting started with Amazon SageMaker Feature Store\n\u2022Store, Discover, and Share Machine Learning Features with Amazon SageMaker Feature Store\n\u2022Enable feature reuse across accounts and teams using Amazon SageMaker Feature Store\n\u2022Understanding the key capabilities of Amazon SageMaker Feature Store\n\u2022Using Amazon SageMaker Feature Store with streaming feature aggregation\n\u2022Extend model lineage to include ML features using Amazon SageMaker Feature Store\nVideos\n\u2022Amazon SageMaker Feature Store Deep Dive Demo\nExamples\n\u2022Using Amazon SageMaker Feature Store with streaming feature aggregation\n\u2022Amazon SageMaker Feature Store Notebook Examples\nSustainability pillar - Best practices\nThe sustainability pillar focuses on environmental impacts, especially energy consumption and e\ufb03ciency, \nsince they are important levers for architects to inform direct action to reduce resource usage.\u00a0This \nsection includes best practices to consider while processing data.\nBest practices\n\u2022MLSUS-04: Minimize idle resources\u00a0 (p. 54)\n\u2022MLSUS-05: Implement data lifecycle policies aligned with your sustainability goals (p. 54)\n\u2022MLSUS-06: Adopt sustainable storage options (p. 55)\nRelated best practices\n\u2022Enable data and compute proximity (MLCOST-21) The two most important factors in\ufb02uencing the \ncarbon footprint of your network usage when transmitting data are the size of the data and the \ndistance traveled. Compress your data before moving it over the network. Minimize data movement \nacross networks when selecting a Region. Store your data close to your producers and train your \nmodels close to your data.\u00a0\n\u2022Enable feature reusability\u00a0(MLCOST-08)- Evaluate if you can avoid data processing by using existing \npublicly available datasets like AWS Data Exchange and Open Data on AWS (which includes the\n53", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d6d58e39-84af-4577-ab1d-b8ba6b9ea284": {"__data__": {"id_": "d6d58e39-84af-4577-ab1d-b8ba6b9ea284", "embedding": null, "metadata": {"page_label": "54", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "78092c57d0c05cb4c648ad2be2625c4e2181d9160b89efdd34a4e9a97b1969f6", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\nAmazon Sustainability Data Initiative). They o\ufb00er a variety of data, including weather and climate \ndatasets, satellite imagery, air quality data, and energy data. By using these curated datasets, you \navoid duplicating the compute and storage resources needed to download the data from the providers, \nstore it in the cloud, organize, and clean it.\u00a0For internal data, you can also reduce the duplication of \nfeature engineering code across teams and projects by using managed feature storage services, such as\nAmazon SageMaker Feature Store.\nMLSUS-04: Minimize idle resources\u00a0\nAdopt a managed and serverless architecture for your data pipeline so that it only provisions resources \nwhen work needs to be done. By doing so, you are not maintaining compute infrastructure 24/7 and you \nminimize idle resources.\nImplementation plan\n\u2022Use managed services - Managed services shift responsibility for maintaining high average utilization, \nand sustainability optimization of the deployed hardware to AWS. Use managed services to distribute \nthe sustainability impact of the service across all tenants of the service, reducing your individual \ncontribution.\n\u2022Create a serverless, event-driven data pipeline - Use AWS Glue and AWS Step Functions for data \ningestion and preprocessing. Step Functions can orchestrate AWS Glue jobs to create event-based \nserverless ETL and ELT pipelines. Because AWS Glue and AWS Step Functions are serverless, compute \nresources are only used as needed and not in an idle state while waiting.\nDocuments\n\u2022Manage AWS Glue Jobs with Step Functions\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 1, identify business goals, validate ML use, and \nprocess data\n\u2022Centralize feature engineering with AWS Step Functions and AWS Glue DataBrew\n\u2022Optimizing your AWS Infrastructure for Sustainability, Part I: Compute\nMetrics\n\u2022If using Amazon Elastic Compute Cloud (Amazon EC2), measure and optimize the CPU Utilization  of \nthe compute instances involved in data preparation.\n\u2022If using Amazon Elastic Container Service (Amazon ECS), measure and optimize the CPU Utilization\nused in the cluster or service.\n\u2022If using Amazon Elastic Kubernetes Service (Amazon EKS), measure and optimize the CPU Utilization\nof your nodes and pods.\n\u2022If using Amazon EMR, optimize the Idle time  of the cluster.\nMLSUS-05: Implement data lifecycle policies aligned with your \nsustainability goals\nClassify data to understand its signi\ufb01cance to your workload and your business outcomes. Use this \ninformation to determine when you can move data to more energy-e\ufb03cient storage or safely delete it.\n54", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "24435b16-0a94-4f38-993f-bd3a10cdf4aa": {"__data__": {"id_": "24435b16-0a94-4f38-993f-bd3a10cdf4aa", "embedding": null, "metadata": {"page_label": "55", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "37dd512ea250b4d6278aaba72db3a4b6353e20f8e82dbe2a993c5d5106326dab", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\nDe\ufb01ne data retention periods that support your sustainability goals while meeting, but not exceeding, \nyour business requirements.\nImplementation plan\n\u2022De\ufb01ne lifecycle policies for all your data classi\ufb01cation types - Determine the requirements for the \nretention and deletion of your data.\n\u2022Manage the lifecycle of all your data - Automatically enforce deletion timelines to minimize the total \nstorage requirements of your workload using Amazon S3 Lifecycle policies.\n\u2022Automatically optimize storage sustainability based on access patterns - Use Amazon S3 Intelligent-\nTiering storage class  to automatically move your data to the most sustainable access tier when access \npatterns change.\nDocuments\n\u2022Implement a data classi\ufb01cation policy\n\u2022Use lifecycle policies to delete unnecessary data\n\u2022Managing your storage lifecycle on Amazon S3\n\u2022Amazon S3 Intelligent-Tiering\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 1, identify business goals, validate ML use, and \nprocess data\nMetrics\n\u2022Measure and optimize the total size of your S3 buckets and storage class distribution, using Amazon \nS3 Storage Lens\nMLSUS-06: Adopt sustainable storage options\nReduce the volume of data to be stored and adopt sustainable storage options to limit the carbon \nimpact of your workload. For artifacts like models and log \ufb01les that must be kept for long-term \ncompliance and audit requirements, use e\ufb03cient compression algorithms and use energy e\ufb03cient cold \nstorage.\u00a0\nImplementation plan\n\u2022Reduce redundancy of processed data - If you can easily re-create an infrequently accessed dataset, \nuse the Amazon S3 One Zone-IA class to minimize the total data stored.\n\u2022Right size block storage for notebooks - Don\u2019t over-provision block storage of your notebooks and \nuse centralized object storage services like Amazon S3 for common datasets to avoid data duplication.\n\u2022Use e\ufb03cient \ufb01le formats - Use Parquet or ORC to train your models. Compared to CSV, they can help \nyou reduce your storage by up to 87%.\n\u2022Migrate to more e\ufb03cient compression algorithms - Evaluate di\ufb00erent compression algorithms and \nselect the most e\ufb03cient for your data. For example, Zstandard produces 10\u201315% smaller \ufb01les than\nGzip  at the same compression speed.\u00a0\n55", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d5c1a266-6b54-47b0-a6b8-02700e9289b5": {"__data__": {"id_": "d5c1a266-6b54-47b0-a6b8-02700e9289b5", "embedding": null, "metadata": {"page_label": "56", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5a658c8b4dfa9519ba0426f60f35598af03396a2a59712ae3e88e2a1bd0b5ba7", "text": "Machine Learning Lens AWS Well-Architected Framework\nModel development lifecycle phase\nDocuments\n\u2022Use technologies that support data access and storage patterns\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 1, identify business goals, validate ML use, and \nprocess data\n\u2022Optimizing your AWS Infrastructure for Sustainability, Part II: Storage\n\u2022Compressing and archiving logs to the Amazon S3 Glacier storage classes\nMetrics\n\u2022Measure and optimize the total size of your S3 buckets and storage class distribution, using Amazon \nS3 Storage Lens\n\u2022If using SageMaker Studio, monitor and optimize the size of the shared Amazon Elastic File System \n(Amazon EFS) volume for the team.\nML lifecycle phase - Model development\nModel development consists of model building, training, tuning, and evaluation.\nBest practices\n\u2022Model training and tuning  (p. 56)\n\u2022Model evaluation  (p. 58)\n\u2022Operational excellence pillar - Best practices (p. 59)\n\u2022Security pillar \u2013 Best practices (p. 61)\n\u2022Reliability pillar \u2013 Best practices (p. 64)\n\u2022Performance e\ufb03ciency pillar \u2013 Best practices (p. 67)\n\u2022Cost optimization pillar \u2013 Best practices (p. 72)\n\u2022Sustainability pillar \u2013 Best practices (p. 83)\nModel training and tuning\nIn this phase, you select a machine learning algorithm that is appropriate for your problem and then \ntrain the ML model. You provide the algorithm with the training data, set an objective metric for the ML \nmodel to optimize on, and set the hyperparameters to optimize the training process.\n56", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "aaa84c4c-1d03-4e76-bf78-5917eac4213f": {"__data__": {"id_": "aaa84c4c-1d03-4e76-bf78-5917eac4213f", "embedding": null, "metadata": {"page_label": "57", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a004496acb7492c3b801fe87d29ccedd035967b88680605d980ebe6e68e96b19", "text": "Machine Learning Lens AWS Well-Architected Framework\nModel training and tuning\nFigure 12: ML model training and tuning: main components\nModel training, tuning, and evaluation require prepared data and engineered features. The following are \nthe main activities in this stage, as listed in Figure 12:\n\u2022Features \u2013 Features are selected as part of the data processing after data quality is assured\n\u2022Building code \u2013 Model development includes building the algorithm and its supporting code. The \ncode-building process should support version control and continuous build, test, and integration \nthrough a pipeline.\n\u2022Algorithm selection \u2013 Selecting the right algorithm involves running many experiments with \nparameter tuning across available options. Factors to consider when evaluating each option can \ninclude success metrics, model explainability, and compute requirements (training/prediction time and \nmemory requirements).\n\u2022Model training  (data parallel, model parallel)\u2013 The process of training a ML model involves providing \nthe algorithm with training data to learn from. Distributed training enables splitting large models and \ntraining datasets across compute instances to reduce training time signi\ufb01cantly. Model parallelism and \ndata parallelism are techniques to achieve distributed training.\n\u2022Model parallelism is the process of splitting a model up between multiple instances or nodes.\n\u2022Data parallelism is the process of splitting the training set in mini-batches evenly distributed across \nnodes. Thus, each node only trains the model on a fraction of the total dataset.\n\u2022Debugging/pro\ufb01ling  \u2013 A machine learning training job can have problems including: system \nbottlenecks, over\ufb01tting, saturated activation functions, and vanishing gradients. These problems can \ncompromise model performance. A debugger provides visibility into the ML training process through \nmonitoring, recording, and analyzing data. It captures the state of a training job at periodic intervals.\n\u2022Validation metrics \u2013 Typically, a training algorithm computes several metrics such as loss and \nprediction accuracy. These metrics determine if the model is learning and generalizing well for making \npredictions on unseen data. Metrics reported by the algorithm depend on the business problem and \nthe ML technique used. For example, a confusion matrix  is one of the metrics used for classi\ufb01cation \nmodels, and Root Mean Squared Error (RMSE) is one of the metrics for regression models.\n57", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9cf2c09a-217b-4eed-9122-3fe96ea89176": {"__data__": {"id_": "9cf2c09a-217b-4eed-9122-3fe96ea89176", "embedding": null, "metadata": {"page_label": "58", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8d07e53af552a01351d6a2a2b38dcef67ad6dd161f82fa0b828fc4842a8d6e4e", "text": "Machine Learning Lens AWS Well-Architected Framework\nModel evaluation\n\u2022Hyperparameter tuning  \u2013 Settings that can be tuned to control the behavior of the ML algorithm are \nreferred to as hyperparameters. The number and type of hyperparameters in ML algorithms are speci\ufb01c \nto each model. Examples of commonly used hyperparameters include: learning rate, number of \nepochs, hidden layers, hidden units and activation functions. Hyperparameter tuning, or optimization, \nis the process of choosing the optimal hyperparameters for an algorithm.\n\u2022Training code container \u2013 Create container images with your training code and its entire dependency \nstack. This will enable the training and deployment of models quickly and reliably at any scale.\n\u2022Model artifacts\u2013 Model artifacts are the outputs that results from training a model. They typically \nconsist of trained parameters, a model de\ufb01nition that describes how to compute inferences, and other \nmetadata.\n\u2022Visualization  \u2013 Enables exploring and understanding data during metrics validation, debugging, \npro\ufb01ling, and hyperparameter tuning.\nFigure 13: ML lifecycle with pre-production pipelines\nFigure 13 shows the pre-production pipelines. The data prepare  pipeline automates data preparation \ntasks. The feature pipeline automates the storing, fetching, and copying of the features into and from \nonline/o\ufb04ine store. The CI/CD/CT pipeline automates the build, train, and release to staging and \nproduction environments.\nModel evaluation\nAfter the model has been trained, evaluate it for its performance and success metrics. You might want \nto generate multiple models using di\ufb00erent methods and evaluate the e\ufb00ectiveness of each model. You \nalso might evaluate whether your model must be more sensitive than speci\ufb01c, or more speci\ufb01c than \nsensitive. For multiclass models, determine error rates for each class separately.\n58", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b05d1ea7-74ad-4d67-8a1f-cce7387cf550": {"__data__": {"id_": "b05d1ea7-74ad-4d67-8a1f-cce7387cf550", "embedding": null, "metadata": {"page_label": "59", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3729ea93b12a7f670640a2d71d59a1da779a1ca0458e57f0a1435416271bc2f2", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\nYou can evaluate your model using historical data (o\ufb04ine evaluation) or live data (online evaluation). In \no\ufb04ine evaluation, the trained model is evaluated with a portion of the dataset that has been set aside as \na\u00a0holdout set . This holdout data is never used for model training or validation-it\u2019s only used to evaluate \nerrors in the \ufb01nal model. The holdout data annotations must have high assigned label correctness for the \nevaluation to make sense. Allocate additional resources to verify the correctness of the holdout data.\nBased on the evaluation results, you might \ufb01ne-tune the data, the algorithm, or both. When you \ufb01ne-\ntune the data, you apply the concepts of data cleansing, preparation and feature engineering.\nFigure 14: ML lifecycle with performance evaluation pipeline added\nFigure 14 includes the model performance evaluation, the data prepare  and CI/CD/CT pipelines that \ufb01ne-\ntune data and/or algorithm, re-training, and evaluation of model results.\nOperational excellence pillar - Best practices\nThe operational excellence pillar includes the ability to run and monitor systems to deliver business value \nand to continually improve supporting processes and procedures. This section includes best practices to \nconsider while developing models that includes training, tuning, and model performance evaluation.\nBest practices\n\u2022MLOE-12: Automate operations through MLOps and CI/CD (p. 59)\n\u2022MLOE-13: Establish reliable packaging patterns to access approved public libraries (p. 61)\nMLOE-12: Automate operations through MLOps and CI/CD\nAutomate ML workload operations using infrastructure as code (IaC) and con\ufb01guration as code (CaC). \nSelect appropriate MLOps mechanisms to orchestrate your ML work\ufb02ows and integrate with CI/CD \npipelines for automated deployments. This approach ensures consistency across your staging and \n59", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "88e87bad-705d-41f6-ae6f-93280e2432dd": {"__data__": {"id_": "88e87bad-705d-41f6-ae6f-93280e2432dd", "embedding": null, "metadata": {"page_label": "60", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7d14fc189d17a3b2d369afe346160ea04e1ec3ce8c17636b4bd7693494939b67", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\nproduction deployment environments. Enable model observability and version control across your \nhosting infrastructure.\nImplementation plan\nYou can choose either AWS CloudFormation or AWS Cloud Development Kit (AWS CDK):\n\u2022Use AWS CloudFormation -AWS CloudFormation enables you to create and provision AWS \ndeployments predictably and repeatedly by using a template \ufb01le to create and delete a collection of \nresources together as a single unit (a stack). You can manage and provision stacks across multiple AWS \naccounts and AWS Regions.\n\u2022Use AWS Cloud Development Kit (AWS CDK) - Use AWS Cloud Development Kit (AWS CDK) (AWS \nCDK) as a software development framework for de\ufb01ning cloud infrastructure in code and provisioning \nit through AWS CloudFormation. You can de\ufb01ne your cloud resources in AWS CDK using familiar \nprogramming languages.\nYou can choose any of the following MLOps strategies based on your ML work\ufb02ows:\n\u2022Use SageMaker Pipelines to orchestrate your work\ufb02ows\nUsing Amazon SageMaker Pipelines, you can create ML work\ufb02ows with Python SDK, and then visualize \nand manage your work\ufb02ow using Amazon SageMaker Studio. Amazon SageMaker Pipelines logs every \nstep of your work\ufb02ow, creating an audit trail of model components such as training data, platform \ncon\ufb01gurations, model parameters, and learning gradients.\u00a0\n\u2022Use AWS Step Functions- You can also use AWS Step Functions Data Science SDK for\nAmazon SageMaker to automate training of a machine learning model. De\ufb01ne all the\nsteps in the work\ufb02ow and set up alerts to start the \ufb02ow.\n\u2022Use third-party tools - Use third-party deployment orchestration tools, such as\nApache Air\ufb02ow, that integrate with AWS service APIs to automate model training and deployment.\nAmazon Managed Work\ufb02ows for Apache Air\ufb02ow (MWAA) orchestrates your work\ufb02ows using Directed \nAcyclic Graphs (DAGs) written in Python.\ndata is available.\nDocuments\n\u2022Infrastructure as Code\n\u2022AWS CloudFormation\n\u2022AWS Cloud Development Kit (AWS CDK) (CDK)\n\u2022SageMaker Pipelines\n\u2022Step Functions Data Science SDK\nBlogs\n\u2022AWS CloudFormation \u2013 Create Your AWS Stack from a Recipe\n\u2022Automate Amazon SageMaker Studio setup using AWS SDK\n\u2022Secure multi-account model deployment with Amazon SageMaker: Part 1\n\u2022Secure multi-account model deployment with Amazon SageMaker: Part 2\n60", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d5a19004-9bea-40b1-8a58-5df097fae01d": {"__data__": {"id_": "d5a19004-9bea-40b1-8a58-5df097fae01d", "embedding": null, "metadata": {"page_label": "61", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "6dae762664f15d910f79f3ce15568745c5fa994f7ebbea4211694289fb17cd7c", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\n\u2022Organize your machine learning journey with SageMaker Pipelines\nMLOE-13: Establish reliable packaging patterns to access \napproved public libraries\nEstablish reliable packaging patterns for data scientists, which include (a) the use of internal repositories \nthat provide access to public libraries and (b) the creation of separate kernels for common ML \nframeworks. Examples of such common ML frameworks include TensorFlow, PyTorch, Scikit-learn, and \nKeras.\nImplementation plan\n\u2022Use container technology - Use or alternatively bring custom containers and store them in Amazon \nElastic Container Registry (Amazon ECR). Using containers, you can train machine learning algorithms \nand deploy models quickly and reliably at any scale.\n\u2022Use artifact repository - Set up AWS CodeArtifact to be used as a central internal artifact repository. \nThis will enable pulling artifacts from internal repositories and reusing them.\nDocuments\n\u2022Train a Deep Learning model with AWS Deep Learning Containers on Amazon EC2\nBlogs\n\u2022Private package installation in Amazon SageMaker running in internet-free mode\n\u2022Bringing your own custom container image to Amazon SageMaker Studio notebooks\n\u2022Integrating Jenkins with AWS CodeArtifact to publish and consume Python artifacts\nSecurity pillar \u2013 Best practices\nThe security pillar encompasses the ability to protect data, systems, and assets to take advantage of \ncloud technologies to improve your security. This section includes best practices to consider during \nmodel development that includes model training, tuning, and model performance evaluation.\nBest practices\n\u2022MLSEC-08: Secure governed ML environment (p. 61)\n\u2022MLSEC-09: Secure inter-node cluster communications (p. 62)\n\u2022MLSEC-10: Protect against data poisoning threats (p. 63)\nMLSEC-08: Secure governed ML environment\nProtect ML operations environments using managed services with best practices including: detective and \npreventive guardrails, monitoring, security, and incident management. Explore data in a managed and \nsecure development environment. Centrally manage the con\ufb01guration of development environments \nand enable self-service provisioning for the users.\nImplementation plan\n\u2022Break out ML workloads by organizational unit access patterns. This will enable delegating required \naccess to each group, such as administrators or data analysts.\n61", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9d542aab-24b3-405b-8af2-e05491c6312e": {"__data__": {"id_": "9d542aab-24b3-405b-8af2-e05491c6312e", "embedding": null, "metadata": {"page_label": "62", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "9262ae968764a5ed384f75b7547e6c5bca41ce927ee81aae01934ff286fa2abc", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\n\u2022Use guardrails and service control policies (SCPs) to enforce best practices for each environment \ntype. Limit infrastructure management access to administrators.\n\u2022Verify all sensitive data has access through restricted, isolated environments. Ensure network \nisolation, dedicated resources, and check service dependencies.\n\u2022Secure ML algorithm implementation using a restricted development environment. Secure model \ntraining and hosting containers by following the security processes required for your organization.\nDocuments\n\u2022Security in Amazon SageMaker\n\u2022Build a secure enterprise machine learning platform on AWS\n\u2022Use Amazon SageMaker Notebook Instances\n\u2022Amazon SageMaker with Guardrails on AWS\nBlogs\n\u2022Setting up secure, well-governed machine learning environments on AWS\n\u2022Securing Amazon SageMaker Studio Connectivity using a private VPC\n\u2022Enable self-service, secured data science using Amazon SageMaker notebooks and AWS Service\nCatalog\n\u2022Accelerating Machine Learning Development with Data Science as a Service from Change Healthcare\nMLSEC-09: Secure inter-node cluster communications\nFor frameworks such as TensorFlow, it\u2019s common to share information like coe\ufb03cients as part of \nthe inter-node cluster communications. The algorithms require that exchanged information stay \nsynchronized across nodes. Secure this information through encryption in transit.\nImplementation plan\n\u2022Enable inter-node encryption in Amazon SageMaker- In distributed computing environments, \ndata transmitted between nodes can traverse wide networks, or even the internet. Enable inter-\nnode encryption through the appropriate controls for the technology choices made. You can instruct \nSageMaker to automatically encrypt inter-container communication for your training job to ensure \nthat data is passed over an encrypted tunnel.\n\u2022Enable encryption in transit in Amazon EMR - There are many applications and execution engines \nin the Hadoop ecosystem, providing a variety of tools to match the needs of your ML and analytics \nworkloads. Amazon EMR has distributed cluster capabilities and is also an option for running training \njobs on the data that is either stored locally on the cluster or in Amazon S3. Amazon EMR makes it \neasy to create and manage fully con\ufb01gured, elastic clusters of Amazon EC2 instances running Hadoop \nand other applications in the Hadoop ecosystem. Amazon EMR provides security con\ufb01gurations to set \nup data encryption at rest while stored on Amazon S3 and local Amazon EBS volumes. It also allows \nthe set-up of Transport Layer Security (TLS) certi\ufb01cates for the encryption of data in transit.\nDocuments\n\u2022Protect Communications Between ML Compute Instances in a Distributed Training Job\n\u2022Amazon EMR Management guide - Security Data Protection & Encryption Options\n\u2022Apache Hadoop on Amazon EMR\n62", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5490ccb3-328f-42ce-af17-a30cad3c2ab3": {"__data__": {"id_": "5490ccb3-328f-42ce-af17-a30cad3c2ab3", "embedding": null, "metadata": {"page_label": "63", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "686d4d4fc643878dfe27c2b185f268a044859d517a78c6087d3e9ab360b8a418", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\nBlogs\n\u2022Encrypt data in transit using a TLS custom certi\ufb01cate provider with Amazon EMR\n\u2022Secure Amazon EMR with Encryption\nExamples\n\u2022Protect Communications Between ML Compute Instances in a Distributed Training Job\n\u2022TF Encrypted\nMLSEC-10: Protect against data poisoning threats\nProtect against data injection and data manipulation that pollutes the training dataset. Data injections \ncan add corrupt training data that can result in incorrect model and outputs. Data manipulations can \nchange existing data (for example, labels) that can result in inaccurate and weak predictive models. \nIdentify and address corrupt data and inaccurate models using security methods and anomaly detection \nalgorithms. Ensure immutability of datasets by providing protection against ransomware and malicious \ncode in installed third-party packages.\nImplementation plan\n\u2022Use only trusted data sources for training data - Verify that you have su\ufb03cient audit controls to \nreplay activity and determine where a change occurred, by whom, and at what time. Before training, \nvalidate the quality of training data to look for strong outliers and potentially incorrect labels.\n\u2022Look for underlying shifts in the patterns and distributions in training data - Using monitoring of \ndata drift, derive the impact to prediction variance. These skews can be an indicator of underlying data \ndrift, and can provide an early warning of unauthorized access targeting the training data.\n\u2022Identify model updates that negatively impact the results before moving them to production - \nDetermine if the retrained model results are di\ufb00erent from the past model iteration. Use past test data \nand previous model iterations as a baseline.\n\u2022Have a rollback plan - Using versioned training data and versioned models, make sure you can revert \nto a known good working model in a failure scenario. Use a fully managed service to store features, \nsuch as the Amazon SageMaker Feature Store. See more details of the Amazon SageMaker Feature \nStore under the Reliability pillar section (MLREL-07).\n\u2022Use low-entropy classi\ufb01cation cases - Look for signi\ufb01cant, unexpected changes. Determine the \nbounds of thresholds, identify classi\ufb01cations that you do not expect to see, and alert if the retrained \nmodel exceeds them.\nDocuments\n\u2022Monitor Bias Drift for models in production\n\u2022Amazon SageMaker model registry now supports rollback of deployed models\n\u2022SageMaker Model Registry - Approve\nBlogs\n\u2022Automated monitoring of your machine learning models with Amazon SageMakerModel Monitor and\nsending predictions to human review work\ufb02ows using Amazon A2I\n\u2022Amazon SageMaker Model Monitor\u2013 Fully Managed Automatic Monitoring for Your Machine Learning\nModels\n\u20227 ways to improve security of your machine learning work\ufb02ows\n63", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1f551067-8c23-4a7a-a7df-6dd3870aa939": {"__data__": {"id_": "1f551067-8c23-4a7a-a7df-6dd3870aa939", "embedding": null, "metadata": {"page_label": "64", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "060b62dbd0ffbe95d9028cdb876c279bf683160f804e79aff06fbae859988303", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nVideos\n\u2022AWS re:Invent 2020: Detect machine learning (ML) model drift in production\nExamples\n\u2022Inawisdom: Machine Learning and Automated Model Retraining with SageMaker\n\u2022Amazon SageMaker Workshop- DevOps work\ufb02ow\nReliability pillar \u2013 Best practices\nThe reliability pillar encompasses the ability of a workload to perform its intended function correctly \nand consistently when it\u2019s expected to. This section includes best practices to consider during model \ndevelopment that includes model training, tuning, and model performance evaluation.\nBest practices\n\u2022MLREL-06: Enable CI/CD/CT automation with traceability (p. 64)\n\u2022MLREL-07: Ensure feature consistency across training and inference (p. 65)\n\u2022MLREL-08: Ensure model validation with relevant data (p. 66)\n\u2022MLREL-09: Establish data bias detection and mitigation (p. 66)\nMLREL-06: Enable CI/CD/CT automation with traceability\nEnable source code, data, and artifact version control of ML workloads to enable roll back to a speci\ufb01c \nversion. Incorporate continuous integration (CI), continuous delivery (CD), and continuous training (CT) \npractices to ML workload operations. This will enable automation with added traceability.\nImplementation plan\n\u2022Use Amazon SageMaker Pipelines- Manual changes to a system can cost additional time and \nimpair reproducibility. Changes to an ML workload should be conducted, tracked and rolled back \nautomatically. MLOps is a collection of best practices around integrating and deploying reproducible, \nauditable changes. MLOps increases your productivity while automating all facets of your ML \ndevelopment cycle (MLDC). Amazon SageMaker Pipelines is the \ufb01rst purpose-built, continuous \nintegration (CI), continuous delivery (CD), and continuous training (CT) service. With SageMaker \nPipelines, create, automate, and manage end-to-end ML work\ufb02ows at scale.\nDocuments\n\u2022AWS MLOps Framework\n\u2022SageMaker Pipelines Overview\n\u2022Continuous Delivery for Machine Learning on AWS\nBlogs\n\u2022Improve your data science work\ufb02ow with a multi-branch training MLOps pipeline using AWS\n\u2022Build a CI/CD pipeline for deploying custom machine learning models using AWS services\n\u2022Create Amazon SageMaker projects with image building CI/CD pipelines\n64", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "eb1957ad-0e77-4c45-8f3a-28d968e52a05": {"__data__": {"id_": "eb1957ad-0e77-4c45-8f3a-28d968e52a05", "embedding": null, "metadata": {"page_label": "65", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a1d9284115eb330afbc81a7b5222bf4b5e8a97d04a0dbcafaf0e6510386e8ba5", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nVideos\n\u2022AWS re:Invent 2020: How to create fully automated ML work\ufb02ows with Amazon SageMaker Pipelines\n\u2022Inawisdom: Machine Learning and Automated Model Retraining with SageMaker\nExamples\n\u2022Amazon Sagemaker MLOps (with classic CI/CD tools) Workshop\n\u2022Amazon SageMaker secure MLOps\nMLREL-07: Ensure feature consistency across training and \ninference\nEnsure consistent, scalable, and highly available features between training and inference using a feature \nstorage. This results in reducing the training-serving skew by keeping feature consistency between \ntraining and inference.\nImplementation plan\n\u2022Use Amazon SageMaker Feature Store -Create, share, and manage features for ML development \nusing SageMaker Feature Store. The Feature Store is a centralized store for features and associated \nmetadata so features can be easily discovered and reused. The online store is used for low latency, \nreal-time inference use cases. The o\ufb04ine store is used for training and batch inference. The Feature \nStore reduces the repetitive data processing and curation work required to convert raw data into \nfeatures for training an ML algorithm. Features generated will be used for both training and \ninference, reducing the training-serving skew. The Feature Store enables feature consistency, feature \nstandardization, and the ability to integrate with Amazon SageMaker Pipelines.\nDocuments\n\u2022Get started with Amazon SageMakerFeature Store\nBlogs\n\u2022Store, Discover, and Share Machine Learning Features with Amazon SageMakerFeature Store\n\u2022Using streaming ingestion with Amazon SageMakerFeature Store to make ML-backed decisions in\nnear-real time\nVideos\n\u2022AWS re:Invent 2020: Amazon SageMakerFeature Store: Store, discover, & share features for ML apps\n\u2022Introducing Amazon SageMaker Feature Store - AWS re:Invent2020\nExamples\n\u2022Amazon SageMaker Feature Store: Introduction to Feature Store\n\u2022Amazon SageMaker Feature Store\n\u2022Amazon SageMaker Feature Store Introduction\n\u2022Amazon SageMaker Feature Store: Streaming Aggregation\n65", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0cedc109-d3ae-4311-aead-ee6e17ed0283": {"__data__": {"id_": "0cedc109-d3ae-4311-aead-ee6e17ed0283", "embedding": null, "metadata": {"page_label": "66", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d223c5a74822779a1d0f287e1e18d3a1f18e20011ea505821e8bc9f6c06a273a", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nMLREL-08: Ensure model validation with relevant data\nPut processes in place to include real and representative data for testing and validation. Data that does \nnot include all possible patterns and scenarios will result in failures once model is in production. Check \nfor a distribution mismatch  between training, validation, and test data as well as the inference data.\nImplementation plan\n\u2022Use Amazon SageMaker Experiments - Your models should be tested and validated using data that \nis representative of what they will encounter in production. This data can include both real-world data \nand engineered data. You should account for all scenarios in your training data so that you can avoid \nerrors when your model is deployed to production. Use Amazon SageMaker Experiments to organize, \ntrack, compare, and evaluate your machine learning experiments.\n\u2022Use Amazon SageMaker Model Monitor - Consider implementing a plan to periodically test endpoints \nfor deviations in model quality. Early detection of deviations can help you determine when to take \ncorrective actions. SageMaker Model Monitor continually monitors the quality of Amazon SageMaker \nML models in production. With Model Monitor, you can set alerts that notify you when there are \ndeviations in the model quality.\nDocuments\n\u2022Evaluating ML Models\n\u2022Cross-Validation of Machine Learning Models\nBlogs\n\u2022Test data quality at scale with Deequ\n\u2022Amazon SageMaker Model Monitor\u2013 Fully Managed Automatic Monitoring for Your Machine Learning\nModels\nExamples\n\u2022Amazon SageMaker Model Monitor\nMLREL-09: Establish data bias detection and mitigation\nDetect and mitigate bias to avoid inaccurate model results. Establish bias detection methodologies at \ndata preparation stage before training starts. Monitor, detect, and mitigate bias after the model is in \nproduction. Establish feedback loops to track the drift over time and initiate a re-training.\nImplementation plan\n\u2022Use Amazon SageMaker Clarify- Amazon SageMaker Clarify helps improve your machine learning \nmodels by detecting potential bias and helping explain how these models make predictions. The \nfairness and explainability functionality provided by SageMaker Clarify takes a step towards enabling \nyou to build trustworthy and understandable ML models. Clarify helps you with the following tasks:\n\u2022Measure biases that can occur during each stage of the ML lifecycle. These stages include data \ncollection, model training, model tuning, and model monitoring.\n\u2022Generate model governance reports targeting risk and compliance teams and external regulators.\n\u2022Provide explanations of the data, models, and monitoring used to assess predictions.\n66", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "bafb06d1-36ba-4a2e-9733-d2c14b4f6635": {"__data__": {"id_": "bafb06d1-36ba-4a2e-9733-d2c14b4f6635", "embedding": null, "metadata": {"page_label": "67", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c556ddd5e8d8f328e3fc42f4ad42cc5159aa2d64790b53304203d6309dd97ce3", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nDocuments\n\u2022Run SageMaker Clarify Processing Jobs for Bias Analysis and Explainability\nBlogs\n\u2022Amazon SageMaker Clarify Detects Bias and Increases the Transparency of Machine Learning Models\nVideos\n\u2022Introducing Amazon SageMakerClarify, part 1 - Bias detection - AWS re:Invent2020\n\u2022Introducing Amazon SageMakerClarify, part 2 - Model explainability - AWS re:Invent2020\nExamples\n\u2022SageMaker Clarify\nPerformance e\ufb03ciency pillar \u2013 Best practices\nThe performance e\ufb03ciency pillar focuses on the e\ufb03cient use of computing resources to meet \nrequirements and the maintenance of that e\ufb03ciency as demand changes and technologies evolve. This \nsection includes best practices to consider during model development that includes model training, \ntuning and model performance evaluation.\nBest practices\n\u2022MLPER-05: Optimize training and inference instance types (p. 67)\n\u2022MLPER-06: Explore alternatives for performance improvement (p. 68)\n\u2022MLPER-07: Establish a model performance evaluation pipeline (p. 69)\n\u2022MLPER-08: Establish feature statistics (p. 70)\n\u2022MLPER-09: Perform a performance trade-o\ufb00 analysis (p. 71)\n\u2022MLPER-10: Detect performance issues when using transfer learning (p. 72)\nMLPER-05: Optimize training and inference instance types\nDetermine how the model type and data velocity a\ufb00ect the choice of training and inference instance \ntypes. Identify the right instance type that supports memory intensive training, or compute intensive \ntraining with high throughput and low latency real-time inference. The speed of model inferences is \ndirectly impacted by model complexity. Selection of high compute instances can accelerate inference \nspeed. GPUs are often the preferred processor type to train many deep learning models. CPUs are often \nsu\ufb03cient for the inference workloads.\nImplementation plan\n\u2022Experiment with alternative instance types to train and deploy - Determine which instance types \nare most appropriate for your ML algorithm and use case. Use multiple instances for training for large \ndatasets to take advantage of scale.\nDocuments\n\u2022Use Amazon SageMaker Notebook Instances\n67", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "fd0a1eed-fc78-4799-ac6b-e6c1db17e241": {"__data__": {"id_": "fd0a1eed-fc78-4799-ac6b-e6c1db17e241", "embedding": null, "metadata": {"page_label": "68", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "bdab0c5d3c6b5c562729918dee24bc1d49b1c9b1c43805e33542aa7a7888759f", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\n\u2022Train a Model with Amazon SageMaker\n\u2022Distributed training libraries\nBlogs\n\u2022Learn how to select ML instances on the \ufb02y in Amazon SageMaker Studio\n\u2022Optimizing I/O for GPU performance tuning of deep learning training in Amazon SageMaker\n\u2022Right-sizing resources and avoiding unnecessary costs in Amazon SageMaker\nVideos\n\u2022How to choose the right instance type for ML inference\n\u2022The right instance type in Amazon SageMaker\nExamples\n\u2022Amazon SageMaker End-to-End Example\nMLPER-06: Explore alternatives for performance improvement\nPerform benchmarks to improve the machine learning model performance. Benchmarking in ML involves \nevaluation and comparison of ML workloads with di\ufb00erent algorithms, features, and architecture \nresources. It enables identifying the combination with optimal performance.\nOptions you can use when benchmarking include:\n\u2022Use more data to broaden the statistical range and improve the success metric of the model.\n\u2022Apply feature engineering to extract important signals in the data for the model.\n\u2022Make alternative algorithm selections for an optimal \ufb01t to the speci\ufb01cs of the data.\n\u2022Ensemble methods that combine the di\ufb00erent advantages of multiple models.\n\u2022Tune the hyperparameters for a given algorithm to calibrate the model for the data.\nImplementation plan\n\u2022Use Amazon SageMaker Experiments to optimize algorithms and features -Begin with a simple \narchitecture, obvious features, and a simple algorithm to establish a baseline. Amazon SageMaker \nprovides built-in algorithms for developing a baseline model. Use Amazon SageMaker Experiments to \norganize, track, compare, and evaluate your machine learning experiments. Test di\ufb00erent algorithms \nwith increasing complexity to observe performance. Combine models into an ensemble to increase \naccuracy, but consider the potential loss of e\ufb03ciency as a trade-o\ufb00. Re\ufb01ne the features by selection \nand modify parameters to optimize model performance. Tune the model\u2019s hyperparameters to \noptimize performance using Amazon SageMaker Hyperparameter Optimization to automate the \nsearch.\nDocuments\n\u2022Improving Model Accuracy\n\u2022Evaluating ML Models\n\u2022Feature Processing with Spark ML and Scikit-learn\n68", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6e96873a-86b9-4928-8e0a-3fb84be04a94": {"__data__": {"id_": "6e96873a-86b9-4928-8e0a-3fb84be04a94", "embedding": null, "metadata": {"page_label": "69", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "71812ffd7268e1fc04783498dbe7a1d66e4c7caa6d83f68a13646b95e3b030ba", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\n\u2022Perform Automatic Model Tuning with SageMaker\n\u2022Amazon SageMaker Experiments: Track and Compare Tutorial\nBlogs\n\u2022Running multiple HPO jobs in parallel on Amazon SageMaker\n\u2022Optimizing portfolio value with Amazon SageMaker automatic model tuning\n\u2022Utilizing XGBoost training reports to improve your models\nVideos\n\u2022Tune your ML models to the highest accuracy with automatic model tuning\n\u2022Organize, Track, and Evaluate ML Training Runs With Amazon SageMaker Experiments\nExamples\n\u2022Feature Engineering Immersion Day Workshop\n\u2022Improving Forecast Accuracy with Machine Learning\n\u2022Ensemble Predictions From Multiple Models\nMLPER-07: Establish a model performance evaluation pipeline\nCapture key metrics related to model performance using an end-to-end performance pipeline to \nevaluate the success of a model. Choose speci\ufb01c metrics based on the use case and the business KPIs. \nSample key metrics include training or validation errors, and prediction accuracy. Speci\ufb01c model \nperformance metrics include Root Mean Squared Error (RMSE), accuracy, precision, recall, F1 score, and \narea under the curve (AUC). Establish a fully automated performance testing pipeline system to initiate \nevaluation every time there is an updated model or data.\nImplementation plan\n\u2022Create an end-to-end work\ufb02ow with Amazon SageMaker Pipelines - Start with a work\ufb02ow template \nto establish an initial infrastructure for model training and deployment. SageMaker Pipelines helps you \nautomate di\ufb00erent steps of the ML work\ufb02ow. These steps include data loading, data transformation, \ntraining, tuning, and deployment. With SageMaker Pipelines, you can share and reuse work\ufb02ows to \nre-create or optimize models, helping you scale ML throughout your organization. Within SageMaker \nPipelines, the SageMaker Model Registry tracks the model versions and respective artifacts. These \nartifacts include the metadata and lineage data collected throughout the model development \nlifecycle. SageMaker Model Registry can also enable automating model deployment with CI/CD.\nDocuments\n\u2022De\ufb01ne a Pipeline\nBlogs\n\u2022Building, automating, managing, and scaling ML work\ufb02ows using Amazon SageMaker Pipelines\n\u2022Extend Amazon SageMaker Pipelines to include custom steps using callback steps\n69", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "52284c99-e945-4292-9546-76dd66009847": {"__data__": {"id_": "52284c99-e945-4292-9546-76dd66009847", "embedding": null, "metadata": {"page_label": "70", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "9ad91a6faf44ac37b3ed438829978e0f73005641a7953d628d71512aecbc87e1", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nVideos\n\u2022Introducing Amazon SageMaker Pipelines\n\u2022How to create fully automated ML work\ufb02ows with Amazon SageMaker Pipelines\nExamples\n\u2022SageMaker Pipelines \u2013 Immersion Day\nMLPER-08: Establish feature statistics\nEstablish key statistics to measure changes in the data that a\ufb00ect model outcomes. The e\ufb00ect of \nchanges in data on model inference depends on the sensitivity of the model to data features. Analyze \nthe feature importance and sensitivity of the model to select the features to monitor. Monitor the \nstatistics of features that have the largest in\ufb02uence on inferences. Place acceptability limits on the \nrange of data to alert when important features drift outside the statistical range of the training data. \nSigni\ufb01cant drifts in important features would suggest model re-training.\nImplementation plan\n\u2022Analyze and evaluate data - Use Amazon SageMaker Data Wrangler to analyze the distribution of the \nselected features. After training the model, map out the regions in feature space where the predictions \nchange abruptly and where the predictions are invariant. Establish a baseline for monitoring the data \nwith Amazon SageMaker Model Monitor. Perform a sensitivity analysis of changes in the feature values \nnear the decision boundaries of the model. Analyze the feature importance to understand how new \ndata will a\ufb00ect the model\u2019s predictions. Amazon SageMakerExperiments will help to organize model \ntesting. Use Amazon SageMaker Clarify to check for data biases and imbalances. Monitor the statistics \nof data used in production inferences. Consider retraining the model if the features are outside the \noriginal distribution of the training data.\nDocuments\n\u2022Amazon SageMaker Data Wrangler: Analyze and Visualize\n\u2022Detect Pretraining Data Bias\nBlogs\n\u2022Exploratory data analysis, feature engineering, and operationalizing your data \ufb02ow into your ML\npipeline with Amazon SageMakerData Wrangler\n\u2022Amazon SageMaker Model Monitor\u2013 Fully Managed Automatic Monitoring for Your Machine Learning\nModels\n\u2022How Clarify helps machine learning developers detect unintended bias\nVideos\n\u2022Prepare data for machine learning with ease, speed, and accuracy\n\u2022Detect machine learning (ML) model drift in production\n\u2022Accelerate data preparation with Amazon SageMakerData Wrangler\n70", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b6cd767d-0c30-4cf1-b0a7-8ad4e3e9e545": {"__data__": {"id_": "b6cd767d-0c30-4cf1-b0a7-8ad4e3e9e545", "embedding": null, "metadata": {"page_label": "71", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "644b5f8372348d988c112f764368ef4e24eb9001bae369312a3d6d79899f2ad3", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nExamples\n\u2022Feature Engineering, ImmersionDay Workshop\nMLPER-09: Perform a performance trade-o\ufb00 analysis\nPerform alternative trade-o\ufb00 analysis to obtain optimal performance and accuracy for a given use-case \ndata and business requirement.\n\u2022Accuracy versus complexity trade-o\ufb00: The simpler a machine learning model is, the more explainable \nare its predictions. Deep learning predictions can potentially outperform linear regression or a decision \ntree algorithm, but at the cost of added complexity in interpretability and explainability.\n\u2022Bias versus fairness trade-o\ufb00: De\ufb01ne a process for managing risks of bias and fairness in model \nperformance. Business value most often aligns with models that have considered historical \nor\u00a0sampling biases in the training data. Further consideration should be given to the disparate impact \nof inaccurate model predictions. For example, underrepresented groups are often more impacted by \nhistorical biases, which might perpetuate unfair practices.\n\u2022Bias versus variance trade-o\ufb00 (supervised ML): The goal is to achieve a trained model with the lowest \nbias versus variance tradeo\ufb00 for a given data set. To help overcome bias and variance errors, you can \nuse:\n\u2022Cross validation\n\u2022More data\n\u2022Regularization\n\u2022Simpler models\n\u2022Dimension reduction (Principal Component Analysis)\n\u2022Stop training early\n\u2022Precision versus recall trade-o\ufb00 (supervised ML): This analysis can be important when precision is \nmore important than recall or vice versa. For example, optimization of precision is more important \nwhen the goal is to reduce false positives. However, optimization of recall is more important when the \ngoal is to reduce false negatives. It\u2019s not possible to have both high precision and high recall-if one is \nincreased, the other decreases. A trade-o\ufb00 analysis helps identify the optimal option for analysis.\nImplementation plan\nConstruct alternate work\ufb02ows to optimize all aspects of business value - Complex models can \ndeliver high accuracy. If the business requirements include low-latency, then the model might need \nto be simpli\ufb01ed with lower complexity. Identify how trade-o\ufb00s a\ufb00ect accuracy and the latency of \ninferences. Test these trade-o\ufb00s using Amazon SageMaker Experiments to keep track of each model \ntype. Amazon SageMakerClarify provides explanations of the data, models, and monitoring used to \nassess predictions. It can measure biases during each stage of the ML lifecycle. Provided explanations \nwill help understanding how fairness a\ufb00ects the business use case. Complex ML models can be slower to \nreturn an inference and more di\ufb03cult to deploy at the edge. Amazon SageMaker Neo enables developers \nto optimize ML models for inference on SageMaker in the cloud and supported devices at the edge.\nDocuments\n\u2022Evaluating ML Models\n\u2022AI Fairness and Explainability Whitepaper\n\u2022Optimize model performance using Amazon SageMaker Neo\n71", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6a709138-ad39-464f-aada-63c9033c592b": {"__data__": {"id_": "6a709138-ad39-464f-aada-63c9033c592b", "embedding": null, "metadata": {"page_label": "72", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0b15791e92502d1f4f6d1cf7f094c5685555ae90e5584c6780fe47072702b322", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nBlogs\n\u2022Amazon SageMaker Experiments \u2013 Organize, Track And Compare Your Machine Learning Trainings\n\u2022Amazon SageMaker Clarify Detects Bias and Increases the Transparency of Machine Learning Models\n\u2022Unlock near 3x performance gains with XGBoost and Amazon SageMaker Neo\nVideos\n\u2022Machine learning and society: Bias, fairness, and explainability\nMLPER-10: Detect performance issues when using transfer \nlearning\nMonitor and ensure that the inherited prediction weights from a transferred model yield the desired \nresults. This approach helps minimize the risk of weak learning and incorrect outputs using pre-trained \nmodels.\nImplementation plan\n\u2022Use Amazon SageMaker Debugger - Transfer learning is a machine learning technique where a model \npre-trained on one task is \ufb01ne-tuned on a new task. When using the transfer learning approach, \nuse\u00a0Amazon SageMaker Debugger to detect hidden problems that might have serious consequences. \nExamine model predictions to see what mistakes were made. Validate the robustness of your model, \nand consider how much of this robustness is from the inherited capabilities. Validate input and \npreprocesses to the model for realistic expectations.\nBlogs\n\u2022When does transfer learning work?\n\u2022Detecting hidden but non-trivial problems in transfer learning models using Amazon SageMaker\nDebugger\nCost optimization pillar \u2013 Best practices\nThe cost optimization pillar includes the continual process of re\ufb01nement and improvement of a system \nover its entire lifecycle. From the initial design of your very \ufb01rst proof of concept to the ongoing \noperation of production workloads, adopting the practices in this document can enable you to build \nand operate cost-aware systems that achieve business outcomes and minimize costs, thus allowing your \nbusiness to maximize its return on investment. This section includes best practices to consider during \nmodel development.\nBest practices\n\u2022MLCOST-09: Select optimal computing instance size (p. 73)\n\u2022MLCOST-10: Use managed build environments (p. 73)\n\u2022MLCOST-11: Select local training for small scale experiments (p. 74)\n\u2022MLCOST-12: Select an optimal ML framework (p. 75)\n\u2022MLCOST-13: Use automated machine learning (p. 76)\n\u2022MLCOST-14: Use managed training capabilities (p. 76)\n\u2022MLCOST-15: Use distributed training (p. 77)\n\u2022MLCOST-16: Stop resources when not in use (p. 78)\n72", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ba4cb2de-e1fc-4358-b10f-2fca22854af9": {"__data__": {"id_": "ba4cb2de-e1fc-4358-b10f-2fca22854af9", "embedding": null, "metadata": {"page_label": "73", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "39c3200abc9e3c9e394efd3f8f76f0e6773d0c3307df63fc490c5d8f9522613f", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\n\u2022MLCOST-17: Start training with small datasets (p. 79)\n\u2022MLCOST-18: Use warm-start and checkpointing hyperparameter tuning (p. 79)\n\u2022MLCOST-19: Use hyperparameter optimization technologies (p. 80)\n\u2022MLCOST-20 - Setup budget and use resource tagging to track costs (p. 80)\n\u2022MLCOST-21: Enable data and compute proximity (p. 81)\n\u2022MLCOST-22: Select optimal algorithms (p. 82)\n\u2022MLCOST-23: Enable debugging and logging (p. 83)\nMLCOST-09: Select optimal computing instance size\nRight size the training instances according to the ML algorithm used for maximum e\ufb03ciency and \ncost reduction. Use debugging capabilities to understand the right resources to use during training. \nSimple models might not train faster on larger instances because they might not be able to bene\ufb01t \nfrom additional compute resources. These models might even train slower due to the high GPU \ncommunication overhead. Start with smaller instances and scale as necessary.\nImplementation plan\n\u2022Use Amazon SageMaker Experiments - Amazon EC2 provides a wide selection of instance types \noptimized to \ufb01t di\ufb00erent use cases. Machine learning workloads can use either a CPU or a GPU \ninstance. Select an instance type from the available EC2 instance types depending on the needs of \nyour ML algorithm. Experiment with both CPU and GPU instances to learn which one gives you the \nbest cost con\ufb01guration. Amazon SageMaker lets you use a single instance or a distributed cluster of \nGPU instances. Use Amazon SageMaker Experiments to evaluate alternative options, and identify \nthe size resulting in optimal outcome. With the pricing broken down by time and resources, you can \noptimize the cost of Amazon SageMaker and only pay for what is needed.\n\u2022Use Amazon SageMaker Debugger - Amazon SageMaker Debugger automatically monitors the \nutilization of system resources, such as GPUs, CPUs, network, and memory, and pro\ufb01les your training \njobs to collect detailed ML framework metrics. You can inspect all resource metrics visually through \nSageMaker Studio and take corrective actions if the resource is under-utilized to optimize cost.\u00a0\nDocuments\n\u2022Amazon SageMaker Debugger\u00a0\nBlogs\n\u2022Right-sizing resources and avoiding unnecessary costs in Amazon SageMaker\n\u2022Identify bottlenecks, improve resource utilization, and reduce ML training costs with the deep pro\ufb01ling \nfeature in Amazon SageMaker Debugger\nVideos\n\u2022AWS re:Invent 2019: Choose the right instance type in Amazon SageMaker, with Texas Instruments\nMLCOST-10: Use managed build environments\nConsider using managed notebooks instead of local ones, or notebooks hosted on a server. Managed \nnotebooks come bundled with security, network, storage, compute capabilities that take a lot of time \nand resources to develop locally. Managed ML build environment also makes it easy to decide the type of \n73", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "fc866898-16ae-448c-82b9-a07528f9cd76": {"__data__": {"id_": "fc866898-16ae-448c-82b9-a07528f9cd76", "embedding": null, "metadata": {"page_label": "74", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d79f7194994afbf932fe94b152aa29b26cb108df348f141e1a1a3fc2ae37a095", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nmachine you prefer so you don\u2019t need to manage any complex AMIs or security groups-this makes it very \neasy to get started. It can also provide access to GPUs and big machines with large amounts of RAM that \nmight not be possible on a local setup.\u00a0\nImplementation plan\n\u2022Use Amazon SageMaker Notebooks - An Amazon SageMaker notebook instance is a ML compute \ninstance running the Jupyter Notebook App. SageMaker manages creating the instance and related \nresources. Use Jupyter notebooks in your notebook instance to prepare and process data, write code \nto train models, deploy models to SageMaker hosting, and test or validate your models. SageMaker \nprovides hosted Jupyter notebooks that require no setup, so you can begin processing your training \ndata sets immediately. With a few clicks in the SageMaker console, you can create a fully managed \nnotebook instance, pre-loaded with useful libraries for machine learning. You only need to add your \ndata.\n\u2022Use Amazon SageMaker Studio - Amazon SageMaker Studio provides a single, web-based visual \ninterface where you can perform all ML development steps, improving data science team productivity. \nSageMaker Studio gives you complete access, control, and visibility into each step required to build, \ntrain, and deploy models. You can quickly upload data, create new notebooks, train and tune models, \nmove back and forth between steps to adjust experiments, compare results, and deploy models \nto production all in one place, making you much more productive. All ML development activities \nincluding notebooks, experiment management, automatic model creation, debugging, and model and \ndata drift detection can be performed with SageMaker Studio.\n\u2022Use SageMaker Canvas -\u00a0Amazon SageMaker Canvas, a new visual, no code capability that allows \nbusiness analysts to build ML models and generate accurate predictions without writing code or \nrequiring ML expertise. Its intuitive user interface lets you browse and access disparate data sources in \nthe cloud or on premises, combine datasets with the click of a button, train accurate models, and then \ngenerate new predictions once new data is available.\nDocuments\n\u2022Amazon SageMaker Notebook Instances\n\u2022Amazon SageMaker Studio\n\u2022Amazon SageMaker Canvas\nBlogs\n\u2022Amazon SageMaker Studio and SageMaker Notebook Instance now come with JupyterLab 3 notebooks \nto boost developer productivity\n\u2022Build, Share, Deploy: how business analysts and data scientists achieve faster time-to-market using no-\ncode ML and Amazon SageMaker Canvas\n\u2022Amazon SageMaker Canvas \u2013 a Visual, No Code Machine Learning Capability for Business Analysts\nExamples\n\u2022SageMaker Example Notebooks\nMLCOST-11: Select local training for small scale experiments\nEvaluate the requirements to train an ML model in the cloud versus on a local machine. Use local option \nwhen experimenting across di\ufb00erent algorithms and con\ufb01gurations with small data sizes. For large \ndata, launch a cloud-based training cluster with one or more compute instances. Right size the compute \ninstances in the training cluster based on the workload.\n74", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "50a1f65c-ae8d-4065-b9e8-7187c2b78138": {"__data__": {"id_": "50a1f65c-ae8d-4065-b9e8-7187c2b78138", "embedding": null, "metadata": {"page_label": "75", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f9a7cd14722980a33e7f1159d4579242b080aa50c1a00bf119ab3120b285d4b6", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nImplementation plan\n\u2022Use Amazon SageMaker - While experimenting with training a model with small datasets, use Amazon \nSageMaker notebook local  mode. This will train your model on the notebook instance itself, instead \nof on a separate managed training cluster. You can iterate and test your work without having to wait \nfor a new training or hosting cluster each time. This saves both time and cost associated with creating \na managed training cluster. Experimentation can also occur outside of a notebook, for example on a \nlocal machine. From your local machine, you can use the SageMaker SDK to train and deploy models \non AWS.\nBlogs\n\u2022Use the Amazon SageMaker local mode to train on your notebook instance\nVideos\n\u2022Train with Amazon SageMaker on your local machine\nExamples\n\u2022Multiple examples showing how to run SageMaker in local mode\nMLCOST-12: Select an optimal ML framework\nOrganize, track, compare and evaluate machine learning (ML) experiments and model versions. Identify \nthe most cost-e\ufb00ective and optimal combination of instance types and ML frameworks. Examples of ML \nframeworks include TensorFlow, PyTorch, and Scikit-learn.\nImplementation plan\n\u2022Use Amazon SageMaker Experiments - Amazon SageMaker Experiments lets you organize, track, \ncompare, and evaluate your machine learning experiments. Using this service, you can experiment \nwith various ML frameworks and see which one gives you the most cost-e\ufb00ective performance. AWS \nDeep Learning  AMIs  and AWS Deep Learning Containers enable you to use several open-source ML \nframeworks for training on your infrastructure. AWS Deep Learning AMIs have popular deep learning \nframeworks and interfaces preinstalled including TensorFlow, PyTorch, Apache MXNet, Chainer, Gluon, \nHorovod, and Keras. The AMI or container can be launched on powerful infrastructure that has been \noptimized for ML performance. SageMaker also allows you to bring your own container where you can \nuse any framework you choose.\nDocuments\n\u2022Use Machine Learning Frameworks, Python, and R with Amazon SageMaker\nBlogs\n\u2022Right-sizing resources and avoiding unnecessary costs in Amazon SageMaker\n\u2022Amazon SageMaker Experiments \u2013 Organize, Track and Compare your Machine Learning Trainings\n75", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6651f453-a67d-44e0-9ec1-dd5c4ff68403": {"__data__": {"id_": "6651f453-a67d-44e0-9ec1-dd5c4ff68403", "embedding": null, "metadata": {"page_label": "76", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e8c1fa2e89a79520607e7fb351b2f2021bef752428594e8aa13e39e9805d7f5b", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nMLCOST-13: Use automated machine learning\nUse automated data analyzer systems when building a model. These systems experiment with and \nselect the best algorithm from the list of high-performing algorithms. They automatically test di\ufb00erent \nsolutions and parameter settings to achieve optimal models. The automated system speeds up the \nprocess, while eliminating manual experimentation and comparisons.\nImplementation plan\n\u2022Use Amazon SageMaker Autopilot - Amazon SageMaker Autopilot automates key tasks of an \nautomatic machine learning (AutoML) process. Autopilot explores your data, selects the algorithms \nrelevant to your problem type, and prepares the data to facilitate model training and tuning. Autopilot \napplies a cross-validation resampling procedure automatically to all candidate algorithms. It tests \nthe ability of these algorithms to predict using data they have not been trained on. It ranks all of the \noptimized models tested by their performance. Autopilot \ufb01nds the best performing model that you \ncan deploy at a fraction of the time normally required.\nBlogs\n\u2022Amazon SageMaker Autopilot \u2013 Automatically Create High-Quality Machine Learning Models with Full\nControl and Visibility\n\u2022Customizing and reusing models generated by Amazon SageMakerAutopilot\nVideos\n\u2022Automatically Build, Train, and Tune ML Models with Amazon SageMaker Autopilot\n\u2022Use Autopilot to automate and explore the machine learning process\nExamples\n\u2022Customer Churn Prediction with Amazon SageMaker Autopilot\n\u2022SageMaker Autopilot\nMLCOST-14: Use managed training capabilities\nMachine learning model training can be an iterative, compute intensive, and time-consuming process. \nInstead of using the notebook itself, which might be running on a small instance, consider o\ufb04oading the \ntraining to a managed cluster of compute resources including both CPUs and GPUs to train the model.\u00a0\nImplementation plan\n\u2022Use Amazon SageMaker managed training capabilities - Amazon SageMaker reduces the time and \ncost to train and tune ML models without the need to manage infrastructure. With SageMaker, easily \ntrain and tune ML models using built-in tools to manage and track training experiments, automatically \nchoose optimal hyperparameters, debug training jobs, and monitor the utilization of system resources \nsuch as GPUs, CPUs, and network bandwidth. SageMaker can automatically scale infrastructure up \nor down based on your training job requirements, from one GPU to thousands, or from terabytes \nto petabytes of storage.SageMaker also o\ufb00ers the highest-performing ML compute infrastructure \ncurrently available-including Amazon EC2 P4d instances, which can reduce ML training costs by up to \n60% compared with previous generations. And, since you pay only for what you use, you can manage \nyour training costs more e\ufb00ectively.\n\u2022Use the Amazon SageMaker Training Compiler - To train deep learning (DL) models faster, you can \nuse the Amazon SageMaker Training Compiler to accelerate the model training process by up to 50% \n76", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "f7e80580-7dfe-495e-a356-2a0567646136": {"__data__": {"id_": "f7e80580-7dfe-495e-a356-2a0567646136", "embedding": null, "metadata": {"page_label": "77", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "372cd00153e3e9a88eb0c0bc615cd374e27b9af2cbc9a1197fab4ad632e4aa1d", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nthrough graph- and kernel-level optimizations that make more e\ufb03cient use of GPUs. Moreover, you \ncan add either data parallelism or model parallelism to your training script with a few lines of code, \nand the SageMaker distributed training libraries will automatically split models and training datasets \nacross GPU instances to help you complete distributed training faster.\n\u2022Use Amazon SageMaker managed Spot training - Amazon SageMaker makes it easy to train machine \nlearning models using managed Amazon EC2 Spot Instances. Managed Spot training can optimize \nthe cost of training models up to 90% over On-demand Instances. SageMaker manages the Spot \ninterruptions on your behalf.\u00a0You can specify which training jobs use Spot Instances and a stopping \ncondition that speci\ufb01es how long SageMaker waits for a job to run using Spot Instances. Metrics and \nlogs generated during training runs are available in CloudWatch.\nDocuments\n\u2022Train a Model with Amazon SageMaker\n\u2022SageMaker Model Training\n\u2022Managed Spot Training in Amazon SageMaker\n\u2022Amazon SageMaker Training Compiler\nBlogs\n\u2022Amazon SageMaker Simpli\ufb01es Training Deep Learning Models with Billions of Parameters\n\u2022Choose the best data source for your Amazon SageMaker training job\n\u2022Managed Spot Training: Save Up to 90% On Your Amazon SageMaker Training Jobs\n\u2022Cinnamon AI saves 70% on ML model training costs with Amazon SageMaker Managed Spot Training\nExamples\n\u2022Optimizing and Scaling Machine Learning Training\nMLCOST-15: Use distributed training\nEnable distributed training for a faster training time, when an algorithm allows it. Use multiple instances \nin a training cluster. Use managed services to help ensure all training instances are automatically shut \ndown when training is completed.\nImplementation plan\n\u2022Use Amazon SageMaker Distributed training libraries - The distributed training libraries\u00a0 in Amazon \nSageMaker automatically split large deep learning models and training datasets across AWS GPU \ninstances in a fraction of the time it takes to do manually. SageMaker achieves these e\ufb03ciencies \nthrough two techniques: data parallelism and model parallelism. Model parallelism splits models too \nlarge to \ufb01t on a single GPU into smaller parts before distributing across multiple GPUs to train, and \ndata parallelism splits large datasets to train concurrently to improve training speed.\u00a0\nDocuments\n\u2022SageMaker's Distributed Data Parallel Library\n\u2022SageMaker's Distributed Model Parallel\n\u2022Distributed Training\n77", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6b2268ac-304a-4dab-8c65-10122666ec5f": {"__data__": {"id_": "6b2268ac-304a-4dab-8c65-10122666ec5f", "embedding": null, "metadata": {"page_label": "78", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b1082bd3f418f561efdff91e4587559772c7d3bdbb63d3c496a1d384d112f58b", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nBlogs\n\u2022New \u2013 Data Parallelism Library in Amazon SageMaker Simpli\ufb01es Training on Large Datasets\n\u2022How Latent Space used the Amazon SageMaker model parallelism library to push the frontiers of\nlarge-scale transformers\n\u2022The science behind Amazon SageMaker\u2019s distributed-training engines\n\u2022Amazon SageMaker XGBoost now o\ufb00ers fully distributed GPU training\nVideos\n\u2022AWS re:Invent 2020: Train billion-parameter models with model parallelism on Amazon SageMaker\n\u2022AWS re:Invent 2020: Fast training and near-linear scaling with Data Parallel in Amazon SageMaker\nExamples\n\u2022Distributed Training\n\u2022Distributed training using Amazon SageMaker Distributed Data Parallel library and debugging using\nAmazon SageMaker Debugger\n\u2022SageMaker developer guide on distributed training\nMLCOST-16: Stop resources when not in use\nStop resources that are not in use to reduce cost. For example, hosted Jupyter environments used to \nexplore small samples of data, can be stopped when not actively in use. Where practical, commit the \nwork, stop them, and restart when needed. The same approach can be used to stop the computing and \nthe data storage services.\nImplementation plan\n\u2022Use CloudWatch Billing Alarms - You can monitor your estimated AWS charges by using Amazon\nCloudWatch. When you enable the monitoring of estimated charges for your AWS account, the \nestimated charges are calculated and sent several times daily to CloudWatch as metric data. Use this \nfeature to receive noti\ufb01cations when your resource charge exceeds a threshold amount.\n\u2022Use SageMaker Lifecycle Con\ufb01guration - A lifecycle con\ufb01guration provides shell scripts that run when \nyou create the notebook instance or whenever you start one. When you create a notebook instance, \nyou can create a new lifecycle con\ufb01guration and its scripts or apply ones that you already have. Use a \nlifecycle con\ufb01guration script to access AWS services from your notebook. These scripts enable checking \nnotebook instance activities and shut them down if idle.\n\u2022Use Amazon SageMaker Studio auto shutdown- Amazon SageMaker Studio provides a uni\ufb01ed,\u00a0web-\nbased visual interface for performing all ML development steps, making data science teams more \nproductive. Idle SageMaker Studio notebooks can be detected and stopped using an auto-shutdown \nJupyterLab extension that can be installed manually or automatically . You can shut down individual \nresources, including notebooks, terminals, kernels, applications, and instances.\nDocuments\n\u2022Shut Down Resources\nBlogs\n\u2022Save costs by automatically shutting down idle resources within Amazon SageMakerStudio\n78", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9a381a7d-cd0c-4002-9bc1-56ca7977e728": {"__data__": {"id_": "9a381a7d-cd0c-4002-9bc1-56ca7977e728", "embedding": null, "metadata": {"page_label": "79", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "546d00041f64d02f6a1f56cd561f12e9f6a12acc6a6c0bf89477757d3c7e994f", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nExamples\n\u2022Sagemaker-studio-auto-shutdown-extension\nMLCOST-17: Start training with small datasets\nStart experimentation with smaller datasets on a small compute instance or local system. This approach \nallows you to iterate quickly at low cost. After the experimentation period, scale up to train with the full \ndataset available on a separate compute cluster. Choose the appropriate storage layer for training data \nbased on the performance requirements.\nImplementation plan\n\u2022Use SageMaker notebooks - Notebooks are a popular way to explore and experiment with data in \nsmall quantities. Iterating with a small sample of the dataset locally and then scaling to train on the \nfull dataset in a distributed manner is common in machine learning. Amazon SageMaker notebook \ninstances provide a hosted Jupyter environment that can be used to explore small samples of data. \u00a0 \nDocuments\n\u2022Use Amazon SageMaker Notebook Instances\n\u2022Customize a Notebook Instance Using a Lifecycle Con\ufb01guration Script\u00a0\nMLCOST-18: Use warm-start and checkpointing hyperparameter \ntuning\nWhere feasible, use warm start hyperparameter tuning. Warm start can consist of using a parent job \nfor a model trained previously or using transfer learning. Warm start of hyperparameter tuning jobs \neliminates the need to start a tuning job from scratch. Create a new hyperparameter tuning job that is \nbased on selected parent jobs or pre-trained models. Use checkpointing capabilities to restart a training \njob from the last saved checkpoint. Reuse previous trainings as prior knowledge, or use checkpointing to \naccelerate the tuning process and reduce the cost.\nImplementation plan\n\u2022Use warm-start hyperparameter tuning - Use warmstart to start a hyperparameter tuning job using \none or more previous tuning jobs as a starting point. The results of previous tuning jobs are used to \ninform which combinations of hyperparameters to search over in the new tuning job. Hyperparameter \ntuning uses Bayesian or random search to choose combinations of hyperparameter values from ranges \nthat you specify.\n\u2022Use checkpointing hyperparameter tuning - Use checkpoints in Amazon SageMaker to save the state \nof ML models during training. Checkpoints are snapshots of the model and can be con\ufb01gured by the \ncallback functions of ML frameworks. You can use the saved checkpoints to restart a training job from \nthe last saved checkpoint.\nBlogs\n\u2022Amazon SageMaker Automatic Model Tuning becomes more e\ufb03cient with warm start of\nhyperparameter tuning jobs\n\u2022Running multiple HPO jobs in parallel on Amazon SageMaker\n79", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "33e1d576-095b-4aab-b3bd-e26ef6f2e005": {"__data__": {"id_": "33e1d576-095b-4aab-b3bd-e26ef6f2e005", "embedding": null, "metadata": {"page_label": "80", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "4587860c28193f669c8667922ca5cf9dd968ad198016bf9a66bf4ab110f4b53e", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nVideos\n\u2022Tune Your ML Models to the Highest Accuracy with Amazon SageMakerAutomatic Model Tuning\nExamples\n\u2022Automatic Model Tuning : Warm Starting Tuning Jobs\nMLCOST-19: Use hyperparameter optimization technologies\nUse automatic hyperparameter tuning to run many training jobs and \ufb01nd the best version of your model. \nUse the algorithm and ranges of hyperparameters that you specify. Use appropriate hyperparameter \nranges, as well as metrics that are realistic and meet the business requirements.\nImplementation plan\n\u2022Use SageMaker automatic model tuning - SageMaker automatic model tuning, also known as \nhyperparameter tuning, \ufb01nds the optimal model by running many training jobs on your dataset. It uses \nthe algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter \nvalues that result in a model that performs the best, as measured by a metric that you choose. To \ncreate a new hyperparameter optimization (HPO) tuning job for one or more algorithms, you need to \nde\ufb01ne the settings for the tuning job. Create training job de\ufb01nitions for each algorithm being tuned, \nand con\ufb01gure the resources for the tuning job.\nDocuments\n\u2022Create a HPO tuning job\nBlogs\n\u2022Running multiple HPO jobs in parallel on SageMaker\nVideos\n\u2022Automatic model tuning with SageMaker\nExamples\n\u2022Large HPO polling examples\nMLCOST-20 - Setup budget and use resource tagging to track \ncosts\nIf you need visibility of your ML cost, set up budgets and consider tagging your notebook instances. \nExamples of tags include the name of the project, the business unit, and environment (such as \ndevelopment, testing, or production).\nTags are useful for cost optimization and can provide a clear visibility into where money is being spent.\n80", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d227d28d-17a2-4c4f-bdc9-e6a1912f6949": {"__data__": {"id_": "d227d28d-17a2-4c4f-bdc9-e6a1912f6949", "embedding": null, "metadata": {"page_label": "81", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b4879b01a1c5b8e168aaf22f4218bddc8833c6a78a77329c1d6df2aaf3fb573e", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nImplementation plan\n\u2022Use AWS Budgets to keep track of cost - AWS Budgets helps you track your Amazon SageMaker cost, \nincluding development, training, and hosting. You can also set alerts and get a noti\ufb01cation when \nyour cost or usage exceeds (or is forecasted to exceed) your budgeted amount. After you create your \nbudget, you can track the progress on the AWS Budgets console.\n\u2022Use AWS Cost Explorer - Visualize, understand, and manage your AWS costs and usage over time \nusing AWS Cost Explorer.\n\u2022Tagging the resources - Consider tagging your Amazon SageMaker notebook instances and the \nhosting endpoints. Cost allocation tags can help track and categorize your cost of ML. It can answer \nquestions such as \u201cCan I delete this resource to save cost?\u201d\nDocuments\n\u2022Managing your costs with AWS Budgets\n\u2022Using Cost Allocation Tags\n\u2022Tagging Best Practices\nBlogs\n\u2022Optimizing costs for machine learning with Amazon SageMaker\n\u2022Automate Cost Control using Service Catalog and AWS Budgets\nMLCOST-21: Enable data and compute proximity\nEnsure that the Region used for training and developing models is the same as the one used for data. \nThis approach helps minimize the time and cost of transferring data to the computation environment.\nImplementation plan\n\u2022Keep data and compute resources in close proximity - Amazon EC2 is hosted in multiple locations \nworld-wide. These locations are composed of Regions, Availability Zones, Local Zones, AWS Outposts, \nand Wavelength Zones. Each Region is a separate geographic area. If you are launching a compute \ncluster, you should launch the cluster in close proximity to your data to get the best performance. Say, \nyour Amazon S3 bucket is in the US West (Oregon) Region, you should launch your cluster in the US \nWest (Oregon) Region to avoid Cross-Region data transfer fees.\nDocuments\n\u2022Regions and Zones\nBlogs\n\u2022Overview of Data Transfer Costs for Common Architectures\nVideos\n\u2022AWS re:Invent 2018: Architecture Patterns for Multi-Region Active-Active Applications\n81", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "7cbe6933-cccb-4ffe-8a30-99e4adc30aa2": {"__data__": {"id_": "7cbe6933-cccb-4ffe-8a30-99e4adc30aa2", "embedding": null, "metadata": {"page_label": "82", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "fe30f324680ca0db469144fe42651f7cd1a16fe67deff0e1c1c04709b6075047", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nMLCOST-22: Select optimal algorithms\nIdentify the basic machine learning paradigm that addresses your ML problem type. Basic machine \nlearning paradigms include: supervised learning, unsupervised learning and reinforcement learning. \nIdentify the acceptable level of tradeo\ufb00 between explainability and success metrics per business \nrequirements. Run prototypes and experiments to explore high performing algorithms. Select \nthe optimal cost-e\ufb03cient algorithms that meet all the business requirements. Improved runtime \nperformance of a tuned algorithm within business requirements, is one step towards optimizing the cost \nof ML.\nImplementation plan\n\u2022Adopt optimal practices\n\u2022Start with simple algorithms, such as regression, and work towards more complex algorithms, such \nas deep learning, to compare the accuracy of the models. Optimize hyperparameters to determine \nwhich algorithm yields the best metrics for the business use case.\n\u2022When selecting the optimal algorithm, run trade-o\ufb00 analysis between data constraints, \ncomputational performance, and maintenance e\ufb00orts. For example, deep learning networks might \nproduce more accurate results, but require more data than tree-based methods. Deep learning \nmethods are also more di\ufb03cult to maintain.\n\u2022Use AWS services\n\u2022Use Amazon SageMaker with a suite of built-in algorithms to train and deploy machine learning \nmodels. AWS provides optimized versions of frameworks, such as TensorFlow, Chainer, Keras, and \nTheano. These frameworks include optimizations for high-performance training across Amazon EC2\ninstance families.\n\u2022Use Amazon SageMaker Experiments to keep track of the models during testing.\n\u2022Use Amazon SageMaker Autopilot to select algorithms automatically.\n\u2022Discover pre-trained ML models on AWS Marketplace - Pre-trained ML models are ready-to-use \nmodels that can be quickly deployed on Amazon SageMaker . By pre-training the models for you, \nsolutions in AWS Marketplace take care of the heavy lifting, helping your team deliver ML powered \nfeatures faster and at a lower cost.\nDocuments\n\u2022Choose an Algorithm\n\u2022Manage Machine Learning with Amazon SageMakerExperiments\n\u2022Automate model development with Amazon SageMakerAutopilot\nBlogs\n\u2022Optimizing costs for machine learning with Amazon SageMaker\n\u2022Amazon SageMaker Experiments \u2013 Organize, Track, and Compare Your Machine Learning Trainings\n\u2022Amazon SageMaker Autopilot \u2013 Automatically Create High-Quality Machine Learning Models with Full\nControl and Visibility\n\u2022Streamline modeling with Amazon SageMaker Studio and the Amazon Experiments SDK\nVideos\n\u2022Accelerate Machine Learning Projects with Hundreds of Algorithms and Models in AWS Marketplace\n\u2022Organize, Track, and Evaluate ML Training Runs with Amazon SageMaker Experiments\n82", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d52a7746-1f43-4e0b-b4fb-fc2cee85d4f6": {"__data__": {"id_": "d52a7746-1f43-4e0b-b4fb-fc2cee85d4f6", "embedding": null, "metadata": {"page_label": "83", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0e7735ea070dc097776a0f3e7fc126d6d4d341efee6bdf05c70848c45d3ac84e", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\nMLCOST-23: Enable debugging and logging\nEnsure that there are su\ufb03cient logs and metrics recorded to capture the runtime and resource \nconsumption. The collected logs and metrics can be analyzed to identify the areas for improvement. \nMonitor compute and data storage consumption. Instrument the machine learning code, and use \ndebugging tools to capture metrics at runtime.\nImplementation plan\n\u2022Use Amazon SageMaker Debugger - Amazon SageMaker Debugger captures the state of a training \njob at periodic intervals. It provides visibility into the ML training process by monitoring, recording, \nand analyzing data with the ability to perform interactive exploration of data captured during training. \nThe debugger has an alerting capability for errors detected during training. For example, it can \nautomatically detect and alert you to commonly occurring errors, such as gradient values getting too \nlarge or too small.\n\u2022Use Amazon CloudWatch -Logs generated during training by Amazon SageMaker are logged to\nAmazon CloudWatch Logs. Use an AWS KMS key to encrypt log data ingested by Amazon CloudWatch \nLogs.\nDocuments\n\u2022Logging and Monitoring\n\u2022Logging Amazon ML API Calls with AWS CloudTrail\n\u2022Amazon SageMaker Debugger - Setup and Use\nBlogs\n\u2022Build Your Own Log Analytics Solution on AWS\n\u2022Pro\ufb01le Your Machine Learning Training Jobs with Amazon SageMaker Debugger\n\u2022Amazon SageMaker Debugger \u2013 Debug Your Machine Learning Models\n\u2022ML Explainability with Amazon SageMaker Debugger\n\u2022The science behind SageMaker\u2019s cost-saving Debugger\nExamples\n\u2022Debugger example notebooks\nVideo\n\u2022Train ML models faster with better insights using Amazon SageMaker Debugger\n\u2022Debugging a Customer Churn Model Using SageMaker Debugger\nSustainability pillar \u2013 Best practices\nThe sustainability pillar focuses on environmental impacts, especially energy consumption and e\ufb03ciency, \nsince they are important levers for architects to inform direct action to reduce resource usage. This \nsection includes best practices to consider while developing models that includes training, tuning, and \nmodel performance evaluation.\nBest practices\n83", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1eba8467-e2b8-49b1-89f3-63f3e9e25d28": {"__data__": {"id_": "1eba8467-e2b8-49b1-89f3-63f3e9e25d28", "embedding": null, "metadata": {"page_label": "84", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "59d7dbc7beeb87ce4a587ab9636099b9460eec9ceca339569886beb792cddf84", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\n\u2022MLSUS-07: De\ufb01ne sustainable performance criteria (p. 84)\n\u2022MLSUS-08: Select energy-e\ufb03cient algorithms (p. 85)\n\u2022MLSUS-09: Archive or delete unnecessary training artifacts (p. 86)\n\u2022MLSUS-10:\u00a0Use e\ufb03cient model tuning methods (p. 86)\nRelated best practices\n\u2022Tradeo\ufb00 analysis on custom versus pre-trained models (MLCOST-04) - Consider whether the \nworkload needs to be developed as a custom model. Many workloads can use the managed AWS AI \nservices. Using these services means that you won\u2019t need the associated resources to collect, store, \nand process data and to prepare, train, tune, and deploy an ML model. If adopting a fully managed AI \nservice is not appropriate, evaluate if you can use pre-existing datasets, algorithms, or models. AWS \nMarketplace o\ufb00ers over 1,400 ML-related assets that customers can subscribe to. You can also \ufb01ne-\ntune an existing model  starting from a pre-trained model, like those available on Hugging Face or\nSageMaker JumpStart. Using pre-trained models from third parties can reduce the resources you need \nfor data preparation and model training.\n\u2022Enable debugging and logging (MLCOST-23) - A debugger like SageMaker Debugger can identify \ntraining problems like system bottlenecks, over\ufb01tting and saturated activation functions. It provides\nbuilt-in rules like LowGPUUtilization or Over\ufb01t\u00a0to monitor your workload and automatically stop a \ntraining job as soon as it detects an issue (such as bug, job failing to converge\u2026). SageMaker Debugger \nalso provides pro\ufb01ler capabilities to detect\u00a0under-utilization of system resources and help right-size \nyour environment. This helps avoid unnecessary carbon emissions.\n\u2022Select optimal computing instance size (MLCOST-09) - Use SageMaker Studio to switch instance \ntypes on the \ufb02y based on your needs (for example, use a low power type for exploratory data analysis, \nand then switch to GPU only to prototype some neural network code). Right size your training jobs \nwith Amazon CloudWatch metrics that monitor resources, such as CPU, GPU, memory, and disk \nutilization.\n\u2022Select local training for small scale experiments (MLCOST-11) and Start training with small \ndatasets  (MLCOST-17) - Experiment with smaller datasets in your development notebook. This \napproach allows you to iterate quickly with limited carbon emission.\n\u2022Stop resources when not in use (MLCOST-16) - When building your model, use lifecycle con\ufb01guration \nscripts  to automatically stop  idle SageMaker Notebook instances. If you are using SageMaker Studio, \ninstall the auto-shutdown Jupyter extension to detect and stop idle resources. Use the fully managed \ntraining process provided by SageMaker to automatically launch training instances and shut them \ndown as soon as the training job is complete. This minimizes idle compute resources and thus limits \nthe environmental impact of your training job.\u00a0\nMLSUS-07: De\ufb01ne sustainable performance criteria\nMake trade-o\ufb00s between your model\u2019s accuracy and its environmental impacts. When we focus only on \nthe model\u2019s accuracy, we \u201cignore the economic, environmental, or social cost of reaching the reported \naccuracy.\u201d Because the relationship between model accuracy and complexity is at best logarithmic, \ntraining a model longer or looking for better hyperparameters only leads to a small increase in \nperformance.\nImplementation plan\n\u2022Establish sustainable performance criteria - De\ufb01ne performance criteria that support your \nsustainability goals while meeting your business requirements, but not exceeding them.\n\u2022Make trade-o\ufb00s - Acceptable decreases in model performance can signi\ufb01cantly reduce sustainability \nimpacts of your models.\n\u2022Stop training early  - In Automatic Model Tuning, early stopping stops the training jobs that a \nhyperparameter tuning job launches early when they are not improving signi\ufb01cantly as measured by \n84", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9ae11ad0-3f51-4a06-96f0-84c71be7438b": {"__data__": {"id_": "9ae11ad0-3f51-4a06-96f0-84c71be7438b", "embedding": null, "metadata": {"page_label": "85", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8f99487f814619abf32ca8a7f5d03df7836baea18139fd6461cfaa8de4195162", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\nthe objective metric. Similarly, SageMaker Debugger provides rules to automatically stop a training job \nas soon as it detects an issue (such as bug, job failing to converge...).\nDocuments\n\u2022Automatic Model Tuning with SageMaker - Stop Training Jobs Early\n\u2022Amazon SageMaker Debugger - Built-in Rules: LossNotDecreasing\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 2, model development\n\u2022Amazon SageMaker Automatic Model Tuning now supports early stopping of training jobs\nMetrics\n\u2022Track the metrics related to the resources provisioned for your training jobs (InstanceCount, \nInstanceType, and VolumeSizeInGB)\n\u2022Measure the e\ufb03cient use of these resources (CPUUtilization, GPUUtilization, GPUMemoryUtilization, \nMemoryUtilization, and DiskUtilization) in the SageMaker Console, the CloudWatch Console or your\nSageMaker Debugger Pro\ufb01ling Report\nMLSUS-08: Select energy-e\ufb03cient algorithms\nTo minimize resource usage, replace algorithms with more e\ufb03cient versions that produce the same \nresult.\u00a0\nImplementation plan\n\u2022Begin with a simple algorithm to establish a baseline - Then test di\ufb00erent algorithms with increasing \ncomplexity to observe whether performance has improved. If so, compare the performance gain \nagainst the di\ufb00erence in resources required.\n\u2022Try to \ufb01nd simpli\ufb01ed versions of algorithms - This approach helps you use less resources to achieve a \nsimilar outcome. For example, DistilBERT , a distilled version of BERT , has 40% fewer parameters, runs \n60% faster, and preserves 97% of its performance.\n\u2022Compress models size without signi\ufb01cant loss of accuracy - Use pruning  to remove weights that \ndon\u2019t contribute much to the model. Use quantization  to represent numbers with the low-bit integers \nwithout incurring signi\ufb01cant loss in accuracy. These techniques speed up inference and save energy \nwith limited impact on accuracy.\n\u2022Employ Amazon SageMaker Neo - Optimize ML models for inference on SageMaker in the cloud and \nsupported devices at the edge.\nDocuments\n\u2022Explore alternatives for performance improvement\n\u2022DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\n\u2022Optimize model performance using Amazon SageMaker Neo\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 2, model development\n85", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "130b46b6-aa65-4a63-8411-c9e7a7fc381d": {"__data__": {"id_": "130b46b6-aa65-4a63-8411-c9e7a7fc381d", "embedding": null, "metadata": {"page_label": "86", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "dc53e9ce89c9f91ec2663fe433e9c023040ffb0c84234af50a2b1f79eaae70b5", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\n\u2022Pruning machine learning models with Amazon SageMaker Debugger and Amazon SageMaker \nExperiments\n\u2022Reduce ML inference costs on Amazon SageMaker with hardware and software acceleration\n\u2022Unlock near 3x performance gains with XGBoost and Amazon SageMaker Neo\nMetrics\n\u2022Track the metrics related to the resources provisioned for your training and inference jobs \n(InstanceCount, InstanceType, and VolumeSizeInGB) and the e\ufb03cient use of these resources\n(CPUUtilization, GPUUtilization, GPUMemoryUtilization, MemoryUtilization, and DiskUtilization) in the\nSageMaker Console, the CloudWatch Console or your SageMaker Debugger Pro\ufb01ling Report\nMLSUS-09: Archive or delete unnecessary training artifacts\nRemove training artifacts that are unused and no longer required to limit wasted resources.\u00a0Determine \nwhen you can archive training artifacts to more energy-e\ufb03cient storage or safely delete them.\u00a0\nImplementation plan\n\u2022Clean up unneeded training resources - Organize your ML experiments with SageMaker Experiments\nto clean up training resources you no longer need.\n\u2022Reduce the volume of logs you keep - By default, CloudWatch retains logs inde\ufb01nitely. By setting \nlimited retention time for your notebooks and training logs, you\u2019ll avoid the environmental impact of \nunnecessary log storage.\nDocuments\n\u2022Clean Up Amazon SageMaker Experiment Resources\n\u2022Change log data retention in CloudWatch Logs\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 2, model development\n\u2022Clean up Your Container Images with Amazon ECR Lifecycle Policies\nMetrics\n\u2022Measure and optimize the total size of your Amazon S3 buckets and storage class distribution, using\nAmazon S3 Storage Lens\n\u2022Measure and optimize the size your of CloudWatch log groups\nMLSUS-10:\u00a0Use e\ufb03cient model tuning methods\nImplement an e\ufb03cient strategy to optimize hyperparameter values to minimize the resources required \nto complete model training. Avoid a brute force strategy wherever possible, as it tests hyperparameter \nvalues without concern for the number of resources used.\u00a0\nImplementation plan\n\u2022Adopt sustainable tuning job strategy - Prefer Hyperband or Bayesian search over random search\n(and avoid grid search). Bayesian search makes intelligent guesses about the next set of parameters \n86", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d83f7beb-4a42-47d5-ab2b-23ffc6c4a76a": {"__data__": {"id_": "d83f7beb-4a42-47d5-ab2b-23ffc6c4a76a", "embedding": null, "metadata": {"page_label": "87", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c73e2678f6e4bbb7a2391472fa34dc7441d48f4a63143f427f017a9e3501bb6f", "text": "Machine Learning Lens AWS Well-Architected Framework\nDeployment lifecycle phase\nto pick based on the prior set of trials. It typically requires 10 times fewer jobs than random search, \nand thus 10 times less compute resources, to \ufb01nd the best hyperparameters. SageMaker Automatic \nModel Tuning now supports Hyperband, a new search strategy that can \ufb01nd the optimal set of \nhyperparameters up to three times faster than Bayesian search for large-scale models such as deep \nneural networks that address computer vision problems.\n\u2022Limit the maximum number of concurrent training jobs - Running hyperparameter tuning jobs \nconcurrently gets more work done quickly. However, with the Bayesian optimization strategy, a tuning \njob improves only through successive rounds of experiments. Typically, running one training job at a \ntime achieves the best results with the least amount of compute resources.\n\u2022Carefully choose the number of hyperparameters and their ranges - You get better results and use \nless compute resources by limiting your search to a few parameters and small ranges of values. If you \nknow that a hyperparameter is log-scaled, convert it to further improve the optimization.\nDocuments\n\u2022Perform Automatic Model Tuning with SageMaker\n\u2022Choosing the Best Number of Concurrent Training Jobs\n\u2022Choosing Hyperparameter Ranges\n\u2022Amazon SageMaker Automatic Model Tuning now provides up to 3x faster hyperparameter tuning with \nHyperband as a new search strategy\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 2, model development\n\u2022Amazon SageMaker automatic model tuning produces better models, faster\n\u2022Amazon SageMaker Automatic Model Tuning: Using Machine Learning for Machine Learning\n\u2022Amazon SageMaker Automatic Model Tuning now provides up to three times faster hyperparameter \ntuning with Hyperband\nMetrics\n\u2022Track the metrics related to the resources provisioned for your hyperparameter tuning jobs\n(InstanceCount, InstanceType, and VolumeSizeInGB)\n\u2022Measure the\u00a0e\ufb03cient use of these resources (CPUUtilization, GPUUtilization, GPUMemoryUtilization, \nMemoryUtilization, and DiskUtilization) in the SageMaker Console and the CloudWatch Console\nML lifecycle phase - Deployment\nAfter you have trained, tuned, and evaluated your model, you can deploy it into production and make \npredictions against this deployed model. Amazon SageMaker Studio can convert notebook code to \nproduction-ready jobs without the need to manage the underlying infrastructure. Be sure to use a \ngovernance process. Controlling deployments through automation combined with manual or automated \nquality gates ensures that changes can be e\ufb00ectively validated with dependent systems prior to \ndeployment to production.\u00a0\n87", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5da5a3ff-cae7-4f99-978f-7a4d19accc9f": {"__data__": {"id_": "5da5a3ff-cae7-4f99-978f-7a4d19accc9f", "embedding": null, "metadata": {"page_label": "88", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "6246e2a2cde6ffc33deb965361546a5503ba9c5a1c86ea3df20d6fb045042525", "text": "Machine Learning Lens AWS Well-Architected Framework\nDeployment lifecycle phase\nFigure 15 \u2013 Deployment architecture diagram\nFigure 15 illustrates the deployment phase of the ML lifecycle in production. An application sends \nrequest payloads to a production endpoint to make inference against the model. Model artifacts are \nfetched from the model registry, features are retrieved from the feature store, and the inference code \ncontainer is obtained from the container repository.\u00a0\nFigure 16: Deployment main components\nFigure 16 lists key components of production deployment including:\n\u2022Blue/green, canary, A/B, shadow deployment/testing - Deployment and testing strategies that \nreduce downtime and risks when releasing a new or updated version.\n\u2022The blue/green  deployment technique provides two identical production environments (initially\nblue  is the existing infrastructure and green  is an identical infrastructure for testing). Once testing is \ndone on the green  environment, live application tra\ufb03c is directed to it from the blue  environment. \nThen the roles of the blue/green environments are switched.\n\u2022With a canary deployment, a new release is deployed to a small group of users while other users \ncontinue to use the previous version. Once you\u2019re satis\ufb01ed with the new release, you can gradually \nroll it out to all users.\n\u2022A/B testing strategy enables deploying changes to a model. Direct a de\ufb01ned portion of tra\ufb03c to the \nnew model. Direct the remaining tra\ufb03c to the old model. A/B testing is similar to canary testing, but \nhas larger user groups and a longer time scale, typically days or even weeks.\n88", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2dc2cd71-fa56-4c3f-9135-21a638f598e5": {"__data__": {"id_": "2dc2cd71-fa56-4c3f-9135-21a638f598e5", "embedding": null, "metadata": {"page_label": "89", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c334e7a13398e9c1918c809670e3f7f99450aba55708bf90decce1fbf5090499", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\n\u2022With shadow deployment strategy, the new version is available alongside the old version. The input \ndata is run through both versions. The older version is used for servicing the production application \nand the new one is used for testing and analysis.\n\u2022Inference pipeline - Figure 17 shows the inference pipeline that automates capturing of the prepared \ndata, performing predictions and post-processing for real-time or batch inferences.\n\u2022Scheduler pipeline - Deployed model is representative of the latest data patterns. When con\ufb01gured \nas shown in Figure 17, re-training at intervals can minimize the risk of data and concept drifts. A \nscheduler can initiate a re-training at business de\ufb01ned intervals. Data preparation, CI/CD/CT, and \nfeature pipelines will also be active during this process.\nFigure 17: ML lifecycle with scheduler re-train, and batch/real-time inference pipelines\nBest practices\n\u2022Operational excellence pillar \u2013 Best practices (p. 89)\n\u2022Security pillar - Best practices\u00a0 (p. 91)\n\u2022Reliability pillar \u2013 Best practices (p. 92)\n\u2022Performance e\ufb03ciency pillar \u2013 Best practices (p. 94)\n\u2022Cost optimization pillar - Best practices\u00a0 (p. 96)\n\u2022Sustainability pillar - Best practices (p. 100)\nOperational excellence pillar \u2013 Best practices\nThe operational excellence pillar includes the ability to run and monitor systems to deliver business value \nand to continually improve supporting processes and procedures.\u00a0\nBest practices\n89", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3d09d64d-422c-486b-b216-e372123e038e": {"__data__": {"id_": "3d09d64d-422c-486b-b216-e372123e038e", "embedding": null, "metadata": {"page_label": "90", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "1b082db9d46dac523eb03a36323df76b8b12431e7a517b13a06974c14e5e1ce8", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\n\u2022MLOE-14: Establish deployment environment metrics (p. 90)\nMLOE-14: Establish deployment environment metrics\nMeasure machine learning operations metrics to determine the performance of a deployed environment. \nThese metrics include memory and CPU/GPU usage, disk utilization, ML endpoint invocations, and \nlatency.\nImplementation plan\n\u2022Record performance-related metrics - Use a monitoring and observability service to record \nperformance-related metrics. These metrics can include database transactions, slow queries, I/O \nlatency, HTTP request throughput, service latency, and other key data.\n\u2022Analyze metrics when events or incidents occur - Use monitoring dashboards and reports to \nunderstand and diagnose the impact of an event or incident. These views provide insight into what \nportions of the workload are not performing as expected.\n\u2022Establish key performance indicators (KPIs) to measure workload performance - Identify the KPIs \nthat indicate whether the workload is performing as intended. An API-based workload might use \noverall response latency as an indication of overall performance, while an e-commerce site might \nchoose to use the number of purchases as its KPI.\n\u2022Use monitoring to generate alarm-based noti\ufb01cations  - Monitor metrics for the de\ufb01ned KPIs and \ngenerate alarms automatically when the measurements are outside expected boundaries.\n\u2022Review metrics at regular intervals - As routine maintenance, or in response to events or incidents, \nreview what metrics are collected and identify the metrics that were key in addressing issues. Identify \nany additional metrics that would help to identify, address, or prevent issues.\n\u2022Monitor and alarm proactively - Use KPIs, combined with monitoring and alerting systems, to \nproactively address performance-related issues. Use alarms to initiate automated actions to remediate \nissues where possible. Escalate the alarm to those able to respond if an automated response is not \npossible. Use a system to predict expected KPI values, and generate alerts and automatically halt or \nroll back deployments if KPIs are outside of the expected values.\n\u2022Use Amazon CloudWatch - Use Amazon CloudWatch metrics for SageMaker endpoints to determine \nthe memory, CPU usage, and disk utilization. Set up CloudWatch Dashboards to visualize the \nenvironment metrics and establish CloudWatch alarms to initiate a noti\ufb01cation via Amazon SNS (Email, \nSMS, WebHook) to notify on events occurring in the runtime environment.\n\u2022Use Amazon EventBridge - Consider de\ufb01ning an automated work\ufb02ow using Amazon EventBridge to \nrespond automatically to events. These events can include training job status changes, endpoint status \nchanges, and increasing the compute environment capacity after it crosses a de\ufb01ned threshold (such \nas CPU or disk utilization).\n\u2022Use AWS Application Cost Pro\ufb01ler - Use AWS Application Cost Pro\ufb01ler to report the cost per tenant \n(model/user).\nDocuments\n\u2022DevOps and AWS\n\u2022Next Generation SageMaker Notebooks \u2013 Now with Built-in Data Preparation, Real-Time Collaboration, \nand Notebook Automation\nVideos\n\u2022DevOps at Amazon: A Look at Our Tools and Processes\n90", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "317b2801-0432-49fd-8d69-08d0614e520e": {"__data__": {"id_": "317b2801-0432-49fd-8d69-08d0614e520e", "embedding": null, "metadata": {"page_label": "91", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f993caa9c16a4078df8f536e7fb841a5a75571fb3f520766ba73a417df51caa8", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\u00a0\nSecurity pillar - Best practices\u00a0\nThe security pillar encompasses the ability to protect data, systems, and assets to take advantage of \ncloud technologies to improve your security.\u00a0\nBest practices\n\u2022MLSEC-11: Protect against adversarial and malicious activities (p. 91)\nMLSEC-11: Protect against adversarial and malicious activities\nAdd protection inside and outside of the deployed code to detect malicious inputs that might result \nin incorrect predictions. Automatically detect unauthorized changes by examining the inputs in detail. \nRepair and validate the inputs before they are added back to the pool.\nImplementation plan\n\u2022Evaluate the robustness of the algorithm - Evaluate your use case and determine bad predictions or \nclassi\ufb01cations. Use sensitivity analysis to evaluate the robustness of the algorithm against increasingly \nperturbed inputs to understand susceptibility to manipulated inputs.\n\u2022Build for robustness from the start - Select diverse features to improve the algorithm\u2019s ability to \nhandle outliers. Consider using models in an ensemble for increased diversity in decisions and for \nrobustness around decision points.\n\u2022Identify repeats - Detect similar repeated inputs to the model to indicate possible threats to the \ndecision boundaries using Amazon SageMaker Model Monitor to run a SageMaker processing job on a \nperiodic interval to analyze the inference data. This can take the form of model brute forcing, where \nthreats iterate only a limited set of variables to determine what in\ufb02uences decision points and derive \nfeature importance.\n\u2022Lineage tracking  - If retraining on untrusted or unvalidated inputs, make sure any model skew is \ntraced back to the data and pruned before retraining a replacement model.\n\u2022Use secure inference API endpoints - Host the model so that a consumer of the model can perform \ninference against it securely. Permit consumers using the API to de\ufb01ne the relationship, restrict access \nto the base model, and provide monitoring of model interactions.\nDocuments\n\u2022Deep ensembles\n\u2022Empirical demonstration of deterministic overcon\ufb01dence\n\u2022Making Machine Learning Robust Against Adversarial Inputs\nBlogs\n\u20227 ways to improve security of your machine learning work\ufb02ows\n\u2022Run ensemble ML models on Amazon SageMaker\nVideos\n\u2022Security and Privacy of Machine Learning\n91", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "7aa07549-71f3-4632-97b1-69ff90f5438e": {"__data__": {"id_": "7aa07549-71f3-4632-97b1-69ff90f5438e", "embedding": null, "metadata": {"page_label": "92", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "15d46779ace791a957a53ab21ae498329c486b56e407ad930eb6d0535ad1c16e", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nExamples\n\u2022Evasion Attacks against Banking Fraud Detection Systems\n\u2022Adversarial Robustness Libraries\n\u2022SecML: A library for Secure and Explainable Machine Learning\nReliability pillar \u2013 Best practices\nThe reliability pillar encompasses the ability of a workload to perform its intended function correctly and \nconsistently when it\u2019s expected to.\u00a0\nBest practices\n\u2022MLREL-10: Automate endpoint changes through a pipeline (p. 92)\n\u2022MLREL-11: Use an appropriate deployment and testing strategy (p. 93)\nMLREL-10: Automate endpoint changes through a pipeline\nManual change management is error prone, and incurs a high e\ufb00ort cost. Use automated pipelines (that \nintegrate with a change management tracking system) to deploy changes to your model endpoints. \nVersioned pipeline inputs and artifacts allow you to track the changes and automatically rollback after a \nfailed change.\nImplementation plan\n\u2022Use Amazon SageMaker Pipelines - Deploying changes through a pipeline is a safe engineering \nmethod that enables consistency. Amazon SageMaker Pipelines  is the purpose-built, easy-to-use \ncontinuous integration and continuous delivery (CI/CD) service which enables you to create, automate, \nand manage end-to-end ML work\ufb02ows at scale.\nDocuments\n\u2022SageMaker Pipelines Overview\n\u2022What is a SageMaker Project?\nBlogs\n\u2022Build a CI/CD pipeline for deploying custom machine learning models using AWS services\n\u2022Building, automating, managing, and scaling ML work\ufb02ows using Amazon SageMaker Pipelines\n\u2022Build Custom SageMaker Project Templates \u2013 Best Practices\nVideos\n\u2022AWS re:Invent 2021: Implementing MLOps practices with Amazon SageMaker\n\u2022AWS re:Invent 2020: How to create fully automated ML work\ufb02ows with Amazon SageMaker Pipelines\n\u2022AWS on Air 2020: AWS What\u2019s Next ft. Amazon SageMaker Pipelines\nExamples\n\u2022Comparing model metrics with SageMaker Pipelines and SageMaker Model Registry\n92", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8fe571b5-fec6-4300-ab5b-7771650c0ded": {"__data__": {"id_": "8fe571b5-fec6-4300-ab5b-7771650c0ded", "embedding": null, "metadata": {"page_label": "93", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "bf484385aa905be6c27cd627baf332913215d0a0e522af5a492b12521409fdd6", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nMLREL-11: Use an appropriate deployment and testing strategy\nRun a trade-o\ufb00 analysis across available and relevant deployment/testing strategies (such as blue/\ngreen,\u00a0canary, shadow, and A/B testing) and select the one that meets your business requirements.\u00a0\nImplement metrics that evaluate model performance to identify when a rollback or roll-forward is \nrequired. When architecting for rollback or roll-forward, evaluate the following for each model:\n\u2022Where is the model artifact stored?\n\u2022Are model artifacts versioned?\n\u2022What changes are included in each version?\n\u2022What version of the model is deployed for a deployed endpoint?\nImplementation plan\n\u2022Deployment/testing in Amazon SageMaker: SageMaker provides managed deployment strategies for \ntesting new versions of your models in production.\n\u2022See the explanation associated with Figure 16 for details of blue/green, canary, and A/B \ndeployment/testing.\n\u2022Blue/green deployments using Amazon SageMaker: Amazon SageMaker automatically uses a \nblue/green deployment to maximize the availability of your endpoints when updating a SageMaker \nreal-time endpoint. The various tra\ufb03c shifting modes in blue/green deployment give you more \ngranular control over shifting tra\ufb03c between the blue and green \ufb02eet. For more details, see Blue/\nGreen deployments in SageMaker.\n\u2022Canary deployment using Amazon SageMaker: The canary deployment option lets you shift one \nsmall portion of your tra\ufb03c (a canary) to the green \ufb02eet and monitor it for a baking period. If the \ncanary succeeds on the green \ufb02eet, the rest of the tra\ufb03c is shifted from the blue \ufb02eet to the green \n\ufb02eet before stopping the blue \ufb02eet.\nFor more information, review canary tra\ufb03c shifting in SageMaker.\n\u2022Linear deployment using Amazon SageMaker: Linear tra\ufb03c shifting allows you to gradually shift \ntra\ufb03c from your old \ufb02eet (blue \ufb02eet) to your new \ufb02eet (green \ufb02eet). With linear tra\ufb03c shifting, you \ncan shift tra\ufb03c in multiple steps, minimizing the chance of a disruption to your endpoint. This blue/\ngreen deployment option gives you the most granular control over tra\ufb03c shifting.\n\u2022A/B testing using Amazon SageMaker: Performing A/B testing between a new model and an old \nmodel with production tra\ufb03c can be an e\ufb00ective \ufb01nal step in the validation process for a new model. \nIn A/B testing, you test di\ufb00erent variants of your models and compare how each variant performs. \nIf the newer version of the model delivers better performance than the previously-existing version, \nreplace the old version of the model with the new version in production. For more details, review test \nmodels in production in the SageMaker documentation.\nDocuments\n\u2022Deployment guardrails: a set of model deployment options in Amazon SageMaker Inference to update \nyour machine learning models in production\n\u2022Blue/Green deployments in Amazon SageMaker\n\u2022Blue/Green Deployment on AWS\n\u2022Perform a canary-based deployment using the blue/green strategy and AWS Lambda\n\u2022Amazon SageMaker \u2013 Testing models in production \u2013 Model A/B test example\n93", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b811f86e-f1d7-4a43-9cbf-1e15507b38ba": {"__data__": {"id_": "b811f86e-f1d7-4a43-9cbf-1e15507b38ba", "embedding": null, "metadata": {"page_label": "94", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5daf9d18d86c1b7eed8da102149b0dfee65a6dcf2b83006675562403a6a5601c", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nBlogs\n\u2022Take advantage of advanced deployment strategies using Amazon SageMaker deployment guardrails\n\u2022A/B Testing ML models in production using Amazon SageMaker\n\u2022Dynamic A/B testing for machine learning models with Amazon SageMaker MLOps projects\n\u2022Deploy shadow ML models in Amazon SageMaker\n\u2022Safely deploying and monitoring Amazon SageMaker endpoints with AWS CodePipeline and AWS \nCodeDeploy\nVideos\n\u2022AWS re:Invent 2020: Canaries in the code mines: Monitoring deployment pipelines\nExamples\n\u2022Amazon SageMaker Inference Deployment Guardrails\n\u2022Amazon SageMaker A/B Testing Pipeline\n\u2022Amazon SageMaker Safe Deployment Pipeline\n\u2022ML Model Shadow Deployment Strategy on AWS\nPerformance e\ufb03ciency pillar \u2013 Best practices\nThe performance e\ufb03ciency pillar focuses on the e\ufb03cient use of computing resources to meet \nrequirements and the maintenance of that e\ufb03ciency as demand changes and technologies evolve.\u00a0\nBest practices\n\u2022MLPER-11: Evaluate cloud versus edge options for machine learning deployment (p. 94)\n\u2022MLPER-12: Choose an optimal deployment option in the cloud (p. 95)\nMLPER-11: Evaluate cloud versus edge options for machine \nlearning deployment\nEvaluate if machine learning applications require near-instantaneous inference results or require \ninference without network connectivity. O\ufb00ering the lowest latency possible might require the removal \nof costly roundtrips to the nearest API endpoints. A reduction in latency can be achieved by running \nthe inference directly on the device itself (on the edge ). A common use-case for such a requirement is \npredictive maintenance in factories.\nImplementation plan\n\u2022Optimize model deployment on the edge - Training and optimizing machine learning models require \nmassive computing resources, so it is a natural \ufb01t for the cloud. Inference takes a lot less computing \npower and is often done in real time when new data is available. When getting inference results with \nvery low latency, con\ufb01rm that your IoT applications can respond quickly to local events. Evaluate and \nchoose the option to meet your business requirements.\n\u2022Amazon SageMaker Edge enables machine learning on edge devices by optimizing, securing, \nand deploying models to the edge, and then monitoring these models on your \ufb02eet of devices, \nsuch as smart cameras, robots, and other smart-electronics, to reduce ongoing operational costs. \nCustomers who train models in TensorFlow, MXNet, PyTorch, XGBoost, and TensorFlow Lite can \nuse SageMaker Edge to improve their performance, deploy them on edge devices, and monitor \n94", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "85d31fb6-cab4-46a9-8d4b-1ca801e25e6d": {"__data__": {"id_": "85d31fb6-cab4-46a9-8d4b-1ca801e25e6d", "embedding": null, "metadata": {"page_label": "95", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a2b74b10ce960a93edd22beeeb78333123f5fa8cfa9688fbb9bd78395acd3f7b", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\ntheir health throughout their lifecycle. SageMaker Edge Compiler optimizes the trained model to \nbe run on an edge device. SageMaker Edge Agent allows you to run multiple models on the same \ndevice. The Agent collects prediction data based on the logic that you control, such as intervals, and \nuploads it to the cloud so that you can periodically retrain your models over time. SageMaker Edge \ncryptographically signs your models so you can verify that they were not tampered with as they \nmove from the cloud to edge devices.\n\u2022Amazon SageMaker Neo enables ML models to be trained once and then run anywhere in the cloud \nand at the edge. SageMaker Neo consists of a compiler and a runtime. The compilation API reads \nmodels exported from various frameworks, converts them into framework-agnostic representations, \nand generates optimized binary code (to run faster with no loss in accuracy). The compiler uses a \nmachine learning model to apply the performance optimizations that extract the best available \nperformance for your model on the cloud instance or edge device. The runtime for each target \nplatform then loads and runs the compiled model.\u00a0\n\u2022SageMaker Neo optimizes machine learning models for inference on cloud instances and edge \ndevices. SageMaker Neo optimizes the trained model and compiles it into an executable. You \nthen deploy the model as a SageMaker endpoint or on supported edge devices and start making \npredictions.\u00a0\n\u2022AWS IoT Greengrass enables ML inferences on edge devices using models trained in the cloud. These \nmodels can be built using Amazon SageMaker, AWS Deep Learning AMI, or AWS Deep Learning \nContainers . These models can be stored in Amazon S3 before being deployed on edge devices.\nDocuments\n\u2022AWS IoT Greengrass ML Inference\n\u2022Amazon SageMaker Edge Manager\n\u2022Getting Started with Neo on Edge Devices\nBlogs\n\u2022Machine Learning at the Edge: Using and Retraining Image Classi\ufb01cation Models with AWS IoT \nGreengrass\n\u2022Monitor and Manage Anomaly Detection Models on a \ufb02eet of Wind Turbines with Amazon SageMaker \nEdge Manager\n\u2022SageMaker Edge Manager Simpli\ufb01es Operating Machine Learning Models on Edge Devices\n\u2022Amazon SageMaker Neo Helps Detect Objects and Classify Images on Edge Devices\n\u2022Machine Learning at the Edge with AWS Outposts and Amazon SageMaker\nVideos\n\u2022Machine Learning at the Edge\n\u2022Getting Started Using Machine Learning at the Edge\n\u2022Train ML Models Once, Run Anywhere in the Cloud & at the Edge with Amazon SageMaker Neo\nMLPER-12: Choose an optimal deployment option in the cloud\nIf models are suitable for cloud deployment, you should determine how to deploy them for best \nperformance e\ufb03ciency according to frequency, latency, and runtime requirements in your use cases.\n95", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ba9c7bd7-49d9-4cac-bc94-1dd6df5ee730": {"__data__": {"id_": "ba9c7bd7-49d9-4cac-bc94-1dd6df5ee730", "embedding": null, "metadata": {"page_label": "96", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "752cc6144c8d14e15b86c94db7eb2cabd96667e79cd264e471146649cfb3dfbf", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\u00a0\nImplementation plan\n\u2022Amazon SageMaker Real-time Inference - Use if you need a persistent endpoint for\u00a0near-\ninstantaneous response from the ML model for requests that can come in any time. You can host \nthe models behind an HTTPS endpoint to be integrated with your applications. SageMaker real-time \nendpoints are fully managed and support autoscaling.\n\u2022Amazon SageMaker Serverless Inference - Use if you receive spiky inference requests that vary \nsubstantially in rate and volume. This is a purpose-built inference option that makes it easy to deploy \nand scale ML models without managing any servers. Serverless Inference is ideal for workloads which \nhave idle periods between tra\ufb03c spurts and can tolerate cold starts.\u00a0\n\u2022Amazon SageMaker Asynchronous Inference - Use if you have model requests with large payload \nsizes (up to 1GB), long processing times (up to 15 minutes), and near-instantaneous latency \nrequirements, SageMaker Asynchronous Inference is ideal as it has larger payload limit and longer \ntime-out limit compared to SageMaker Real-time inference. SageMaker Asynchronous Inference \nqueues incoming requests and processes them asynchronously with an internal queueing system.\n\u2022Amazon SageMaker Batch Transform - Use if you do not need near-instantaneous response from \nthe ML model and can gather data points together into a large batch for a schedule-based inference. \nWhen a batch transform job starts, SageMaker initializes compute instances and distributes the \ninference or preprocessing workload among them. SageMaker Batch Transform automatically splits \ninput \ufb01les into mini-batches (so that you won\u2019t need to worry about out-of-memory (OOM) for large \ndatasets) and shuts down compute instances once the entire dataset is processed.\u00a0\nDocuments\n\u2022Amazon SageMaker Real-time Inference\n\u2022Amazon SageMaker Serverless Inference\n\u2022Amazon SageMaker\u00a0Asynchronous Inference\n\u2022Amazon SageMaker Batch Transform\nBlogs\n\u2022Announcing managed inference for Hugging Face models in Amazon SageMaker\n\u2022Performing batch inference with TensorFlow Serving in Amazon SageMaker\n\u2022Deploying ML models using SageMaker Serverless Inference\n\u2022Run computer vision inference on large videos with Amazon SageMaker asynchronous endpoints\nVideos\n\u2022AWS re:Invent 2021 - Achieve high performance and cost-e\ufb00ective model deployment\n\u2022AWS re:Invent 2021 - Amazon SageMaker serverless inference\nExamples\n\u2022Deploy models with Amazon SageMaker\nCost optimization pillar - Best practices\u00a0\nThe cost optimization pillar includes the continual process of re\ufb01nement and improvement of a system \nover its entire lifecycle. From the initial design of your very \ufb01rst proof of concept to the ongoing \noperation of production workloads, adopting the practices in this document can enable you to build \n96", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "54f226c7-5dbc-4765-89f6-4db23d066799": {"__data__": {"id_": "54f226c7-5dbc-4765-89f6-4db23d066799", "embedding": null, "metadata": {"page_label": "97", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e7910cefe09eb0b36f2c4f0690f8274d5231c838cc75f1252379f9008b122a64", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\u00a0\nand operate cost-aware systems that achieve business outcomes and minimize costs, thus allowing your \nbusiness to maximize its return on investment (ROI).\u00a0\nBest practices\n\u2022MLCOST-24: Use appropriate deployment option (p. 97)\n\u2022MLCOST-25: Explore cost e\ufb00ective hardware options (p. 98)\n\u2022MLCOST-26: Right-size the model hosting instance \ufb02eet (p. 99)\nMLCOST-24: Use appropriate deployment option\nUse real-time inference for low latency and ultra-high throughput for use cases with steady tra\ufb03c \npatterns. Use batch transform for o\ufb04ine inference on data batches for use cases with large datasets. \nDeploy models at edge to optimize, secure, monitor, and maintain machine learning models on \ufb02eets of \nedge devices such as smart cameras, robots, personal computers, and mobile devices.\nImplementation plan\n\u2022Use Amazon SageMaker - Amazon SageMaker has a broad selection of ML infrastructure and model \ndeployment options to make it easy to deploy ML models at the best price-performance for any \nuse case. It is a fully managed service and integrates with MLOps tools, so you can scale your model \ndeployment, reduce inference costs, manage models more e\ufb00ectively in production, and reduce \noperational burden.\u00a0\n\u2022Use Amazon SageMaker Real-time Inference, Amazon SageMaker Serverless Inference, Amazon \nSageMaker Asynchronous Inference, and Amazon SageMaker Batch Transform - See \u201cMLPER-11: \nEvaluate cloud versus edge options for machine learning deployment\u201c.\n\u2022Use Amazon SageMaker Multi-Model endpoints - Multi-model endpoints provide a scalable and \ncost-e\ufb00ective solution to deploying large numbers of models. They use a shared serving container \nthat is enabled to host multiple models. This approach reduces hosting costs by improving endpoint \nutilization compared with using single-model endpoints. It also reduces deployment overhead \nbecause Amazon SageMaker manages loading models in memory and scaling them based on the \ntra\ufb03c patterns to them.\n\u2022Use Amazon SageMaker multi-container endpoints - SageMaker multi-container endpoints enable \nyou to deploy multiple containers that use di\ufb00erent models or frameworks on a single SageMaker \nendpoint. The containers can be run in a sequence as an inference pipeline, or each container can be \naccessed individually by using direct invocation to improve endpoint utilization and optimize costs.\n\u2022Use Amazon SageMaker Pipelines - See \u201cMLREL-10: Automate endpoint changes through a \npipeline\u201c.\n\u2022Use Amazon SageMaker Edge - See \u201cOptimize model deployment on the edge\u201d under \u201cMLPER-10: \nEvaluate machine learning deployment option (cloud versus edge)\u201d.\u00a0\nDocuments\n\u2022Deploy models for inference\n\u2022SageMaker hosting options\n\u2022SageMaker Serverless Inference\n\u2022SageMaker Asynchronous Inference\n\u2022SageMaker Batch Transform\n\u2022Deploy models at the edge with SageMaker Edge Manager\n97", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "933798c2-3223-4f20-98fa-d279b2246401": {"__data__": {"id_": "933798c2-3223-4f20-98fa-d279b2246401", "embedding": null, "metadata": {"page_label": "98", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "80330171d6ee35a3139402e7ed1640f12f40cea378ef016827b4a7110973ca45", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\u00a0\nBlogs\n\u2022Using Amazon SageMaker inference pipelines with multi-model endpoints\n\u2022Save on inference costs by using Amazon SageMaker multi-model endpoints\n\u2022Deploy multiple serving containers on a single instance using Amazon SageMaker multi-container \nendpoints\n\u2022Run computer vision inference on large videos with Amazon SageMaker asynchronous endpoints\n\u2022Batch Inference at Scale with Amazon SageMaker\n\u2022Amazon SageMaker Edge Manager Simpli\ufb01es Operating Machine Learning Models on Edge Devices\nExamples\n\u2022SageMaker Serverless Inference Walkthrough\n\u2022SageMaker Edge Manager Workshop\nMLCOST-25: Explore cost e\ufb00ective hardware options\nMachine learning models that power AI applications are becoming increasingly complex resulting in \nrising underlying compute infrastructure costs. Up to 90% of the infrastructure spend for developing \nand running ML applications is often on inference. Look for cost-e\ufb00ective infrastructure solutions for \ndeploying their ML applications in production.\nImplementation plan\n\u2022Use Amazon SageMaker Neo - Please see details of Amazon SageMaker Neo under \u201cMLPER-10: \nEvaluate machine learning deployment option (cloud versus edge)\u201d. For inference in the cloud, \nSageMaker Neo speeds up inference and saves cost by creating an inference optimized container in \nSageMaker hosting. For inference at the edge, SageMaker Neo saves developers months of manual \ntuning by automatically tuning the model for the selected operating system and processor hardware.\n\u2022Use Amazon SageMaker Elastic Inference - Amazon Elastic Inference (EI) is a service that lets you \nattach just the right amount of GPU-powered inference acceleration to any EC2 instance. By using \nAmazon EI, you can speed up the throughput and decrease the latency of getting real-time inferences \nfrom your deep learning models that are deployed as Amazon SageMaker hosted models, but at a \nfraction of the cost of using a GPU instance for your endpoint. Add an Amazon EI accelerator in one of \nthe available sizes to a deployable model in addition to a CPU instance type, and then add that model \nas a production variant to an endpoint con\ufb01guration that you use to deploy a hosted endpoint. You \ncan also add an Amazon EI accelerator to a SageMaker notebook instance so that you can test and \nevaluate inference performance when you are building your models.\n\u2022Use Amazon EC2 Inf1 Instances - Amazon EC2 Inf1 instances deliver high-performance ML inference \nat the lowest cost in the cloud. They deliver up to 2.3-times higher throughput and up to 70% lower \ncost per inference than comparable current generation GPU-based Amazon EC2 instances. Inf1 \ninstances are built from the ground up to support machine learning inference applications. They \nfeature up to 16 AWS Inferentia chips, high-performance machine learning inference chips designed \nand built by AWS. Additionally, Inf1 instances include second generation Intel Xeon Scalable processors \nand up to 100 Gbps networking to deliver high throughput inference.\nDocuments\n\u2022Use Amazon SageMaker Elastic Inference\n\u2022What Is Amazon Elastic Inference?\n\u2022Optimize model performance using Neo\n\u2022Amazon EC2 Inf1 Instances\n98", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "420e00f4-cafc-4887-9b71-16ca52ca11a2": {"__data__": {"id_": "420e00f4-cafc-4887-9b71-16ca52ca11a2", "embedding": null, "metadata": {"page_label": "99", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "fdcc2f8a484fadf34a07114686dd215ea4218de2589bfcff0eb445ebc14aa0a4", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\u00a0\nBlogs\n\u2022Increasing performance and reducing the cost of MXNet inference using Amazon SageMaker Neo and \nAmazon Elastic Inference\n\u2022Reduce ML inference costs on Amazon SageMaker with hardware and software acceleration\n\u2022Announcing availability of Inf1 instances in Amazon SageMaker for high performance and cost-\ne\ufb00ective machine learning inference\nExamples\n\u2022Increasing performance and reducing cost of deep learning inference using Amazon SageMaker Neo \nand Amazon Elastic Inference\nMLCOST-26: Right-size the model hosting instance \ufb02eet\nUse e\ufb03cient compute resources to run models in production. In many cases, up to 90% of the \ninfrastructure spend for developing and running an ML application is on inference, making it critical \nto use high-performance, cost-e\ufb00ective ML inference infrastructure. Selecting the right way to host \nand the right type of instance can have a large impact on the total cost of ML projects. Use automatic \nscaling (autoscaling) for your hosted models. Auto scaling  dynamically adjusts the number of instances \nprovisioned for a model in response to changes in your workload.\u00a0\nImplementation plan\n\u2022Use Amazon SageMaker Inference Recommender - Amazon SageMaker Inference Recommender \nautomatically selects the right compute instance type, instance count, container parameters, \nand model optimizations for inference to maximize performance and minimize cost. You can use \nSageMaker Inference Recommender from SageMaker Studio, the AWS Command Line Interface (AWS \nCLI), or the AWS SDK, and within minutes, get recommendations to deploy your ML model. You can \nthen deploy your model to one of the recommended instances or run a fully managed load test on a \nset of instance types you choose without worrying about testing infrastructure. You can review the \nresults of the load test in SageMaker Studio and evaluate the tradeo\ufb00s between latency, throughput, \nand cost to select the most optimal deployment con\ufb01guration.\n\u2022Use AutoScaling with Amazon SageMaker - Amazon SageMaker supports an Autoscaling feature that \nmonitors your workloads and dynamically adjusts the capacity to maintain steady and predictable \nperformance at the lowest possible cost. When the workload increases, autoscaling brings more \ninstances online. When the workload decreases, autoscaling removes unnecessary instances, helping \nyou reduce your compute cost. SageMaker automatically attempts to distribute your instances across \nAvailability Zones. So, we strongly recommend that you deploy multiple instances for each production \nendpoint for high availability. If you\u2019re using a VPC, con\ufb01gure at least two subnets in di\ufb00erent \nAvailability Zones so Amazon SageMaker can distribute your instances across those Availability Zones.\nDocuments\n\u2022Automatically Scale Amazon SageMaker Models\n\u2022Amazon SageMaker Inference Recommender\nBlogs\n\u2022Ensure e\ufb03cient compute resources on Amazon SageMaker\n\u2022Con\ufb01guring autoscaling inference endpoints in Amazon SageMaker\n\u2022Announcing Amazon SageMaker Inference Recommender\n99", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "7a6d51bf-e565-40bc-bde9-bb5a9e297c9d": {"__data__": {"id_": "7a6d51bf-e565-40bc-bde9-bb5a9e297c9d", "embedding": null, "metadata": {"page_label": "100", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f7d10fce4203cface5dee82e6c5bd3ebad53fa22e2c18bad7e7e8d45417c89ac", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\nExamples\n\u2022Right-sizing your Amazon SageMaker Endpoints\n\u2022Automatically Scale Amazon SageMaker Models\n\u2022SageMaker Inference Recommender\nSustainability pillar - Best practices\nThe sustainability pillar focuses on environmental impacts, especially energy consumption and e\ufb03ciency, \nsince they are important levers for architects to inform direct action to reduce resource usage.\u00a0\nBest practices\n\u2022MLSUS-11: Align SLAs with sustainability goals (p. 100)\n\u2022MLSUS-12: Use e\ufb03cient silicon (p. 101)\n\u2022MLSUS-13: Optimize models for inference (p. 102)\n\u2022MLSUS-14: Deploy multiple models behind a single endpoint (p. 102)\nRelated best practices\n\u2022Allow automatic scaling of the model endpoint (MLREL-11) - Con\ufb01gure automatic scaling  for \nAmazon SageMaker Endpoints or use Serverless Inference and make e\ufb03cient use of GPU with Amazon \nElastic Inference. Elastic Inference allows you to attach just the right amount of GPU-powered \ninference acceleration to any EC2 or SageMaker instance type or ECS task. While training jobs process \nhundreds of data samples in parallel, inference jobs usually process a single input in real time, and \nthus consume a small amount of GPU compute. Amazon Elastic Inference allows you to reduce the cost \nand environmental impact of your inference by using GPU resources more e\ufb03ciently.\n\u2022Evaluate machine learning deployment option (cloud versus edge) (MLPER-11 ) - When working \non IoT use-cases, evaluate if running ML inference at the edge can reduce the environmental impact \nof your workload. For that, consider factors like the compute capacity of your devices, their energy \nconsumption or the emissions related to data transfer to the Cloud. When deploying ML models to \nedge devices, consider using Amazon SageMaker Edge Manager which integrates with SageMaker Neo \nand AWS IoT GreenGrass.\n\u2022Select optimal computing instance size (MLCOST-09) - Amazon SageMaker Inference Recommender\nautomates load testing and model tuning across SageMaker ML instances. It helps you select the \nbest instance type and con\ufb01guration (such as instance count, container parameters, and model \noptimizations) to ensure the maximum e\ufb03ciency of the resources provisioned for inference.\nMLSUS-11: Align SLAs with sustainability goals\nDe\ufb01ne service level agreements (SLAs) that support your sustainability goals while meeting your \nbusiness requirements. De\ufb01ne SLAs to meet your business requirements, not exceed them. Make trade-\no\ufb00s that signi\ufb01cantly reduce environmental impacts in exchange for acceptable decreases in service \nlevels.\nImplementation plan\n\u2022Queue incoming requests and process them asynchronously - If your users can tolerate some \nlatency, deploy your model on serverless or asynchronous endpoints to reduce resources that are idle \nbetween tasks and minimize the impact of load spikes. These options will automatically scale the \ninstance or endpoint count to zero when there are no requests to process, so you only maintain an \ninference infrastructure when your endpoint is processing requests.\n100", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "16261675-b0bc-4666-abbe-6a265963e1a0": {"__data__": {"id_": "16261675-b0bc-4666-abbe-6a265963e1a0", "embedding": null, "metadata": {"page_label": "101", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "092b245897649867133cdadc8d62217a9b306cc7adbe48cfbacd285aa7b3f200", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\n\u2022Adjust availability - If your users can tolerate some latency in the rare case of a failover, don't \nprovision extra capacity. If an outage occurs or an instance fails, Amazon SageMaker automatically \nattempts to distribute your instances across Availability Zones. Adjusting availability is an example of a\nconscious trade o\ufb00 you can make to meet your sustainability targets.\n\u2022Adjust response time  - When you don't need real-time inference, use SageMaker Batch Transform. \nUnlike a persistent endpoint, clusters are decommissioned when batch transform jobs \ufb01nish so you \ndon't continuously maintain an inference infrastructure.\nDocuments\n\u2022Amazon SageMaker Asynchronous inference\n\u2022Amazon SageMaker Batch Transform\n\u2022Optimize software and architecture for asynchronous and scheduled jobs\n\u2022Best practices for deploying models on SageMaker Hosting Services\n\u2022Align SLAs with sustainability goals\n\u2022Sustainability as a non-functional requirement\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 3, deployment and monitoring\nVideos\n\u2022AWS re:Invent 2021 - Architecting for sustainability - Optimize capacity for Sustainability\nMLSUS-12: Use e\ufb03cient silicon\nUse the most e\ufb03cient instance type compatible with your ML workload.\nImplementation plan\nAWS o\ufb00ers several purpose-built compute architectures that are optimized to minimize the\u00a0sustainability \nimpact of ML workloads:\n\u2022For CPU-based ML inference, use AWS Graviton3 - These processors o\ufb00er the best performance \nper watt in Amazon EC2. They use up to 60% less energy than comparable EC2 instances. Graviton3\nprocessors deliver up to three times better performance compared to Graviton2 processors for ML \nworkloads, and they support b\ufb02oat16.\n\u2022For deep learning inference, use AWS Inferentia - The Amazon EC2 Inf2 instances o\ufb00er up to 50% \nbetter performance/watt over comparable Amazon EC2 instances because they and the underlying\nInferentia2 accelerators are purpose built to run DL models at scale. Inf2 instances help you meet your \nsustainability goals when deploying ultra-large models.\n\u2022For training, use AWS Trainium - The Amazon EC2 trn1 instances based on the custom designed AWS \nTrainium chips o\ufb00er up to 50% cost-to-train savings over comparable Amazon EC2 instances. When \nusing a Trainium-based instance cluster, the total energy consumption for training BERT Large from \nscratch is approximately 25% lower compared to a same-sized cluster of comparable accelerated EC2 \ninstances.\nDocuments\n\u2022Instances with AWS Inferentia\n101", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5d18ca32-71b8-4ddd-b8ee-eba02b78ccda": {"__data__": {"id_": "5d18ca32-71b8-4ddd-b8ee-eba02b78ccda", "embedding": null, "metadata": {"page_label": "102", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e23f232441a2168e3ffb6b4aa0dba413341d7b9fa95e023baad6b2e45ce29b4b", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\n\u2022Use instance types with the least impact\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 3, deployment and monitoring\n\u2022Achieving 1.85x higher performance for deep learning based object detection with an AWS Neuron \ncompiled YOLOv4 model on AWS Inferentia\n\u2022Deploying TensorFlow OpenPose on AWS Inferentia-based Inf1 instances for signi\ufb01cant price \nperformance improvements\n\u2022Amazon EC2 Update \u2013 Inf1 Instances with AWS Inferentia Chips for High Performance Cost-E\ufb00ective \nInferencing\nMLSUS-13: Optimize models for inference\nImprove e\ufb03ciency of your models and thus use less resources for inference by compiling the models into \noptimized forms.\u00a0\nImplementation plan\n\u2022Use open-source model compilers - Libraries such as Treelite (for decision tree ensembles) improve \nthe prediction throughput of models, due to more e\ufb03cient use of compute resources.\n\u2022Use third-party tools - Solutions like Hugging Face In\ufb01nity allow you to accelerate transformer \nmodels and run inference not only on GPUs but also on CPUs.\n\u2022Use\u00a0Amazon SageMaker Neo - SageMaker Neo enables developers to optimize ML models for \ninference on SageMaker in the cloud and supported devices at the edge. SageMaker Neo runtime \nconsumes as little as one-tenth the footprint of a deep learning framework while optimizing models to \nperform up to 25 times faster with no loss in accuracy.\nDocuments\n\u2022Optimize model performance using Neo\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 3, deployment and monitoring\n\u2022Unlock near 3x performance gains with XGBoost and Amazon SageMaker Neo\nMLSUS-14: Deploy multiple models behind a single endpoint\nHost multiple models behind a single endpoint to improve endpoint utilization. Sharing endpoint \nresources is more sustainable and less expensive than deploying a single model behind one endpoint.\nImplementation plan\nAmazon SageMaker provides three methods to deploy multiple models to a single endpoint:\n\u2022Host multiple models in one container behind one endpoint (MLCOST-24) - SageMaker multi-\nmodel endpoints (MME) are served using a single container. This feature is ideal when you have a large \nnumber of similar models that you can serve through a shared serving container and don\u2019t need to \naccess all the models at the same time. This can help cut inference costs and reduce carbon emissions \nby up to 90% .\n102", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "09b90653-4f78-4475-b516-3530d9a96e7e": {"__data__": {"id_": "09b90653-4f78-4475-b516-3530d9a96e7e", "embedding": null, "metadata": {"page_label": "103", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0f5929f418b6e1dd794be06e97243ce75da4ba51c3bdde30b44a1ec872587d5f", "text": "Machine Learning Lens AWS Well-Architected Framework\nMonitoring lifecycle phase\n\u2022Host multiple models which use di\ufb00erent containers behind one endpoint (MLCOST-24) \u2013 \nSageMaker multi-container endpoint (MCE) support deploying up to 15 containers that use di\ufb00erent \nmodels or framework on a single endpoint, and invoking them independently or in sequence for \nlow-latency inference and cost savings. The models can be completely heterogenous, with their own \nindependent serving stack.\n\u2022Use SageMaker inference pipelines - An inference pipeline  is an Amazon SageMaker model that \nis composed of a linear sequence of containers deployed behind a single endpoint. You can use an \ninference pipeline to combine preprocessing, predictions, and post-processing data science tasks. \nThe output from the one container is passed as input to the next. When de\ufb01ning the containers for a \npipeline model, you also specify the order in which the containers are run.\nDocuments\n\u2022Host multiple models in one container behind one endpoint\n\u2022Host multiple models which use di\ufb00erent containers behind one endpoint\n\u2022Host models along with pre-processing logic as serial inference pipeline behind one endpoint\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 3, deployment and monitoring\n\u2022Save on inference costs by using Amazon SageMaker multi-model endpoints\nML lifecycle phase \u2013 Monitoring\nThe model monitoring system must capture data, compare that data to the training set, de\ufb01ne rules to \ndetect issues, and send alerts. This process repeats on a de\ufb01ned schedule, when initiated by an event, or \nwhen initiated by human intervention. The issues detected in the monitoring phase include: data quality, \nmodel quality, bias drift, and feature attribution drift.\u00a0\nFigure 18: Post deployment monitoring - main components\nFigure 18 lists key components of monitoring, including:\n\u2022Model explainability - Monitoring system uses explainability  to evaluate the soundness of the model \nand if the predictions can be trusted.\n\u2022Detect drift - Monitoring system detects data and concept drifts, initiates an alert, and sends it to the \nalarm manager system. Data drift is signi\ufb01cant changes to the data distribution compared to the data \nused for training. Concept drift is when the properties of the target variables change. Any kind of drift \nresults in model performance degradation.\u00a0\n\u2022Model update pipeline  - If the alarm manager identi\ufb01es any violations, it launches the model update \npipeline for a re-train. This can be seen in Figure 19. The Data prepare , CI/CD/CT, and Feature pipelines \nwill also be active during this process.\n103", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1cad1474-3962-4700-a384-3222ac908adb": {"__data__": {"id_": "1cad1474-3962-4700-a384-3222ac908adb", "embedding": null, "metadata": {"page_label": "104", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5e05e966041189fd326fdf446f223d4a6bd3ed9d80a49b1e2755a2bef43205b1", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\nFigure 19: ML lifecycle with model update re-train and batch/real-time inference pipelines\nBest practices\n\u2022Operational excellence pillar \u2013 Best practices (p. 104)\n\u2022Security pillar \u2013 Best practices (p. 107)\n\u2022Reliability pillar \u2013 Best practices (p. 108)\n\u2022Performance e\ufb03ciency pillar \u2013 Best practices (p. 111)\n\u2022Cost optimization pillar \u2013 Best practices (p. 116)\n\u2022Sustainability pillar \u2013 Best practices (p. 118)\nOperational excellence pillar \u2013 Best practices\nThe operational excellence pillar includes the ability to run and monitor systems to deliver business value \nand to continually improve supporting processes and procedures. This section includes best practices to \nconsider for monitoring models in production.\nBest practices\n\u2022MLOE-15: Enable model observability and tracking (p. 104)\n\u2022MLOE-16: Synchronize architecture and con\ufb01guration, and check for skew across \nenvironments (p. 106)\nMLOE-15: Enable model observability and tracking\nEstablish model monitoring mechanisms to identify and proactively avoid any inference issues. ML \nmodels can degrade in performance over time due to drifts. Monitor metrics that are attributed to \nyour model\u2019s performance. For real time inference endpoints, measure the operational health of the \n104", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2735894f-d8f9-4f6e-aaf1-f15fdea733c8": {"__data__": {"id_": "2735894f-d8f9-4f6e-aaf1-f15fdea733c8", "embedding": null, "metadata": {"page_label": "105", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "18acb99be671eba64b34d181b304e43c2ad127fd5e68502ee34a614510359afa", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\nunderlying compute resources hosting the endpoint and the health of endpoint responses. Establish \nlineage to trace hosted models back to versioned inputs and model artifacts for analysis.\nImplementation plan\n\u2022Use Amazon SageMaker Model Monitor - Continually monitor the quality of Amazon SageMaker ML \nmodels in production and compare with the results from training using SageMaker Model Monitor.\n\u2022Use Amazon CloudWatch - Amazon SageMaker Model Monitor automatically sends metrics to Amazon \nCloudWatch so that you can gather and analyze usage statistics for your ML models.\n\u2022Use SageMaker Model Dashboard - View, search, and explore your models in a centralized portal \nfrom the SageMaker console. Set up monitors with Amazon SageMaker Model Monitor and track \nthe performance of your models that are hosted on real-time inference endpoints. Find models that \nviolate thresholds you have set for data quality, model quality, bias, and explainability\n\u2022Use Amazon SageMaker Clarify - Identify various types of bias that can emerge during model training \nor when the model is in production. This helps improve your ML models by detecting potential bias \nand helping explain the predictions that the models make. SageMaker Clarify helps explain how these \nmodels make predictions using a feature attribution approach. It also monitors inferences that the \nmodels make in production for bias drift or feature attribution drift. SageMaker Clarify provides tools \nto help you generate model governance reports that you can use to inform risk and compliance teams, \nand external regulators.\n\u2022Track your model pipeline with SageMaker ML lineage Tracking \u2013 Lineage tracking creates and \nstores information about the steps of a machine learning work\ufb02ow from data preparation to model \ndeployment. Keep a running history of model discovery experiments. Establish model governance by \ntracking model lineage artifacts for auditing and compliance veri\ufb01cation.\n\u2022Use SageMaker Model Cards to simplify model information gathering \u2013 Documentation on \nmodel information, such as business requirements, key decisions, and observations during model \ndevelopment and evaluation, is required to support approval work\ufb02ows, registration, audits, customer \ninquiries, and monitoring. Amazon SageMaker Model Cards provide a single location to store model \ninformation (for example, performance goals, and risk rating) and training and evaluation results \n(for example, bias or accuracy measurements) in the AWS Management Console, streamlining \ndocumentation throughout a model\u2019s lifecycle.\n\u2022Use the automated validation capability of Amazon SageMaker \u2013 Amazon SageMaker Inference \nenables you to compare the performance of new models against production models, using the same \nreal-world inference request data in real time. Amazon SageMaker can be used to route a copy of the \ninference requests received by the production model to the new model and generate a dashboard to \ndisplay performance di\ufb00erences across key metrics in real time.\nDocuments\n\u2022Amazon SageMaker Model Monitor\n\u2022Monitoring Amazon ML with Amazon CloudWatch Metrics\n\u2022How Amazon CloudWatch works\n\u2022Clarify, Fairness and Explainability\n\u2022SageMaker Model Dashboard\n\u2022Amazon SageMaker Model Cards\n\u2022Amazon SageMaker Shadow Testing\nBlogs\n\u2022Architect and build the full machine learning lifecycle with AWS: An end-to-end Amazon SageMaker \ndemo\n\u2022Improve governance of your machine learning models with Amazon SageMaker\n105", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "60ae2c9d-d5bc-41ad-b4dc-8c9f7c11bb7e": {"__data__": {"id_": "60ae2c9d-d5bc-41ad-b4dc-8c9f7c11bb7e", "embedding": null, "metadata": {"page_label": "106", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e21b89ba7cc8791c78e3b2b022f4584da21189096c109bb22bc927b14bafe235", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar best practices\n\u2022New for Amazon SageMaker \u2013 Perform Shadow Tests to Compare Inference Performance Between ML \nModel Variants\nVideos\n\u2022Introducing Amazon SageMaker Clarify, part 1 - Bias detection- AWS re:Invent 2020\n\u2022Introducing Amazon SageMaker Clarify, part 2 - Model explainability - AWS re:Invent 2020\n\u2022AWS re:Invent 2020: Understand ML model predictions & biases with Amazon SageMaker Clarify\n\u2022AWS re:Invent 2022 - Minimizing the production impact of ML model updates with shadow testing\nExamples\n\u2022Monitoring bias drift and feature attribution drift with Amazon SageMaker Clarify\nMLOE-16: Synchronize architecture and con\ufb01guration, and \ncheck for skew across environments\nEnsure that all systems and con\ufb01gurations are identical across development and deployment phases. \nOtherwise, the same algorithm can result in di\ufb00erent inference results depending on di\ufb00erences in \nsystem architectures. Ensure that the model gets the same range of accuracy in development, staging, \nand production environments. Perform this check as part of the normal promotion process.\nImplementation plan\n\u2022Use AWS CloudFormation - AWS CloudFormation gives you an easy way to model a collection \nof related AWS and third-party resources. CloudFormation provisions these resources quickly \nand\u00a0consistently, and manages them throughout their lifecycles by treating infrastructure as code. \nYou can use a CloudFormation template to create, update, and delete an entire stack as a single \nunit, as\u00a0often as you need to, instead of managing resources individually. You also can manage \nand provision stacks across multiple AWS accounts and AWS Regions. This will synchronize your \narchitecture and con\ufb01guration across environments.\n\u2022Use Amazon SageMaker Model Monitor -Continually monitor the quality of Amazon SageMaker \nmachine learning models in production and compare with the results from training using SageMaker \nModel Monitor . Set alerts that notify you when there are deviations in the model quality. Early and \nproactive detection of these deviations enables you to take corrective actions. These actions can \ninclude retraining models, auditing upstream systems, and \ufb01xing quality issues without having to \nmonitor models manually or build additional tools. Model Monitor provides monitoring capabilities \nthat do not require coding; you also have the \ufb02exibility to monitor models by adding code to provide \ncustom analysis.\nDocuments\n\u2022Amazon SageMaker Model Monitor\n\u2022Implement infrastructure as code\nBlogs\n\u2022Amazon SageMaker Model Monitor \u2013 Fully Managed Automatic Monitoring for your Machine Learning\nModels\n\u2022AWS CloudFormation \u2013 Create Your AWS Stack From a Recipe\n106", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "fe4d57f5-81b9-4ff0-8c2e-95e1e59f6a41": {"__data__": {"id_": "fe4d57f5-81b9-4ff0-8c2e-95e1e59f6a41", "embedding": null, "metadata": {"page_label": "107", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b340844da3b9b9d196f2453eb18df36226d40f759b89ccfef93caaae084d5965", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar best practices\nExamples\n\u2022Introduction to Amazon SageMaker Model Monitor\n\u2022Model Monitor Visualization\nSecurity pillar \u2013 Best practices\nThe security pillar encompasses the ability to protect data, systems, and assets to take advantage of \ncloud technologies to improve your security. This section includes best practices to consider when \nmonitoring models in production.\nBest practices\n\u2022MLSEC-12: Restrict access to intended legitimate consumers (p. 107)\n\u2022MLSEC-13: Monitor human interactions with data for anomalous activity (p. 108)\nMLSEC-12: Restrict access to intended legitimate consumers\nUse least-privileged permissions to invoke the deployed model endpoint. For consumers who are \nexternal to the workload environment, provide access via a secure API.\nImplementation plan\n\u2022Use secure inference API endpoints - Host the model so that a consumer of the model can perform \ninference against it securely. Enable consumers using the API to de\ufb01ne the relationship, restrict access \nto the base model, and provide monitoring of model interactions.\n\u2022Secure inference endpoints - Only authorized parties should make inferences against the ML model. \nTreat inference endpoints as you would any other HTTPS API. Ensure that you follow guidance from \nthe AWS Well-Architected Framework to provide network controls, such as restricting access to speci\ufb01c \nIP ranges, and bot control. The HTTPS requests for these API calls should be signed, so that the \nrequester identity can be veri\ufb01ed, and the requested data is protected in transit.\nDocuments\n\u2022Amazon SageMaker: Real-time Inference\n\u2022Give SageMaker Hosted Endpoints Access to Resources in Your Amazon VPC\n\u2022Register and Deploy Models with Model Registry\nBlogs\n\u2022Integrating machine learning models into your Java-based microservices\n\u2022How Financial Institutions can use AWS to Address Regulatory Reporting\n\u2022Secure deployment of Amazon SageMaker resources\nVideos\n\u2022AWS re:Invent 2019: End-to-End machine learning using Spark and Amazon SageMaker\nExamples\n\u2022Amazon SageMaker secure MLOps\n107", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "282a8b34-3df7-429a-bd8d-9e8182f9f19a": {"__data__": {"id_": "282a8b34-3df7-429a-bd8d-9e8182f9f19a", "embedding": null, "metadata": {"page_label": "108", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e2c90a6492bb9c401fcdd5e84ac165deb2cd6ac3f5cf72276df4f7c00902301f", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\n\u2022Accelerating Machine Learning Development with Data Science as a Service from Change Healthcare\nMLSEC-13: Monitor human interactions with data for anomalous \nactivity\nEnsure that data access logging is enabled. Audit for anomalous data access events, such as access \nevents from abnormal locations, or activity exceeding the baseline for that entity. Use services and tools \nthat support anomalous activity alerting, and combine their use with data classi\ufb01cation to assess risk. \nEvaluate using services to aid in monitoring data access events.\nImplementation plan\n\u2022Enable data access logging - Verify that you have data access logging for all human CRUD (create, \nread, update, and delete) operations, including the details of who accessed what elements, what action \nthey took, and at what time.\n\u2022Classify your data - Use Amazon Macie for protecting and classifying training and inference data in\nAmazon S3. Amazon Macie is a fully managed security service. It uses ML to automatically discover, \nclassify, and protect sensitive data in AWS. The service recognizes sensitive data, such as personally \nidenti\ufb01able information (PII) or intellectual property.\n\u2022Monitor and protect - Use Amazon GuardDuty to monitor for malicious and unauthorized activities. \nThis will enable protecting AWS accounts, workloads, and data stored in Amazon S3.\n\u00a0 Documents\n\u2022Amazon SageMaker Incident Response - Logging & Monitoring\n\u2022Amazon GuardDuty S3 Finding Types - which aid in anomaly detection for S3 resource access events.\nBlogs\n\u2022Building a Self-Service, Secure, & Continually Compliant Environment on AWS\n\u2022How to Use New Advanced Security Features for Amazon Cognito user pools\n\u2022Best practices for setting up Amazon Macie with AWS Organizations\nVideos\n\u2022Protect Your Data in S3 with Amazon Macie and Amazon GuardDuty - AWS Online Tech Talks\n\u2022AWS re:Invent 2020: Protecting sensitive data with Amazon Macie and Amazon GuardDuty\nExamples\n\u2022Controlling and auditing data exploration activities with Amazon SageMaker Studio and AWS Lake\nFormation\nReliability pillar \u2013 Best practices\nThe reliability pillar encompasses the ability of a workload to perform its intended function correctly \nand consistently when it\u2019s expected to. This section includes best practices to consider while monitoring \ndeployed models in production.\n108", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "329664e1-93b8-47d3-8228-779c06f43bee": {"__data__": {"id_": "329664e1-93b8-47d3-8228-779c06f43bee", "embedding": null, "metadata": {"page_label": "109", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "606b6bbc39d2f2b6a116808d9c8fd47669d92b877dc3de392a4759ace7829c80", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nBest practices\n\u2022MLREL-12: Allow automatic scaling of the model endpoint (p. 109)\n\u2022MLREL-13: Ensure a recoverable endpoint with a managed version control strategy (p. 110)\nMLREL-12: Allow automatic scaling of the model endpoint\nImplement capabilities that allow the automatic scaling of model endpoints. This helps ensure the \nreliable processing of predictions to meet changing workload demands. Include monitoring on endpoints \nto identify a threshold that initiates the addition or removal of resources to support current demand.\nAfter a request to scale is received, put in place a solution to scale backend resources supporting that \nendpoint.\nImplementation plan\n\u2022Con\ufb01gure automatic scaling for Amazon SageMaker Endpoints- Amazon SageMaker supports\nautomatic scaling (autoscaling)  for your hosted models. SageMaker Endpoints can be con\ufb01gured \nwith autoscaling. This ensures that as tra\ufb03c increases in your application your endpoint can maintain \nthe same level of service availability. Automatic scaling is a key feature of the cloud. It allows you to \nautomatically provision new resources horizontally to handle increased user demand or system load. \nAutomatic scaling is also a key component of creating event-driven architectures and is a necessary \ncapability of any distributed system.\n\u2022Use Amazon Elastic Inference- With Amazon Elastic Inference, you can choose the CPU instance in \nAWS that is best suited to the overall compute and memory needs of your application. Separately \ncon\ufb01gure the right amount of GPU-powered inference acceleration, allowing you to e\ufb03ciently utilize \nresources and reduce costs.\n\u2022Use Amazon Elastic Inference with EC2 Auto Scaling - When you create an Auto Scaling group, you \ncan specify the information required to con\ufb01gure the Amazon EC2 instances. This includes Elastic \nInference accelerators. To do this, specify a launch template with your instance con\ufb01guration and the \nElastic Inference accelerator.\nDocuments\n\u2022Automatically Scale Amazon SageMaker Model\n\u2022What is Amazon Elastic Inference?\nBlogs\u00a0\n\u2022Con\ufb01guring autoscaling inference endpoints in Amazon SageMaker\nVideos\n\u2022Build, Train and Deploy ML Models at Scale with Amazon SageMaker\n\u2022Deploy Your ML Models to Production at Scale with Amazon SageMaker\nExamples\n\u2022Automatically Scale Amazon SageMaker Models\n109", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b2724f08-36b0-4f0a-992a-f84d40efc4f7": {"__data__": {"id_": "b2724f08-36b0-4f0a-992a-f84d40efc4f7", "embedding": null, "metadata": {"page_label": "110", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e10de8e47218c2da0dce41a5bb2b7e5dc54454f9462827960cbce29f8bdd23a9", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar best practices\nMLREL-13: Ensure a recoverable endpoint with a managed \nversion control strategy\nEnsure an endpoint responsible for hosting model predictions, and all components responsible for \ngenerating that endpoint, are fully recoverable. Some of these components include model artifacts, \ncontainer images, and endpoint con\ufb01gurations. Ensure all required components are version controlled, \nand traceable in a lineage tracker system.\nImplementation plan\n\u2022Implement MLOps best practices with Amazon SageMaker Pipelines and Projects - Amazon\nSageMaker Pipelines is a service for building machine learning pipelines. It automates developing, \ntraining, and deploying models in a versioned, predictable manner.\u00a0Amazon SageMaker Projects enable \nteams of data scientists and developers to collaborate on machine learning business problems. A \nSageMaker project is an Service Catalog provisioned product that enables you to easily create an \nend-to-end ML solution. SageMaker Projects entities include pipeline executions, registered models, \nendpoints, datasets, and code repositories.\n\u2022Use infrastructure as code (IaC) tools - Use AWS CloudFormation to de\ufb01ne and build your \ninfrastructure, including your model endpoints. Store your CloudFormation code in git repositories, \nsuch as AWS CodeCommit, so that you can version control your infrastructure code.\n\u2022Use Amazon Elastic Container Registry (Amazon ECR) - Store your containers in Amazon ECR, an \nartifact repository for Docker containers. Amazon ECR automatically creates a version hash for your \ncontainers as you update them, allowing you to roll back to previous versions.\nDocuments\n\u2022AWS CloudFormation\n\u2022Infrastructure as Code\n\u2022SageMaker Pipelines Overview\n\u2022What is AWS CodeCommit?\n\u2022What is a SageMaker Project?\n\u2022What is Service Catalog?\n\u2022What is Amazon Elastic Container Registry\nBlogs\n\u2022How to manage Amazon SageMaker code with AWS CodeCommit\n\u2022Building, automating, managing, and scaling ML work\ufb02ows using Amazon SageMaker Pipelines\n\u2022Multi-account model deployment with Amazon SageMaker Pipelines\n\u2022Automate feature engineering pipelines with Amazon SageMaker\nVideos\n\u2022Infrastructure as Code on AWS - AWS Online Tech Talks\n\u2022AWS re:Invent 2020: How to create fully automated ML work\ufb02ows with Amazon SageMaker Pipelines\n\u2022Introducing Amazon SageMaker Pipelines - AWS re:Invent 2020\n\u2022AWS re:Invent 2020: Implementing MLOps practices with Amazon SageMaker\n110", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a4a28d65-b44c-4b11-a1c7-1d4925562bb3": {"__data__": {"id_": "a4a28d65-b44c-4b11-a1c7-1d4925562bb3", "embedding": null, "metadata": {"page_label": "111", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "dbe656ccf3ab64b0d8e5b33a6c9635195d6c30164806b7e41f97a244b57a0209", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nExamples\n\u2022CI/CD Pipeline for AWS CloudFormation templates on AWS\n\u2022Amazon SageMaker MLOps\nPerformance e\ufb03ciency pillar \u2013 Best practices\nThe performance e\ufb03ciency pillar focuses on the e\ufb03cient use of computing resources to meet \nrequirements and the maintenance of that e\ufb03ciency as demand changes and technologies evolve. This \nsection includes best practices to consider while monitoring models in production.\nBest practices\n\u2022MLPER-13: Evaluate model explainability (p. 111)\n\u2022MLPER-14: Evaluate data drift (p. 112)\n\u2022MLPER-15: Monitor, detect, and handle model performance degradation (p. 112)\n\u2022MLPER-16: Establish an automated re-training framework (p. 113)\n\u2022MLPER-17: Review for updated data/features for retraining  (p. 115)\n\u2022MLPER-18: Include human-in-the-loop monitoring  (p. 115)\nMLPER-13: Evaluate model explainability\nEvaluate model performance as constrained by the explainability requirements of the business. \nCompliance requirements, business objectives, or both might require that the inferences from a model \nbe directly explainable. Evaluate the explainability needs, and the trade-o\ufb00 between explainability \nand model complexity. Then select the model type or evaluation metrics. This approach provides \ntransparency into the reasons that a particular inference was attained given the input data.\nImplementation plan\n\u2022Use Amazon SageMaker Clarify to explain model results - Amazon SageMaker Clarify helps improve \nyour ML models by detecting potential bias and helping explain the predictions that models make. \nIt helps you identify various types of bias in data that can emerge during model training or\u00a0in \nproduction. SageMaker Clarify helps explain how these models make predictions using a feature \nattribution approach. It also monitors inferences that the models make in production for bias or \nfeature attribution drift. The fairness and explainability functions provided by SageMaker Clarify help \nyou build less biased and more understandable machine learning models. It also provides tools to help \nyou generate model governance reports that you can use to inform risk and compliance teams, and \nexternal regulators.\nDocuments\n\u2022Amazon SageMaker Clarify Model Explainability\n\u2022Feature Attributions that Use Shapley Values\n\u2022What is Fairness and Model Explainability for Machine Learning Predictions?\nBlogs\n\u2022ML model explainability with Amazon SageMakerClarify and the SKLearn pre-built container\n\u2022Explaining Amazon SageMakerAutopilot models with SHAP\n\u2022Human-in-the-loop review of model explanations with Amazon SageMakerClarify and Amazon A2I\n111", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1594be14-f158-41cf-870b-6c49b3f7bc7a": {"__data__": {"id_": "1594be14-f158-41cf-870b-6c49b3f7bc7a", "embedding": null, "metadata": {"page_label": "112", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "64703fb68bb319be9809533561f3066a2663eeb442710ce17e88fe8ae2d3221c", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nVideos\n\u2022Interpretability and explainability in machine learning\n\u2022Explaining Credit Decisions with Amazon SageMaker\nExamples\n\u2022Fairness and Explainability with SageMaker Clarify\n\u2022Explainability with Amazon SageMaker Debugger\nMLPER-14: Evaluate data drift\nUnderstand the e\ufb00ects of data drift on model performance. In cases where the data has drifted, the \nmodel could generate inaccurate predictions. Consider a strategy that monitors and adapts to data drift \nthrough re-training.\nImplementation plan\n\u2022Use Amazon SageMaker Model Monitor, and SageMaker Clarify- Amazon SageMaker Model Monitor\nhelps you maintain high-quality ML models by detecting model and concept drift in real time, and \nsending you alerts so you can take immediate action. Model and concept drift are detected by \nmonitoring the quality of the model. Independent variables (also known as features) are the inputs to \nan ML model, and dependent variables are the outputs of the model. Additionally, SageMaker Model \nMonitor is integrated with Amazon SageMaker Clarify to help you identify potential bias in your ML \nmodels.\nDocuments\n\u2022Amazon SageMaker Model Monitor\n\u2022Amazon SageMaker Clarify - Model Explainability\nBlogs\n\u2022Amazon SageMaker Clarify Detects Bias and Increases the Transparency of Machine Learning Models\nVideos\n\u2022Detect machine learning (ML) model drift in production\nExamples\n\u2022Amazon SageMaker Clarify\nMLPER-15: Monitor, detect, and handle model performance \ndegradation\nModel performance could degrade over time for reasons such as data quality, model quality, model bias, \nand model explainability. Continuously monitor the quality of the ML model in real time. Identify the \nright time and frequency to retrain and update the model. Con\ufb01gure alerts to notify and initiate actions \nif any drift in model performance is observed.\n112", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d12d9941-4b4b-4e5c-83d6-3814b9aba1a6": {"__data__": {"id_": "d12d9941-4b4b-4e5c-83d6-3814b9aba1a6", "embedding": null, "metadata": {"page_label": "113", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "649606ca05257f594ea7ca5d468d0e2d094972d88a76bb77e8e5397445de4351", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nImplementation plan\n\u2022Monitor model performance - Amazon SageMaker Model Monitor continually monitors the quality of \nAmazon SageMaker machine learning models in production. Establish a baseline during training before \nmodel is in production. Collect data while in production and compare changes in model inferences. \nObservations of drifts in the data statistics will indicate that the model may need to be retrained. The \ntiming of drifts will establish a schedule for retraining. Use SageMaker Clarify to identify model bias. \nCon\ufb01gure alerting systems with Amazon CloudWatch to send noti\ufb01cations for unexpected bias or \nchanges in data quality.\n\u2022Perform automatic scaling - Amazon SageMaker includes automatic scaling capabilities for \nyour hosted model to dynamically adjust underlying compute supporting an endpoint based on \ndemand. This capability ensures that your endpoint can dynamically support demand while reducing \noperational overhead.\n\u2022Monitor endpoint metrics  - Amazon SageMaker also outputs endpoint metrics for monitoring the \nusage and health of the endpoint. Amazon SageMaker Model Monitor provides the capability to \nmonitor your ML models in production and provides alerts when data quality issues appear. Create \na mechanism to aggregate and analyze model prediction endpoint metrics using services, such \nas Amazon OpenSearch Service (OpenSearch Service). OpenSearch Service supports Kibana  for \ndashboards and visualization. The traceability of hosting metrics back to versioned inputs allows for \nanalysis of changes that could be impacting current operational performance.\nDocuments\n\u2022Amazon SageMaker Model Monitor\n\u2022How Amazon CloudWatch works\n\u2022Fairness and Explainability with SageMaker Clarify\nBlogs\n\u2022Monitoring in-production ML models at large scale using Amazon SageMaker Model Monitor\n\u2022ML model explainability with Amazon SageMaker Clarify and the SKLearn pre-built container\nVideos\n\u2022Understand ML model predictions & biases with Amazon SageMaker Clarify\n\u2022Deep Dive on Amazon SageMaker Debugger & Amazon SageMaker Model Monitor\n\u2022Detect machine learning (ML) model drift in production\nExamples\n\u2022Amazon SageMaker Model Monitor Examples- Github\nMLPER-16: Establish an automated re-training framework\nMonitor the data and the model predictions. Run analyses of model performance against de\ufb01ned metrics \nto identify errors due to data and concept drift. Automate model re-training to mitigate these errors \non \ufb01xed scheduled intervals, or when model variance reaches a de\ufb01ned threshold. Automated model \nretraining can also be started as enough new data becomes available.\n113", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a3c154fc-6974-4b25-8e88-b73e082741e6": {"__data__": {"id_": "a3c154fc-6974-4b25-8e88-b73e082741e6", "embedding": null, "metadata": {"page_label": "114", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "aa73411c2c2fef0f21a4ad632bf6ddbb6159133a3dc2833403bad4d2693b9acc", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nImplementation plan\n\u2022Identify retraining opportunities - Monitor data statistics and ML inferences at production using \nAmazon SageMaker Model Monitor. If the data drifts beyond a de\ufb01ned threshold, then start retraining. \nAdditionally, retraining can be initiated at de\ufb01ned scheduled intervals (to meet business requirements) \nor when additional training data is available. AWS supports mechanisms for automatically starting \nretraining based on a new data PUT to an Amazon S3 bucket. Ensure model versioning is supported \nwhen incorporating additional data into your models. This enables re-creating an inadvertently \ndeleted model artifact using the combined versions of components used to create the versioned \nartifact.\n\u2022Use Amazon SageMaker Pipelines - A retraining pipeline can be developed using Amazon SageMaker \nPipelines  that enables orchestration using step creation and management.\n\u2022Use AWS Step Functions- You can also use AWS Step Functions Data Science SDK for Amazon\nSageMaker to automate training of a machine learning model. De\ufb01ne all the steps in the work\ufb02ow \nand set up alerts to start the \ufb02ow. To detect the presence of new training data in an S3 bucket, AWS \nCloudTrail combined with Amazon CloudWatch Events allows you to start an AWS Step Function \nwork\ufb02ow to initiate retraining tasks in your training pipeline.\n\u2022Use third-party tools - Use third-party deployment orchestration tools, such as Jenkins , that integrate \nwith AWS service APIs to automate model retraining when new data is available.\nDocuments\n\u2022Amazon SageMaker Model Building Pipelines\n\u2022Retraining Models on New Data\n\u2022Amazon SageMaker Model Monitor\n\u2022Train a Machine Learning Model (using AWS Step Functions)\n\u2022AWS Step Functions Data Science SDK for Python\nBlogs\n\u2022Monitoring in-production ML models at large scale using Amazon SageMaker Model Monitor\n\u2022Automating model retraining and deployment using the AWS Step Functions Data Science SDK for\nAmazon SageMaker\n\u2022Automating complex deep learning model training using Amazon SageMaker Debugger and AWS Step\nFunctions\n\u2022Build a CI/CD pipeline for deploying custom machine learning models using AWS services\n\u2022Create SageMaker Pipelines for training, consuming and monitoring your batch use cases\nVideos\n\u2022How to create fully automated ML work\ufb02ows with Amazon SageMaker Pipelines (29:23)\n\u2022Machine Learning and Automated Model Retraining with SageMaker\nExamples\n\u2022Autopilot, Debugger and Model Monitor \u2013 Immersion Day\n\u2022Amazon SageMaker MLOps\n114", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9cba0db7-520d-4073-8cbb-3d3281ffd877": {"__data__": {"id_": "9cba0db7-520d-4073-8cbb-3d3281ffd877", "embedding": null, "metadata": {"page_label": "115", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "fb3cd7f0b0b97a51877803c16f7ed244f76cead2cea4c7b4e3ca9d1e774888e6", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar best practices\nMLPER-17: Review for updated data/features for retraining\nEstablish a framework to run data exploration and feature engineering at pre-determined time intervals \nbased on data volatility and availability. New features that have not been considered in the model \ntraining can a\ufb00ect the accuracy of model inferences.\nImplementation plan\n\u2022Explore changing data with Amazon SageMaker Data Wrangler - Evaluate the rate of change of \nthe business environment to set a schedule for validating and possibly changing model input data \nand features. Analyze the data using Amazon SageMaker Data Wrangler and explore new features. \nEstablish a team who will periodically evaluate and possibly change features and retrain the model.\nDocuments\n\u2022Prepare ML Data with Amazon SageMaker Data Wrangler\n\u2022Amazon SageMaker Model Monitor\nBlogs\n\u2022Exploratory data analysis, feature engineering, and operationalizing your data \ufb02ow into your ML \npipeline with Amazon SageMaker Data Wrangler\u00a0\nVideos\n\u2022Introducing Amazon SageMaker Data Wrangler \u2013 AWS re:Invent 2020\nMLPER-18: Include human-in-the-loop monitoring\nUse human-in-the-loop monitoring to monitor model performance e\ufb03ciently. When automating \ndecision processes, the human labeling of model results is a reliable quality test for model inferences.\nCompare human labels with model inferences to estimate model performance degradation. Perform \nmitigation as model re-training.\nImplementation plan\n\u2022Use Amazon Augmented AI to get human review - Learn how to design a quality assurance \nsystem for model inferences. Establish a team of subject matter experts to audit model inference \nin production. Use Amazon Augmented AI (Amazon A2I) to get human review of low-con\ufb01dence \npredictions or random prediction samples. Amazon A2I uses resources in IAM, SageMaker, and Amazon\nS3 to create and run your human review work\ufb02ows.\nDocuments\n\u2022Using Amazon Augmented AI for Human Review\nBlogs\n\u2022Human-in-the-loop review of model explanations with Amazon SageMaker Clarify and Amazon A2I\n\u2022Verifying and adjusting your data labels to create higher quality training datasets with Amazon\nSageMaker Ground Truth\n115", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6e317b08-05cc-4dad-908b-b88bec15f99d": {"__data__": {"id_": "6e317b08-05cc-4dad-908b-b88bec15f99d", "embedding": null, "metadata": {"page_label": "116", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7d8024fb37e27e59783b10a364d15751ba2acaf41a784498b34235dc637a4c16", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nVideos\n\u2022Easily Implement Human in the Loop into Your Machine Learning Predictions with Amazon A2I\nCost optimization pillar \u2013 Best practices\nThe cost optimization pillar includes the continual process of re\ufb01nement and improvement of a system \nover its entire lifecycle. From the initial design of your very \ufb01rst proof of concept to the ongoing \noperation of production workloads, adopting the practices in this document can enable you to build \nand operate cost-aware systems that achieve business outcomes and minimize costs, thus allowing \nyour business to maximize its return on investment. This section includes best practices to consider for \nmonitoring models in production.\nBest practices:\n\u2022MLCOST-27: Monitor usage and cost by ML activity (p. 116)\n\u2022MLCOST-28: Monitor Return on Investment for ML models (p. 117)\n\u2022MLCOST-29: Monitor endpoint usage and right-size the instance \ufb02eet (p. 117)\nMLCOST-27: Monitor usage and cost by ML activity\nUse cloud resource tagging to manage, identify, organize, search for, and \ufb01lter resources. Tags help \ncategorize resources by purpose, owner, environment, or other criteria. Associate costs with resources \nusing ML activity categories, such as re-training and hosting, by using tagging to manage and optimize \ncost in deployment phases. Tagging can be useful for generating billing reports with breakdown of cost \nby associated resources.\nImplementation plan\n\u2022Use AWS tagging -A tag is a label that you or AWS assigns to an AWS resource. Each tag consists of a \nkey and a value. For each resource, each tag key must be unique, and each tag key can have only one \nvalue. You can use tags to organize your resources, and cost allocation tags to track your AWS costs \non a detailed level. AWS uses the cost allocation tags to organize your resource costs on your cost \nallocation report. This will make it easier for you to categorize and track your AWS costs. AWS provides \ntwo types of cost allocation tags, an AWS-generated tag and user-de\ufb01ned tags.\n\u2022Use AWS Budgets to keep track of cost - AWS Budgets helps you track your Amazon SageMaker cost, \nincluding development, training, and hosting. You can also set alerts and get a noti\ufb01cation when \nyour cost or usage exceeds (or is forecasted to exceed) your budgeted amount. After you create your \nbudget, you can track the progress on the AWS Budgets console.\nDocuments\n\u2022Tagging AWS resources\n\u2022Use Tags to Track and Allocate Amazon SageMaker Studio Notebooks Costs\n\u2022Tagging best practices\n\u2022Managing your costs with AWS Budgets\nBlogs\n\u2022Optimizing costs for machine learning with Amazon SageMaker\n116", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "9ce7d08a-fda4-4486-bc99-6a7530c893ba": {"__data__": {"id_": "9ce7d08a-fda4-4486-bc99-6a7530c893ba", "embedding": null, "metadata": {"page_label": "117", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3c59a159113018f5fdd1dd8a62c90a1686df6d1a6ec266056309577996e61cbd", "text": "Machine Learning Lens AWS Well-Architected Framework\nCost optimization pillar best practices\nVideos\n\u2022How can I tag my AWS resources to divide up my bill by cost center or project?\nMLCOST-28: Monitor Return on Investment for ML models\nOnce a model is deployed into production, establish a reporting capability to track the value which is \nbeing delivered. For example:\n\u2022If a model is used to support customer acquisition: How many new customers are acquired and what is \ntheir spend when the model\u2019s advice is used compared with a baseline.\n\u2022If a model is used to predict when maintenance is needed: What savings are being made by optimizing \nthe maintenance cycle.\nE\ufb00ective reporting enables you to compare the value delivered by an ML model against the ongoing \nruntime cost and to take appropriate action. If the ROI is substantially positive, are there ways in which \nthis might be scaled to similar challenges, for example. If the ROI is negative, could this be addressed by \nremedial action, such as reducing the model latency by using server less inference, or reducing the run \ntime cost by changing the compromise between model accuracy and model complexity, or layering in an \nadditional simpler model to\u00a0triage or \ufb01lter the cases that are submitted to the full model.\nImplementation plan\n\u2022Use dashboard reporting - Using a reporting tool such as Amazon QuickSight to develop business \nfocused reports showing the value delivered by using the model in terms of business KPIs.\nDocuments\n\u2022Amazon QuickSight\nMLCOST-29: Monitor endpoint usage and right-size the instance \n\ufb02eet\nEnsure e\ufb03cient compute resources are used to run models in production. Monitor your endpoint usage \nand right-size the instance \ufb02eet. Use automatic scaling (autoscaling) for your hosted models. Autoscaling\ndynamically adjusts the number of instances provisioned for a model in response to changes in your \nworkload.\u00a0\nImplementation plan\n\u2022Monitor Amazon SageMaker endpoints with Amazon CloudWatch -\u00a0You can \nmonitor Amazon SageMaker using Amazon CloudWatch, which collects raw \ndata and processes it into readable, near real-time metrics. Use metrics such \nas\u00a0CPUUtilization,\u00a0GPUUtilization,\u00a0MemoryUtilization,\u00a0GPUUtilization to view your endpoint's resource \nutilization and use the information to right-size the endpoint instance.\n\u2022Use autoscaling with Amazon SageMaker - Amazon SageMaker supports autoscaling that monitors \nyour workloads and dynamically adjusts the capacity to maintain steady and predictable performance \nat the lowest possible cost. When the workload increases, autoscaling brings more instances online. \nWhen the workload decreases, autoscaling removes unnecessary instances, helping you reduce your \ncompute cost. SageMaker automatically attempts to distribute your instances across Availability Zones. \nSo, we strongly recommend that you deploy multiple instances for each production endpoint for \nhigh availability. If you\u2019re using a VPC, con\ufb01gure at least two subnets in di\ufb00erent Availability Zones so \nAmazon SageMaker can distribute your instances across those Availability Zones.\n117", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2f19385f-3a04-44af-83a3-fc74a84e5155": {"__data__": {"id_": "2f19385f-3a04-44af-83a3-fc74a84e5155", "embedding": null, "metadata": {"page_label": "118", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "db0e75459c4d26a762ccd94c4183fb8b8fd9ec50c9c20a53f17eab35b76fabe4", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\n\u2022Determine the resource placement carefully \u2013 Amazon FSx for Lustre can be an input data source \nfor Amazon SageMaker. When FSx for Lustre is used as an input data source, Amazon SageMaker \nML training jobs are accelerated by eliminating the initial Amazon S3 download step. However, as a \nbest practice, it is recommended that customers deploy FSx for Lustre and SageMaker in the same \nAvailability Zone. Deploying them across Availability Zones or VPC can result in a signi\ufb01cant cost.\nDocuments\n\u2022Automatically Scale Amazon SageMaker Model\n\u2022Monitor Amazon SageMaker endpoints with Amazon CloudWatch\nBlogs\n\u2022Use Amazon CloudWatch custom metrics for real-time monitoring of Amazon SageMaker model \nperformance\n\u2022Speed up training on Amazon SageMaker using Amazon FSx for Lustre and Amazon EFS \ufb01le systems\nSustainability pillar \u2013 Best practices\nThe sustainability pillar focuses on environmental impacts, especially energy consumption and e\ufb03ciency, \nsince they are important levers for architects to inform direct action to reduce resource usage.\u00a0This \nsection includes best practices to\u00a0consider\u00a0for monitoring models in production.\nBest practices:\n\u2022MLSUS-15: Measure material e\ufb03ciency (p. 118)\n\u2022MLSUS-16: Retrain only when necessary (p. 119)\nMLSUS-15: Measure material e\ufb03ciency\nMeasure e\ufb03ciency of your workload in provisioned resources per unit of work, to measure not only the \nbusiness success of the workload, but also its material e\ufb03ciency. Use this measure as a baseline for your \nsustainability improvement process.\nImplementation plan\n\u2022Use provisioned resources per unit of work as a key performance indicator - Divide the provisioned \nresources by the business outcomes achieved to determine the provisioned resources per unit of work. \nThis allows you to normalize your sustainability KPIs and compare the performance over time.\n\u2022Establish a baseline  - Understand the resources provisioned by your workload to complete a unit of \nwork (for example, training the model or making a prediction)\n\u2022Estimate improvement - Estimate improvement as both the quantitative reduction in resources \nprovisioned and the percentage change from your baseline resources provisioned per unit of work. \nQuantify the net bene\ufb01t from your improvement over time to show the return on investment from \nyour improvement activities.\nResources\n\u2022Measure results and replicate successes\n118", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e2711742-f757-4022-bf22-bb821c839f2d": {"__data__": {"id_": "e2711742-f757-4022-bf22-bb821c839f2d", "embedding": null, "metadata": {"page_label": "119", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "cd0fda5dac43a1cd809739ef9a772d6602529c40b87ca309273d73a37637f714", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar best practices\nVideos\n\u2022AWS re:Invent 2021 - Architecting for sustainability - Resources per Unit of Work\nMLSUS-16: Retrain only when necessary\nBecause of model drift, robustness requirements, or new ground truth data being available, models \nusually need to be retrained. Instead of retraining arbitrarily, monitor your ML model in production, \nautomate your model drift detection and only retrain when your model\u2019s predictive performance has \nfallen below de\ufb01ned KPIs.\nImplementation plan\n\u2022Determine key performance indicators - With business stakeholders, identify a minimum acceptable \naccuracy and a maximum acceptable error.\n\u2022Monitor your model deployed in Production - Automate your model drift detection using Amazon \nSageMaker Model Monitor\n\u2022Automate your retraining pipelines - Use Amazon SageMaker Pipelines, AWS Step Functions Data \nScience SDK for Amazon SageMaker or third-party tools to automate your retraining pipelines.\u00a0\nResources\n\u2022MLPER-01: Determine key performance indicators\nBlogs\n\u2022Optimize AI/ML workloads for sustainability: Part 3, deployment and monitoring\n\u2022Monitoring in-production ML models at large scale using Amazon SageMaker Model Monitor\n\u2022Automating model retraining and deployment using the AWS Step Functions Data Science SDK for \nAmazon SageMaker\n\u2022Automate model retraining with Amazon SageMaker Pipelines when drift is detected\n119", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "dd721291-856e-4a75-9837-64455143a669": {"__data__": {"id_": "dd721291-856e-4a75-9837-64455143a669", "embedding": null, "metadata": {"page_label": "120", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "89160a7bc67310dc0ccf7262486fe497d64cde4896ada927306bc470f0b01d3f", "text": "Machine Learning Lens AWS Well-Architected Framework\nConclusion\nThe Well-Architected ML design principles in this paper provide the guidance for the best practices \ncollection. The technology and cloud agnostic best practices across the Well-Architected pillars provide \narchitectural guidance for each phase of the ML lifecycle. Implementation plans provide guidance on \nimplementing these best practices on AWS.\nArchitecture diagrams demonstrate the lifecycle phases with the supporting technologies, that \nenable many of the best practices introduced in this paper. The ML lens extends the Well-Architected \nFramework, and builds speci\ufb01c machine learning best practices upon it. As you work towards building \nand deploying production ML workloads in AWS, we recommend reviewing the AWS Well-Architected \nFramework pillar best practices.\nUse the Lens to help ensure that your ML workloads are architected with operational excellence, security, \nreliability, performance e\ufb03ciency, cost optimization, and sustainability in mind. Plan early and make \ninformed decisions when designing new workloads. Use the best practices to guide you through building \nand deploying new workloads faster. Using the lens guidance, evaluate existing workloads regularly to \nidentify, mitigate, and address potential issues early.\n120", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "fffddfea-212c-4b5b-98a3-dc90decd275d": {"__data__": {"id_": "fffddfea-212c-4b5b-98a3-dc90decd275d", "embedding": null, "metadata": {"page_label": "121", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "2501377b6e528e49f25f21a92ceac515257590f2cd89bc1b7a626dfe63b80c42", "text": "Machine Learning Lens AWS Well-Architected Framework\nSME reviewers\nContributors\nThe following individuals and organizations contributed to this document:\n\u2022Benoit de Chateauvieux - Startup Solutions Architect, Amazon Web Services\n\u2022Dan Ferguson - Sr. Specialist Solutions Architect \u2013 PE, Amazon Web Services\n\u2022Michael Hsieh \u2013 Principal AI/ML Specialist SA, WWSO BDSI, Amazon Web Services\n\u2022Ganapathi Krishnamoorthi \u2013 Principal Startup Solutions Architect - AI/ML, Amazon Web Services\n\u2022Neil Mackin \u2013 Principal ML Strategist, AWS Customer Engineering, Amazon Web Services\n\u2022Haleh Najafzadeh - Senior Manager, Well-Architected Content, Amazon Web Services\n\u2022Raj Pathak \u2013 Senior Solutions Architect, WWCS Geo Solutions Architecture, Amazon Web Services\n\u2022Ram Pathangi \u2013 Solutions Architect, WWCS Geo Solutions Architecture, Amazon Web Services\n\u2022Raju Patil \u2013 Data Scientist, AWS WWCO Professional Services, Amazon Web Services\n\u2022Eddie Pick - Manager, Startup Solutions Architect, Amazon Web Services\n\u2022Deepali Rajale \u2013 Specialist Technical Account Manager \u2013 AI/ML (Sp), AWS Enterprise Support, Amazon \nWeb Services\n\u2022Brendan Sisson - Principal Solutions Architect, Amazon Web Services\n\u2022Dhiraj Thakur \u2013 Senior Solutions Architect, Amazon Web Services\n\u2022Pallavi Nargund - Principal Solutions Architect, Amazon Web Services\n\u2022Patrick Roberts - Senior Data Scientist, AWS WWCO Professional Services, Amazon Web Services\n\u2022Raju Penmatcha - Senior Solutions Architect, AI Platforms, Amazon Web Services\n\u2022Jess Clark - Principal Security Engineer \u2013 Identity and Access Management, Amazon Web Services\n\u2022Emily Soward - Data Scientist, AWS WWCO Professional Services, Amazon Web Services\n\u2022Amit Lulla - Senior Solutions Architect ISV, AWS WWCS Geo Solutions Architect, Amazon Web Services\n\u2022Giuseppe Angelo Porcelli - Principal ML Solutions Architect, AI Platforms, Amazon Web Services\n\u2022Shelbee Eigenbrode - Principal AI/ML Specialist Solutions Architect, AWS WWSO AI/ML, Amazon Web \nServices\n\u2022Phi Nguyen \u2013 Front End Developer, AWS WWCO Professional Services, Amazon Web Services\n\u2022Jeremy Sobek - Technical Curriculum Developer, AWS T&C Curriculum, Amazon Web Services\nSubject matter expert (SME) reviewers\n\u2022Mohammad Arbabshirani \u2013 Sr. Data Scientist Manager, AWS WWCO Professional Services, Amazon Web \nServices\n\u2022Chris Boomhower \u2013 Machine Learning Engineer, AWS WWCO Professional Services, Amazon Web \nServices\n\u2022Bruno Klein \u2013 Machine Learning Engineer, AWS WWCO Professional Services, Amazon Web Services\n\u2022Bruce Ross - Lens Leader, Senior Solutions Architect Well-Architected, Amazon Web Services\n121", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "319f7530-4375-498b-a6cf-7d8fcf4dd5ec": {"__data__": {"id_": "319f7530-4375-498b-a6cf-7d8fcf4dd5ec", "embedding": null, "metadata": {"page_label": "122", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7494a63c0c57b8773d82f10c2266597ec497e45fb7abe685f1a4e7774fdd9020", "text": "Machine Learning Lens AWS Well-Architected Framework\nReferences\n\u2022AWS Architecture Center\n\u2022Architecture Best Practices for Machine Learning\n\u2022AWS Well-Architected Framework\n\u2022AWS Operational Excellence pillar\n\u2022AWS Security pillar\n\u2022AWS Reliability pillar\n\u2022AWS Performance E\ufb03ciency pillar\n\u2022AWS Cost Optimization pillar\n\u2022AWS Sustainability pillar\n\u2022Amazon AI Fairness and Explainability Whitepaper\n\u2022Overview of Deployment Options on AWS\n\u2022Crisp-DM 1.0\n\u2022Announcing New Tools for Building with Generative AI on AWS | Amazon Web Services\n\u2022Get started with generative AI on AWS using Amazon SageMaker JumpStart | Amazon Web Services\n122", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "7882e238-b741-4e4c-a95f-d1f6e87080c0": {"__data__": {"id_": "7882e238-b741-4e4c-a95f-d1f6e87080c0", "embedding": null, "metadata": {"page_label": "123", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a84ac3513e63171f7a937e68d848559059171b48fff076da598bf28e31a798b2", "text": "Machine Learning Lens AWS Well-Architected Framework\nDocument history\nTo be noti\ufb01ed about updates to this whitepaper, subscribe to the RSS feed.\nChange Description Date\nMajor update  (p. 123) Whitepaper updated to \nre\ufb02ect current best practices, \nimplementation guidance, and \nAWS services.\nAdded the sustainability pillar \nthat describes reducing your \nimpact on the environment \nwhile taking advantage of AWS \nadvanced AI/ML capabilities for \nyour business.\nUpdated technical references \nand resources including product \ndocumentation, blog posts, \ninstructional and video links, and \nsolution briefs.July 5, 2023\nMinor update  (p. 123) Fixed broken links. April 6, 2023\nMinor update  (p. 123) Corrected typo. July 21, 2022\nMajor update  (p. 123) Whitepaper updated to re\ufb02ect \ncurrent best practices and AWS \nservices.October 12, 2021\nMinor changes  (p. 123) Updated links in the whitepaper.January 21, 2021\nInitial publication  (p. 123) Machine Learning Lens \ufb01rst \npublished.April 16, 2020\nNote\nTo subscribe to RSS updates, you must have an RSS plug-in enabled for the browser that you are \nusing.\n123", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "c5c84cff-1b15-4ab4-a35b-9f69fc464367": {"__data__": {"id_": "c5c84cff-1b15-4ab4-a35b-9f69fc464367", "embedding": null, "metadata": {"page_label": "124", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f509aa89a2ded6ee9498527bf9faa3c2e74196b7080e837095f5e1a705a33e00", "text": "Machine Learning Lens AWS Well-Architected Framework\nOperational excellence pillar\nBest practices arranged by pillar\nThis is a list of best practices outlined in this paper organized by the pillars of the AWS Well-Architected \nFramework.\nOperational excellence pillar\n\u2022MLOE-01: Develop the right skills with accountability and empowerment (p. 10)\n\u2022MLOE-02: Discuss and agree on the level of model explainability (p. 10)\n\u2022MLOE-03: Monitor model compliance to business requirements (p. 11)\n\u2022MLOE-04: Establish ML roles and responsibilities (p. 17)\n\u2022MLOE-05: Prepare an ML pro\ufb01le template (p. 19)\n\u2022MLOE-06: Establish model improvement strategies (p. 20)\n\u2022MLOE-07: Establish a lineage tracker system (p. 21)\n\u2022MLOE-08: Establish feedback loops across ML lifecycle phases (p. 22)\n\u2022MLOE-09: Review fairness and explainability (p. 23)\n\u2022MLOE-10: Pro\ufb01le data to improve quality (p. 39)\n\u2022MLOE-11: Create tracking and version control mechanisms (p. 40)\n\u2022MLOE-12: Automate operations through MLOps and CI/CD (p. 59)\n\u2022MLOE-13: Establish reliable packaging patterns to access approved public libraries (p. 61)\n\u2022MLOE-14: Establish deployment environment metrics (p. 90)\n\u2022MLOE-15: Enable model observability and tracking (p. 104)\n\u2022MLOE-16: Synchronize architecture and con\ufb01guration, and check for skew across \nenvironments (p. 106)\nSecurity pillar\n\u2022MLSEC-01: Validate ML data permissions, privacy, software, and license terms (p. 12)\n\u2022MLSEC-02: Design data encryption and obfuscation\u00a0 (p. 24)\n\u2022MLSEC-03: Ensure least privilege access (p. 41)\n\u2022MLSEC-04: Secure data and modeling environment (p. 42)\n\u2022MLSEC-05: Protect sensitive data privacy (p. 44)\n\u2022MLSEC-06: Enforce data lineage (p. 45)\n\u2022MLSEC-07: Keep only relevant data (p. 45)\n\u2022MLSEC-08: Secure governed ML environment (p. 61)\n\u2022MLSEC-09: Secure inter-node cluster communications (p. 62)\n\u2022MLSEC-10: Protect against data poisoning threats (p. 63)\n\u2022MLSEC-11: Protect against adversarial and malicious activities (p. 91)\n\u2022MLSEC-12: Restrict access to intended legitimate consumers (p. 107)\n\u2022MLSEC-13: Monitor human interactions with data for anomalous activity (p. 108)\n124", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "c17b24b2-c75b-4897-8473-7f75ea473ff2": {"__data__": {"id_": "c17b24b2-c75b-4897-8473-7f75ea473ff2", "embedding": null, "metadata": {"page_label": "125", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "308a964df2dc4fd5d0894fa9d5a77da66e2cc672fd3272eee3c674f11b6ccb15", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar\nReliability pillar\n\u2022MLREL-01: Use APIs to abstract change from model consuming applications (p. 24)\n\u2022MLREL-02: Adopt a machine learning microservice strategy (p. 25)\n\u2022MLREL-03: Use a data catalog (p. 46)\n\u2022MLREL-04: Use a data pipeline (p. 47)\n\u2022MLREL-05: Automate managing data changes (p. 48)\n\u2022MLREL-06: Enable CI/CD/CT automation with traceability (p. 64)\n\u2022MLREL-07: Ensure feature consistency across training and inference (p. 65)\n\u2022MLREL-08: Ensure model validation with relevant data (p. 66)\n\u2022MLREL-09: Establish data bias detection and mitigation (p. 66)\n\u2022MLREL-10: Automate endpoint changes through a pipeline (p. 92)\n\u2022MLREL-11: Use an appropriate deployment and testing strategy (p. 93)\n\u2022MLREL-12: Allow automatic scaling of the model endpoint (p. 109)\n\u2022MLREL-13: Ensure a recoverable endpoint with a managed version control strategy (p. 110)\nPerformance e\ufb03ciency pillar\n\u2022MLPER-01: Determine key performance indicators (p. 13)\n\u2022MLPER-02: Use purpose-built AI and ML services and resources (p. 27)\n\u2022MLPER-03: De\ufb01ne relevant evaluation metrics (p. 27)\n\u2022MLPER-04: Use a modern data architecture (p. 49)\n\u2022MLPER-05: Optimize training and inference instance types (p. 67)\n\u2022MLPER-06: Explore alternatives for performance improvement (p. 68)\n\u2022MLPER-07: Establish a model performance evaluation pipeline (p. 69)\n\u2022MLPER-08: Establish feature statistics (p. 70)\n\u2022MLPER-09: Perform a performance trade-o\ufb00 analysis (p. 71)\n\u2022MLPER-10: Detect performance issues when using transfer learning (p. 72)\n\u2022MLPER-11: Evaluate cloud versus edge options for machine learning deployment (p. 94)\n\u2022MLPER-12: Choose an optimal deployment option in the cloud (p. 95)\n\u2022MLPER-13: Evaluate model explainability (p. 111)\n\u2022MLPER-14: Evaluate data drift (p. 112)\n\u2022MLPER-15: Monitor, detect, and handle model performance degradation (p. 112)\n\u2022MLPER-16: Establish an automated re-training framework (p. 113)\n\u2022MLPER-17: Review for updated data/features for retraining  (p. 115)\n\u2022MLPER-18: Include human-in-the-loop monitoring  (p. 115)\nCost optimization pillar\n\u2022MLCOST-01: De\ufb01ne overall return on investment (ROI) and opportunity cost (p. 14)\n\u2022MLCOST-02: Use managed services to reduce total cost of ownership (TCO) (p. 15)\n\u2022MLCOST-03: Identify if machine learning is the right solution (p. 28)\n\u2022MLCOST-04: Tradeo\ufb00 analysis on custom versus pre-trained models (p. 29)\n\u2022MLCOST-05: Use managed data labeling (p. 50)\n125", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "3667f914-f05d-489f-9f6c-6f4297542f0e": {"__data__": {"id_": "3667f914-f05d-489f-9f6c-6f4297542f0e", "embedding": null, "metadata": {"page_label": "126", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b77f227c779bea6d0f85f08b3bdd794cfda21541666026abdb62fff2d8faecfb", "text": "Machine Learning Lens AWS Well-Architected Framework\nSustainability pillar\n\u2022MLCOST-06: Use data wrangler tools for interactive analysis (p. 51)\n\u2022MLCOST-07: Use managed data processing capabilities (p. 52)\n\u2022MLCOST-08: Enable feature reusability (p. 52)\n\u2022MLCOST-09: Select optimal computing instance size (p. 73)\n\u2022MLCOST-10: Use managed build environments (p. 73)\n\u2022MLCOST-11: Select local training for small scale experiments (p. 74)\n\u2022MLCOST-12: Select an optimal ML framework (p. 75)\n\u2022MLCOST-13: Use automated machine learning (p. 76)\n\u2022MLCOST-14: Use managed training capabilities (p. 76)\n\u2022MLCOST-15: Use distributed training (p. 77)\n\u2022MLCOST-16: Stop resources when not in use (p. 78)\n\u2022MLCOST-17: Start training with small datasets (p. 79)\n\u2022MLCOST-18: Use warm-start and checkpointing hyperparameter tuning (p. 79)\n\u2022MLCOST-19: Use hyperparameter optimization technologies (p. 80)\n\u2022MLCOST-20 - Setup budget and use resource tagging to track costs (p. 80)\n\u2022MLCOST-21: Enable data and compute proximity (p. 81)\n\u2022MLCOST-22: Select optimal algorithms (p. 82)\n\u2022MLCOST-23: Enable debugging and logging (p. 83)\n\u2022MLCOST-24: Use appropriate deployment option (p. 97)\n\u2022MLCOST-25: Explore cost e\ufb00ective hardware options (p. 98)\n\u2022MLCOST-26: Right-size the model hosting instance \ufb02eet (p. 99)\n\u2022MLCOST-27: Monitor usage and cost by ML activity (p. 116)\n\u2022MLCOST-28: Monitor Return on Investment for ML models (p. 117)\n\u2022MLCOST-29: Monitor endpoint usage and right-size the instance \ufb02eet (p. 117)\nSustainability pillar\n\u2022MLSUS-01: De\ufb01ne the overall environmental impact or bene\ufb01t (p. 16)\n\u2022MLSUS-02: Consider AI services and pre-trained models (p. 30)\n\u2022MLSUS-03: Select sustainable Regions (p. 31)\n\u2022MLSUS-04: Minimize idle resources\u00a0 (p. 54)\n\u2022MLSUS-05: Implement data lifecycle policies aligned with your sustainability goals (p. 54)\n\u2022MLSUS-06: Adopt sustainable storage options (p. 55)\n\u2022MLSUS-07: De\ufb01ne sustainable performance criteria (p. 84)\n\u2022MLSUS-08: Select energy-e\ufb03cient algorithms (p. 85)\n\u2022MLSUS-09: Archive or delete unnecessary training artifacts (p. 86)\n\u2022MLSUS-10:\u00a0Use e\ufb03cient model tuning methods (p. 86)\n\u2022MLSUS-11: Align SLAs with sustainability goals (p. 100)\n\u2022MLSUS-12: Use e\ufb03cient silicon (p. 101)\n\u2022MLSUS-13: Optimize models for inference (p. 102)\n\u2022MLSUS-14: Deploy multiple models behind a single endpoint (p. 102)\n\u2022MLSUS-15: Measure material e\ufb03ciency (p. 118)\n\u2022MLSUS-16: Retrain only when necessary (p. 119)\n126", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8454af88-76d1-42ca-bbba-cba6abe0bb71": {"__data__": {"id_": "8454af88-76d1-42ca-bbba-cba6abe0bb71", "embedding": null, "metadata": {"page_label": "127", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "9b898fcbfa5504513865c392b78b8afe45ed8016a2f109d366f58c8a2c5c98c8", "text": "Machine Learning Lens AWS Well-Architected Framework\nBusiness goal identi\ufb01cation phase\nBest practices by ML lifecycle phase\nThere are six phases in the machine learning lifecycle and within each there are six pillars of the Well-\nArchitected Framework. The following index lists the best practices by lifecycle phase.\nBusiness goal identi\ufb01cation phase\nOperational excellence pillar\n\u2022MLOE-01: Develop the right skills with accountability and empowerment (p. 10)\n\u2022MLOE-02: Discuss and agree on the level of model explainability (p. 10)\n\u2022MLOE-03: Monitor model compliance to business requirements (p. 11)\nSecurity pillar\n\u2022MLSEC-01: Validate ML data permissions, privacy, software, and license terms (p. 12)\nReliability pillar\nThere are no reliability pillar best practices for business goal identi\ufb01cation.\nPerformance e\ufb03ciency pillar\n\u2022MLPER-01: Determine key performance indicators (p. 13)\nCost optimization pillar\n\u2022MLCOST-01: De\ufb01ne overall return on investment (ROI) and opportunity cost (p. 14)\n\u2022MLCOST-02: Use managed services to reduce total cost of ownership (TCO) (p. 15)\nSustainability pillar\n\u2022MLSUS-01: De\ufb01ne the overall environmental impact or bene\ufb01t (p. 16)\nML problem framing phase\nOperational excellence pillar\n\u2022MLOE-04: Establish ML roles and responsibilities (p. 17)\n127", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "15164e8e-9b3d-4256-a881-8112ac53ef63": {"__data__": {"id_": "15164e8e-9b3d-4256-a881-8112ac53ef63", "embedding": null, "metadata": {"page_label": "128", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "2d026f5814de2e0015109015d763af31181b37d98339952e2330d159a5e7e43f", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar\n\u2022MLOE-05: Prepare an ML pro\ufb01le template (p. 19)\n\u2022MLOE-06: Establish model improvement strategies (p. 20)\n\u2022MLOE-07: Establish a lineage tracker system (p. 21)\n\u2022MLOE-08: Establish feedback loops across ML lifecycle phases (p. 22)\n\u2022MLOE-09: Review fairness and explainability (p. 23)\nSecurity pillar\n\u2022MLSEC-02: Design data encryption and obfuscation\u00a0 (p. 24)\nReliability pillar\n\u2022MLREL-01: Use APIs to abstract change from model consuming applications (p. 24)\n\u2022MLREL-02: Adopt a machine learning microservice strategy (p. 25)\nPerformance e\ufb03ciency pillar\n\u2022MLPER-02: Use purpose-built AI and ML services and resources (p. 27)\n\u2022MLPER-03: De\ufb01ne relevant evaluation metrics (p. 27)\nCost optimization pillar\n\u2022MLCOST-03: Identify if machine learning is the right solution (p. 28)\n\u2022MLCOST-04: Tradeo\ufb00 analysis on custom versus pre-trained models (p. 29)\nSustainability pillar\n\u2022MLSUS-02: Consider AI services and pre-trained models (p. 30)\n\u2022MLSUS-03: Select sustainable Regions (p. 31)\nData processing phase\nOperational excellence pillar\n\u2022MLOE-10: Pro\ufb01le data to improve quality (p. 39)\n\u2022MLOE-11: Create tracking and version control mechanisms (p. 40)\nSecurity pillar\n\u2022MLSEC-03: Ensure least privilege access (p. 41)\n\u2022MLSEC-04: Secure data and modeling environment (p. 42)\n\u2022MLSEC-05: Protect sensitive data privacy (p. 44)\n128", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ab98099b-77e2-41dc-b46f-0ec927a2113d": {"__data__": {"id_": "ab98099b-77e2-41dc-b46f-0ec927a2113d", "embedding": null, "metadata": {"page_label": "129", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c0d39d9a8c621ea4763ed4021160ea304d9cf002a23283315096b46e5c480726", "text": "Machine Learning Lens AWS Well-Architected Framework\nReliability pillar\n\u2022MLSEC-06: Enforce data lineage (p. 45)\n\u2022MLSEC-07: Keep only relevant data (p. 45)\nReliability pillar\n\u2022MLREL-03: Use a data catalog (p. 46)\n\u2022MLREL-04: Use a data pipeline (p. 47)\n\u2022MLREL-05: Automate managing data changes (p. 48)\nPerformance e\ufb03ciency pillar\n\u2022MLPER-04: Use a modern data architecture (p. 49)\nCost optimization pillar\n\u2022MLCOST-05: Use managed data labeling (p. 50)\n\u2022MLCOST-06: Use data wrangler tools for interactive analysis (p. 51)\n\u2022MLCOST-07: Use managed data processing capabilities (p. 52)\n\u2022MLCOST-08: Enable feature reusability (p. 52)\nSustainability pillar\n\u2022MLSUS-04: Minimize idle resources\u00a0 (p. 54)\n\u2022MLSUS-05: Implement data lifecycle policies aligned with your sustainability goals (p. 54)\n\u2022MLSUS-06: Adopt sustainable storage options (p. 55)\nModel development phase\nOperational excellence pillar\n\u2022MLOE-12: Automate operations through MLOps and CI/CD (p. 59)\n\u2022MLOE-13: Establish reliable packaging patterns to access approved public libraries (p. 61)\nSecurity pillar\n\u2022MLSEC-08: Secure governed ML environment (p. 61)\n\u2022MLSEC-09: Secure inter-node cluster communications (p. 62)\n\u2022MLSEC-10: Protect against data poisoning threats (p. 63)\nReliability pillar\n\u2022MLREL-06: Enable CI/CD/CT automation with traceability (p. 64)\n129", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "34920f57-fb59-4c92-9817-35fc4d302cd6": {"__data__": {"id_": "34920f57-fb59-4c92-9817-35fc4d302cd6", "embedding": null, "metadata": {"page_label": "130", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d53e0a0ae8a61eddb3183cb0ef86796312e52eef2e17dbf3d625c36fc45b597a", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar\n\u2022MLREL-07: Ensure feature consistency across training and inference (p. 65)\n\u2022MLREL-08: Ensure model validation with relevant data (p. 66)\n\u2022MLREL-09: Establish data bias detection and mitigation (p. 66)\nPerformance e\ufb03ciency pillar\n\u2022MLPER-05: Optimize training and inference instance types (p. 67)\n\u2022MLPER-06: Explore alternatives for performance improvement (p. 68)\n\u2022MLPER-07: Establish a model performance evaluation pipeline (p. 69)\n\u2022MLPER-08: Establish feature statistics (p. 70)\n\u2022MLPER-09: Perform a performance trade-o\ufb00 analysis (p. 71)\n\u2022MLPER-10: Detect performance issues when using transfer learning (p. 72)\nCost optimization pillar\n\u2022MLCOST-09: Select optimal computing instance size (p. 73)\n\u2022MLCOST-10: Use managed build environments (p. 73)\n\u2022MLCOST-11: Select local training for small scale experiments (p. 74)\n\u2022MLCOST-12: Select an optimal ML framework (p. 75)\n\u2022MLCOST-13: Use automated machine learning (p. 76)\n\u2022MLCOST-14: Use managed training capabilities (p. 76)\n\u2022MLCOST-15: Use distributed training (p. 77)\n\u2022MLCOST-16: Stop resources when not in use (p. 78)\n\u2022MLCOST-17: Start training with small datasets (p. 79)\n\u2022MLCOST-18: Use warm-start and checkpointing hyperparameter tuning (p. 79)\n\u2022MLCOST-19: Use hyperparameter optimization technologies (p. 80)\n\u2022MLCOST-20 - Setup budget and use resource tagging to track costs (p. 80)\n\u2022MLCOST-21: Enable data and compute proximity (p. 81)\n\u2022MLCOST-22: Select optimal algorithms (p. 82)\n\u2022MLCOST-23: Enable debugging and logging (p. 83)\nSustainability pillar\n\u2022MLSUS-07: De\ufb01ne sustainable performance criteria (p. 84)\n\u2022MLSUS-08: Select energy-e\ufb03cient algorithms (p. 85)\n\u2022MLSUS-09: Archive or delete unnecessary training artifacts (p. 86)\n\u2022MLSUS-10:\u00a0Use e\ufb03cient model tuning methods (p. 86)\nModel deployment phase\nOperational excellence pillar\n\u2022MLOE-14: Establish deployment environment metrics (p. 90)\n130", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "7e566163-3f76-45f6-9269-13216856f748": {"__data__": {"id_": "7e566163-3f76-45f6-9269-13216856f748", "embedding": null, "metadata": {"page_label": "131", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a24129e18e2488bd99f885c3069b4995ef53bfa5cb0b639f0d917189a23a143e", "text": "Machine Learning Lens AWS Well-Architected Framework\nSecurity pillar\nSecurity pillar\n\u2022MLSEC-11: Protect against adversarial and malicious activities (p. 91)\nReliability pillar\n\u2022MLREL-10: Automate endpoint changes through a pipeline (p. 92)\n\u2022MLREL-11: Use an appropriate deployment and testing strategy (p. 93)\nPerformance e\ufb03ciency pillar\n\u2022MLPER-11: Evaluate cloud versus edge options for machine learning deployment (p. 94)\n\u2022MLPER-12: Choose an optimal deployment option in the cloud (p. 95)\nCost optimization pillar\n\u2022MLCOST-24: Use appropriate deployment option (p. 97)\n\u2022MLCOST-25: Explore cost e\ufb00ective hardware options (p. 98)\n\u2022MLCOST-26: Right-size the model hosting instance \ufb02eet (p. 99)\nSustainability pillar\n\u2022MLSUS-11: Align SLAs with sustainability goals (p. 100)\n\u2022MLSUS-12: Use e\ufb03cient silicon (p. 101)\n\u2022MLSUS-13: Optimize models for inference (p. 102)\n\u2022MLSUS-14: Deploy multiple models behind a single endpoint (p. 102)\nModel monitoring phase\nOperational excellence pillar\n\u2022MLOE-15: Enable model observability and tracking (p. 104)\n\u2022MLOE-16: Synchronize architecture and con\ufb01guration, and check for skew across \nenvironments (p. 106)\nSecurity pillar\n\u2022MLSEC-12: Restrict access to intended legitimate consumers (p. 107)\n\u2022MLSEC-13: Monitor human interactions with data for anomalous activity (p. 108)\nReliability pillar\n\u2022MLREL-12: Allow automatic scaling of the model endpoint (p. 109)\n131", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "c552cc2c-8f7a-4d21-b1e6-06ad758bdd83": {"__data__": {"id_": "c552cc2c-8f7a-4d21-b1e6-06ad758bdd83", "embedding": null, "metadata": {"page_label": "132", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7031dfba44bdfefc55e75db0e82f8f812a781417fcc242f6569d1502d70d1f57", "text": "Machine Learning Lens AWS Well-Architected Framework\nPerformance e\ufb03ciency pillar\n\u2022MLREL-13: Ensure a recoverable endpoint with a managed version control strategy (p. 110)\nPerformance e\ufb03ciency pillar\n\u2022MLPER-13: Evaluate model explainability (p. 111)\n\u2022MLPER-14: Evaluate data drift (p. 112)\n\u2022MLPER-15: Monitor, detect, and handle model performance degradation (p. 112)\n\u2022MLPER-16: Establish an automated re-training framework (p. 113)\n\u2022MLPER-17: Review for updated data/features for retraining  (p. 115)\n\u2022MLPER-18: Include human-in-the-loop monitoring  (p. 115)\nCost optimization pillar\n\u2022MLCOST-27: Monitor usage and cost by ML activity (p. 116)\n\u2022MLCOST-28: Monitor Return on Investment for ML models (p. 117)\n\u2022MLCOST-29: Monitor endpoint usage and right-size the instance \ufb02eet (p. 117)\nSustainability pillar\n\u2022MLSUS-15: Measure material e\ufb03ciency (p. 118)\n\u2022MLSUS-16: Retrain only when necessary (p. 119)\n132", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6eb460ca-d2dc-410c-8f3a-04d290cf1146": {"__data__": {"id_": "6eb460ca-d2dc-410c-8f3a-04d290cf1146", "embedding": null, "metadata": {"page_label": "133", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "4c17b5448e4e80aef3a5283efacec5398349a8df44ad170cd3254a46b72c4bdf", "text": "Machine Learning Lens AWS Well-Architected Framework\nNotices\nCustomers are responsible for making their own independent assessment of the information in this \ndocument. This document: (a) is for informational purposes only, (b) represents current AWS product \no\ufb00erings and practices, which are subject to change without notice, and (c) does not create any \ncommitments or assurances from AWS and its a\ufb03liates, suppliers or licensors. AWS products or services \nare provided \u201cas is\u201d without warranties, representations, or conditions of any kind, whether express or \nimplied. The responsibilities and liabilities of AWS to its customers are controlled by AWS agreements, \nand this document is not part of, nor does it modify, any agreement between AWS and its customers.\n\u00a9 2023 Amazon Web Services, Inc. or its a\ufb03liates. All rights reserved.\n133", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ba69243e-3a12-42c9-aeca-d4406d19ffc3": {"__data__": {"id_": "ba69243e-3a12-42c9-aeca-d4406d19ffc3", "embedding": null, "metadata": {"page_label": "134", "file_name": "wellarchitected-machine-learning-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "174dc4a6a1ec955adb80f4acb00a3d44ba0482e11372de8c85cf3216aa539938", "text": "Machine Learning Lens AWS Well-Architected Framework\nAWS glossary\nFor the latest AWS terminology, see the AWS glossary in the AWS Glossary Reference.\n134", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2982bc50-a4e8-4841-b82f-b418d287760b": {"__data__": {"id_": "2982bc50-a4e8-4841-b82f-b418d287760b", "embedding": null, "metadata": {"page_label": "i", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "52452aa19548474a935d33ac62bc254d2918c2f566f625a3c98a26539358b8cc", "text": "SaaS Lens\nAWS Well-Architected Framework", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a22499e8-4915-443b-b21f-64b00fd32027": {"__data__": {"id_": "a22499e8-4915-443b-b21f-64b00fd32027", "embedding": null, "metadata": {"page_label": "ii", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b8bae0b380687e208c2b33626d265947c57db0872874716cb7e54944e699afbe", "text": "SaaS Lens AWS Well-Architected Framework\nSaaS Lens: AWS Well-Architected Framework\nCopyright \u00a9 2023 Amazon Web Services, Inc. and/or its a\ufb03liates. All rights reserved.\nAmazon's trademarks and trade dress may not be used in connection with any product or service that is not \nAmazon's, in any manner that is likely to cause confusion among customers, or in any manner that disparages or \ndiscredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may \nor may not be a\ufb03liated with, connected to, or sponsored by Amazon.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "60205bdb-ebc2-4602-a4b3-13b0eb2c82f0": {"__data__": {"id_": "60205bdb-ebc2-4602-a4b3-13b0eb2c82f0", "embedding": null, "metadata": {"page_label": "iii", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0306dc69cd85a30766cdde1a2620e009d06497a81bb494597f53d03dde4e82b3", "text": "SaaS Lens AWS Well-Architected Framework\nTable of Contents\n........................................................................................................................................................v\nAbstract and introduction...................................................................................................................1\nIntroduction..............................................................................................................................1\nCustom lens availability..............................................................................................................1\nDe\ufb01nitions .........................................................................................................................................2\nTenant......................................................................................................................................2\nSilo, Pool, and Bridge Models......................................................................................................2\nSaaS Identity.............................................................................................................................3\nTenant Isolation.........................................................................................................................3\nData Partitioning........................................................................................................................3\nNoisy Neighbor ..........................................................................................................................4\nTenant Onboarding....................................................................................................................4\nTenant Tiers..............................................................................................................................4\nTenant Activity and Consumption.................................................................................................4\nMetering and Billing ...........................................................................................................4\nTenant-Aware Operations............................................................................................................5\nGeneral design principles ....................................................................................................................6\nScenarios...........................................................................................................................................8\nServerless SaaS..........................................................................................................................8\nPreventing cross tenant access.............................................................................................9\nLayers hide tenant details.................................................................................................10\nAmazon EKS SaaS....................................................................................................................11\nFull stack isolation ...................................................................................................................14\nUni\ufb01ed onboarding, management, and operations................................................................15\nHybrid SaaS deployment...........................................................................................................16\nMulti-tenant microservices.........................................................................................................17\nTenant insights........................................................................................................................18\nPillars of the Well-Architected Framework...........................................................................................20\nOperational excellence..............................................................................................................20\nDe\ufb01nition ........................................................................................................................20\nBest practices..................................................................................................................21\nResources........................................................................................................................26\nSecurity...................................................................................................................................26\nDe\ufb01nition ........................................................................................................................26\nBest practices..................................................................................................................27\nResources.......................................................................................................................36\nReliability................................................................................................................................37\nDe\ufb01nition ........................................................................................................................37\nBest practices..................................................................................................................37\nResources........................................................................................................................41\nPerformance e\ufb03ciency..............................................................................................................41\nDe\ufb01nition ........................................................................................................................41\nBest practices..................................................................................................................42\nResources........................................................................................................................46\nCost optimization .....................................................................................................................47\nDe\ufb01nition ........................................................................................................................47\nBest practices..................................................................................................................47\nResources........................................................................................................................51\nSustainability...........................................................................................................................52\nDe\ufb01nition ........................................................................................................................52\nBest practices..................................................................................................................52\nResources........................................................................................................................56\nConclusion .......................................................................................................................................57\nContributors ....................................................................................................................................58\niii", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "ab2adc6a-e073-4b56-8a2a-34d06dfc0a31": {"__data__": {"id_": "ab2adc6a-e073-4b56-8a2a-34d06dfc0a31", "embedding": null, "metadata": {"page_label": "iv", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e72b36c16c3856a807ede7dd3463710aec6f6ac50cdefb6d04bb3947b4a91053", "text": "SaaS Lens AWS Well-Architected Framework\nDocument revisions..........................................................................................................................59\nNotices............................................................................................................................................60\niv", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "62e4cb50-d712-410e-a0eb-61701437e07a": {"__data__": {"id_": "62e4cb50-d712-410e-a0eb-61701437e07a", "embedding": null, "metadata": {"page_label": "v", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "89ff1ea9e00ba031919309ea76b5fe9ecdb2427461cd7a8f5f405a64ed5dfa0f", "text": "SaaS Lens AWS Well-Architected Framework\nThis whitepaper contains additional guidance not found in the SaaS Lens of the AWS Well-Architected \nTool.\nv", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2f0ea052-355b-4ed4-89e7-0326c33f7cf1": {"__data__": {"id_": "2f0ea052-355b-4ed4-89e7-0326c33f7cf1", "embedding": null, "metadata": {"page_label": "1", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "ffb3269f1f3e8bb6747cbf4b6593a3a366b321a0777d3876e1bf10197307d885", "text": "SaaS Lens AWS Well-Architected Framework\nIntroduction\nSaaS Lens\nPublication date: April 4, 2023  (Document revisions  (p. 59))\nThis paper describes the SaaS Lens for the AWS Well-Architected Framework, which enables customers \nto review and improve their cloud-based architectures and better understand the business impact \nof their design decisions. We address general design principles as well as speci\ufb01c best practices and \nguidance in \ufb01ve conceptual areas that we de\ufb01ne as the pillars of the Well-Architected Framework.\nNote\nThis whitepaper contains additional guidance not found in the SaaS Lens of the AWS Well-\nArchitected Tool.\nIntroduction\nThe AWS Well-Architected Framework helps you understand the pros and cons of decisions you make \nwhile building systems on AWS. By using the Framework you will learn architectural best practices for \ndesigning and operating reliable, secure, e\ufb03cient, and cost-e\ufb00ective systems in the cloud. It provides \na way for you to consistently measure your architectures against best practices and identify areas for \nimprovement. We believe that having well-architected systems greatly increases the likelihood of \nbusiness success.\nIn this \u201cLens\u201d we focus on how to design, deploy, and architect your multi-tenant software as a service \n(SaaS) application workloads in the AWS Cloud. For brevity, we have only covered details from the Well-\nArchitected Framework that are speci\ufb01c to SaaS workloads. You should still consider best practices \nand questions that have not been included in this document when designing your architecture. We \nrecommend that you read the AWS Well-Architected Framework whitepaper.\nThis document is intended for those in technology roles, such as chief technology o\ufb03cers (CTOs), \narchitects, developers, and operations team members. After reading this document, you will understand \nAWS best practices and strategies to use when designing architectures for SaaS applications.\nCustom lens availability\nCustom lenses extend the best practice guidance provided by AWS Well-Architected Tool. AWS WA Tool \nallows you to create your own custom lenses , or to use lenses created by others that have been shared \nwith you.\nTo determine if a custom lens is available for the lens described in this whitepaper, reach out to your \nTechnical Account Manager (TAM), Solutions Architect (SA), or AWS Support.\n1", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e5cf1c92-6363-4a9e-ae8a-e3fb5a75f60b": {"__data__": {"id_": "e5cf1c92-6363-4a9e-ae8a-e3fb5a75f60b", "embedding": null, "metadata": {"page_label": "2", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "98059c859ef939a3713df5ebad33924e76503e3f05ba46264790aad959c6fdbe", "text": "SaaS Lens AWS Well-Architected Framework\nTenant\nDe\ufb01nitions\nThe AWS Well-Architected Framework is based on six pillars: operational excellence, security, \nreliability, performance e\ufb03ciency, cost optimization, and sustainability. SaaS adds a new dimension \nof considerations to each of these pillars. The multi-tenant nature of SaaS applications, requires \narchitects to reconsider how they address security, operational e\ufb03ciency, stability, and agility of their \nSaaS environments. In this section, we will present an overview of the SaaS concepts that will be used \nthroughout this document. There are 10 areas you should consider when building a SaaS architecture.\nTopics\n\u2022Tenant (p. 2)\n\u2022Silo, Pool, and Bridge Models (p. 2)\n\u2022SaaS Identity (p. 3)\n\u2022Tenant Isolation (p. 3)\n\u2022Data Partitioning (p. 3)\n\u2022Noisy Neighbor  (p. 4)\n\u2022Tenant Onboarding (p. 4)\n\u2022Tenant Tiers (p. 4)\n\u2022Tenant Activity and Consumption (p. 4)\n\u2022Tenant-Aware Operations (p. 5)\nTenant\nA tenant is the most fundamental construct of a SaaS environment. As a SaaS provider building an \napplication, you are making this application available to your customers. Any customer that you sign up \nto use your SaaS environment is one of the tenants of your system. The sum total of all the customers \nusing your SaaS environment are the tenants. Imagine, for example, that your organization has created \nan accounting service that you want to make available to other companies that will use your service to \nmanage their businesses. Each one of these companies would be viewed as a tenant of your system.\nUpon signing up, a tenant will typically provide user information for the tenant administrator. This \ntenant administrator can then log into the system and con\ufb01gure it based on the needs of their business. \nThis includes having the ability to add users to a given tenant environment.\nThe software that is provided in this model is referred to as a multi-tenant SaaS system because each \nof the tenants of the service are consuming a single, shared system that supports the needs of these \ntenants through a uni\ufb01ed experience. An update to the system, for example, would typically be applied \nto all tenants of that system.\nSilo, Pool, and Bridge Models\nSaaS applications can be built with a variety of di\ufb00erent architectural models. Regulatory, competitive, \nstrategic, cost e\ufb03ciency, and market considerations all have some in\ufb02uence on the shape of your SaaS \narchitecture. At the same time, there are strategies and patterns that are applied when de\ufb01ning the \nfootprint of a SaaS application. These patterns fall into one of three categories\u2014silo, bridge, and pool.\nThe silo model refers to an architecture where tenants are provided dedicated resources. Imagine, for \nexample, as SaaS environment where each tenant of your system has a fully independent infrastructure \n2", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "855685cf-dbbd-4c93-ba41-47f7c349dc32": {"__data__": {"id_": "855685cf-dbbd-4c93-ba41-47f7c349dc32", "embedding": null, "metadata": {"page_label": "3", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "438a70bf8a7a473981ddd6af62b001d650a958c3470e1e57ef8b58c4ce4c5772", "text": "SaaS Lens AWS Well-Architected Framework\nSaaS Identity\nstack. Or, perhaps each tenant of your system has a separate database. When some or all of a tenant\u2019s \nresources are deployed in this dedicated fashion, we refer to this as a silo model. It\u2019s important to note \nthat\u2014even though the silo has dedicated resources\u2014a silo environment still relies on a shared identity, \nonboarding, and operational experience where all tenants are managed and deployed via a shared \nconstruct. This di\ufb00erentiates SaaS from a managed service model where customers might be running \nseparate versions of your product with separate onboarding, management, and operational experiences.\nIn contrast, the pool model  of SaaS refers to a scenario where tenants share resources. This is the \nmore classic notion of multi-tenancy where tenants rely on shared, scalable infrastructure to achieve \neconomies of scale, manageability, agility, and so on. These shared resources can apply to some or all of \nthe elements of your SaaS architecture, including compute, storage, messaging, etc.\nThe \ufb01nal pattern is the bridge model . Bridge  is meant to acknowledge the reality that SaaS businesses \naren\u2019t always exclusively silo or pool. Instead, many systems have a mixed mode where some of the \nsystem is implemented in a silo model and some is in a pooled model. For example, some microservices \nin your architecture might be implemented with silo and others might use pool. The regulatory pro\ufb01le of \na service\u2019s data and its noisy neighbor attributes might steer a microservice to a silo model. Meanwhile \nthe agility, access patterns, and cost pro\ufb01le of another microservice could tip it toward a pool model.\nSaaS Identity\nMost systems already rely on an identity provider for authentication. In the world of SaaS, we need to \nextend the notion of identity to incorporate tenancy into our de\ufb01nition of identity. This means that, after \nauthenticating a user, we need to know who the user is as well as which tenant that user is associated \nwith. This merging of the user identity with the tenant identity is referred to as a SaaS identity. This \nconcept is a foundational element of a SaaS architecture, providing the tenant context that is used to \nimplement the underlying multi-tenant policies and strategies that are part of a SaaS application.\nTenant Isolation\nTenant isolation is one of the foundational topics that every SaaS provider must address. As independent \nsoftware vendors (ISVs) make the shift toward SaaS and adopt a shared infrastructure model to \nachieve cost and operational e\ufb03ciency, they also have to take on the challenge of determining how \ntheir multi-tenant environments will ensure that each tenant is prevented from accessing another \ntenant\u2019s resources. Crossing this boundary in any form would represent a signi\ufb01cant and potentially \nunrecoverable event for a SaaS business.\nWhile the need for tenant isolation is viewed as essential to SaaS providers, the strategies and \napproaches to achieving this isolation are not universal. There are a wide range of factors that can \nin\ufb02uence how tenant isolation is realized in any SaaS environment. The domain, compliance, deployment \nmodel, and the selection of AWS services all bring their own unique set of considerations to the tenant \nisolation story.\nRegardless of how the isolation is implemented, each SaaS architecture needs to ensure that it has put \nin place the constructs that are needed to ensure that each tenant\u2019s resources have been e\ufb00ectively \nisolated.\nData Partitioning\nAs you look at di\ufb00erent architecture patterns for representing multi-tenant data, you must make choices \nabout how that data is organized. Will the data be stored in separate database, for example, or will it \n3", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6c446d7e-6a87-4955-8fe7-a496ad2a53ea": {"__data__": {"id_": "6c446d7e-6a87-4955-8fe7-a496ad2a53ea", "embedding": null, "metadata": {"page_label": "4", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "2e9ea086a0eb76b3b48b69c195b2185112b79cbe667807d54f37b8c6e18ddb4e", "text": "SaaS Lens AWS Well-Architected Framework\nNoisy Neighbor\nbe comingled in a shared construct? These multi-tenant storage mechanisms and patterns are typically \nreferred to as data partitioning.\nNoisy Neighbor\nNoisy neighbor is a term that is often applied to general architecture patterns and strategies. The idea \nbehind noisy neighbor is that a user of a system could place load on the system\u2019s resources that could \nhave an adverse e\ufb00ect on other users of the system. The end result could be that one user could degrade \nthe experience of another user.\nThis concept has expanded relevance in a multi-tenant environment where tenants may be consuming \nshared resources. Adding to the complexity here is that workloads in a multi-tenant environment can \nbe unpredictable. The combination heightens the need for SaaS architectures to employ their own \nstrategies that can manage and minimize the potential impacts of noisy tenants.\nTenant Onboarding\nSaaS applications rely on a frictionless model for introducing new tenants into their environment. This \noften requires the orchestration of a number of components to successfully provision and con\ufb01gure all \nthe elements needed to create a new tenant. This process, in SaaS architecture, is referred to as tenant \nonboarding. It\u2019s important to note that tenant onboarding can be initiated directly by tenants or as part \nof a provider-managed process.\nTenant Tiers\nA SaaS application is often architected to support a range of market segments, providing separate \npricing and experiences to a spectrum of customer pro\ufb01les. These pro\ufb01les are often referred to as tiers. \nSupporting the varying needs of these di\ufb00erent tiers means introducing architectural constructs that can \nshape the experience of each tier. These tiering models can in\ufb02uence the cost, operations, management, \nand reliability footprint of a SaaS solution.\nTenant Activity and Consumption\nIn multi-tenant SaaS environments, it\u2019s important to have visibility into how tenants are using your \napplication and imposing load on your system\u2019s architecture. Tracking this information at the tenant \nlevel allows you to assess your system\u2019s ability to e\ufb00ectively scale and support the constantly evolving \nworkloads being placed on your environment. The metrics and insights that are collected from a SaaS \nsystem are frequently referred to as tenant activity and consumption.\nMetering and Billing\nSaaS products are often sold in a pay-as-you-go model where the cost of a product is determined based \non the consumption pro\ufb01le of a customer. This model allows customers to have a pricing model that \nis more tightly coupled to the value and load they are placing on a SaaS system. In this mode, SaaS \nproviders will de\ufb01ne and introduce metering mechanism that will measure consumption. This metering \ndata is typically sent to a billing system that aggregates the billing information and generates a bill. \nConsumption-based pricing represents one model for pricing that can be combined with additional \npricing strategies (subscription, for example).\n4", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "bb46a5df-d5f2-457a-995d-47a978d431b2": {"__data__": {"id_": "bb46a5df-d5f2-457a-995d-47a978d431b2", "embedding": null, "metadata": {"page_label": "5", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c88b3292e91e00e1977450d63cf5513bad8ab74e65c051ec72d85a1afdebca4a", "text": "SaaS Lens AWS Well-Architected Framework\nTenant-Aware Operations\nTenant-Aware Operations\nThe operations experience for SaaS environments introduces the need for additional mechanisms and \ntooling that can be used to create tenant-aware insights into the activity and consumption patterns of \nindividual tenants and tiers. The idea here is that SaaS providers need to be able to view system activity \nand health through the lens of individual tenants and tenant tiers. This is essential to diagnosing and \nevaluating the trends and patterns of activity and consumption for individual tenants.\n5", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8d114a4e-2cb0-4873-936f-a2da6dcf9711": {"__data__": {"id_": "8d114a4e-2cb0-4873-936f-a2da6dcf9711", "embedding": null, "metadata": {"page_label": "6", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a6c8866c18a18798ea8d5f187e933dc6e07ac7a5efc5c4b7d7e236ba7a629084", "text": "SaaS Lens AWS Well-Architected Framework\nGeneral design principles\nThe Well-Architected Framework identi\ufb01es a set of general design principles to facilitate good design in \nthe cloud for SaaS applications:\n\u2022There\u2019s no one-size-\ufb01ts-all SaaS architecture: The needs of SaaS businesses, the nature of their \ndomain, their compliance requirements, the segments of their market, the nature of their solution\u2014\nall of these factors have a distinct in\ufb02uence on the architecture of a SaaS environment. Every SaaS \narchitecture should be surrounded with an operational and customer experience that realizes the \nagility and software as a service tenets that are core to succeeding as a SaaS o\ufb00ering. Regardless of \nhow the system is architected, the system should enable tenants to be onboarded, managed, and \noperated through a single pane of glass that allows the SaaS organization to achieve the agility and \neconomies of scale that are foundational to building a SaaS business.\n\u2022Decompose each service based on its multi-tenant load and isolation pro\ufb01le: If you\u2019re decomposing \nyour system into services, your decomposition strategy should consider how multi-tenant loads, tenant \ntiers, and isolation requirements will in\ufb02uence the services that are part of your system. In these \nscenarios, each service needs to be considered separately. Some services might be able to pool data, \nfor example, while others might need to silo the data they manage based on compliance or noisy \nneighbor considerations. You might also \ufb01nd that some services will be deployed in a silo model to \nenable tiering strategies. Premium tenants, for example, might have some services that are available in \na silo model as part of the value story of the premium tier.\n\u2022Isolate all tenant resources: The success of a SaaS system relies heavily on a security model that \nensures that tenant resources are always protected from any cross-tenant access. A robust SaaS \narchitecture will introduce isolation strategies across all layers of the architecture, providing speci\ufb01c \nconstructs that ensure that any attempt to access a tenant resource is valid for the current tenant \ncontext.\n\u2022Design for growth: The move to a SaaS model is often about growth for SaaS organizations. As you \nde\ufb01ne the architectural and operational footprint of your SaaS o\ufb00ering, you must continually be \nthinking about how your environment will be able to support an accelerating wave of new tenants. \nSaaS architects must build a highly agile, frictionless environment that can accommodate spikes in \ntenant onboarding without adding signi\ufb01cant operational overhead. The idea here is to allow for \ngrowth in your customer base that doesn\u2019t expand the operational or infrastructure footprint of your \nSaaS environment.\n\u2022Instrument, capture, and analyze tenant metrics: When you put multiple tenants into an \nenvironment\u2014especially a shared environment\u2014it can be challenging to have a clear view of how \ntenants are using your system. SaaS teams need to invest in metrics instrumentation that can surface \ninsights into the features tenants are using, the load they are putting on your system, the bottlenecks \nthey are facing, the cost pro\ufb01le of their activities, and so on. This data is core to analyzing tenant \ntrends that directly impact the business, architectural, and operational health of a SaaS company and \ninform its strategy.\n\u2022Onboard tenants through a single, automated, repeatable process: SaaS is all about agility. A \nkey piece of this agility story is the tenant onboarding process. A robust SaaS system will include a \nfrictionless, repeatable process for onboarding new tenants to your system. This promotes scale and is \ncore to enabling growth. It also ensures that new customers will have a faster path to value.\n\u2022Plan to support multiple tenant experiences: SaaS markets and customers don\u2019t all \ufb01t into a single \npro\ufb01le. SaaS companies often need to support a range of tenant pro\ufb01les that can place di\ufb00erent \ndemands on your architecture and operations. As a SaaS provider and architect, it\u2019s essential to model \nthese tenant personas and build a single environment that includes the constructs and mechanisms \nneeded to span a range of tenant experiences without requiring one-o\ufb00 versions of your product. It\u2019s \nimportant to identify the value boundaries of your system to enable the business to create tiers of \nyour o\ufb00ering that can reach multiple segments and promote a customer\u2019s advancement through these \ntiers.\n6", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8a69121f-1a40-443f-b0a7-0e170606c9ed": {"__data__": {"id_": "8a69121f-1a40-443f-b0a7-0e170606c9ed", "embedding": null, "metadata": {"page_label": "7", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3c9d38af95ed93b4bd6664414820b99f349fd4a0864f8bb8dfcf455e336486a3", "text": "SaaS Lens AWS Well-Architected Framework\n\u2022Support one-o\ufb00 requirements through global customization: SaaS agility and innovation are \nachieved by having a single environment that is run by all customers. Being able to update, manage, \nand operate all customers collectively is foundational to SaaS. The reality is, though, some customers \nmay request customizations. These customizations should be introduced as con\ufb01guration options \nthat are available to any customer. Keeping these features in the core of the o\ufb00ering enables a SaaS \ncompany to support one-o\ufb00 needs without undermining the agility, operational e\ufb03ciency, and \ninnovation goals of the business.\n\u2022Bind user identity to tenant identity: Every layer of your architecture is likely to need some notion \nof tenant context to be able to log data, record metrics, access data, and so on. This means that \ntenant context needs to become a \ufb01rst-class construct that can be resolved and easily accessed by \nthe layers of your application without invoking another service. The authentication and authorization \nexperience of your solution should bind the tenant identity (and potentially other tenant attributes) \nto the identity of the authenticated user. This will yield a SaaS identity  that is passed through all the \nlayers of your system, enabling easy access to tenant context.\n\u2022Align infrastructure consumption with tenant activity: The activity of tenants in a SaaS environment \nis often unpredictable. Which resources tenants are consuming, how they\u2019re consuming them, and \nwhen they are consuming them can vary signi\ufb01cantly. The number of tenants in your system can also \nchange regularly. While these factors can present scaling challenges, a robust SaaS architecture will \nemploy policies that limit over-provisioning and align an application\u2019s infrastructure consumption with \nthe real-time trends in tenant activity. This promotes tighter alignment between tenant workloads and \nthe cost pro\ufb01le of your overall SaaS infrastructure.\n\u2022Limit developer awareness of multi-tenant concepts: While tenancy will \ufb02ow though the layers of \nyour architecture, it should be your goal to limit the degree to which developers have exposure to \ntenancy. As a rule of thumb, a developer\u2019s experience writing a multi-tenant service should not be all \nthat di\ufb00erent from writing a service that has no notion of tenancy. If developers need to introduce \ntenancy throughout their code, this will make it challenging to manage and enforce compliance with \nyour application\u2019s multi-tenant policies and mechanisms. This means providing libraries and reusable \nconstructs to developers that hide the details of tenancy.\n\u2022SaaS is a business strategy\u2014not a technical implementation: SaaS environments and their \nunderlying technology choices are shaped directly by the agility, innovation, and competitive needs \nof the business. The emphasis and mindset here centers around the creation of a service experience \nfor customers that focuses on zero downtime, regular updates, and closer connection with customers. \nThis means designing an architectural and operational footprint that can promote continual evolution \nand rapid response to market demands. A technically solid architecture that doesn\u2019t enable agility, \ninnovation, and operational e\ufb03ciency will be unlikely to keep pace with the competitive landscape of \nthe market\u2014especially if you\u2019re competing with other SaaS providers.\n\u2022Create tenant-aware operational views: Operations teams are presented with a new set of challenges \nin a multi-tenant environment. While having a global view of a system\u2019s health and activity remains \nimportant in SaaS environments, a robust SaaS operational footprint will also include insights \ninto how speci\ufb01c tenants or tenant tiers are exercising your system. SaaS operations teams should \nconstruct dashboards and views that enable them to analyze and pro\ufb01le the activity and load of \nindividual tenants. Being able to view and troubleshoot usage through the lens of individual tenants is \nessential to building a proactive, e\ufb03cient multi-tenant operations experience.\n\u2022Measure the cost impact of individual tenants: The business, architects, and operations teams for \na SaaS company often need to have a clear picture of how tenants are impacting the cost footprint \nof a SaaS environment. For example, are tenants in the basic tier imposing higher costs than tenants \nin the premium tier? Are tenant consumption patterns or features changing the cost pro\ufb01le of \nyour environment? These are among the questions that can best be answered by have a clear view \ninto tenant cost pro\ufb01les. This is especially important to understand in environments where tenant \nresources are shared by multiple tenants. Collecting and surfacing this data often provides a SaaS \nbusiness with valuable insights that can shape the architecture and business model of a SaaS company.\n7", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8cc15a07-0c0a-446b-95db-8d0270d9ebfc": {"__data__": {"id_": "8cc15a07-0c0a-446b-95db-8d0270d9ebfc", "embedding": null, "metadata": {"page_label": "8", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e2ae575bccd5e3a9550d8934cc80c35fc4c0e7471a80bf9936e5b61ef819cf73", "text": "SaaS Lens AWS Well-Architected Framework\nServerless SaaS \nScenarios\nIn this section, we will cover a series of scenarios that represent common patterns and strategies that are \nused when designing and building SaaS solutions on AWS. We will present the assumptions we made for \neach of these scenarios, the common drivers for the design, and a reference architecture of how these \nscenarios are realized using AWS architecture constructs.\nTopics\n\u2022Serverless SaaS  (p. 8)\n\u2022Amazon EKS SaaS (p. 11)\n\u2022Full stack isolation  (p. 14)\n\u2022Hybrid SaaS deployment (p. 16)\n\u2022Multi-tenant microservices (p. 17)\n\u2022Tenant insights (p. 18)\nServerless SaaS\nThe move to a SaaS delivery model is accompanied by a desire to maximize cost and operational \ne\ufb03ciency. This can be especially challenging in a multi-tenant environment where the activity of tenants \ncan be di\ufb03cult to predict. Finding a mix of scaling strategies that align tenant activity with the actual \nconsumption of resources can be elusive. The strategy that works today might not work tomorrow.\nThese attributes make SaaS a compelling \ufb01t for a serverless model. By removing the notion of servers \nfrom your SaaS architecture, organizations are able to rely on managed services to scale and deliver the \nprecise amount of resources your application consumes. This simpli\ufb01es the architecture and operational \nfootprint of your application, removing the need to continually chase and manage scaling policies. This \nalso reduces the operational overhead and complexity, pushing more of operational responsibility to \nmanaged services.\nAWS o\ufb00ers a range of services that can be used to implement a serverless SaaS solution. The diagram in \nFigure 1 provides an example of a serverless architecture.\n8", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d628ee03-b299-4c6a-b21f-f770ee01651b": {"__data__": {"id_": "d628ee03-b299-4c6a-b21f-f770ee01651b", "embedding": null, "metadata": {"page_label": "9", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "ddb175054f48d07269dcb56dc7c0edecf76c61c3f39a67e6474aaccf911ddc9f", "text": "SaaS Lens AWS Well-Architected Framework\nPreventing cross tenant access\nFigure 1: Serverless SaaS architecture\nHere you\u2019ll see that the moving parts of a Serverless SaaS architecture aren\u2019t all that di\ufb00erent than a \nclassic serverless web application architecture. On the left of this diagram, you see that we have our web \napplication hosted and served from an Amazon S3 bucket (presumably using one of the modern client \nframeworks like React, Angular, etc.).\nIn this architecture, the application is leveraging Amazon Cognito as our SaaS identity provider. The \nauthentication experience here yields a token that includes our SaaS context that is conveyed via a JSON \nWeb Token (JWT). This token is then injected into our interactions with all downstream application \nservices.\nThe interaction with our serverless application microservices is orchestrated by the Amazon API Gateway. \nThe gateway plays multiple roles here. It validates incoming tenant tokens (via a Lambda authorizer), it \nmaps each tenant\u2019s requests to microservices, and it can be used to manage the SLAs of di\ufb00erent tenant \ntiers (via usage plans).\nYou\u2019ll also see that we\u2019ve represented a series of microservices here that are placeholders for the various \nservices that would implement the multi-tenant IP of your SaaS application. Each microservice here is \ncomposed from one or more Lambda functions that implement the contract of your microservice. In \nalignment with microservices best practices, these services also encapsulate the data that they manage. \nThese services rely on the incoming JWT token to acquire and apply tenant context wherever it is \nneeded.\nWe\u2019ve also shown storage here for each microservice. To conform to microservice best practices, each \nmicroservice owns the resources that it manages. A database, for example, cannot be shared by two \nmicroservices. SaaS also adds a wrinkle here, since the multi-tenant representation of data can change \non a service-by-service basis. One service may have separate databases for each tenant (silo) while \nanother might comingle the data in the same table (pool). The storage choices you make here are meant \nto be driven by compliance, noisy neighbor, isolation, and performance considerations.\nFinally, on the right-hand side of this diagram, you\u2019ll see a series of shared services. These services \ndeliver all the functionality that is shared by all of the tenants that are running in the left-hand side of \nthe diagram. These services represent common services that are typically built as separate microservices \nthat are needed to onboard, manage, and operate tenants.\nMore information on general serverless well-architected best practices can be found in the Serverless \nApplications Lens whitepaper .\nPreventing cross tenant access\nEach SaaS architecture must also consider how it will prevent tenants from accessing the resources of \nanother tenant. Some wonder about the need to isolate tenants with AWS Lambda since, by design, only \none tenant can ever be running a Lambda function at a given moment in time. While this is true, our \nisolation must also consider ensuring that a tenant running a function is not accessing other resources \nthat might belong to another tenant.\nFor SaaS providers, there are two basic approaches to implementing isolation in a serverless SaaS \nenvironment. This \ufb01rst option follows the silo pattern, deploying a separate set of Lambda functions \nfor each tenant. With this model, you\u2019ll de\ufb01ne an execution role for each tenant and deploy separate \nfunctions for each tenant with their execution role. This execution role will de\ufb01ne which resources are \naccessible to a given tenant. You might, for example, deploy a collection of premium tier tenants in this \nmodel. However, this can be di\ufb03cult to manage and may come up against account limits (depending on \nhow many tenants your system supports).\nThe other option here aligns more with the pool model. Here, functions are deployed with an execution \nrole that has a scope that\u2019s broad enough to accepts calls from all tenants. In this mode, you must apply \n9", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "cc100d8a-9eb9-4264-a6a6-6fdb2e8a1bf4": {"__data__": {"id_": "cc100d8a-9eb9-4264-a6a6-6fdb2e8a1bf4", "embedding": null, "metadata": {"page_label": "10", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "ef0900c499873308c0b048175f6b26cf811c646207b8565a771726ccd3d2b212", "text": "SaaS Lens AWS Well-Architected Framework\nLayers hide tenant details\nisolation scoping at runtime in the implementation of your multi-tenant functions. The diagram in Figure \n2 provides an example of how this would be addressed.\nFigure 2: Isolation in a serverless environment\nIn this example, you\u2019ll see that we have three tenants accessing a set of Lambda functions. Because these \nfunctions are being shared, they are deployed with an execution role that covers all tenants. Within \nthe implementation of these functions, our code will use the context of the current tenant (supplied \nvia a JWT) to acquire a new set of tenant-scoped credentials from AWS Security Token Service (AWS \nSTS). Once we have these credentials, they can be used to access resources with tenant context. In this \nexample, we\u2019re using these scoped credentials to access storage.\nIt\u2019s important to note that this model does push part of the isolation model into the code of your \nLambda functions. There are techniques (function wrappers, for example) that can introduce this concept \noutside the view of developers. The details of acquiring these credentials can also be moved to a Lambda \nlayer to make this a more seamless, centrally managed construct.\nLayers hide tenant details\nOne of our goals with any SaaS architecture is to limit developer awareness of tenant details. In \nserverless SaaS environments, you can use Lambda layers as a way to create shared code that can \nimplement multi-tenant policies outside the view of developers.\nThe diagram in Figure 3 provides an example of how Lambda layers can be used to address these multi-\ntenant concepts. Here you\u2019ll see that we have two separate microservices (Product and Order) that have \na need to publish log and metrics data. The key detail here is that both services need to inject tenant \ncontext into their log messages and metric events. However, it would be less than ideal to have each \nservice implementing these policies on their own. Instead, we\u2019ve introduced a layer that includes code \nthat manages the publishing of this data.\n10", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "34c53004-df1e-415a-a1b3-523668a4ee94": {"__data__": {"id_": "34c53004-df1e-415a-a1b3-523668a4ee94", "embedding": null, "metadata": {"page_label": "11", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "cd771fce59faeea8893d8d535766701736e2966150a8ee4f11af6f6e6e75aa75", "text": "SaaS Lens AWS Well-Architected Framework\nAmazon EKS SaaS\nFigure 3: Lambda layers hide away tenant details\nYou\u2019ll notice that our layer includes logging and metrics helpers that accept a JWT token. This allows \neach microservice to simply call these functions and supply the token without any concern for which \ntenant they are working with. Then, within the layer, the code uses the JWT token to resolve the tenant \ncontext and inject it into the log messages and metric events.\nThis is just a snippet of how layers can be applied to hide tenant context. The real value is that the \npolicies and mechanisms for injecting tenant context are completely removed from the developer \nexperience. They\u2019re also updated, versioned, and deployed separately. This allows these policies to be \nmore centrally managed in your environment without introducing separate microservices that could add \nlatency and create bottlenecks.\nAmazon EKS SaaS\nFor many SaaS providers, the pro\ufb01le of Amazon Elastic Kubernetes Service (Amazon EKS) represents a \ngood \ufb01t with their microservices development and architectural goals. It provides a way to build and \ndeploy multi-tenant microservices that can help them realize their agility, scale, cost, and operational \ngoals without requiring a complete shift in their development tooling and mindset. The rich community \nof Kubernetes tools and solutions also o\ufb00ers SaaS developers a range of di\ufb00erent options for building, \nmanaging, securing, and operating their SaaS environments.\nFor container-based environments, much of the architecture is focused on how to successfully ensure \nthat we\u2019re preventing cross-tenant access. While there can be a temptation to allow tenants to share \ncontainers, this presumes that tenants would be comfortable with a notion of soft multi-tenancy. For \nmost SaaS environments, though, the isolation requirements demand a more robust implementation of \nisolation.\nThese isolation factors can have a signi\ufb01cant impact on the architectural model that gets built with \nAmazon EKS. The general guidance for building SaaS architectures with Amazon EKS is to prevent any \nsharing of containers across tenants. While this adds complexity to the footprint of the architecture, it \naddresses the fundamental need to ensure that we have created an isolation model that will address the \ndomain, compliance, and regulatory needs of multi-tenant customers.\nLet\u2019s look at a sample architecture to see the fundamental elements of a SaaS Amazon EKS environment. \nSince there are lots of moving parts to this solution, let\u2019s start by looking at the shared services that are \nused to support the core, horizontal concepts that span all of our tenants (shown in Figure 4).\n11", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8488713f-0dd7-48de-b9e1-af422da6431d": {"__data__": {"id_": "8488713f-0dd7-48de-b9e1-af422da6431d", "embedding": null, "metadata": {"page_label": "12", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "81d439f7403d8be8dd10335eee9a05b40ad769ac79738bff3ac55a9b50675485", "text": "SaaS Lens AWS Well-Architected Framework\nAmazon EKS SaaS\nFirst, you\u2019ll notice that we have the foundational elements that are part of any highly available, highly \nscalable AWS architecture. The environment includes a VPC that consists of three Availability Zones. \nRouting of inbound tra\ufb03c from tenants is managed by Amazon Route\u00a053, which is con\ufb01gured to direct \nincoming application requests to the endpoint de\ufb01ned by our NGINX ingress controller. The controller \nenables selected routing within our Amazon EKS cluster that is essential to the multi-tenant routing that \nyou\u2019ll see below.\nFigure 4: Amazon EKS SaaS shared services architecture\nThe services running in the Amazon EKS cluster represent a sampling of a few of the common services \nthat are typically part of a SaaS environment. Registration is used to orchestrate the onboarding of \nnew tenants. Tenant management manages the state and attributes of all the tenants in the system, \nstoring this data in an Amazon DynamoDB table. User management provides the basic operations to add, \ndelete, enable, disable, and update tenants. The identities it manages are stored in Amazon Cognito. \nAWS CodePipeline is also included to represent the tooling that is used to provision each new tenant that \nis onboarded to the system.\nThis architecture only represents the foundational elements of our SaaS environment. We now need \nto look at what it means to introduce tenants into this environment. Given the isolation considerations \ndescribed previously, our Amazon EKS environment will create separate namespaces for each tenant and \nsecure those namespaces to ensure that we have a robust tenant isolation model.\n12", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e34387b6-51a2-480e-aafa-1f0e7f957ec9": {"__data__": {"id_": "e34387b6-51a2-480e-aafa-1f0e7f957ec9", "embedding": null, "metadata": {"page_label": "13", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "9b640d7052290ea9330f08be17584cf395fa2014625ca5654feba611d620fab5", "text": "SaaS Lens AWS Well-Architected Framework\nAmazon EKS SaaS\nFigure 5: Deploying tenant environments in Amazon EKS\nThe diagram in Figure 5 provides a view of these namespaces within our SaaS architecture. On the \nsurface, this architecture looks very much like the previous baseline diagram. The key di\ufb00erence is that \nwe\u2019ve deployed the services that are part of our application into separate namespaces. In this example, \nthere are two tenants with distinct namespaces. Within each, we have deployed some sample services \n(Order and Product).\nEach of the tenant namespaces are provisioned by the registration service that is shown above. This \nwould use continuous delivery services (like AWS CodePipeline) to kick-o\ufb00 a pipeline that creates the \nnamespace, deploys the services, creates tenant resources (databases, etc.), and con\ufb01gures the routing. \nThis is where the ingress controller comes into play. Each provisioned namespace creates a separate \ningress resource for each of the microservices in that namespace. This enables tenant tra\ufb03c to be routed \nto the appropriate tenant namespace.\nWhile namespaces allow you to have clear boundaries between the tenant resources in your Amazon EKS \ncluster, these namespaces are more of a grouping construct. The namespace alone does not ensure that \nyour tenant loads are protected from cross-tenant access.\nTo enhance the isolation story of our Amazon EKS environment, we\u2019ll need to introduce di\ufb00erent security \nconstructs that can restrict the access of any tenant running in a given namespace. The diagram in Figure \n6 provides a high-level illustration of an approach you can take to control the experience of each tenant.\n13", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "546ad69f-ddc3-45af-9994-3828fb9247eb": {"__data__": {"id_": "546ad69f-ddc3-45af-9994-3828fb9247eb", "embedding": null, "metadata": {"page_label": "14", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "9b75e68c0951fcc5e105f32835d7a37bfdf4cd66065f0fe6a4b36d151a2c7e46", "text": "SaaS Lens AWS Well-Architected Framework\nFull stack isolation \nFigure 6: Isolating tenant resources\nThere are two speci\ufb01c constructs introduced here. At the namespace level, you\u2019ll see that we have \ncreated separate pod security policies. These are native Kubernetes networking security policies that can \nbe attached to a policy. In this example, these policies are used to limit network tra\ufb03c between tenant \nnamespaces. This represents a coarse-grained way to prevent one tenant from accessing the compute \nresources of another tenant.\nIn addition to securing the namespaces, you also must ensure that the resources accessed by the services \nrunning in a namespace are restricted. In this example, we have two examples of isolation. The Order \nmicroservice uses a table per tenant model (silo) and has IAM policies that restrict access to a speci\ufb01c \ntenant. The Product microservice uses a pooled model where tenant data is comingled and relies on an \nIAM policy that\u2019s applied to each item to restrict tenant access.\nFull stack isolation\nSaaS organizations are motivated by the economies of scale that come with sharing infrastructure \nresources across tenants. At the same time, there are real-world factors that might result in a SaaS \narchitecture where some or all of the tenants within your environment require dedicated (siloed) \ninfrastructure. Compliance, noisy neighbor, tiering strategies, legacy technologies\u2014these are among the \nlong list consideration that could lead you to o\ufb00ering tenants their own infrastructure. This is referred to \nas a siloed or full stack isolation SaaS.\nThis approach is frequently mistaken for a managed service provider (MSP) where a company\u2019s product \nis installed and managed on a one-o\ufb00 basis for individual customers. This approach, while valid, does \nnot align with the SaaS tenets. The key to a SaaS model is to adopt a value system where all tenants are \nmanaged and operated through a single, uni\ufb01ed experience. This means that every tenant is running the \nsame version of the software, they all get deployments at the same time, they are all onboarded through \nthe same process, and they are all managed through a single operational experience, which applies to all \ntenants.\nThis approach doesn\u2019t deliver the cost e\ufb03ciencies of a shared infrastructure model (pool). Its distributed \nnature can also make operations and deployment more complex. Still, done right, a full stack model can \nstill achieve the agility, innovation, and operational e\ufb03ciency goals that are central to the SaaS mindset.\nThe diagram in Figure 7 provides a clearer picture of the full stack isolation (silo) model. Each tenant \nenvironment in this model is straightforward. You\u2019ll see here that we\u2019ve provided a separate VPC for \neach tenant. These VPCs hold the full isolated stack that will be used by each tenant. The compute \nand storage constructs could be composed from any combination of AWS services. The key is that each \ntenant environment is meant to have the same infrastructure con\ufb01guration and the same version of your \nproduct. So, adding new tenants is as simple as provisioning another VPC with the same infrastructure \nfootprint for each tenant.\nYou\u2019ll also notice that this model use Amazon Route\u00a053 to route the incoming tra\ufb03c to the appropriate \nVPC. The routing relies on a model where subdomains are assigned to each tenant. This is a very \ncommon pattern in SaaS environments. This routing can also be achieved by inspecting the contents \nof a tenant JWT token, determining their tenant context, and triggering routing rules through an \ninjected tenant header. This approach, however, can push account limits and might require tuning to \naddress the latency of a runtime resolution of a tenant\u2019s identity. Still, it is a valid option for some SaaS \nenvironments.\n14", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0430fc8d-6a26-497f-898e-03b0a85b81e3": {"__data__": {"id_": "0430fc8d-6a26-497f-898e-03b0a85b81e3", "embedding": null, "metadata": {"page_label": "15", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "2eacfa987ba02e00c6cc050d3a0da5382a17ffe52d2a9ef1d7b0fc67521743eb", "text": "SaaS Lens AWS Well-Architected Framework\nUni\ufb01ed onboarding, management, and operations\nFigure 7: Full stack (silo) isolation\nWhile this example illustrates a VPC-per-tenant model, there are other architectures that can be used \nto implement the full stack model. Some organizations might choose to use an account-per-tenant \nmodel where each tenant environment is deployed in a separate provisioned account. The option you \nchoose will vary depending on the number of tenants you need to support and the overall management \nexperience that you\u2019re targeting. In some cases, the number of tenants you need to support could exceed \nthe number of VPCs that can be created within an AWS account.\nUni\ufb01ed onboarding, management, and operations\nThe real SaaS elements of the full stack isolation (silo) model come in when we look at the onboarding, \nmanagement, and operations of this experience. To realize the full value proposition of SaaS, this \nmodel must introduce a collection of services that can be used to manage and operate all of the tenant \nenvironments.\nThe diagram in Figure 8 provides a view of these extra layers of services. What we introduce here is an \nentirely separate set of services that are built around the needs of the SaaS provider\u2019s administration and \nmanagement experience.\n15", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "39d46e22-8060-498b-8ba2-838913edcc37": {"__data__": {"id_": "39d46e22-8060-498b-8ba2-838913edcc37", "embedding": null, "metadata": {"page_label": "16", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "64118f6885b7e309bc8a5845c85966d7a39dd1aaef8981201295f6155a60e4b6", "text": "SaaS Lens AWS Well-Architected Framework\nHybrid SaaS deployment\nFigure 8: Managing full stack isolated environments\nWhile the stack of our tenant environments is shaped by domain, legacy, and other requirements, the \nstack of our management experience is completely driven by the goals and usage patterns that can be \nquite di\ufb00erent than those that apply to tenants.\nThis management very much conforms to a classic serverless SaaS application model. You\u2019ll see that \nwe have two entry points into our administration environment. One is the Admin application that \nuses Amazon CloudFront and Amazon S3 to serve up the application experience that is used by SaaS \nadministrators to manage and con\ufb01gure tenant environment. You\u2019ll also see the signup and API \nexperience highlighted here. This represents the ability to trigger tenant onboarding via a public API \nrequest. This API can also be part of a SaaS provider\u2019s developer API experience.\nFinally, we\u2019ve also highlighted a collection of microservices that represent the shared services that are \nused to orchestrate the onboarding, management, and operations experience. We\u2019ve chosen Lambda \nas the model for our microservices, based on its management, scale, and cost e\ufb03ciency model. These \nservices could be implemented with other AWS compute services.\nOn the right-hand side of the diagram, you\u2019ll see the individual VPCs that represent each of our tenant \nenvironments. In this VPC-per-tenant model, you\u2019ll need to open a valid path for your management \nplane to be able to con\ufb01gure and access the resources of these tenant environments. AWS o\ufb00ers a \nnumber of options for this, including AWS PrivateLink, VPC peering, and Amazon EventBridge. The \noption you choose will depend on the nature of the management experience you are building.\nHybrid SaaS deployment\nThe needs of customers in SaaS environments can vary signi\ufb01cantly for a business. While there are \nsigni\ufb01cant cost and operational advantages to building a SaaS solution that has all customers running \nin shared infrastructure model (pool), there might be times when customers are not willing to share \ninfrastructure resources with other tenants.\nThis need for one-o\ufb00 customers to have their own environment can be challenging for SaaS providers. \nWhile SaaS providers feel the business pressure to support this model, they also know that supporting \nvariations of this nature will undermine the overall SaaS goals of the business. Each new one-o\ufb00 \ncustomer can add operational overhead and complexity. As each new customer is added in this model, \nyou quickly \ufb01nd yourself sliding further away from the innovation, agility, and cost e\ufb03ciency bene\ufb01ts \nthat come from a shared infrastructure model.\n16", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "b11457ea-fb77-40d4-8815-d72ef7af070b": {"__data__": {"id_": "b11457ea-fb77-40d4-8815-d72ef7af070b", "embedding": null, "metadata": {"page_label": "17", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "029298d085c54f3996391a57cde7e321ddc35f9e3df6a9e17e9306458d3ae1c3", "text": "SaaS Lens AWS Well-Architected Framework\nMulti-tenant microservices\nThere are, however, architectural and operational strategies that can embrace this model without fully \ncompromising your SaaS vision. The diagram in Figure 9 provides a conceptual view of how you could \naddress this challenge.\nFigure 9: Hybrid deployment model\nIn this diagram, you\u2019ll notice that we have two separate deployments of our SaaS environment. The left \nside is deployed in a pooled model with shared infrastructure. The majority of our tenants are running \nin this environment. However, on the right side, we\u2019ve deployed a separate copy of the multi-tenant \nenvironment that is hosting one tenant (tenant 4).\nThe key to this strategy is that both environments (the left and right) are running the same  version of \nthe SaaS application. Any new changes or updates are applied to both environments at the same time. \nMore importantly, you\u2019ll see that we have a single, uni\ufb01ed management experience that spans both \nof these environments. Onboarding, identity, metering, and billing are shared and common to both \nenvironments.\nThis shared experience allows a SaaS organization to manage and operate these environments through a \nsingle pane of glass. By \ufb01tting these one-o\ufb00 tenants into this model, you\u2019re able to minimize the impact \nto the overall agility and operational e\ufb03ciency of your SaaS environment. This model impacts cost \ne\ufb03ciency and adds operational complexity. However, it can represent a reasonable compromise for many \nSaaS companies.\nMulti-tenant microservices\nThe microservices running in a multi-tenant environment must address additional considerations. These \nmicroservices must be able to reference and apply tenant context within each service. At the same time, \nit\u2019s also our goal to limit the degree to which developers need to introduce any tenant awareness into \ntheir code.\nTo achieve this goal, SaaS microservices\u2014regardless of their compute model\u2014should introduce libraries, \nmodules, and shared constructs that can push tenant-speci\ufb01c processing into code. These constructs hide \nthe policies and mechanisms that are needed to resolve and apply tenant context.\nThe diagram in Figure 10 provides a view into how you can streamline multi-tenant development of \nyour microservices. The key idea here is that we\u2019ve taken anything that relies on tenant context and used \nlibraries to apply multi-tenant policies.\n17", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "dbba49b7-3dbc-4cc7-b743-7abff4a2ad6c": {"__data__": {"id_": "dbba49b7-3dbc-4cc7-b743-7abff4a2ad6c", "embedding": null, "metadata": {"page_label": "18", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "124b1314de729cc7ecb58d310a94392a4ea61875274bbf0131d6f2deeed95bf8", "text": "SaaS Lens AWS Well-Architected Framework\nTenant insights\nThis example illustrates a number of scenarios where a SaaS microservice might need access to tenant \ncontext. The \ufb02ow starts with a call into our microservice with a request to get a list of products. \nSomewhere in the code of our service, your service logs a message. The microservice developer simply \nlogs a message to a logging wrapper. This wrapper gets the tenant context from the Token Manager and \ninjects that context into our message that is, in this example, published to Amazon S3. Our log policies \nand how tenant data lands in logs in managed by whichever policies we choose to include in our logging \nhelper.\nThis theme continues across the rest of the experience here. Our call to getProducts() \ufb01rst gets the \ntenant identi\ufb01er from the Token Manager. It then uses this context to get tenant-scoped credentials from \nan isolation manager before using these credentials to get the product data from DynamoDB.\nFigure 10: Developing multi-tenant microservices\nFinally, our service records a metric (perhaps execution time) using the same mechanism for resolving the \ntenant identi\ufb01er and injecting tenant context into the metrics messages.\nThe practices outlined here are not meant to introduce heavyweight constructs into your microservices. \nThis abstraction of tenancy follows the general design practices of pushing common concepts into \nshared code. It\u2019s important to note that all of the concepts represented in this diagram are running \nwithin the context of a single microservice. Each of these blocks simply represent code that is reused by \nyour microservice. Breaking these concepts into separate services would add latency and complexity that \nwould typically not be justi\ufb01ed.\nTenant insights\nAs companies move into a multi-tenant model, it becomes increasingly challenging to capture and \nsurface insights into how tenants are using your application. This is especially true with the resources of \nyour SaaS environment that are shared by tenants.\nAt the same time, with all your tenants potentially running in one shared environment, the ability to \nhave a clear view into tenant activity and consumption is essential to building a robust SaaS o\ufb00ering. \nKnowing what features of the product tenants are using, knowing how tenants are pushing the \narchitecture of your environment, and having visibility into how di\ufb00erent tiers of tenants are scaling are \namong the insights that SaaS companies need to be able to e\ufb00ectively operate a healthy SaaS business.\n18", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6bcadbeb-eb95-4980-89e0-d1271f16694e": {"__data__": {"id_": "6bcadbeb-eb95-4980-89e0-d1271f16694e", "embedding": null, "metadata": {"page_label": "19", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "4199a0ba5de13fd47e2a4266911251a182f656d0b3480c970871cd24b0a6ef46", "text": "SaaS Lens AWS Well-Architected Framework\nTenant insights\nThe scope of SaaS metrics is intentionally broad. This is because metrics are consumed in multiple \ncontexts by di\ufb00erent roles within a SaaS organization. This means you need to be thinking beyond the \ninfrastructure health. SaaS metrics often include business agility, feature consumption, microservice \nactivity, scaling trends, and so on. The idea is to capture and correlate tenant and tier usage trends with \napplication and consumption activity.\nYou can imagine having various dashboards for the di\ufb00erent roles that would consume this data. \nA product manager, for example, might want insights into feature-oriented metrics. Meanwhile, an \noperations person might be using this data to assess the health and consumption trends of individual \ntenants and tiers.\nFigure 11: Ingest and visualize SaaS metrics\nThe architecture for capturing and surfacing this data is relatively straightforward. It includes all \nthe mechanisms needed to convey, publish, ingest, aggregate, and visualize these SaaS metrics. The \ndiagram in Figure 11 provides a view of an architecture that could be used to building your SaaS metrics \nenvironment on AWS.\nThe sources of the metric data you\u2019ll want to capture could be somewhat diverse. As the diagram \nsuggests, your solution might need to capture some of the metrics from native AWS sources \n(CloudWatch, for example). However, a signi\ufb01cant portion of this data will come from the code that you \ninstrument into your SaaS application. It\u2019s here that you\u2019ll want to invest in publishing metrics that best \ncapture the insights that can maximize the business and operational value of your domain\u2019s data.\nThe data from these sources is typically represented with a common schema that can represent \nthe di\ufb00erent types of consumption in your application (counts, durations, features, etc.). In this \nexample, this data is ingested with Amazon Kinesis Data Firehose, which publishes the data to Amazon \nRedshift. Finally, Amazon QuickSight is used to build the di\ufb00erent dashboards that are used across the \norganizations to view the trends of tenants and tiers.\n19", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "266fe314-180c-43db-861f-0e0bd4443b78": {"__data__": {"id_": "266fe314-180c-43db-861f-0e0bd4443b78", "embedding": null, "metadata": {"page_label": "20", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b20f4a85032bcfaeb4a69c71a9cd45c33908c72433ab841ad9473fb4a793c27b", "text": "SaaS Lens AWS Well-Architected Framework\nOperational excellence\nPillars of the Well-Architected \nFramework\nThis section describes each of the pillars, and includes de\ufb01nitions, best practices, questions, \nconsiderations, and key AWS services that are relevant when architecting solutions for multi-tenant SaaS \napplications.\nFor brevity, we have only included questions that are speci\ufb01c to SaaS workloads. Questions that have \nnot been included in this document should still be considered when designing your architecture. We \nrecommend that you read the AWS Well-Architected Framework whitepaper.\nPillars\n\u2022Operational excellence pillar (p. 20)\n\u2022Security pillar (p. 26)\n\u2022Reliability pillar (p. 37)\n\u2022Performance e\ufb03ciency pillar (p. 41)\n\u2022Cost optimization pillar  (p. 47)\n\u2022Sustainability pillar (p. 52)\nOperational excellence pillar\nThe operational excellence pillar includes the ability to run and monitor systems to deliver business value \nand to continually improve supporting processes and procedures.\nThe operational excellence pillar provides an overview of design principles, best practices, and questions. \nYou can \ufb01nd prescriptive guidance on implementation in the Operational Excellence Pillar whitepaper.\nTopics\n\u2022De\ufb01nition  (p. 20)\n\u2022Best practices (p. 21)\n\u2022Resources (p. 26)\nDe\ufb01nition\nThere are three best practice areas for operational excellence in the cloud:\n\u2022Prepare\n\u2022Operate\n\u2022Evolve\nOperations teams need to understand their business and customer needs so that they can e\ufb00ectively and \ne\ufb03ciently support business outcomes. Operations creates and uses procedures to respond to operational \n20", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "66e071f2-2645-4ee4-a05d-c3f66eaa0659": {"__data__": {"id_": "66e071f2-2645-4ee4-a05d-c3f66eaa0659", "embedding": null, "metadata": {"page_label": "21", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "60aea9a95746bbef9f117d10f211273a82ccc06c1318b1caeca0078ffacd63e4", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nevents and validates their e\ufb00ectiveness to support business needs. Operations collects metrics that are \nused to measure the achievement of desired business outcomes. Everything continues to change\u2014your \nbusiness context, business priorities, customer needs, etc. It\u2019s important to design operations to support \nevolution over time in response to change and to incorporate lessons learned through their performance.\nBest practices\nTopics\n\u2022Prepare (p. 21)\n\u2022Operate  (p. 21)\n\u2022Evolve (p. 25)\nPrepare\nThere are no operational practices unique to SaaS applications.\nOperate\nSaaS OPS 1: How are you able to e\ufb00ectively monitor and manage the operational health of a multi-\ntenant environment?\nIn multi-tenant environments, where all of an organization\u2019s customers might be deployed in a shared \ninfrastructure model, the need for a more detailed operational view of health is often essential to the \nsuccess and growth and of a SaaS business. Any outage or health issue has the potential of cascading \nacross all the tenants of your system and taking a SaaS service down for all customers. This means \nthat SaaS organizations must place a premium on creating an operational experience that will enable \noperations teams to e\ufb00ectively analyze and respond to continually shifting workloads of a SaaS \nenvironment.\nBuilding a robust multi-tenant operational experience requires SaaS companies to create or customize \ntooling to introduce the more granular views of health and activity that are needed in a SaaS \nenvironment. This often means using a combination of existing tools and custom solutions to create \nan experience that supports tenancy and tenant tiers as \ufb01rst-class concepts within the operational \nexperience.\nA SaaS operations dashboard, for example, should include views of health that are presented through \nthe lens of tenants and tenant tiers. While viewing the global view of health is still part of this \nexperience, a SaaS operations team also needs the ability to see the health and activity of tenants. \nThe diagram in Figure 12 provides a conceptual view of one way a SaaS provider might surface tenant \nactivity as a \ufb01rst-class construct.\nThe simpli\ufb01ed view in this diagram highlights a few samples of operational views that would add value \nin multi-tenant environment. At the top-left of the page, you\u2019ll see a view of health for the most active \ntenants. The color indicators shown could focus attention to tenants that might be experiencing issues \nthat, when looking at a global view of health, have not been surfaced. This allows operations to react \nand respond proactively to any issues that might not be entirely apparent to a tenant.\n21", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8aebb037-bc89-4ee5-aabe-45a8ec55e795": {"__data__": {"id_": "8aebb037-bc89-4ee5-aabe-45a8ec55e795", "embedding": null, "metadata": {"page_label": "22", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "07abf0d8d8c01071644084dea9dc3ed0b5f8b11800fe378b3d74ae710c069614", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nFigure 12: Tenant-aware operations views\nIn the top-right of this view, you\u2019ll see data on tenant resource consumption. The idea here is to view \nconsumption of AWS resources on a tenant-by-tenant basis, allowing you to see how particular tenants \nare exercising speci\ufb01c services. At the bottom, you\u2019ll see a view of consumption that illustrates how \ntenants are consuming the various microservices of your application. The data here lets operations have \nviews into how tenants are consuming the various services of your system and determine if a particular \ntenant or tier might be saturating a particular microservice.\nIn addition to providing this general view of tenant activity, your operational experience should also \ninclude the ability to drill into the operational data for individual tenants and tiers. Imagine support \nscenarios where a speci\ufb01c tenant or tenant tier is experiencing issues. In these cases, you\u2019ll want to \nbe able to access operational data and view it through the lens of that particular tenant or tier. This is \nessential to being able to troubleshoot and diagnose issues in a multi-tenant setting.\nCreating these operational views relies on having access to operational data that includes the tenant \nand tiering context that\u2019s required to create the operational views that can analyze insights by tenant \nor tenant tier. This requires SaaS architects to give care consideration to how and where they can inject \ntenant context into the various mechanisms that are used to record health and activity events. For \nexample, logs should include mechanisms to ensure that tenant context (such as tenant identi\ufb01er and \ntier) are injected into your system\u2019s log data.\nThe views that you choose to construct, however, will vary based on the nature of your application\u2019s \ndesign and architecture. Generally, teams should be thinking about the operational views that will \nenable operations teams to e\ufb00ectively monitor tenant trends and build the instrumentation into their \nenvironments from the outset. Adding these concepts into your application later in your development \nprocess is more challenging and will likely undermine both development and operational experiences.\n22", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "fc31f3fc-d029-46a4-8617-39921d4187c3": {"__data__": {"id_": "fc31f3fc-d029-46a4-8617-39921d4187c3", "embedding": null, "metadata": {"page_label": "23", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3c0e3904c597205a6101be4846856508352680d7e6746e95729adace3d2ae957", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nNote\nThe numbering of the questions in this whitepaper has been changed to match the order in \nthe SaaS Lens of the AWS Well-Architected Tool. SaaS OPS 2  is described in the following best \npractice, Evolve (p. 25).\nSaaS OPS 3: How are new tenants onboarded to your system?\nSaaS solutions are highly focused on maximizing agility and innovation. Tenant onboarding plays a key \nrole in this agility story. By creating an architecture that promotes a frictionless, repeatable onboarding \nprocess, SaaS organizations are able to streamline, optimize, and scale their ability to introduce new \ntenants into their SaaS environment. This enables SaaS companies to support rapid growth and o\ufb00er \ncustomers an experience the accelerates their overall time to value.\nIt\u2019s important to note that automated onboarding applies to both B2C and B2B SaaS environments. \nWhile some SaaS o\ufb00erings might not include a self-service onboarding experience, this does not reduce \nthe need for a frictionless onboarding experience. Even when onboarding is an internally executed \nprocess, it should still automate all the elements of tenant creation. The need for reduced friction is \nfoundational to creating a solution that aligns with SaaS best practices.\nGenerally, the onboarding process for a SaaS application requires the orchestration of a series of shared \nservices that can con\ufb01gure and provision all the resources needed to introduce a new tenant. The \ndiagram in Figure 13 provides a high-level view of how you could implement this onboarding via a series \nof microservices.\nThe \ufb02ow of the onboarding experience represented in this diagram covers all the steps needed to \nintroduce a tenant and have them begin using your SaaS system. At the front of this process, a tenant \ncalls our registration service requesting to create a new tenant. From this point forward, the registration \nservice will then sit at the middle of the onboarding process, orchestrating all the services needed to \ncreate the new tenant environment.\nThe next step in this process is to create a new user. This new user will represent the administrator for \nthis new tenant. To support this process, we\u2019ve included a user management service. This service doesn\u2019t \nhold data about the user, but it creates the user in an identity provider (in this case Amazon Cognito). It \nalso creates any IAM policies that are needed to support the isolation requirements of this tenant.\n23", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "c8c63531-2643-493a-aeca-e051b9998f22": {"__data__": {"id_": "c8c63531-2643-493a-aeca-e051b9998f22", "embedding": null, "metadata": {"page_label": "24", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "900f30a5ebf1b79100e5fc741cce552427eb4088988b9ae74852a78f74bfb8da", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nFigure 13: Frictionless tenant onboarding\nIn this model, we\u2019ve also relied on a strategy that use a separate Amazon Cognito user pool for each \ntenant. This allows us to customize the identity experience for each tenant of our system (password \npolicies, multi-factor authentication, etc.). By selecting this approach, we must map each user ID to a \ncorresponding user pool. This mapping is managed by the user management service.\nAfter the user is created, our process now creates a tenant. This separation of tenant as a distinct service \nis essential to SaaS environments. It provides a centralized way to manage the state and attributes of \na tenant completely separate from the users that are associated with that tenant. A tenant\u2019s tier or the \nstatus, for example, would be controlled by the tenant management service.\nAs part of onboarding, a SaaS system must often establish a footprint in a billing system. In this \nexample, you\u2019ll see that we inform the billing integration service that we\u2019re creating a new tenant. This \nservice then assumes responsibility for creating a new account with the billing provider. This includes \ncon\ufb01guring the plan or tier for the tenant (free, bronze, platinum, etc.).\nThe last step in the process shown in the diagram relates to the provisioning of tenant infrastructure. \nSome SaaS architectures will include dedicated tenant resources. In these scenarios, our onboarding \nprocess must provision these new resources before our tenant can be activated.\nWhile the \ufb02ow represented here could vary depending on the nature of your environment, the concepts \nrepresented here are common to the onboarding process. Automating the creation, con\ufb01guration, and \nprovisioning of tenant resources is fundamental to creating a rich, scalable multi-tenant experience.\nSaaS OPS 4: How do you support the need for tenant-speci\ufb01c customizations?\nOne of the signi\ufb01cant challenges SaaS architects face is the need to ensure that all tenants are running \nthe same version of their product. This is especially true for companies that have migrated to SaaS and \nhave grown accustomed to supporting unique customer requirements through one-o\ufb00 versions of their \nproduct.\nWhile this might seem tempting, any movement away from a uni\ufb01ed customer management, operations, \nsupport, and deployment experience directly undermines the overall agility of a SaaS organization. As \neach new custom environment is introduced, a SaaS organization slowly makes its way to a traditional \nsoftware model. Ultimately, this ends up eroding the cost, operational e\ufb03ciency, and general innovation \ngoals that are core the SaaS business model.\nThe challenge, then, is to \ufb01nd a strategy that allows you to meet these occasional one-o\ufb00 needs without \ncreating a forked version of your product. The compromise here is achieved through the introduction \nof customization options that are added to the overall o\ufb00ering. So, instead of spinning o\ufb00 a separate \nversion, you\u2019d invest the extra time and e\ufb00ort into \ufb01guring out how these new features can be added in a \nway that makes them available to all customers. Then, through tenant con\ufb01guration, you can determine \nwhich tenants will have these new capabilities enabled.\nA common approach to this problem is to use feature \ufb02ags. Feature \ufb02ags are commonly used by \napplication developers as a way to have multiple paths of execution in a common code base with \ufb02ags \nthat enable or disable each of the di\ufb00erent capabilities at runtime. This technique, which is often used \nas a general development strategy, provides an e\ufb00ective way to introduce customization into your SaaS \nenvironment. Each feature \ufb02ag would correlate to a tenant con\ufb01guration option. This con\ufb01guration \nwould be evaluated at runtime and in\ufb02uence the features that are enabled for each tenant.\nThe diagram in Figure 14 provides a conceptual view of how these \ufb02ags would be applied. A series of \n\ufb02ags will be turned on and o\ufb00 for individual tenants, determining which capabilities are enabled for a \ntenant. These con\ufb01guration options would be changed as a tenant signs up for new features of a SaaS \no\ufb00ering. In some cases, these \ufb02ags can be associated with tiers (instead of individual tenants).\n24", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8d1117cc-d2f9-4142-9eb7-16776bedb037": {"__data__": {"id_": "8d1117cc-d2f9-4142-9eb7-16776bedb037", "embedding": null, "metadata": {"page_label": "25", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "1dd718f3e2ff7658b3b3e7b2b8ef4626b5ab8a89591fe83cd2911c2cf82fa1f6", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nFigure 14: Managing tenant needs with feature \ufb02ags\nFeature \ufb02ags are just one way to achieve this. The key takeaway here is that\u2014even if a single tenant \nneeds a unique feature\u2014that feature should be introduced as a customization to the core platform. How \nyou apply that customization can vary based on the stack and design of your system. The intent is to \nensure that we can deploy and manage a single version of our product.\nWhile this can be a powerful construct, it should be applied with caution. If, by introducing feature \ufb02ags, \nyou create a complex maze of options that end up presenting every tenant a unique experience, your \nsystem will quickly become unmanageable. Try to be selective about how and when you introduce these \n\ufb02ags. As a rule of thumb, the business should not see this as a sales tool that enables the organization to \no\ufb00er one-o\ufb00 customizations to new customers.\nEvolve\nSaaS OPS 2: How are you capturing and surfacing metric data that can be used to analyze the \nusage and consumption trends of individual tenants?\nTo continually evolve your SaaS operations experience, you\u2019ll need to have access to a rich collection of \noperational data that can be used to analyze your multi-tenant SaaS environment. This often means \ninstrumenting and publishing a much richer collection of tenant metrics from your application that \ncan accurately capture the activity and consumption patterns of the tenants that are exercising your \nenvironment.\nSaaS metrics go beyond the fundamental of infrastructure consumption (CPU, memory, etc.), identifying \nspeci\ufb01c operational usage patterns that are fundamental to understanding the operation of multi-\ntenant loads in your environment. Analysis of this data will allow SaaS organizations to assess trends \nthat are happening across their system and identify opportunities to introduce policies or changes to the \nunderlying architecture that will continually improve the reliability, scalability, cost e\ufb03ciency, and overall \nagility of a SaaS o\ufb00ering.\nThere are two distinct elements of capturing and surfacing metric data. First, your application must \npublish the metric data that can provide useful operational insights into your SaaS environment. You\u2019ll \nneed to identify key points in your application where you\u2019ll want to capture and publish these metrics.\nThe other piece of the puzzle here is the ingestion, aggregation, and surfacing of this data. There is \na wide spectrum of tools that you can choose here from AWS or one of the AWS Partner Network \n25", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "677c6b26-a79f-4c2d-a38d-7fb93dcbd66c": {"__data__": {"id_": "677c6b26-a79f-4c2d-a38d-7fb93dcbd66c", "embedding": null, "metadata": {"page_label": "26", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3540697395ed2ae148ed33e4af7c9ecdf4cdfe4abbfbfaf06314fa57dff48aef", "text": "SaaS Lens AWS Well-Architected Framework\nResources\n(APN) Partners. Ultimately, the ingestion component of this becomes more of a data warehouse and \nbusiness intelligence question. The SaaS architecture scenarios listed previously in this document \nincludes a Tenant Insights scenario. This scenario outlines an architecture for ingesting metric data. That \narchitecture represents one of the patterns you can apply to address this need.\nWhile our focus here is on the operational view of these tenant metrics, you can imagine that these \nmetrics have usage in multiple contexts across a SaaS business. The operational requirement is for your \narchitecture to ensure that the organization is actively collecting and analyzing tenant activity and \nconsumption trends to identify opportunities to evolve your SaaS system. This \ufb01ts with the broader \ntheme of building the foundational tooling that can be used to assess the continually shifting mix of \ntenants and tenant workloads.\nResources\nRefer to the following resources to learn more about our best practices related to operational excellence.\nDocumentation and blogs\n\u2022GPSTEC309-SaaS Monitoring Creating a Uni\ufb01ed View of Multi-tenant Health featuring New Relic \nSlides\n\u2022Feature Toggles (aka Feature Flags)\nVideos\n\u2022AWS re:Invent 2016: The Secret to SaaS (Hint: It's Identity) (GPSSI404)\n\u2022AWS re:Invent 2017: GPS: SaaS Monitoring - Creating a Uni\ufb01ed View of Multi-tenant Health featuring \nNew Relic (GPSTEC309)\nSecurity pillar\nThe security pillar includes the ability to help protect information, systems, and assets while delivering \nbusiness value through risk assessments and mitigation strategies.\nTopics\n\u2022De\ufb01nition  (p. 26)\n\u2022Best practices (p. 27)\n\u2022Resources (p. 36)\nDe\ufb01nition\nThere are \ufb01ve best practice areas for security in the cloud:\n\u2022Identity and access management\n\u2022Detective controls\n\u2022Infrastructure protection\n\u2022Data protection\n\u2022Incident response\nMulti-tenancy adds a layer of additional considerations to your SaaS architecture. With SaaS, you have \nusers that are now accessing a shared environment in the context of a given tenant. This context must be \n26", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "da579822-a8d9-44d6-9ca2-162a163f971a": {"__data__": {"id_": "da579822-a8d9-44d6-9ca2-162a163f971a", "embedding": null, "metadata": {"page_label": "27", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e5138009a1840a3ca38ebf5f71d8c38805ccebb1e3c7b35e98c43b7178c62256", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\ncaptured and conveyed across all the layers of your application\u2019s architecture and plays a fundamental \nrole in securing the overall footprint of your environment.\nFrom a security perspective, you need to look at how tenancy is introduced into your environment and \nhow it is used to secure tenant resources. Overall, you need to ensure that each tenant has a carefully \nconstrained experience that prevents them from accessing any other tenant\u2019s resources.\nBest practices\nTopics\n\u2022Identity and access management (p. 27)\n\u2022Detective controls (p. 28)\n\u2022Infrastructure protection (p. 29)\n\u2022Data protection (p. 36)\n\u2022Incident response (p. 36)\nIdentity and access management\nSaaS SEC 1: How are you associating tenant context with users and applying that context within \nyour SaaS architecture?\nThe move to a multi-tenant architecture often begins with identity. Each user that accesses your \napplication must be connected with a tenant. This binding of a user identity to a tenant is informally \nreferred to as a SaaS identity . The key attribute of the SaaS identity is that it elevates tenant context to a \n\ufb01rst-class construct, connecting it directly to the overall authentication and authorization model of your \nSaaS application.\nThis approach allows tenant context to \ufb02ow through all the layers of the architecture using the same \narchitecture constructs that are used to convey and access user identity. For example, if you have 100 \nmicroservices in your application, you want each of those services to be able to acquire and apply tenant \ncontext without requiring a roundtrip to another service. Managing this context through another service \nadds latency and often creates bottlenecks in your architecture.\nInjecting tenant context into your identity can be achieved through multiple patterns. The identity \nprovider and technology you select for your application will directly shape the approach and strategies \nthat you\u2019ll end up applying to introduce this context into your experience. While the tools might \nchange, the fundamental need is to introduce tenancy into the overall authentication experience of your \nenvironment where tenancy is injected at the point where a user enters your application.\nThe diagram in Figure 15 provides an example of how this is commonly achieved using AWS services. \nThis example includes the common components and technologies that would be used to inject tenant \ncontext into a SaaS environment. This is illustrated on the left side of the diagram, where a tenant \ncompletes a sign-up form, and triggers a call to your application\u2019s registration service.\n27", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "91cb8502-219c-4eff-9de0-0a2c7237ea0a": {"__data__": {"id_": "91cb8502-219c-4eff-9de0-0a2c7237ea0a", "embedding": null, "metadata": {"page_label": "28", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "bd0301ccb5660e4d7e0927bb1af1a7616e1294a474f02ed0397bd184fb7b1a40", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nFigure 15: Injecting tenant content\nThis registration service creates a tenant and then creates a user in Amazon Cognito. As part of this \nprocess, you introduce custom claims into user\u2019s attributes that hold information about the user\u2019s \nrelationship to a tenant. These custom claims become part of the identity signature of your user, \nconnecting them directly with a tenant as a \ufb01rst-class construct.\nAfter the onboarding is completed, you then can look at how these user and tenant attributes \nare applied when a user logs in (the right-hand side of the diagram). Here you\u2019ll see that the user \nauthenticates against Amazon Cognito and, as part of that process, returns a JSON web token (JWT) that \nincludes the custom claims created during the onboarding process.\nNow you have a token that has all the information that you need to inject tenant context into the \ninteractions with multi-tenant application services. In this example, we show the JWT being passed as a \nbearer token in the header of each request to the Product microservice. This service can now acquire and \napply the context from this token without calling another service.\nFinally, this Product microservice makes a call to an Order microservice, passing the JWT in the header of \nthe request. This illustrates how the tenant context can \ufb02ow across all of your microservice calls without \nadding any additional lookups or latency.\nThis example happens to rely on Amazon Cognito to connect the user and tenant identities. However, \nthis same model could be implemented with other identity providers or alternate authentication \nschemes. The key here is that you\u2019re building an authentication experience that can yield a \nrepresentation that connects tenant and users. This representation should then be available to all the \nlayers of your solution.\nDetective controls\nThere are no security practices unique to SaaS applications.\n28", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "a46dcfec-2c24-41d6-93da-a2310a152af9": {"__data__": {"id_": "a46dcfec-2c24-41d6-93da-a2310a152af9", "embedding": null, "metadata": {"page_label": "29", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "031c8cb6fb828e91e4079296f903dbb3e0b9bd9016134a67b139453f7cbb1ebb", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nInfrastructure protection\nSaaS SEC 2: How are you ensuring that tenant resources are protected from cross-tenant access?\nTenant isolation is one of the foundational topics that every SaaS provider must address. As independent \nsoftware vendors (ISVs) make the shift toward SaaS and adopt a shared infrastructure model to achieve \ncost and operational e\ufb03ciency, they also take on the challenge of determining how their multi-tenant \nenvironments will ensure that tenants are prevented from accessing another tenant\u2019s resources. Crossing \nthis boundary in any form would represent a signi\ufb01cant and potentially unrecoverable event for a SaaS \nbusiness.\nWhile the need for tenant isolation is viewed as essential to SaaS providers, the strategies and \napproaches to achieving this isolation are not universal. There are a wide range of factors that can \nin\ufb02uence how tenant isolation is realized in any SaaS environment. The domain, compliance, deployment \nmodel, and the selection of AWS services all bring their own unique set of considerations to the tenant \nisolation story.\nTopics\n\u2022The isolation mindset  (p. 29)\n\u2022Core isolation concepts (p. 30)\nThe isolation mindset\nAt the conceptual level, many SaaS providers would agree on the importance and value of protecting \nand isolating tenant resources. However, as you dig into the details of implementing an isolation \nstrategy, you\u2019ll often \ufb01nd that each SaaS ISV has their own de\ufb01nition of what is enough  isolation.\nGiven these varying perspectives, we have outlined some tenets below that will help guide your overall \nvalue system for tenant isolation. Every SaaS provider should establish a clear set of high-level isolation \nrequirements that will guide their teams as they de\ufb01ne the isolation footprint of their SaaS environment. \nThe following are some key tenets that typically shape the overall SaaS tenant isolation model:\nIsolation is not optional  \u2013 Isolation is a foundational element of SaaS and every system that delivers a \nsolution in a multi-tenant model should ensure that their systems take measures to ensure that tenant \nresources are isolated.\nAuthentication and authorization are not equal to isolation  \u2013 While it is expected that you will control \naccess to your SaaS environments through authentication and authorization, getting beyond the entry \npoints of a login screen or an API does not mean you have achieved isolation. This is just one piece of the \nisolation puzzle and is not enough on its own.\nIsolation enforcement should not be left to service developers \u2013 While developers are never \nexpected to introduce code that might violate isolation, it\u2019s unrealistic to expect that they will never \nunintentionally cross a tenant boundary. To mitigate this, scoping of access to resources should be \ncontrolled through some shared mechanism that is responsible for applying isolation rules (outside the \nview of developers).\nIf there\u2019s not an out-of-the box isolation solution, you may have to build it yourself \u2013 There are a \nnumber of security mechanisms, such as AWS Identity and Access Management (IAM), that can help you \nsimplify the path to tenant isolation. Combining these tools with your broader security scheme can help \nmake isolation an easier process.. However, there might be scenarios where your isolation model is not \ndirectly addressed by a corresponding tool or technology. The absence of a clear solution should not \nrepresent an opportunity to lower your isolation requirements\u2014even if that means building something \nof your own.\n29", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e89b4c78-7132-4e87-95fa-7ce530384cbf": {"__data__": {"id_": "e89b4c78-7132-4e87-95fa-7ce530384cbf", "embedding": null, "metadata": {"page_label": "30", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "15af79beb2128b447a8f630dbbed7ea30009ae41ede38761b308facafb5c3971", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nIsolation is not a resource-level construct \u2013 In the world of multi-tenancy and isolation, some will \nview isolation as a way to draw a hard boundary between concrete infrastructure resources. This often \ntranslates into isolation model where you might have separate databases, compute instances, accounts, \nor virtual private clouds (VPCs) for each tenant. While these are common forms of isolation, they are \nnot the only way to isolate tenants. Even in scenarios where resources are shared\u2014in fact, especially in \nenvironments where resources are shared\u2014there are ways to achieve isolation. In this shared resource \nmodel, isolation can be a logical construct that is enforced by runtime applied policies. The key point \nhere is that isolation should not be equated to having siloed resources.\nDomains may impose speci\ufb01c isolation requirements \u2013 While there are many approaches to achieving \ntenant isolation, the realities of a given domain might impose constraints that will require a speci\ufb01c \n\ufb02avor of isolation. For example, some high compliance industries may require that every tenant have its \nown database. In these cases, the shared, policy-based approaches to isolation may not be adequate.\nCore isolation concepts\nPart of the challenge of isolation is that there are multiple de\ufb01nitions of tenant isolation. For some, \nisolation is almost a business construct where they think about entire customers requiring their own \nenvironments. For others, isolation is more of an architectural construct that overlays the services and \nconstructs of their multi-tenant environment. The sections below will explore the di\ufb00erent types of \nisolation, and associate speci\ufb01c terminology with the varying isolation constructs.\nTopics\n\u2022Silo isolation  (p. 30)\n\u2022Pool isolation (p. 32)\n\u2022The bridge model  (p. 34)\n\u2022Tier-based isolation  (p. 34)\n\u2022Targeted isolation (p. 35)\nSilo isolation\nWhile SaaS providers are often focused on the value of sharing resources, there are still scenarios where \na SaaS provider might choose to have some (or all) of their tenants deployed in a model where each \ntenant is running a fully siloed stack of resources. Some would say that this full-stack model does not \nrepresent a SaaS environment. However, if you\u2019ve surrounded these separate stacks with shared identity, \nonboarding, metering, metrics, deployment, analytics, and operations, then this is a valid variant of \nSaaS that trades economies of scale and operational e\ufb03ciency for compliance, business, or domain \nconsiderations. With this approach, isolation is an end-to-end construct that spans an entire customer \nstack. The diagram in Figure 16 provides a conceptual view of this view of isolation.\nFigure 16: Silo isolation model\n30", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "02fa8f05-2300-4c66-9309-e8ab21ffa369": {"__data__": {"id_": "02fa8f05-2300-4c66-9309-e8ab21ffa369", "embedding": null, "metadata": {"page_label": "31", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "adfec9f72f1f66b80a5b300559f6499c98b51d7b0ce5308cdc047ac9bb7e8f49", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nThis diagram highlights the basic footprint of the siloed deployment model. The technologies that are \nused to run these stacks are mostly irrelevant here. This could be a monolith, it could be serverless, or \nit could be any mix of the various application architecture models. The key concept is to take whatever \nstack the tenant has and surround it with some construct to encapsulate all the moving parts of that \nstack. This becomes the boundary for isolation. As long as you can prevent a tenant from escaping their \nfully encapsulated environment, you\u2019ve achieved the isolation.\nGenerally, this model of isolation is much simpler to enforce. There are often well-de\ufb01ned constructs \nthat will enable you to implement a robust isolation model. While this model presents some real \nchallenges to the cost and agility goals of a SaaS environment, it can be appealing to those that have \nvery strict isolation requirements.\nSilo model pros and cons\nEach SaaS environment and business domain has its own unique set of requirements that might make \nsilo a \ufb01t. However, if you\u2019re leaning in this direction, you\u2019ll de\ufb01nitely want to factor in some of the \nchallenges and overhead associated with the silo model. These are some of the pros and cons that you \nneed to consider if you are exploring a silo model for your SaaS solution:\nPros\n\u2022Supporting challenging compliance models \u2013 Some SaaS providers are selling into regulated \nenvironments that impose strict isolation requirements. The silo model provides these ISVs with an \noption that enables them to o\ufb00er to some or all of their tenants the option of being deployed in a \ndedicated model.\n\u2022No noisy neighbor concerns \u2013 While all SaaS providers should be attempting to limit the impacts of \nnoisy neighbor conditions, some customers will still express reservations about the potential of having \ntheir workloads impacted by the activity of other tenants using the system. The silo model addresses \nthis concern by o\ufb00ering a dedicated environment with no potential for noisy neighbor scenarios.\n\u2022Tenant cost tracking \u2013 SaaS providers are often highly focused on understanding how each tenant is \nimpacting their infrastructure costs. Calculating a cost-per-tenant can be challenging in some SaaS \nmodels. However, the coarse-grained nature of the silo model provides you with a simpler way to \ncapture and associate infrastructure costs with each tenant.\n\u2022Reduced scope of impact \u2013 The silo model generally reduces your exposure when there might be some \noutage or event that surfaces in your SaaS solution. Since each SaaS provider is running in its own \nenvironment, any failures that occur within a given tenant\u2019s environment will likely be constrained to \nthat environment. While one tenant may experience an outage, the error cannot cascade through the \nremaining tenants that are using your system.\nCons\n\u2022Scaling issues  \u2013 There are limits on the number of accounts that can be provisioned. This limit might \nprevent you from selecting the account-based model. There are also general concerns about how a \nrapidly growing number of accounts might undermine the management and operational experience \nof your SaaS environment. For example, having 20 siloed accounts for each of your tenants might \nbe manageable. However, if you have a thousand tenants, that number would likely begin to impact \noperational e\ufb03ciency and agility.\n\u2022Cost  \u2013 With every tenant running in its own environment, much of the cost e\ufb03ciency that is \ntraditionally associated with SaaS solutions is not realized. Even if these environments scale \ndynamically, you\u2019ll likely have periods of the day when you\u2019ll have idle resources that are going \nunconsumed. While this is a completely acceptable model, it undermines the ability of your \norganization to achieve the economies of scale and margin bene\ufb01ts that are essential to the SaaS \nmodel.\n\u2022Agility \u2013 The move to SaaS is often directly motivated by a desire to innovate at a faster pace. This \nmeans adopting a model that enables the organization to respond and react to market dynamics at a \n31", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "6aa64a4f-46e5-4974-88fe-7efd3374aa37": {"__data__": {"id_": "6aa64a4f-46e5-4974-88fe-7efd3374aa37", "embedding": null, "metadata": {"page_label": "32", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "688213dd076a93728f9abd846a0f1720d7e10a617d3fd248612d0a26ce5cd215", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nrapid pace. A key part of this is being able to unify the customer experience and quickly deploy new \nfeatures and capabilities. While there are measures you can take with the silo model to try to limit its \nimpact on agility, the highly decentralized nature of the silo model adds complexity that impacts your \nability to easily manage, operate, and support your tenants.\n\u2022Onboarding automation  \u2013 SaaS environments place a premium on automating the introduction \nof new tenants. Whether these tenants are being onboarded in a self-service model or using an \ninternally managed provisioning process, you will still need to automate onboarding. And, when you \nhave separate siloes for each tenant, this often becomes a much more heavyweight process. The \nprovisioning of a new tenant will require the provisioning of new infrastructure and, potentially, the \ncon\ufb01guration of new account limits. These added moving parts introduce overhead that introduces \nadditional dimensions of complexity into the overall onboarding automation, enabling you to focus \nless time on your customers.\n\u2022Decentralized management and monitoring \u2013 The goal with SaaS is to have a single pane of glass \nthat enables you to manage and monitor all tenant activity. This requirement is especially important \nwhen you have siloed tenant environments. The challenge here is that you must now aggregate the \ndata from a more decentralized tenant footprint. While there are mechanisms that will enable you \nto create an aggregate view of your tenants, the e\ufb00ort and energy needed to build and manage this \nexperience is more complex in a siloed model.\nPool isolation\nYou can see how the silo model of isolation maps very nicely for many SaaS companies. Many companies \nthat are moving to SaaS are seeking out the e\ufb03ciency, agility, and cost bene\ufb01ts of being able to have \ntheir tenants share some or all of their underlying infrastructure. This shared infrastructure approach, \nwhich is referred to as a pool model, adds a level of complexity to the isolation story. The diagram in \nFigure 17 provides an illustration of the challenge associated with implementing isolation in a pooled \nmodel.\nFigure 17: Pool isolation model\nIn this model, you\u2019ll notice that our tenants are consuming infrastructure that is shared by all tenants. \nThis enables the resources to scale in direct proportion to the actual load being imposed by the tenants. \nThe right side of the diagram narrows in on the compute aspect of one of the services, highlighting the \nfact that tenants 1-N might all be running side-by-side within your shared compute at any given time. \nThe storage in this example is also shared and is represented as a table indexed by individual tenant \nidenti\ufb01ers.\nThis model can work well for SaaS providers, however, it has the potential to complicate the overall \nisolation story. With shared resources, implementing isolation is not as clear and typical networking and \nIAM constructs cannot be relied upon to create boundaries between tenants.\n32", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2cb03bf5-7c94-4f48-a878-a3eaa70875e4": {"__data__": {"id_": "2cb03bf5-7c94-4f48-a878-a3eaa70875e4", "embedding": null, "metadata": {"page_label": "33", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "9f1361e38e281600a23f5bc97889684c6fe8f2d39ca321ae0f679282326a8d3a", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nThe key here is that\u2014even though this is a more challenging environment to isolate\u2014you cannot use \nthis as a rationale to relax the isolation requirements of your environment. The shared model increases \nthe chance for cross-tenant access and, as such, it represents an area that requires you to be especially \ndiligent about ensuring that resources are isolated.\nAs we dig deeper into the pool isolation model, you\u2019ll see how this architectural footprint introduces a \nunique blend of challenges\u2014each of which requires its own type of isolation constructs to successfully \nisolate a tenant\u2019s resources.\nPool model pros and cons\nWhile having everything shared can enable a lot of e\ufb03ciency and optimization, it also requires SaaS \nproviders to weigh some of the tradeo\ufb00s that come with adopting this model. In many cases, the pros \nand cons of the pool model end up surfacing as the inverse of pros and cons we covered for the silo \nmodel. These are the key pros and cons that are typically associated with the pool isolation model.\nPros\n\u2022Agility \u2013 When you move your tenants into a shared infrastructure model, you can leverage the natural \ne\ufb03ciencies and simplicity that help streamline the agility of your SaaS o\ufb00ering. At its core, the pool \nmodel is all about enabling SaaS providers to manage, scale, and operate all of their tenants with one \nuni\ufb01ed experience. Centralizing and standardizing the experience is foundational to enabling SaaS \nproviders to more easily manage and apply changes to all tenants without having to perform one-o\ufb00 \ntasks on a tenant-by-tenant basis. This operational e\ufb03ciency is key to the overall agility footprint of \nyour SaaS environment.\n\u2022Cost e\ufb03ciency \u2013 Many companies are drawn to SaaS for its cost e\ufb03ciency. A big part of this cost \ne\ufb03ciency is commonly associated with the pool model of isolation. In a pooled environment, your \nsystem will scale based on the actual load and activity of all of your tenants. If all the tenants are \no\ufb04ine, your infrastructure costs should be minimal. The key concept here is that pooled environments \ncan adjust to tenant load dynamically and enable you to better align tenant activity with resource \nconsumption.\n\u2022Simpli\ufb01ed management and operations  \u2013 The pool model of isolation gives you one view into all \nthe tenants in a system. You can manage, update, and deploy all of your tenants through a single \nexperience that touches all your tenants in the system. This makes most aspects of the management \nand operations footprint simpler.\n\u2022Innovation \u2013 The agility that is enabled by the pooled isolation model also tends to be core to \nenabling SaaS providers to innovate at a faster pace. The more you move away from distributed \nmanagement and the complexity of the silo model, the more you\u2019re free to focus on the features and \nfunctions of your product.\nCons\n\u2022Noisy neighbor  \u2013 The more resources are shared, the more chances there are for one tenant to impact \nthe experience of another. For example, any activity from one tenant that puts a heavy load on the \nsystem has the potential to impact other tenants. A good multi-tenant architecture and design will try \nto limit these impacts, but there\u2019s always some chance of a noisy neighbor condition impacting one or \nmore of your tenants in a pooled isolation model.\n\u2022Tenant cost tracking \u2013 In a silo model, it\u2019s much easier to attribute consumption of a resource to a \nspeci\ufb01c tenant. However, in a pooled model, the attribution of resources consumption becomes more \nchallenging. Each SaaS provider should look for ways to instrument their systems and surface the \ngranular data needed to e\ufb00ectively associate consumption with individual tenants.\n\u2022Increased scope of impact \u2013 Sharing all resources shared also introduces some operational risk. In \nthe silo model, when one tenant has a failure, the impact of that failure could likely be limited to that \none tenant. However, in a pooled environment, an outage will likely impact all the tenants in your \nsystem, which can have a signi\ufb01cant impact on your business. This usually requires an even deeper \n33", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "1c9e1be4-e2b8-4f35-bda5-cbfa857c94b2": {"__data__": {"id_": "1c9e1be4-e2b8-4f35-bda5-cbfa857c94b2", "embedding": null, "metadata": {"page_label": "34", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e2980ed9fec8da609edc7b5288472fe38037cefb35291753e05371973f924c5a", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\ncommitment to building a resilient environment that can identify, surface, and gracefully recover from \nfailures.\n\u2022Compliance pushback \u2013 While there are measures you can take to isolate your tenants in a pool \nmodel, the notion of sharing infrastructure can create situations where you may be unwilling to run \nin this model. This is especially true in environments with compliance or regulatory rules for a domain \nimpose strict constraints on the accessibility and isolation of resources. Even in these cases, though, \nthis might mean some portion of the system will need to be siloed.\nThe bridge model\nWhile the silo and pool models have very distinct approaches to isolation, the isolation landscape for \nmany SaaS providers is less absolute. As you look at real application problems and you decompose your \nsystems into smaller services, you will often discover that your solution will require a mix of the silo and \npool models. This mixed model is what we would refer to as the bridge model of isolation. The diagram \nin Figure 18 provides an example of how the bridge model might be realized in a SaaS solution.\nFigure 18: Bridge isolation model\nThis diagram highlights how the bridge model enables you to combine the silo and pool models. Here \nwe have a monolithic architecture with classic web and application tiers. The web tier, for this solution, \nis deployed in a pool model that is shared by all tenants. While the web tier is shared, the underlying \nbusiness logic and storage of our application are actually deployed in a silo model where each tenant has \nits own application tier and storage.\nIf the monolith was broken into microservices, each of the various microservices in your system could \nleverage combinations of the silo and pool models. More detail on this approach will follow in the \ndescription of speci\ufb01cs of applying silo and pool models with di\ufb00erent AWS constructs. The key takeaway \nhere is that your view of the silo and pool models will be much more granular for environments that are \ndecomposed into a collection of services that have varying isolation requirements.\nTier-based isolation\nWhile most of our discussion of isolation focuses on the mechanics of preventing cross-tenant access, \nthere are also scenarios where the tiering of your o\ufb00ering might in\ufb02uence your isolation strategy. In \nthis case, it\u2019s less about how you\u2019re isolating tenants and more about how you might package and o\ufb00er \ndi\ufb00erent \ufb02avors of isolation to di\ufb00erent tenants with di\ufb00erent pro\ufb01les. Still, this is another consideration \nthat could determine which models of isolation you\u2019ll need to support to address the full spectrum of \ncustomers you want to engage. The diagram in Figure 19 provides an example of how isolation might \nvary across tiers.\nThe below example uses a mix of silo and pool isolation models that have been o\ufb00ered up as tiers to \nthe tenants. Tenants in the Silver tier are running in the pooled environment. While these tenants are \nrunning in a shared infrastructure model, they still fully expect that their resources will be protected \nfrom any cross-tenant access. The tenant on the right has required that a completely dedicated (silo) \n34", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5860f938-2dfb-4f17-bb92-80870b08f490": {"__data__": {"id_": "5860f938-2dfb-4f17-bb92-80870b08f490", "embedding": null, "metadata": {"page_label": "35", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "be340915e0d4786ff4cbd4c74fa914ba305d63b44ef18395330a17b7c2e6cf00", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nenvironment be o\ufb00ered. To support this, the SaaS provider has created a Premium tier model that \nenables tenants to run in this dedicated model likely at a substantially higher price point.\nWhile SaaS providers generally try to limit o\ufb00ering a silo model to their customers, many SaaS \nbusinesses have this notion of a private pricing where these tenants o\ufb00er to pay a premium to be \ndeployed in this model. In fact, SaaS companies will not publish this as an option or identify it as a tier \nto limit the number of customers that chose this option. If too many of your tenants fall into this model, \nyou\u2019ll begin to fall back to a fully siloed model and inherit many of the challenges that are outlined \npreviously.\nFigure 19: Tier-based isolation\nTo limit the impact of these one-o\ufb00 environments, SaaS providers will often require these premium \ncustomers to run the same version of the product that is deployed to the pooled environment. This \nenables the ISV to continue to manage and operate both environments through a single pane of glass. \nEssentially, the silo environment becomes a clone of the pooled environment that happens to be \nsupporting one tenant.\nTargeted isolation\nIt\u2019s important to note that the isolation choices in your system can be quite granular. Each microservice \nof your system and each resource those services touch has the option of being con\ufb01gured with a \ndi\ufb00erent model of isolation. Let\u2019s look at some sample microservices to better understand how you \nmight vary the isolation model across a varying microservices. The diagram in Figure 20 provides a view \nof microservices that use both the silo and pool models of isolation.\nIn this diagram, you\u2019ll see a system that has implemented three di\ufb00erent microservices: product, \norder, and account. The deployment and storage models of each of these microservices highlights how \nisolation (for security or noisy neighbor) could land in a SaaS environment.\nLet\u2019s review the isolation model for each of these services. The Product microservice at the top right \nwas deployed in a complete pooled model where both the compute and the storage are shared for all \ntenants. The table here re\ufb02ects that tenants all land here as separate items that are indexed in the same \ntable. The assumption is that the data will be isolated with policies that can restrict access to tenant \nitems in this table. The Order microservice is only for tenants 1 through 3 and also implemented in \na pooled model. The only di\ufb00erence here is that it\u2019s supporting a subset of tenants. Essentially, any \ntenant that doesn\u2019t get a dedicated (silo) deployment of the Order microservice would be running in this \npooled deployment (think of it as tenants 1..N with the exception of the few that get pulled out as silo \nmicroservices).\nFor the purposes of this discussion, let\u2019s focus on the siloed services which are represented by the \ndedicated order  microservices (top right) and the Account microservice (bottom). You\u2019ll notice that we\u2019ve \ndeployed standalone instances of the Order microservice for tenants 4 and 5. The idea here is that these \ntenants had some requirements for the order processing (compliance, noisy neighbor, etc.) that required \n35", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "2c946974-2911-4231-8f7f-c082b3d9e378": {"__data__": {"id_": "2c946974-2911-4231-8f7f-c082b3d9e378", "embedding": null, "metadata": {"page_label": "36", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "78c79e1d435399ce559d6cbf9b266bc77cd4989eafdac343f3cc2c1a7d83584c", "text": "SaaS Lens AWS Well-Architected Framework\nResources\nthis service to be deployed in a silo model. Here the compute and storage are both dedicated entirely to \neach of these tenants.\nFinally, at the bottom is the Account microservice which represents a silo model but only at the storage \nlevel. The compute of the microservice is shared by all tenants but each tenant has a dedicated database\nthat holds its account data. In this scenario, the isolation concern is focused exclusively on separating the \ndata. The compute is still enabled to be shared.\nFigure 20: Targeted isolation\nThis model shows how the silo discussion becomes much more granular. Security, noisy neighbor, \nand a variety of factors will determine how and when you might adopt a silo isolation model for your \nservices. The key takeaway here is that the silo model is not an all-or-nothing decision. You can think \nabout applying the silo model to speci\ufb01c components of your application and only absorb this model\u2019s \nchallenges where it\u2019s actually needed, such as when a potential customer demands its use. In this case, \na more detailed discussion with the customer, you \ufb01nd out that there are only a few speci\ufb01c areas of \nstorage and processing that are of concern. Doing so will enable you to get the e\ufb03ciencies of the pool \nmodel for those parts of the system that do not require silo isolation and also give you the \ufb02exibility to \no\ufb00er a tiered structure to support a mix of both silo and pool models for individual services.\nData protection\nThere are no security practices unique to SaaS applications.\nIncident response\nThere are no security practices unique to SaaS applications.\nResources\nRefer to the following resources to learn more about our best practices for security.\nDocumentation and blogs\n\u2022Isolating SaaS Tenants with Dynamically Generated IAM Policies\n\u2022Partitioning Pooled Multi-Tenant SaaS Data with Amazon DynamoDB\n\u2022Multi-tenant data isolation with PostgreSQL Row Level Security\n36", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5de0d47a-e4bb-4cea-8dc4-ab1e8c65c45e": {"__data__": {"id_": "5de0d47a-e4bb-4cea-8dc4-ab1e8c65c45e", "embedding": null, "metadata": {"page_label": "37", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "76ac7910570e84fc98efacd249b714293e7ffc9d24ed4b95f8288d2f4f89d900", "text": "SaaS Lens AWS Well-Architected Framework\nReliability\n\u2022Identity Federation and SSO for SaaS on AWS\n\u2022Managing SaaS Identity Through Custom Attributes and Amazon Cognito\n\u2022Onboarding and Managing Agents in a SaaS Solution\n\u2022Amazon Cognito API Reference\n\u2022Building Serverless SaaS with Lambda layers (GitHub)\n\u2022Modeling SaaS Tenant Pro\ufb01les on AWS\nWhitepapers\n\u2022SaaS Tenant Isolation Strategies whitepaper\n\u2022SaaS Storage Strategies whitepaper\nVideos\n\u2022AWS re:Invent 2017: SaaS and OpenID Connect: The Secret Sauce of Multi-Tenant Identity\n\u2022AWS re:Invent 2016: The Secret to SaaS (Hint: It's Identity)\n\u2022AWS re:Invent 2019: SaaS tenant isolation patterns\nReliability pillar\nThe reliability pillar includes the ability of a system to recover from infrastructure or service disruptions, \ndynamically acquire computing resources to meet demand, and mitigate disruptions such as \nmiscon\ufb01gurations or transient network issues.\nTopics\n\u2022De\ufb01nition  (p. 37)\n\u2022Best practices (p. 37)\n\u2022Resources (p. 41)\nDe\ufb01nition\nThere are three best practice areas for reliability in the cloud:\n\u2022Foundations\n\u2022Change management\n\u2022Failure management\nTo achieve reliability, a system must have a well-planned foundation and monitoring in place, with \nmechanisms for handling changes in demand or requirements. The system should be designed to detect \nfailure and automatically heal itself.\nBest practices\nTopics\n\u2022Foundations (p. 38)\n\u2022Change management  (p. 40)\n\u2022Failure management (p. 41)\n37", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "91598b3a-84f8-471f-9eb2-39e5b009052a": {"__data__": {"id_": "91598b3a-84f8-471f-9eb2-39e5b009052a", "embedding": null, "metadata": {"page_label": "38", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "538c2361d5cd8f9367d2619d0cdc71f0592db64faf04a8595a3206c2172fe5f4", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nFoundations\nSaaS REL 1: How do you limit an individual tenant\u2019s ability to impose load that might impact \navailability for other tenants of your system?\nThe workloads of tenants in a multi-tenant environment can be continually shifting. Tenants may \nimpose di\ufb00erent types of load on the system. New tenants with new workload pro\ufb01les might also be \ncontinually added to the system. These factors can make it very challenging for SaaS companies to \ncreate an architecture that is resilient enough to react and respond to these evolving needs.\nThese variations in load can have an adverse impact on a tenant\u2019s experience. Imagine a scenario where \na single tenant ends up placing an extreme load on some aspect of your system. This can be especially \npronounced if they can interact with your system via an API. In this case, the load of this tenant could \nend up consuming a disproportionate level of the system\u2019s resources which, in turn, could end up \nimpacting the reliability of the overall system or another tenant\u2019s experience.\nThis ability for one tenant to impact another can get more complicated for systems that have a tiered \no\ufb00ering. For example, a system might have basic, advanced, and premium tiers. If each of these tiers \nare allowed to impose any level of load on the system, we might \ufb01nd that the basic tier is impacting the \nreliability of a premium tier tenant.\nIn a multi-tenant environment, you need to be especially proactive in your e\ufb00orts to identify workloads \nand patterns of consumption that could impact the reliability of your system. Reliability issues in a multi-\ntenant environment can easily cascade through your system and, potentially, impact the experience of all\nof your customers.\nTo address these workload issues, your system must introduce mechanisms that can detect and resolve \nworkload issues before they can impact the reliability of your application.\nThe architecture of your application and your application stack will in\ufb02uence the strategies you apply to \nprevent tenant\u2019s from impacting the reliability of your system and the experience of other tenants. One \ncommon approach is to use throttling to prevent tenants from consuming excess resources. The diagram \nin Figure 21 provides an example of doing this using Amazon API Gateway.\nIn this example, you\u2019ll see that we have leveraged usage plans with API Gateway to de\ufb01ne separate \nusage experiences for each tenant of the system. This approach uses separate API keys for the basic and \nadvanced tiers of the system and these keys are connected to usage plans that have di\ufb00erent SLAs. This \napproach enables two di\ufb00erent levels of control. First, it can ensure that all tenants are prevented from \nsaturating our system with requests through the con\ufb01guration of the usage plans. The other bene\ufb01t \nis that we can use these usage plan con\ufb01gurations to prevent lower tier tenants from impacting the \nexperience of higher tier tenants.\nWhile this model relies on API Gateway to implement a throttling policy, this core concept can be applied \nto other infrastructure constructs. The fundamental goal of this approach is to have some ability to \nmonitor and manage access at the entry point to your application, detecting and throttling any tenant \nthat may impose load that could impact the overall reliability of your environment.\n38", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "182e299a-c8af-46a2-b457-5a314f74d9f9": {"__data__": {"id_": "182e299a-c8af-46a2-b457-5a314f74d9f9", "embedding": null, "metadata": {"page_label": "39", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f340bdcd69247abac3087d03ddedf714e5c069e7ae787008affbe8e1ded9aa20", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nFigure 21: Throttling tenants by tier\nSaaS REL 2: How do you proactively detect and maintain tenant health?\nReliability in a SaaS environment is often very much in\ufb02uenced by a provider\u2019s ability to proactively \nidentify and remediate issues before they impact a tenant. Building a proactive view of health in a multi-\ntenant environment requires you to surface additional reliability data that provides more detailed, \ntenant-aware insights into the health trends of your tenant workloads.\nThese tenant-aware insights are used to identify tenant speci\ufb01c trends, activities, or insights that can \ne\ufb00ectively capture condition that could impact the reliability for that tenant or the entire system. Having \nthis data and surfacing it proactively, allows you to build alarms, policies, and automation that can \nattempt to heal the system without incurring an outage.\nTo make this possible, you\u2019ll need to introduce code into your application that will publish health \ninsights with tenant context. This starts by identifying the work\ufb02ows and events in your architecture that \nrepresent useful health data. This could be consumption data, scaling insights, latency metrics, and so \non. Each of these insights would be published via log \ufb01le or to a data warehouse that would aggregate \nthe data.\nOnce you have this health data aggregated in a repository, you can then introduce tooling that can \nsurface alarms or trigger policies based on an analysis of the aggregated health data.\nSaaS REL 3: How are you testing the multi-tenant capabilities of your SaaS application?\nThe testing model for a multi-tenant environment goes beyond simply ensuring that the functionality \nof your application works as expected. SaaS providers must also create tests that will validate that your \nsystem can e\ufb00ectively address common reliability challenges that are associated with a multi-tenant \nsolution.\nThere are a number of di\ufb00erent dimensions that you\u2019ll want to include as part of your multi-tenant \ntesting strategy. In many cases, these tests are targeted at validating the constructs that you have in \nplace to address the scale, operations, and reliability footprint of your SaaS product.\nIt\u2019s important to note that SaaS testing is often about simulating the extremes that your application \nmight encounter. You should be focused on building a suite of tests that can e\ufb00ectively model and \nevaluate how your system will respond to the expected and the unexpected. In addition to ensuring that \ncustomers have a positive experience, your tests must also consider how cost e\ufb00ectively it is achieving \nscale. If you are over-allocating resources in response to activity, you\u2019re likely impacting the bottom line \nfor the business.\n39", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "39ce3ac3-3746-49af-815f-214883e8f4b6": {"__data__": {"id_": "39ce3ac3-3746-49af-815f-214883e8f4b6", "embedding": null, "metadata": {"page_label": "40", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a4ce7f6242ad15374774b2813daa691de667af0aec76ebc3f7b1fe15111427d3", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nSome speci\ufb01c areas where you might augment your load and performance testing strategy in a SaaS \nenvironment are:\n\u2022Cross-tenant impact tests \u2013 Create tests that simulate scenarios where a subset of your tenants place \na disproportionate load on your system. This will allow you to determine how the system responds \nwhen load is not distributed evenly among tenants, and assess how this might a\ufb00ect overall tenant \nexperience. If your system is decomposed into separately scalable services, you\u2019ll want to create tests \nthat validate the scaling policies for each service to ensure that they\u2019re scaling on the right criteria.\n\u2022Tenant consumption tests \u2013 Create a range of load pro\ufb01les (for example, \ufb02at, spikey, and random) \nthat track both resource and tenant activity metrics, and determine the delta between consumption \nand tenant activity. You can ultimately use this delta as part of a monitoring policy that could identify \nsuboptimal resource consumption. You can also use this data with other testing data to determine if \nyou\u2019ve sized your instances correctly, have IOPS con\ufb01gured correctly, and are optimizing your AWS \nfootprint.\n\u2022Tenant work\ufb02ow tests \u2013 Use these tests to assess how the di\ufb00erent work\ufb02ows of your SaaS \napplication respond to load in a multi-tenant context. The idea is to pick well-known work\ufb02ows of \nyour solution, and concentrate load on those work\ufb02ows with multiple tenants to determine if these \nwork\ufb02ows create bottlenecks or over-allocation of resources in a multi-tenant setting.\n\u2022Tenant onboarding tests \u2013 As tenants sign up for your system, you want to be sure that they have a \npositive experience and that your onboarding \ufb02ow is resilient, scalable, and e\ufb03cient. This is especially \ntrue if your SaaS solution provisions infrastructure during the onboarding process. You\u2019ll want to \ndetermine that a spike in activity doesn\u2019t overwhelm the onboarding process. This is also an area \nwhere you might have dependencies on third-party integrations (billing, for example). You\u2019ll likely \nwant to validate that these integrations can support their SLAs. In some cases, you might implement \nfallback strategies to handle potential outage for these integrations. In these cases, you\u2019ll want to \nintroduce tests that verify that these fault tolerance mechanisms are performing as expected.\n\u2022API throttling tests \u2013 The idea of API throttling is not unique to SaaS solutions. In general, any API you \npublish should include the notion of throttling. With SaaS, you also need to consider how tenants at \ndi\ufb00erent tiers can impose load via your API. A tenant in a free tier, for example, might not be allowed \nto impose the same load as a tenant in the gold tier. This enables you to verify that the throttling \npolicies associated with each tier are being successfully applied and enforced.\n\u2022Data distribution tests  \u2013 In most cases, SaaS tenant data will not be uniformly distributed. These \nvariations in a tenant\u2019s data pro\ufb01le can create an imbalance in your overall data footprint, and \nmight a\ufb00ect both the performance and cost of your solution. To o\ufb00set this dynamic, SaaS teams \nwill typically introduce sharding policies that account for and manage these variations. Sharding \npolicies are essential to the performance and cost pro\ufb01le of your solution, and, as such, they represent \na prime candidate for testing. Data distribution tests allow you to verify that the sharding policies \nyou\u2019ve adopted will successfully distribute the di\ufb00erent patterns of tenant data that your system may \nencounter. Having these tests in place early might help you avoid the high cost of migrating to a new \npartitioning model after you\u2019ve already stored signi\ufb01cant amounts of customer data.\n\u2022Tenant isolation testing \u2013 SaaS customers expect that every measure will be taken to ensure that \ntheir environments are secured and inaccessible by other tenants. To support this requirement, \nSaaS providers build in a number of policies and mechanisms to secure each tenant\u2019s data and \ninfrastructure. Introducing tests that continually validate the enforcement of these policies is essential \nto any SaaS provider.\nAs you can see, this test list is focused on ensuring that your SaaS solution will be able to handle load \nin a multi-tenant context. Load for SaaS is often unpredictable, and you will \ufb01nd that these tests often \nrepresent your best opportunity to uncover key load and performance issues before they impact one or \nall of your tenants. In some cases, these tests might also surface new points of in\ufb02ection that may merit \ninclusion in the operational view of your system.\nChange management\nThere are no reliability practices unique to SaaS applications.\n40", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "64cd83c3-9f45-4a33-9c3f-022af88bc827": {"__data__": {"id_": "64cd83c3-9f45-4a33-9c3f-022af88bc827", "embedding": null, "metadata": {"page_label": "41", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "430db3ff73738b655972d39fefcd457fdeb9cf86b6c897d8c47d213f3b862535", "text": "SaaS Lens AWS Well-Architected Framework\nResources\nFailure management\nThere are no reliability practices unique to SaaS applications.\nResources\nRefer to the following resources to learn more about our best practices related to reliability.\nDocumentation and blogs\n\u2022Monolith to serverless SaaS: Migrating to multi-tenant architecture\n\u2022Testing SaaS Solutions on AWS\n\u2022Importance of Service Level Agreement for SaaS Providers\n\u2022Using Amazon SQS in a Multi-Tenant SaaS Solution\n\u2022Partitioning Pooled Multi-Tenant SaaS Data with Amazon DynamoDB\n\u2022Architecting Successful SaaS: Interacting with Your SaaS Customer\u2019s Cloud Accounts\n\u2022Amazon EC2 Auto Scaling\n\u2022Creating and using usage plans with API keys\n\u2022Managing Concurrency for a Lambda Function\n\u2022Amazon API Gateway: Throttle API requests for better throughput\n\u2022Amazon CloudWatch Observability of your AWS resources and applications on AWS and on-premises\n\u2022Amazon CloudWatch Publishing Custom Metrics\nVideos\n\u2022AWS re:Invent 2017: SaaS Monitoring - Creating a Uni\ufb01ed View of Multi-tenant Health featuring New \nRelic\n\u2022AWS re:Invent 2019: Building serverless SaaS on AWS\n\u2022AWS re:Invent 2019: Serverless SaaS deep dive: Building serverless SaaS on AWS (ARC410-R)\nPerformance e\ufb03ciency pillar\nThe performance e\ufb03ciency pillar focuses on the e\ufb03cient use of computing resources to meet \nrequirements and maintaining that e\ufb03ciency as demand changes and technologies evolve.\nTopics\n\u2022De\ufb01nition  (p. 41)\n\u2022Best practices (p. 42)\n\u2022Resources (p. 46)\nDe\ufb01nition\nThere are four best practice areas for performance e\ufb03ciency in the cloud:\n\u2022Selection (compute, storage, database, network)\n\u2022Review\n\u2022Monitoring\n\u2022Tradeo\ufb00s\n41", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "28206012-5b8f-40f8-8aa4-ad984cc002ac": {"__data__": {"id_": "28206012-5b8f-40f8-8aa4-ad984cc002ac", "embedding": null, "metadata": {"page_label": "42", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f1936a3db78de83e0aa83db6ee5f6a47b0ccdf139fe47390b714fd27015d010f", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nTake a data-driven approach to selecting a high-performance architecture. Gather data on all aspects \nof the architecture, from the high-level design to the selection and con\ufb01guration of resource types. \nBy reviewing your choices on a cyclical basis, you will ensure that you are taking advantage of the \ncontinually evolving AWS Cloud.\nMonitoring will ensure that you are aware of any deviance from expected performance and can take \naction on it. Finally, your architecture can make tradeo\ufb00s to improve performance, such as using \ncompression or caching, or relaxing consistency requirements.\nBest practices\nTopics\n\u2022Selection (p. 42)\n\u2022Review (p. 45)\n\u2022Monitoring  (p. 45)\n\u2022Tradeo\ufb00s (p. 46)\nSelection\nSaaS PERF 1: How do you prevent one tenant from adversely impacting the experience of another \ntenant?\nIn a multi-tenant environment, tenants might have pro\ufb01les and use cases that impose signi\ufb01cantly \ndi\ufb00erent loads on your system. New tenants with new workload pro\ufb01les might also be continually added \nto the system. These factors can make it very challenging for SaaS companies to build an architecture \nthat can meet the rapidly evolving performance requirements each of these tenants.\nHandling and managing these variations in tenant load is key to the performance pro\ufb01le of a SaaS \nenvironment. A SaaS architecture must be able to successfully detect these tenant consumption \ntrends and apply strategies that can scale e\ufb00ectively to meet tenant demands or restrict the activity of \nindividual tenants.\nThere are a variety of strategies that can be used to manage these scenarios where a tenant might be \nplacing a disproportionate load on your system. This can be achieved through isolation of high-demand \nresources, introduction of scaling strategies, or the application of throttling policies.\nIn the simplest and most extreme case, you might consider creating tenant-speci\ufb01c deployments for \nparts of your application. The diagram in Figure 22 illustrates one way that you might decompose your \nsystem to address performance challenges.\n42", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "8b684f6c-f6bb-4556-b366-65a4fcf11e6d": {"__data__": {"id_": "8b684f6c-f6bb-4556-b366-65a4fcf11e6d", "embedding": null, "metadata": {"page_label": "43", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "aea7d72cc7ea5237f8336dd2dbbb7adbda954a9cef1d6dd98b581430d27980c8", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nFigure 22: Addressing performance with siloed services\nIn this example, you\u2019ll notice that we have two distinct deployment footprints (some in a silo model and \nsome in a pool model). On the left side of the diagram, you\u2019ll see that separate instances of Product, \nOrder, and Cart microservices have been deployed for each tenant. Meanwhile, on the right side of the \ndiagram, you\u2019ll see a collection of microservices that are shared by all tenants.\nThe basic idea behind the approach is to carve out speci\ufb01c services that are seen as critical to the \nperformance pro\ufb01le of our application. By separating them out, your system can ensure that the load \nof any one tenant won\u2019t impact the performance of other tenants (for this set of services). This strategy \ncan increase costs and decrease the operational agility of your environment, but still represents a valid \nway to target performance areas. This same approach may also be applied to address compliance and \nisolation requirements.\nYou might, for example, deploy an order management microservice for each tenant to limit any ability \nfor one tenant to adversely impact another tenant\u2019s order processing experience. This adds operational \ncomplexity and reduces cost e\ufb03ciency, but can be used as a brute force way to selectively target cross-\ntenant performance issues for key areas of your application.\nIdeally, you should try to address these performance requirements through constructs that can address \ntenant load issues without absorbing the overhead and cost of separately deployed services. Here you \nwould focus on creating a scaling pro\ufb01le that allows your shared infrastructure to e\ufb00ectively respond to \nshifts in tenant load and activity.\nA container-based architecture, such as Amazon EKS or Amazon ECS, could be con\ufb01gured to scale your \nservices based on tenant demand without requiring any signi\ufb01cant over-provisioning of resources. The \nability for containers to scale rapidly enhances your system\u2019s ability to respond e\ufb00ectively to spikey \ntenant loads. Combining the scaling speed of containers with the cost pro\ufb01le of AWS Fargate often \nrepresents a solid blend of elasticity, operational agility, and cost e\ufb03ciency that can help organizations \naddress the spikey loads of tenants without over-provisioning environments.\nA serverless SaaS architecture built with AWS Lambda could also be a good \ufb01t for addressing the spikey \ntenant loads. The managed nature of AWS Lambda allows your application\u2019s services to scale rapidly to \naddress spikes in tenant load. There might be concurrency and cold start factors you\u2019d need to factor \ninto this approach. However, it can represent an e\ufb00ective strategy for limiting cross-tenant performance \nimpacts.\nWhile a responsive scaling strategy can help with this problem, you might want to put other measures \nin place to simply prevent tenants from imposing loads that would have cross-tenant impacts. In \nthese scenarios, you might choose to detect and constrain the activity of the tenants by setting limits \n(potentially by tier) that would apply throttling to control the level of load the place on your system. This \nwould be achieved by introducing throttling policies that would examine the load of tenants, identify \nand activity that exceeds limits, and throttle their experience.\n43", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "bf4131d1-52aa-4c34-9d31-4033ee3b9ed7": {"__data__": {"id_": "bf4131d1-52aa-4c34-9d31-4033ee3b9ed7", "embedding": null, "metadata": {"page_label": "44", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b0ab76c09e9c9d89dd2aabc545e98bbaf5b49e158c22c2d0648d54d204e6c7b3", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nSaaS PERF 2: How are you ensuring that the consumption of infrastructure resources aligns with \nthe activity and workloads of tenants?\nThe business model of SaaS companies often relies heavily on a strategy that allows them to align \nthe costs of their infrastructure with the actual activity of their tenants. Since the load and makeup \nof the tenants in a SaaS system is continually changing, you need an architecture strategy that can \ne\ufb00ectively scale the consumption of resources in a pattern a pattern that very much mirrors these real-\ntime, unpredictable patterns of consumption that are part of the SaaS experience.\nThe graph in Figure 23 provides a hypothetical example of an environment that has aligned \ninfrastructure consumption and tenant activity. Here the blue solid line represents the actual activity \ntrends of tenants spanning a window of time. The red dashed line represents the actual infrastructure \nthat\u2019s being provisioned to address the load of tenants.\nFigure 23: Aligning tenant activity and consumption\nOur strategy here, in an ideal environment, would be to keep the gap between the red a blue line as \nsmall as possible. You\u2019ll always have some margin for error here where you have some cushion to ensure \nthat you\u2019re not impacting the availability or performance of the system. At the same time, you want to \nbe able to deliver just enough infrastructure to support the current  performance needs of your tenants.\nThe key challenge here is that the load shown in this diagram is often unpredictable. While there may \nbe some general trends, your architecture and scaling strategies can\u2019t assume that the load today will be \nthe same tomorrow or even in the next hour.\nThe simplest approach to aligning consumption with activity is to use AWS services that provide a \nserverless experience. The classic example of this would be AWS Lambda. With AWS Lambda, you can \nbuild a model where servers and scaling policies are no longer your responsibility. With serverless, your \nSaaS application will only incur those charges that are directly correlated with tenant consumption. If \nthere\u2019s no load on your SaaS system, there will be no AWS Lambda costs.\nAWS Fargate also enables a container-based version of this this serverless mindset. By using Fargate with \nAmazon EKS or Amazon ECS, you only pay for the container compute costs that are actually consumed \nby your application.\n44", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5a7b0ad3-5d6a-498c-941e-ecd496f539bf": {"__data__": {"id_": "5a7b0ad3-5d6a-498c-941e-ecd496f539bf", "embedding": null, "metadata": {"page_label": "45", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "369d41560e53d0d4aaafe308473004ef38d9a972bfc69385c934574ce40bd1ef", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nThis ability to use a serverless model extends beyond compute constructs. For example, the storage \npieces of your solution can rely on serverless technology as well. Amazon Aurora Serverless allows you \nto store relational data without needing to size the instances that are running your database. Instead, \nAmazon Aurora Serverless will size your environment based on actual load and only charge for what your \napplication consumes.\nAny model that lets you move away from a need to create scaling policies is going to streamline your \noperational and cost experience. Instead of continually chasing the elusive perfect automatic scaling \ncon\ufb01guration, you can focus more of your time and energy on the features and functions of your \napplication. This also enables the business to grow and accept new tenants without being concerned \nabout unexpected jumps in its AWS bill.\nFor scenarios where serverless may not be an option, you\u2019ll need to fall back to traditional scaling \nstrategies. In these scenarios, you\u2019ll need to capture and publish tenant consumption metrics and de\ufb01ne \nscaling policies based on these metrics.\nReview\nThere are no performance practices unique to SaaS applications.\nMonitoring\nSaaS PERF 3: How do you enable varying levels of performance for di\ufb00erent tenant tiers and plans?\nSaaS solutions are often o\ufb00ered in a tiered model where tenants will have access to di\ufb00erent \nexperiences. Performance can often be an area that is used to di\ufb00erentiate tiers of a SaaS environment, \nusing performance as a way to create a value boundary that would compel tenants to move to higher \nlevel tiers.\nIn this model, your architecture will introduce constructs that will monitor and control the experience \nof each tier. This isn\u2019t just about maximizing performance\u2014it\u2019s also about limiting the consumption \nof lower tiered tenants. Even if your system could accommodate the load of these tenants, you might \nchoose to limit this load purely based on cost or business considerations. This is often part of ensuring \nthat the cost footprint of a tenant correlates with the revenue that tenant contributes to the business.\nThe least complex way to approach this problem is to introduce throttling policies that are associated \nwith individual tenant tiers. As a tenant reaches a limit, you would apply the throttling and limit their \nconsumption.\nThere are also scenarios where you can use speci\ufb01c AWS con\ufb01gurations to con\ufb01gure the consumption \npro\ufb01le of a tenant tiers. For example, in AWS Lambda, you can use reserve concurrency to limit the \nconsumption of a given tenant tier. The diagram in Figure 24 provides an example of how this could be \nrealized.\nFigure 24: Controlling tenant performance with reserve concurrency\n45", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "fca95e2f-1efa-4d85-905a-5f7c9ff71cf5": {"__data__": {"id_": "fca95e2f-1efa-4d85-905a-5f7c9ff71cf5", "embedding": null, "metadata": {"page_label": "46", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "4810ffb5d9de69be0dcce9c71a6c79eada57f0018015988420d1005e86651705", "text": "SaaS Lens AWS Well-Architected Framework\nResources\nIn this example, we\u2019ve created three separate tenant tiers and deployed three separate collections of \nour SaaS application\u2019s microservices for each of these tiers. These collections are also con\ufb01gured with \nseparate reserve concurrency settings which are used to determine how many concurrent function \ninvocations can be running for that group of functions. The Basic tier has a reserve concurrency of 100 \nand the Advanced tier has 300. The idea here is that the consumption of my lower end tiers will be \ncapped, leaving all the remain concurrency for the premium tier.\nThis approach aligns nicely with our goal of o\ufb00ering the best experience our preferred tiers while also \nlimiting a lower tier\u2019s ability to consume excess resources and impact the performance of our higher tier \ntenants.\nContainers also have unique strategies for addressing tiering for performance. Within Amazon EKS, for \nexample, you can con\ufb01gure separate ResourceQuotas  and LimitRanges  to control the amount of \nresources that are available in a namespace.\nWhile these constraints are helpful in con\ufb01guring a tenant\u2019s performance experience, some SaaS \napplications will actually address performance through application design and decomposition strategies. \nThis might be achieved by deploying siloed microservices for higher tier tenants, eliminating any noisy \nneighbor considerations for these speci\ufb01c services. In fact, you might \ufb01nd that the decomposition of your \nsystem into microservices might be directly in\ufb02uenced by the tiering and performance pro\ufb01le you are \ntargeting.\nIn some cases, your SaaS application might also introduce architectural constructs that optimize the \nexperience of higher tier tenants. Imagine, for example, o\ufb00ering caching of key data to premium tier \ntenants. By limiting the cache to just these users, you avoid the expense of having a cache that must \nsupport all users. The e\ufb00ort to introduce these optimizations should be o\ufb00set with enough value to the \ncustomer and the business to warrant the investment.\nTradeo\ufb00s\nThere are no performance practices unique to SaaS applications.\nResources\nRefer to the following resources to learn more about our best practices related to performance e\ufb03ciency.\nDocumentation and blogs\n\u2022Optimizing SaaS Tenant Work\ufb02ows and Costs Blog\n\u2022Using Amazon SQS in a Multi-Tenant SaaS Solution\n\u2022Importance of Service Level Agreement for SaaS Providers\n\u2022Amazon API Gateway: Throttle API requests for better throughput\n\u2022Creating and using usage plans with API keys\n\u2022Monitoring CloudWatch metrics for your Auto Scaling groups and instances\n\u2022Dynamic scaling for Amazon EC2 Auto Scaling\nWhitepapers\n\u2022SaaS Storage Strategies Building a Multi-tenant Storage Model on AWS\n\u2022SaaS Tenant Isolation Strategies whitepaper\nVideos\n\u2022AWS re:Invent 2018: SaaS Reference: Review of Real-World Patterns & Strategies\n\u2022AWS re:Invent 2016: Optimizing SaaS Solutions for AWS\n46", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "58596b44-01cf-48b5-9a29-4980a6a8bc58": {"__data__": {"id_": "58596b44-01cf-48b5-9a29-4980a6a8bc58", "embedding": null, "metadata": {"page_label": "47", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0bec59c5f498cdedb3611c875faae6210f1ad66f04c4ecbe79bd3256774e5e86", "text": "SaaS Lens AWS Well-Architected Framework\nCost optimization\n\u2022SaaS Metrics: The Ultimate View of Tenant Consumption\n\u2022Microservices decomposition for SaaS environments (ARC210)\n\u2022SaaS tenant isolation patterns\nCost optimization pillar\nThe cost optimization pillar includes the continual process of re\ufb01nement and improvement of a system \nover its entire lifecycle. From the initial design of your very \ufb01rst proof of concept to the ongoing \noperation of production workloads, adopting the practices in this paper will enable you to build and \noperate cost-aware systems that achieve business outcomes and minimize costs, thus allowing your \nbusiness to maximize its return on investment.\nTopics\n\u2022De\ufb01nition  (p. 47)\n\u2022Best practices (p. 47)\n\u2022Resources (p. 51)\nDe\ufb01nition\nThere are four best practice areas for cost optimization in the cloud:\n\u2022Cost-e\ufb00ective resources\n\u2022Matching supply and demand\n\u2022Expenditure awareness\n\u2022Optimizing over time\nAs with the other pillars, there are tradeo\ufb00s to consider. For example, do you want to optimize for speed \nto market or for cost? In some cases, it\u2019s best to optimize for speed\u2014going to market quickly, shipping \nnew features, or simply meeting a deadline\u2014rather than investing in upfront cost optimization.\nDesign decisions are sometimes guided by haste as opposed to empirical data, as the temptation always \nexists to overcompensate \u201cjust in case\u201d rather than spend time benchmarking for the most cost-optimal \ndeployment.\nThis often leads to drastically over-provisioned and under-optimized deployments. The following \nsections provide techniques and strategic guidance for the initial and ongoing cost optimization of your \ndeployment\nBest practices\nTopics\n\u2022Cost-e\ufb00ective resources (p. 47)\n\u2022Matching supply and demand  (p. 48)\n\u2022Expenditure awareness (p. 48)\n\u2022Optimizing over time (p. 51)\nCost-e\ufb00ective resources\nThere are no cost practices unique to SaaS applications.\n47", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "21a62b73-3743-47d1-9b9e-bae68398b840": {"__data__": {"id_": "21a62b73-3743-47d1-9b9e-bae68398b840", "embedding": null, "metadata": {"page_label": "48", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "78d33c5fa2ab3033920bbf9a1cf326ee0541cd4503a688c8b09f0e5577545dc8", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nMatching supply and demand\nThere are no cost practices unique to SaaS applications.\nExpenditure awareness\nSaaS COST 1: How do you measure the resource consumption of individual tenants?\nMeasuring and attributing costs in a multi-tenant environment begins with having a solid strategy \nfor attributing consumption to tenants. This will require teams to design and develop a consumption \nmapping model that represents a clear view of how tenants are consuming the resources of your system. \nThe ultimate goal is to arrive at a collection of insights that will allow you to allocate a percentage of \nconsumption to each tenant of your system.\nAssembling this view of consumption can be particularly challenging in a multi-tenant environment \nwhere tenants might be sharing some or all of the system\u2019s resources. This more \ufb01ne-grained \nconsumption model removes many of the options and tooling strategies that are often used to attribute \nconsumption in an AWS environment (tagging, for example).\nWhile there\u2019s no single model for de\ufb01ning how tenant consumption is captured in a SaaS architecture, \nthere are some common strategies that should be considered when selecting a strategy for your \napplication. First, you\u2019ll want to look at the overall cost pro\ufb01le of your SaaS environment and determine \nhow your application is in\ufb02uencing the costs in your AWS bill. For some environments, your costs might \nbe heavily concentrated in a few areas of your application. In these scenarios, you might get a better \nROI on gathering consumption data for just those areas that contribute most to your bill. For example, if \nAmazon S3 represents 1% of your bill, there might be little value in calculating your tenant\u2019s Amazon S3 \nconsumption.\nThe other factor you\u2019ll want to consider here is granularity. There are less invasive approaches that \ncan approximate tenant consumption that may be adequate for your environment. This really comes \ndown to striking a balance between the level of consumption detail you\u2019re after and the complexity of \ninstrumenting and capturing the data that\u2019s need to attribute consumption.\nLet\u2019s start by looking at the simplest model for approximating tenant consumption. The diagram in \nFigure 25 provides a conceptual view of one way you could capture tenant activity in a minimally invasive \nmodel. The basic approach here is to inspect each call that is made to the API using as AWS Lambda \nauthorizer. The authorizer would extract the tenant context from the incoming JWT and publish an event \nthat records this activity for the tenant. An alternate approach to this would be to use AWS X-Ray to \ncapture this data (instead of the Amazon API Gateway).\n48", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "66fce120-6bd6-4c37-a4ee-2bd6a8d8fcbc": {"__data__": {"id_": "66fce120-6bd6-4c37-a4ee-2bd6a8d8fcbc", "embedding": null, "metadata": {"page_label": "49", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "ef7c61ba3a15b23c6f6e72dd66f3c8bf4e7b54df6f5936b83c32f1b8406ced23", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nFigure 25: Minimally invasive capture of tenant consumption\nThere\u2019s also a placeholder on the diagram for aggregating and calculating tenant consumption. The \nstrategy and tools you choose to \ufb01ll in this gap will depend on the nature of the data, its lifecycle, and \nhow it \ufb01ts into your broader SaaS metrics and analytics story. You may choose to include this data as \npart of the general metrics footprint of your SaaS environment, pulling out the insights that are essential \nto allocating consumption to tenants.\nThis particular approach relies on tracking frequency of calls for each tenant as a way to infer the level \nof consumption for each tenant. While the number of calls to a service might not precisely correlate to \nconsumption, for some environments this may represent a reasonable compromise.\nA more granular view of consumption can be created by introducing more specialized instrumentation \ninto the details of your application. The diagram in Figure 26 provides a view of how you might introduce \nmetrics instrumentation into the microservices of your SaaS application.\nFigure 26: Instrumenting microservices with tenant consumption events\nIn this example, we\u2019ve introduced metrics instrumentation into each microservice of our application. \nThese microservices will capture more detailed data about how tenants are consuming this service and \nits related resources. This detailed data is published as an event and aggregated. Here we\u2019ve shown \nAmazon CloudWatch, AWS Lambda, Amazon Kinesis Data Firehose, and Amazon S3 being used to publish \n49", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "cf9cc8e9-0c58-4411-a85d-b111a9119a55": {"__data__": {"id_": "cf9cc8e9-0c58-4411-a85d-b111a9119a55", "embedding": null, "metadata": {"page_label": "50", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "db708eb042b08afed9d25fc6d6ac28786a87c26c008ee2804b7dc0e46bce6b51", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nand ingest the data. This data would then be analyzed and, based on your own modeling, arrive at a \ndistribution of consumption across tenants.\nAttributing tenant consumption gets more challenging as you look beyond the microservices of your \napplication. You might have to develop speci\ufb01c, targeted strategies on a service-by-service basis. Storage \nservices, for example, might require a separate service that can pro\ufb01le storage consumption. This might \nrequire looking at IOPS, data footprint, and other factors to analyze consumption for tenants.\nSaaS COST 2: How are you correlating tenant consumption with the costs of your infrastructure?\nThe dynamic nature of SaaS environments can make it challenging to understand how the cost pro\ufb01le \nof your system\u2019s infrastructure might be changing. The shifting needs and mix of tenants in your \nsystem will likely lead to signi\ufb01cant \ufb02uctuations in the cost of operating your SaaS environment. At the \nsame time, a SaaS business needs to have a clear picture of how tenants are in\ufb02uencing costs to make \nstrategic decisions about how to build, sell, and operate their SaaS application.\nTo understand the business value of having better insights into how tenants are in\ufb02uencing costs for \nthe business, let\u2019s look at one example of how cost data could be applied in a SaaS environment. The \ngraph in Figure 27 provides an example of a scenario where the costs of a SaaS environment were \ncorrelated with revenue from those tenants and the size of the ecommerce catalog being managed by \nthese tenants.\nFigure 27: Costs per tenant by tier\nThis graph illustrates the distribution of costs across the tiers of a SaaS o\ufb00ering. Here you\u2019ll see a large \ndi\ufb00erence between the infrastructure costs of Basic and Advanced tier tenants. The key observation is \nthat the Basic tier, which generates the smallest revenue, is responsible for the largest portion of the \nsystem\u2019s infrastructure costs. Meanwhile, the Advanced tier, which generates the most revenue, has a \nmuch smaller cost footprint. This imbalance likely means there\u2019s something wrong with our model.\nThis is just one example of how having access to costs broken down by tenants and tiers is essential to \nSaaS providers. Access to this cost per tenant data allows a SaaS organization to assess a wide range of \narchitectural considerations that can be in\ufb02uencing the cost pro\ufb01le of your environment. It can also help \nguide pricing and tiering strategies.\nThere are two fundamental aspects associated with assembling this cost per tenant data. First, you\u2019ll \nneed some way to attribute and calculate tenant consumption to arrive at a percentage of consumption \nfor each tenant (see above for details on how this consumption data is collected). After you have the \nconsumption data, you\u2019ll need to correlate this data with cost information from your AWS bill to arrive at \na cost per tenant calculation.\n50", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "12508da3-9c2f-4421-b59d-ecf7f4908b99": {"__data__": {"id_": "12508da3-9c2f-4421-b59d-ecf7f4908b99", "embedding": null, "metadata": {"page_label": "51", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3023ff6210e4d36849f0e12173230bc45fe30e2b05c65231e29bfe62fc338ddd", "text": "SaaS Lens AWS Well-Architected Framework\nResources\nThere are a number of options available for accessing the collection billing data. AWS provides APIs \nthat can be used to ingest and aggregate this billing data or you can explore a range of APN Partner \nsolutions to ingest this data and access the costs through these solutions. The shortest path here is often \nto engage with an APN Partner to deal with the nuances of ingesting and summarizing AWS cost.\nThe high-level view of this experience is captured in Figure 28. You\u2019ll see that we have two distinct sets \nof data that we need to collect. One process will aggregate and ingest the data from your AWS bill \nsummarizing the costs in a manner that aligns with the granularity of costs that are relevant to your cost \nper tenant model. Next, you\u2019ll see the tenant consumption aggregation which analyzed tenant activity \nand assigns a percentage of consumption to each tenant. Finally, these consumption percentages are \napplied to the infrastructure costs to arrive at the cost per tenant.\nFigure 28: Calculating cost per tenant\nAfter you have this data, you can choose how best to represent the resulting costs. Generally, it would \nseem valuable to have costs per tenant across a range of services that are core to your business. \nHowever, you could use weighting and calculate an overall cost per tenant for other analyses that you \nmight perform.\nOptimizing over time\nThere are no cost practices unique to SaaS applications.\nResources\nRefer to the following resources to learn more about AWS best practices for cost optimization.\nDocumentation and blogs\n\u2022Calculating Tenant Costs in SaaS Environments\n\u2022Calculating SaaS Cost Per Tenant: A PoC Implementation in an AWS Kubernetes Environment\n\u2022SaaS metrics deep dive: A look inside multi-tenant analytics\n\u2022SaaS Analytics and Metrics: Capturing and Surfacing the Data That's Fundamental to Your Success\n\u2022Monitoring tools in AWS\nVideos\n51", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "e222d955-4e80-4b37-a79e-9bf1fdff1c50": {"__data__": {"id_": "e222d955-4e80-4b37-a79e-9bf1fdff1c50", "embedding": null, "metadata": {"page_label": "52", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "344a7ae9da90b2c95f64d2d1f2c7459b1859fc427271d5c0750ea827eeaca0ab", "text": "SaaS Lens AWS Well-Architected Framework\nSustainability\n\u2022SaaS Metrics: The Ultimate View of Tenant Consumption\nSustainability pillar\nThe sustainability pillar focuses on the long-term environmental impacts of SaaS products. This pillar \nhelps organizations design and operate their SaaS products in a way that minimizes their environmental \nfootprint: Reducing energy consumption and increasing e\ufb03ciency across all components of a workload \nby maximizing the bene\ufb01ts from the provisioned resources and minimizing the total resources required. \nIt helps organizations understand the trade-o\ufb00s involved in various design and operational decisions \nand make informed choices that align with their values and long-term business goals. By considering \nsustainability from the beginning, organizations can create SaaS products that not only meet the needs \nof their customers but also contribute to a more sustainable future.\nTopics\n\u2022De\ufb01nition  (p. 52)\n\u2022Best practices (p. 52)\n\u2022Resources (p. 56)\nDe\ufb01nition\nOptimize workload placement, and optimize your architecture for user, software, data, hardware, and \ndevelopment and deployment patterns to increase energy e\ufb03ciency. Each of these areas represents \nopportunities to employ best practices to reduce the sustainability impact of your cloud workload by \nmaximizing utilization, and minimizing waste and the total resources deployed and powered to support \nyour workload.\n\u2022Region selection\n\u2022User behavior patterns\n\u2022Software and architecture patterns\n\u2022Data patterns\n\u2022Hardware patterns\n\u2022Development and deployment patterns\nBest practices\nThere are six best practice areas for sustainability in the cloud:\nTopics\n\u2022Region selection (p. 53)\n\u2022User behavior patterns (p. 53)\n\u2022Software and architecture patterns (p. 55)\n\u2022Data patterns (p. 55)\n\u2022Hardware patterns (p. 55)\n\u2022Development and deployment patterns (p. 56)\nUnlike the other pillars, the numbering of the sustainability best practices indicates the estimated \ncomplexity of implementing that best practice. We recommend that you consider this order when \nplanning your sustainability improvement plan.\n52", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5592b931-3f83-402b-9f3a-3d539bcc499d": {"__data__": {"id_": "5592b931-3f83-402b-9f3a-3d539bcc499d", "embedding": null, "metadata": {"page_label": "53", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "87c351bfb8dbf7bb34ea6dd0bfd10d4a873bc97ed55216fb1c48a8557aeb3fed", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\n\u2022SaaS SUS 1: How do you use deployment models (silo, bridge, pool) to align tenant consumption with \nresource utilization?\n\u2022SaaS SUS 2:\u00a0How do you maximize the value from the resources that the SaaS environment consumes?\n\u2022SaaS SUS 3:\u00a0Do you have a tenant o\ufb00-boarding plan for inactive tenants? How do you decommission \ntenant resources that are not being used to limit or prevent waste?\n\u2022SaaS SUS 4: How do you provide per-tenant footprint visibility (such as resource utilization and carbon \nemission data) in your SaaS environment?\nRegion selection\nThere are no sustainability practices unique to SaaS applications.\nUser behavior patterns\nSaaS SUS 3:\u00a0Do you have a tenant o\ufb00-boarding plan for inactive tenants? How do you \ndecommission tenant resources that are not being used to limit or prevent waste?\nEach tenant in the SaaS solution has a footprint that includes infrastructure resources such as compute, \nstorage, and relevant data. When a tenant decides to o\ufb00-board (stop using the SaaS solution), the \nrespective tenant\u2019s footprint should be decommissioned when there is no expectation that the tenant is \nlikely to be re-activated. The faster unused resources can be decommissioned (such as by automating the \nprocess), the lower the impact, as decommissioned resources equate to energy saved. Since this process \ninvolves data archiving or deletion, it should be described as part of the service level agreement (SLA).\n\u2022Best Practice\u201301: Keep an updated list of infrastructure resources allocated per tenant.\n\u2022Best Practice\u201302: Maintain a runbook with a list of steps required to o\ufb00-board a tenant, and \nperiodically test it in non-production environment to help ensure it\u2019s current.\n\u2022Best Practice\u201303: Use automation tools to run decommissioning steps to avoid human errors, and \nspeed up the run time. This process should not a\ufb00ect the performance of active tenants.\n\u2022Best Practice\u201304: Before decommissioning, the SaaS provider should ensure, if required, that a copy \nof the data is created to meet any audit or compliance requirements, and to restore or reactivate the \ntenant in the future.\n\u2022Best Practice\u201305: Start automated decommissioning processes as part of a process approval system, \nsuch as a ServiceNow-approved work\ufb02ow.\n\u2022Best Practice\u201306: Use auto-scaling to remove capacity as demand change.\nAWS services recommendation:\n\u2022AWS Systems Manager Inventory\u00a0provides visibility into your AWS computing environment.\n\u2022AWS Con\ufb01g\u00a0provides a detailed view of the con\ufb01guration of AWS resources in your AWS account. This \nincludes how the resources are related to one another and how they were con\ufb01gured in the past so \nthat you can see how the con\ufb01gurations and relationships change over time.\n\u2022AWS Cost and Usage Report\u00a0(CUR) with\u00a0resource tags\u2014 You can use the resource columns in AWS \nCost and Usage Reports to \ufb01nd information about the speci\ufb01c resources covered by a line item. These \ncolumns include user-de\ufb01ned cost allocation tags.\n\u2022AWS CloudFormation\u00a0templates describe your desired resources and their dependencies so that \nyou can launch and con\ufb01gure them together as a stack. You can use a template to create, update, \nand delete an entire stack as a single unit, as often as you need to, instead of managing resources \nindividually.\n53", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "0009f90f-7556-43e5-800e-3795c22b484f": {"__data__": {"id_": "0009f90f-7556-43e5-800e-3795c22b484f", "embedding": null, "metadata": {"page_label": "54", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c394bf1d26df37b809603f137e93a9e9f17693f683c41a2db13ce57516bece24", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\n\u2022AWS Step Functions\u00a0provides serverless orchestration for modern applications. Orchestration centrally \nmanages a work\ufb02ow by breaking it into multiple steps, adding \ufb02ow logic, and tracking the inputs and \noutputs between the steps.\n\u2022Amazon S3 Inventory\u00a0provides comma-separated values (CSV),\u00a0Apache optimized row columnar \n(ORC),\u00a0or\u00a0Apache Parquet\u00a0output \ufb01les that list your objects and their corresponding metadata on a \ndaily or weekly basis for an S3 bucket or a shared pre\ufb01x (that is, objects that have names that begin \nwith a common string).\n\u2022Amazon S3 storage classes\u00a0(and the S3 Glacier classes in particular) can be used to store or archive a \ntenant\u2019s data for long-term retention and with reduced energy consumption.\n\u2022Amazon EC2 Auto Scaling and \u00a0 Application Auto Scaling  can help you make smart scaling decisions.\n\u2022Amazon QuickSight\u00a0provides you with data driven analysis and visualization.\nSaaS SUS 4: How do you provide per-tenant footprint visibility (such as resource utilization and \ncarbon emission data) in your SaaS environment?\nRe\ufb02ecting the consumption level per tenant creates awareness, visibility into the SaaS solutions\u2019 \ncustomers sustainability footprint, and improvement process.\n\u2022Best Practice\u201301:\u00a0Instrument your SaaS application to collect metrics at a per-tenant level. The goal is \nto accurately capture all the activities and consumption patterns of each tenant in your system.\n\u2022Best Practice\u201302: Use application and system monitoring tools to identify infrastructure usage \npatterns on a per-tenant basis. This data must contain information that ties it back to the tenant.\n\u2022Best Practice\u201303: Provide detailed dashboards and visualizations of per-tenant operational data across \nthe di\ufb00erent layers of the SaaS solution. This data includes total compute required, such as CPU and \nmemory usage, total data transfer and network costs, and total data and storage costs. The goal is to \ncreate a uni\ufb01ed view of the per-tenant footprint, which provides useful operational insights in to your \nSaaS environment.\nAWS services recommendation:\n\u2022AWS SaaS Lens guidance on\u00a0Tenant-aware Operations\u2014 SaaS providers need to be able to view \nsystem activity and health through the lens of individual tenants and tenant tiers. This is essential to \ndiagnosing and evaluating the trends and patterns of activity and consumption for individual tenants.\n\u2022AWS SaaS guidance on\u00a0Tenant Activity and Consumption\u2014Provide\u00a0visibility into how tenants are using \nyour application and imposing load on your system\u2019s architecture.\n\u2022Amazon Cloudwatch\u00a0and tools from AWS Partners such as DataDog or New Relic can be used to \ncapture and surface per-tenant metrics and consumption data.\n\u2022AWS Systems Manager Inventory\u00a0provides visibility into your AWS compute environment.\n\u2022AWS Cost and Usage Reports\u00a0(AWS CUR) with\u00a0resource tags\u2014 You can use the resource columns in \nAWS CUR to \ufb01nd information about the speci\ufb01c resources covered by a line item. These columns \ninclude user-de\ufb01ned cost allocation tags.\n\u2022Tracking SaaS resource and consumption\u2014This presentation\u00a0goes through the best practices for \ncapturing and surfacing tenant level consumption patterns using an AWS partner solution.\n\u2022Use the\u00a0 AWS Customer Carbon Footprint Toolto track, measure, review, and forecast the carbon \nemissions generated from your AWS usage.\n54", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "5e7af52a-7fad-4005-b292-ddbe11edde82": {"__data__": {"id_": "5e7af52a-7fad-4005-b292-ddbe11edde82", "embedding": null, "metadata": {"page_label": "55", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "13c8806f3e062b7e46762ce7e8dcac548b2ee39f18622b74c345901125cc310e", "text": "SaaS Lens AWS Well-Architected Framework\nBest practices\nSoftware and architecture patterns\nSaaS SUS 1: How do you use deployment models (silo, bridge, pool) to align tenant consumption \nwith resource utilization?\n\u2022Best Practice\u201301: Have a good understanding of the key value and principles behind the silo, pool, and \nbridge models, including awareness how silo and pool strategies can be applied more granularly across \nthe layers and services of your solution.\n\u2022Best Practice\u201302:\u00a0Understand the operational tradeo\ufb00s of each model. Build a uni\ufb01ed onboarding, \noperations, and analytics experience spanning any of these models.\u00a0\n\u2022Best Practice\u201303:\u00a0Have a complete end-to-end automated tenant onboarding process that maps the \ntenancy models to the resources that are provisioned at each architecture layer or component. Also \nhave detailed insights into the footprint and consumption costs and tradeo\ufb00s associated with each of \nthese models\nSaaS applications can be built using a variety of di\ufb00erent architectural models. Regulatory, competitive, \nstrategic, cost e\ufb03ciency, and market considerations all in\ufb02uence the shape of your SaaS architecture. \nAt the same time, there are strategies and patterns that can be applied when de\ufb01ning the footprint of \nthe components within a SaaS application. These patterns\u2014silo, bridge, and pool\u2014can be applied in \ncombinations to enable the most e\ufb03cient consumption of infrastructure resources.\nAWS services recommendation:\n\u2022AWS WA SaaS Lens guidance on\u00a0Architectural model\n\u2022SaaS Tenant Isolation Strategies whitepaper\n\u2022Amazon EKS SaaS reference solution\u00a0https://docs.aws.amazon.com/wellarchitected/latest/saas-lens/ \namazon-eks-saas.html\n\u2022Serverless SaaS reference solution\u00a0https://docs.aws.amazon.com/wellarchitected/latest/saas-lens/ \nserverless-saas.html\nData patterns\nThere are no sustainability practices unique to SaaS applications.\nHardware patterns\nSaaS SUS 2:\u00a0How do you maximize the value from the resources that the SaaS environment \nconsumes?\nSaaS, by its nature, tries to promote the sharing of infrastructure across tenants to maximize e\ufb03ciency \nand economies of scale. SaaS providers should continually evaluate their opportunities to maximize \ninfrastructure sharing to promote reduced energy consumption. SaaS providers should have an iterative \nimprovement process that allows them to identify opportunities to limit excess resource consumption.\n\u2022Best Practice\u201301: Use managed services\u00a0to shift the responsibility\u00a0for maintaining optimal utilization \nof the deployed hardware to AWS.\n\u2022Best Practice\u201302: Right-size compute resources based on your architecture and iteratively optimize by \ntracking utilization, and use auto-scaling to handle peak system load.\n55", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "38561bbb-c574-4920-b0a3-1a110bd0d658": {"__data__": {"id_": "38561bbb-c574-4920-b0a3-1a110bd0d658", "embedding": null, "metadata": {"page_label": "56", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8c89fe638de87c7ec490cff46075b2276e759b5325615c7af7398e4eaa37d160", "text": "SaaS Lens AWS Well-Architected Framework\nResources\n\u2022Best Practice\u201303: Use serverless computing and other managed services to automatically scale \nresources as needed, eliminates tasks for infrastructure provisioning and management, and resources \nutilization is optimized.\u00a0\nAWS services recommendation:\n\u2022AWS Compute Optimizer\u00a0analyzes the con\ufb01guration and utilization metrics of your AWS resources. It \nreports whether your resources are optimal, and generates optimization recommendations.\n\u2022Amazon CloudWatch metrics\u00a0provide data about the performance of your system, for example, CPU \nutilization.\n\u2022Auto Scaling \u2014AWS provides multiple services that you can use to scale your application.\n\u2022Examples of AWS managed services:\n\u2022Amazon Relational Database Service (Amazon RDS)\n\u2022AWS Fargate\n\u2022Amazon Redshift\n\u2022Amazon Managed Streaming for Apache Kafka (Amazon MSK)\n\u2022Amazon DynamoDB\n\u2022Amazon Elastic Kubernetes Service (Amazon EKS)\n\u2022Lab\u2014Rightsizing Recommendations\n\u2022Serverless on AWS\u00a0helps you build and run applications without thinking about servers, capacity sizing \nand provisioning, and maintenance.\nDevelopment and deployment patterns\nThere are no sustainability practices unique to SaaS applications.\nResources\nRefer to the following resources to learn more about AWS best practices for sustainability.\nDocumentation and blogs\n\u2022Building Sustainable, E\ufb03cient, and Cost-Optimized Applications on AWS\n\u2022Optimize your AWS Infrastructure for Sustainability (a three-part blog series)\n\u2022Best Practices from IBM and AWS for Optimizing SaaS Solutions for Sustainability\n\u2022Let\u2019s Architect! Architecting for sustainability\n\u2022How to select a Region for your workload based on sustainability goals\nLabs\n\u2022AWS Well-Architected Labs for Sustainability Pillar\n\u2022AWS Well-Architected Labs \u2013 Cloud Intelligence Dashboards\n56", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "57d32a91-4be6-49d0-aef8-19f6f1cb0385": {"__data__": {"id_": "57d32a91-4be6-49d0-aef8-19f6f1cb0385", "embedding": null, "metadata": {"page_label": "57", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3789f0e8d53cbfd2f710e4cef04cea1828baab321217d965d1a21bd1367260eb", "text": "SaaS Lens AWS Well-Architected Framework\nConclusion\nThe AWS Well-Architected Framework provides architectural best practices across the pillars for \ndesigning and operating reliable, secure, e\ufb03cient, cost-e\ufb00ective, and sustainable systems in the cloud \nfor SaaS applications. The framework provides a set of questions that allows you to review an existing \nor proposed architecture, and also a set of AWS best practices for each pillar. Using the framework in \nyour architecture will help you produce stable and e\ufb03cient systems, which allows you to focus on your \nfunctional requirements.\n57", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "77bf99ad-8414-46cf-b799-e328740d3acc": {"__data__": {"id_": "77bf99ad-8414-46cf-b799-e328740d3acc", "embedding": null, "metadata": {"page_label": "58", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "41696d865bb3125c06ceaa6c9d1bf716cd872975d0ccd1d4ff75bc6348fa3c89", "text": "SaaS Lens AWS Well-Architected Framework\nContributors\nThe following individuals and organizations contributed to this document:\n\u2022Tod Golding, Sr. Principal Solution Architect, AWS SaaS Factory\n\u2022Raman Pujani, Sr. Solution Architect, AWS\n\u2022Ranjith Raman, Sr. Solution Architect, AWS SaaS Factory\n\u2022Akshay Patel, Business Lead, AWS SaaS Factory\n\u2022Oren Reuveni, Principal Solution Architect, AWS SaaS Factory\n58", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d8492b7e-6136-4943-a8a6-598347b4b111": {"__data__": {"id_": "d8492b7e-6136-4943-a8a6-598347b4b111", "embedding": null, "metadata": {"page_label": "59", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "1cc287ab3577ded323dd96bc380fe10acc0f1f6a460f8d29f4e544240d66e23f", "text": "SaaS Lens AWS Well-Architected Framework\nDocument revisions\nTo be noti\ufb01ed about updates to this whitepaper, subscribe to the RSS feed.\nChange Description Date\nMajor update  (p. 52) Guidance for sustainability was \nadded.April 4, 2023\nMinor update  (p. 59) Corrected numbering of \nquestions to match the \nSaaS Lens in the AWS Well-\nArchitected Tool.September 23, 2022\nMinor update  (p. 59) Figure 28 corrected. August 1, 2022\nMinor update  (p. 59) Figure corrected for clarity. December 11, 2020\nInitial publication  (p. 59) SaaS Lens \ufb01rst published. December 3, 2020\n59", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}, "d734584e-e0e1-4ca2-b774-e5103bb42ce8": {"__data__": {"id_": "d734584e-e0e1-4ca2-b774-e5103bb42ce8", "embedding": null, "metadata": {"page_label": "60", "file_name": "wellarchitected-saas-lens.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "56b4fc7b76032e2badb2c132c19f2359958601e765b989371274f6208c54b38a", "text": "SaaS Lens AWS Well-Architected Framework\nNotices\nCustomers are responsible for making their own independent assessment of the information in this \ndocument. This document: (a) is for informational purposes only, (b) represents current AWS product \no\ufb00erings and practices, which are subject to change without notice, and (c) does not create any \ncommitments or assurances from AWS and its a\ufb03liates, suppliers or licensors. AWS products or services \nare provided \u201cas is\u201d without warranties, representations, or conditions of any kind, whether express or \nimplied. The responsibilities and liabilities of AWS to its customers are controlled by AWS agreements, \nand this document is not part of, nor does it modify, any agreement between AWS and its customers.\n\u00a9 2023 Amazon Web Services, Inc. or its a\ufb03liates. All rights reserved.\n60", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "4"}}, "docstore/metadata": {"b38ad971-09ae-4992-a330-a66c4c1ea89c": {"doc_hash": "bb0e582f4d0dbf5270a8c8b8a4c49943571bb2854446b41eef091455684c3653"}, "5f106622-5002-4af2-a057-d9b680bc55d3": {"doc_hash": "3b1f727e9396931c854394387b4696632b267b1e445dddf40a707e5621d1596b"}, "65d8966f-d13f-4693-a654-1f7dcabe2735": {"doc_hash": "3d1f009cdc5a54df58933640f9f327e1d5d783030d0653bd7cac756c25442b09"}, "8f0505f8-e679-49ee-add1-1359ff3fb459": {"doc_hash": "0b5339fa11cb88676cb978a91fc25c02a8dd39a1cbc7d18bbb2e4883caeed20f"}, "f7dbc5ad-eb28-4b98-a7a1-bab3be464fb0": {"doc_hash": "b29923a447e57791498c6699569d132db4a9b658ecd23f03d922c2ecfe0ace3c"}, "2da8750a-2945-4a9a-8465-05d3ad7a56f9": {"doc_hash": "77b1fdce8c33b460587bcaf6baf997553161d57ff5a184c35bcf5e7594d8c597"}, "1e464a5b-33a7-4909-9a59-a05023940ce2": {"doc_hash": "96f01e8af7c0c17275dee588b29d7ef3585183dfb04921890ef81bad20004c88"}, "8c2ce767-4d92-458d-8296-c3c74b15bf8a": {"doc_hash": "7025a0d3dd2b0f6ab3b36790e3a214236ad891b5215247709158d9ddb2aa0d3d"}, "95c10028-2833-4cf8-ba34-a10acf6961bc": {"doc_hash": "ed38c112920b5f5c86a2c6dc414de85d8fc8bda570f3a97519f1ea7e2d378f31"}, "4e4297a0-8686-4c0a-96da-d64efe42c342": {"doc_hash": "4f840e05374c00cd99f00b0e1baec767dc82a644a961e653ea4ad54f8760e458"}, "0631ae6e-79f0-4349-812d-04b6abe3c508": {"doc_hash": "34f961d2ce82590ddd956b2ee34a43e899a4739ebc3a545ce8139fb0e5fea753"}, "0e5a0d8e-cbab-455e-baf4-6d86e578df4a": {"doc_hash": "4cf4681914efffdc3e6194faefe59de7c8f4e299e3f79f6ece01c4fe62ebde48"}, "9c895da6-46ff-4858-a64b-0ce6e85a0e20": {"doc_hash": "39bb7d8c92a40d997fdc7df984e0a363d13eb8c6b2cfcb197fac5f35a14d0082"}, "29009cc5-7cec-4414-b6b5-1122b0dcc608": {"doc_hash": "7ce0542130ab8f97bb24f4781857dda6a8219ed56064f81e871b37a37a7707e5"}, "6c109ac7-b9c5-4c50-b021-1109bed04c4c": {"doc_hash": "7978f7a313248188f2b1b9ab448419a7100fb2ba7822ca7deca60fc16247efb9"}, "aca4d3a9-72f6-4864-9b8d-41b1a569250c": {"doc_hash": "a526bf91f615bd35aa71cd791f0c0ef912c17bed3fd5fe0d868f0c33fff22b04"}, "d91a466e-171b-49c8-86d0-d830bb2afa66": {"doc_hash": "e05472e247fb3235907fea21b43a14ef4509f2bcac15ccb46caee9dd02271b03"}, "40f2f61c-d30b-4f64-a6a4-b696b779f3ca": {"doc_hash": "531c3fc129121774587cf4083269d05a792904a67a21f840ca04a6614fa6d00b"}, "a7f77840-1699-4a9c-a4e0-a8930859e108": {"doc_hash": "95082600a2a657520fe07c8a3bd80fc938d07d8a3e596dbc2675c6abc64be71c"}, "45fce943-29a5-447f-b479-0a5f6c56c3dc": {"doc_hash": "0856fe5bb8d63b801847f9d5544a514eabd85b2f7656bcc00d6eb660e8d4a7c4"}, "3c38926b-1165-4b7e-874e-61f5451caeb8": {"doc_hash": "8a6cfafbd1d390f7ddabff9ef4cb21fc7ae0a30eddffe81c7c63a6d648997094"}, "7ac7b86a-c241-40c3-aa5e-633d57664ae1": {"doc_hash": "1f26d7d4cbf9cd5b69453d09a40d8f354f63ddefcb1d3c0bec5b503c576a016e"}, "2005b2e7-6ef5-48ba-87d5-84c5ca28f2a0": {"doc_hash": "11bb7cde7e9a0abcade01de5ba88446e38b621aff1f3cc0c574a43ffc0840dfd"}, "177739f7-3b26-4aa1-9b09-6bc7f6216cb1": {"doc_hash": "ba599712665971f92dfd9999c16ed1c1a61156b2f4b0084bed7fb328599c5c19"}, "20cdffd4-ac78-4277-9648-78030b9c6947": {"doc_hash": "0c2e28e5ca7507efb749331e4c0bd0e5d9603974e1bfad49f8076bb64edcc99a"}, "14c811f9-f598-4207-927e-db7b44ec50a8": {"doc_hash": "b966b1f9a1e23c10525e194a4d26886b448b8079f583aadfb9db5ea24bc69587"}, "54c7cb72-fa64-4810-b4a3-ecf10c4fb96b": {"doc_hash": "e2019b1738afc94f74e8b57b07da56776da17460e0a68cbc68d93b03886533cb"}, "9b12d3d6-074f-4c98-ae23-064e3c69f9d2": {"doc_hash": "b880306602e1f437f118190076b09e1b3e9f0ce0cf9afe089adaa067d33b94c1"}, "c21c532a-4f79-46c1-be9e-4df8a747d0f7": {"doc_hash": "ffe85bd7423df234deed8e8ecd7ed074450cd00c7ce19940698e4e18bcea948b"}, "3842e99a-2650-40c0-b16a-b61e78d1e9ed": {"doc_hash": "57647cb555aeae68f1a955dc392c964238ba2eaa8be5bfefd3a5e48fb0c96579"}, "42bd699d-fa8d-4a09-bb41-8860b20e9f5d": {"doc_hash": "21fdbfeea7987bc2a55803cd1352cc0243d578eed856e976ec00a4898f77afb7"}, "812766a6-45d3-4d20-bd04-ad94a48d0d33": {"doc_hash": "5ea2b7d110e0b0ef45b3cba3a79cf0c47ab66eb6b6e1c480367ef18ab05ecccf"}, "dfa9253f-bed4-4ddc-a803-aec564ff8dad": {"doc_hash": "e12697b36cb07e220caf0ebc1dec19c5e28507b31dbce33e4be00f5623d1b770"}, "fda2ce6f-0d7b-4009-b497-99e86f975da3": {"doc_hash": "76b6329e170a988ea079505266c30e032e993eaa72ccea686e0e118fdf71d7a9"}, "3ec3ae7a-ffac-4c87-8c04-caa72a303f67": {"doc_hash": "82a675767b1bb89c11691b0ab9cd2f4897ea9ccdc8257d9e32df65980e2fb51d"}, "68b365e1-80a1-4472-8d72-98af9ddd4896": {"doc_hash": "033e25f7bbdb00c9ce900e69c0e4aac774191deb0b83e5eb1f42950c33ecd3d8"}, "9b0fceb8-0bc8-41c2-aed1-f97a08ef3f3a": {"doc_hash": "9820f8c9970849d58272121ebc13df8bb85271b2dd6dec7acb0db569aa10f0ca"}, "8767b2d6-be0a-4a23-800f-265bbf9a5f3c": {"doc_hash": "bc2d2ab997edff55d8964a04710d354920aa2aa69387d30b5150ed03724715e3"}, "dbe92b06-a541-41a7-8577-56b76deec4c2": {"doc_hash": "9f55ad40751f4e4f1633be764d934bac55f4a8fcd3939ac13a87f42a43752e74"}, "d26f97ed-ad92-4474-b9c3-7e9de017d41a": {"doc_hash": "df60a0cc2c3ad79aa7e6b736e48469074fb4d9a6f2ab209e565dcdbd57f53087"}, "e3cee8ab-c185-4092-a5fb-9f719b5cb2d7": {"doc_hash": "f2f452003dc2f95d16a7a9b9942ecf86a13d5c9dcc5fcdd9b439e415d3a91d48"}, "457d42a9-59ef-42d9-8b35-5a58df3e85d9": {"doc_hash": "584d1b4905534452dfd51ce4800fd89bba1230d976e2ad7454050095a0afbf9b"}, "8b7e2e61-199a-497a-bf99-02119a3abdf5": {"doc_hash": "ec9ac762dadf4956c12283ee06d03939cc51a0540d86964c2381d1a2c904ec6d"}, "8b9d7a58-c4db-42e9-99fe-a2eb40df8844": {"doc_hash": "3318cf1210fa5f7684de87616a879be9c63b5cb8a59450039bf0dea18320c345"}, "a20be1d1-4818-4dfe-ae67-d94bd94f4c73": {"doc_hash": "95e9bf14ed75e5e178c6f8fbc96835a16c3060ab447b386f4684fda1e0a9a3ee"}, "cd0d76de-e528-442f-87ef-29d1dab122b1": {"doc_hash": "3063780501c76d6038167f3f5d71a1dd8b28b01a66ed763cabb8ee1182a56a31"}, "34917ff7-256a-4baf-a212-b45eb3d01c07": {"doc_hash": "b15f569c81889674755b4bcc8db2c094d40f9581697ff14d9e49f759256e73cf"}, "489dc0a1-7c0f-48bc-b46a-205f9c4516b4": {"doc_hash": "c8834a8ce2385bbaddbad52e1398af97ccac6272fa6830fbcad18554362f16ad"}, "b31f59b9-5b0a-4462-bdc8-38789cca3443": {"doc_hash": "a07edc4be7ef72bbdd7e46d7a833d95a512ab9c81cc154087f742945f2d9d93f"}, "9fc765de-0cdd-47dc-a129-b565c38d796f": {"doc_hash": "3d3259977673045eb059a7c98af3150c3399ffd1b7f557a04eebebe37a020194"}, "835fdb68-abf3-4132-bf29-06ee797f10f1": {"doc_hash": "a6b4f4cf8a7092d5a66dcc599701ea10d0987658c13b86ae4c5af0a1fe26a34d"}, "45154fc6-f116-43cc-8a6d-c29586fc99b8": {"doc_hash": "78d5751f9f9fc91eeaf5ee42448a3b22ca465610108f5b368bf2e65dbf6ea945"}, "851590c6-153e-416c-8bad-f8c5d26ff028": {"doc_hash": "e25a1a590d86dbb89a0ad7f56ee595e69612af5084b551e0eb6ba8b425e4ab0b"}, "74366646-fecd-4f17-a0f7-66d10e37b486": {"doc_hash": "8d6d2af784092af4284d32ba19c0d8b5368f42fe332899dffa10a8ac640a9e86"}, "adc9f31c-d6d0-416e-9d9c-6902f3fec5db": {"doc_hash": "a41da9448a8baa623ba7e852ddf8f357011b548e068d4475bbc1da21e1cf3947"}, "1b181185-31e2-43c7-bcdc-03d7ecfa297c": {"doc_hash": "388691a2c86f76c78e44d2bdf3d370484c3d857a38b9c025f13dff84827de555"}, "a3d2784d-383b-4e04-a924-56ca3b9c49f8": {"doc_hash": "4cc6bc82bc6c83aea2bfa2fb15eb97c8152542e26e4d9a9b209c8b67defa7b51"}, "b066b474-fb1f-4e28-abe1-4145deb8d92a": {"doc_hash": "92cfdd5de513cf1784f4d68f3266fdb814dd60a2dd1ecbac643052b27d7b763d"}, "73edc339-2561-413c-be3c-e0108472c132": {"doc_hash": "3fe13f6fe489bbdc88054bffb346ae93c1f3a789e1e9dfc8cbf386ed7e81c79b"}, "ffff6569-b880-4212-9acf-94579d727b5e": {"doc_hash": "40dd6513c3a94b227f1d931064afece9f1f20fa1973cc47d1a8ac1c4a479f364"}, "d2271768-c076-4390-8e40-646319ac6dbe": {"doc_hash": "32eb138055d5caefcc797b81459d4e186a6417f749c7f3eb9f26a113795a2867"}, "24182e46-ab35-422a-9c31-8f6be461b6b7": {"doc_hash": "621269097bb1bde04c633b70e12e817c4198a06c8470582f3886222d5a1bec69"}, "0f844ba7-a94a-4cbe-8138-a8b4bf346903": {"doc_hash": "8b7ead7659f6b151469c11593e57f318c3a5774043bbf236f85cf15d867acc44"}, "0737c330-17b5-4818-8d7e-9f23dcc614d1": {"doc_hash": "c87cb3b2201f9f7bf1e4df076169a410c751ddc6613d134344e0f68f7ed66230"}, "f41a0c8d-7fda-4dac-8b42-eeb0f16ff679": {"doc_hash": "624c071cbdb4ad2953ab955403027c6828d8cf9325b8a0e230670e5c8a77bbc8"}, "132dc50c-6c11-4b5b-a5e1-e51309a2d38e": {"doc_hash": "559bcbe2de5852f605b1be558b88bba6ff6217444fe3fe9df51dad19a0657d99"}, "e886fd8e-fef8-4591-bc30-3450723143ab": {"doc_hash": "cb3c419406c3e82798c9dd605fd12b4469232a68b0f0bf50790329f5d420f075"}, "e13ea540-a15e-4464-b390-633ae96d583b": {"doc_hash": "7c7ec2343d0843584e275d7ca538f3023d01a9e7969edd5f5ecf68234ae4a3d0"}, "a4210b08-d4aa-488a-9682-4ccd870e3d39": {"doc_hash": "5580f8fc08bf8911cfc12056be11f65ea2ed54b6ad1aba09263fc733a66c0473"}, "0e0386c5-6512-483d-8f25-118d3d4d6e21": {"doc_hash": "b4dee3f49ee8aeb45cc915ce230e7081ca6bc198821d83436c969c623939b0c3"}, "9fa2f37b-cbdd-44f1-a7da-108152550a6a": {"doc_hash": "02cf11379a565ea43c8d9334edc63584b14d38be642ad7a07239ed1271e01705"}, "be4c134a-3313-4b76-bc34-b315203c29a1": {"doc_hash": "069fbbde475ebab13c94ce57429371fdd9c4d78f3d6a9125b5d5fbda989a3a50"}, "794130ef-b676-469c-b0f6-0f9ed0fec89e": {"doc_hash": "f5e468d415af474f3f03c377c72f9004d3be693bb0dbfbc143fe6a51bfda49a8"}, "a0c9ce45-f84d-447b-8d34-195b5443daca": {"doc_hash": "fd4e25940c98b179753b6f3d5dc27462a885c319a76ba42b75157af5042a0319"}, "16d6c94a-ab46-45e9-9274-ba1adda8b6ab": {"doc_hash": "028521502b43f96f6d931691937d13186ea5f69935708efe4b01ed0702db6999"}, "59fb1121-3299-4e31-83cb-4f6dfe910636": {"doc_hash": "fc62abe80fa4566fef2d253edb6acea1459c30f63595e7e799155e25175d77ee"}, "17328d74-0d1e-46bb-88fc-dbeef5027a26": {"doc_hash": "7a53fb4ff8ca2006918066d5c847f460f08babfd0661d3b766152e49e613539f"}, "38a6fcc4-88a6-403a-8510-8126e7316530": {"doc_hash": "3b1bc9d0211c890df02b447dfd57c74d4f0ab01c05ee7e61a42d451b614277df"}, "c7392cd3-f989-40f9-a962-e977c414b863": {"doc_hash": "c6a1c6756e8dd77fc3c4b4151101f28cc3c740929959ca4c096a4053b8ee8fef"}, "012abdf7-ad5a-4d9b-ac75-c5ab28111b2e": {"doc_hash": "add1285dda1e81d47eef0f5995eef82ae1576d24e55d5e81b4ab1083a3c96660"}, "ce5607c5-b927-4759-bbb0-9a34b9895e96": {"doc_hash": "1e261f054881938ab3d7fe8fb56d2e1b869cb1e341207a32345f30bd4981dfac"}, "3d01798f-5c31-49b9-a74f-a8353d6a5556": {"doc_hash": "3d61e243e3223d3f63108f75c5305fea03425f978147cbe2e9bedf7a4883ac4d"}, "3a53e92f-a683-4a17-ac37-47cc1322b365": {"doc_hash": "328130f90037e05adc3f4940e3f4a4cc480f9e0d9a5a31f32b1ed8f9172357fe"}, "ce9f010e-2040-4132-8503-6e85612947b3": {"doc_hash": "8d7c0e426242f1e6f6e57827d86dccead1824a71f738278ee7988009a7bf2392"}, "b02387c7-9b89-4ea3-a892-3edb7698d803": {"doc_hash": "249f6df74a59cab8922fd87e6e20b78070f4daebf0645b55de667461915956c4"}, "542252ad-b1ba-488b-8230-baf3f7e74d43": {"doc_hash": "cd0f461945621ace98c81e503c37a2cdad476c0d3c519b60081c9b4cdfa56c7f"}, "cc22a6cf-1ceb-4c37-8fd1-2c68bdc38c06": {"doc_hash": "08dcf9cda65d75798568d9b4986b89fb488621fa1cbfdb5c2e31f86e36911196"}, "235bb362-f4f0-4e43-bc11-3b811ba4b893": {"doc_hash": "1380408257b64086a5904eba8f6da7951175fa12b2d9db28a3b5aee3b7caf9df"}, "042b1a07-c587-40ad-9d0b-708d5c8b47e6": {"doc_hash": "c09051cca999a52e680a90010bdb9e7f8cf2f277b8a59186e0e8301c782063ab"}, "5024b8f8-3b99-42eb-b11d-3311b18e6df1": {"doc_hash": "b3ebd598f19c872ad5ae122a9d99d73069b48a21b5b7c931006c5ec10882d52a"}, "4cb7b0b5-9eec-4a7f-ae2f-da09ac6fbb69": {"doc_hash": "8072f9352afc59368307b98a13c4d9d4340816abddf042fae36537141b1008c6"}, "6fd73020-5820-4d26-96d5-470c72eeafc1": {"doc_hash": "8395239158f20c9cc36dc8381e08e3a768ee78712863851868b2622205da7a39"}, "0d7273c6-cb5d-4907-b15d-d142af2291db": {"doc_hash": "03f46485fad8cb1d70ca2a3410d1fb6106aa9b078dd13ea6dc4e0a8ec8551467"}, "a8c8b567-6928-4ab7-b873-9d01340684e5": {"doc_hash": "9d8542f1c0ef4d76c6edb5cf53d00c4848bf297caa4d48f43857e8034995007a"}, "b662809d-35e3-4044-9bfc-5b074abaa5ba": {"doc_hash": "0263aa5b97edfb2ac5c00167ec772f41d2e9198a75cf48db7c5ce51ccd856d28"}, "6bbb7b79-b119-4de8-b320-c0309bed4a66": {"doc_hash": "55183d9cbb5e898f54ed430d8bb4674ed496010d036219fd8cbfb2b4cb220e76"}, "9b2b4a82-184b-4cad-a3d0-8d3742e8f812": {"doc_hash": "8c5711fcfb095de997a446472710e9f62b0f81e1bbd9362b59dfea4ba1dac504"}, "1aea3e2d-7d3c-4ece-977c-064d428bca0f": {"doc_hash": "96a587fe5adf0ee1a0ecd6927e852edf00caed597dd8e697f5187fb99c109dab"}, "fc6f3aa7-2ce8-4d7f-bd50-739c4c0860aa": {"doc_hash": "4f5644a50fed7fc8c18c25d7383b1d3d01fb3b776a398af4bbda897a5d5f3fdd"}, "8a391d8a-d60b-4a53-971f-91b142dd98f6": {"doc_hash": "dccb44db360e8e4972c65a181d910f33e38fceaf0c0249f9e98daee58214ce31"}, "108aaa77-e612-4ac5-bfbe-b787362e6ed7": {"doc_hash": "a22ce92464a99fe8ec383a54193a45b6f5a4146490722e67db50027dd79f1006"}, "d7364d04-8a29-460d-86f9-2725a0064930": {"doc_hash": "7f61596ec1bce624a0ae631b7338c1a3a3f405620f07adf65639bc813f342d71"}, "8bab5b0a-b53d-4bd2-9321-0532e3e1ef9f": {"doc_hash": "f5193e74b37411654695793ba0beacb97e8797e5e0e899257d76fe0321a32972"}, "f6f17138-2e2e-4f8c-b654-f5ed779b482c": {"doc_hash": "a2aeddc03fc35532ba32cac90340c24027b73d55504121f68a8d712043896f30"}, "cd276a77-0bfd-4287-836b-a79de8c02bfd": {"doc_hash": "b3ef7379eed9bdd7e3575eece05e733f3a22ede7ece04e272f8c387aed7d1dd6"}, "02520605-6a51-4736-af7a-f2904f6d12c8": {"doc_hash": "3a50265bdb365d74fad1708236b28747d75d49732f914cb7da8e31f24f6cfcc7"}, "eed1b0f4-d126-4221-b0c3-4bafb995fc79": {"doc_hash": "fdcb31c456ee2205df9d7ffc6bcc5481ac1fa727d51839d49aa0c8926fbc415e"}, "3c772d1a-02fa-4653-b6dc-1a6d90fe8fcd": {"doc_hash": "fbf976f479d19422fc02dc59f507777f9fdde370822d121014a9f7082f2d2021"}, "3524ca56-3321-417f-881f-c3fe0acb0375": {"doc_hash": "94754be6e7e69c528f1826c11b0b93e90082b4097ceba850ef046781dde8f0e5"}, "e51cf2c3-e0e1-48c1-b3ec-38991aa3bfe9": {"doc_hash": "0d745b3d48fa3e1a1313e0b562fae8b44bcc6f68d51805927cbeb2775595fc9b"}, "65163188-181d-41ce-9f9d-a0b0d242a93b": {"doc_hash": "cbde89d4c14eb0c416245f68292a327d09c50d76982d54c8f3fa5c58b5b2a5a0"}, "38833b59-b4ed-48d0-83a9-4cd209baf87a": {"doc_hash": "db0a4055e6b8e36e4de75fe653fc1d43bc3b57e8568e3433f238da4dbcedfb66"}, "d75d8e54-13fe-4671-9043-f34c342f8d88": {"doc_hash": "8757ea326c8597264c812c42cb057996e561ed4cd6d0aa5317b43794f39fe014"}, "4b10c00e-57b2-40db-b7a4-8fb11f199cb6": {"doc_hash": "26598c9c5c4bebf7e87cec27f4ad6649e853e2899f7b5428ade5c48a5837345a"}, "1ace74c1-a0db-4332-87fb-bfb1562dab76": {"doc_hash": "85619f928dd5a51fe1015272949ee5a49bbdf8cd4e67dbf8f26dcff995a4a999"}, "ddcba91a-faca-4059-bbc3-46b2236e4f63": {"doc_hash": "6b32d26e272229809e9c20942e90924645fc54db06a0bac788fdbb3e241dcc6e"}, "b1da7218-e574-4f34-8005-8ccb7247dc28": {"doc_hash": "d357246352d8bd0522f3de6da123b0b6f31ccffc28d55393b0c2f1cabef4bec7"}, "e21b6fd7-d52b-4f46-88a9-ba5b129f2e08": {"doc_hash": "355bf0139d3d3a4a98b2c1fcf7c214a5c97704e02f102ed60d9698d55dff483c"}, "2b6772e8-5e09-4481-ac10-a60bd84aea3d": {"doc_hash": "51bbb31ba5601ac655022b1678a630814ba7cb10e05e57cb139c6fe5f83ad47c"}, "4e89613c-a0dd-4abe-b993-ca89bd0b0fa4": {"doc_hash": "0a1957e72de03f10f0339d672134415394cd9939e8ea4d7fadef05ca7a56b233"}, "c92bc4a8-c51b-4167-81ea-f07af5a0c90b": {"doc_hash": "b3230a6db053b312c9b3738743e8af6a092661cb10df18da55c5cf8c05670515"}, "ceca8eaf-78ad-4897-b5dd-76b2c6481cba": {"doc_hash": "10f8abe9d47c7ab1e4cfc01dfe3f03ccf51e9ea0822cf18e71507e7a4fbba7bb"}, "36b59e84-4ff4-4b11-92b1-0c48cc82d8a5": {"doc_hash": "bd57ac700701c3ae60429f143c932ebaf60a5729920bb0e0d6c6e77cbc2de445"}, "fdb66548-1ccb-4b87-b3ff-2436fec1b957": {"doc_hash": "727c0c5769b45c21cd3762b943ad2002036c33a0300e4923223e8753fb741840"}, "f79335f6-322e-4ad3-9c65-b6797ce9c556": {"doc_hash": "5c813f26914b6dd1a3d80a9dbf431fee6ceafb6c3ea151cb2ed336675f9b99cf"}, "cd822cf7-8fc5-4862-95f8-6a9be92ea497": {"doc_hash": "a856a2e2dab99d46f3c560cb8e25c6ffd0c0be7ff251ea882b01be464fe7524c"}, "a8feecca-a381-4c12-b2f4-33d6d2c267f3": {"doc_hash": "85e2c8dc529359b28e2131bced2885fa5d1128c8d20abfcf8b22a3d77de44ddc"}, "35888876-ac0a-4092-a389-29012c1b3ede": {"doc_hash": "027b9e3150bb343e688dcce0bb0e1b867dae187c85d943f0c689fd0cc3334336"}, "e54ade80-4ede-479a-8eca-33a92e0b11cb": {"doc_hash": "a5148cbbb6cadc1b54b44b7dca5cbb1540c1018bdc0d43294cdd306d10cc30c8"}, "7d86cf0a-bf4a-4153-b2a0-bd9ca24615fb": {"doc_hash": "1b9807546f252f7a714839bbcee40dc7783de4473819c20078c1d7f37729ed30"}, "45e9509c-785d-407d-aa11-30a27cc8cba2": {"doc_hash": "cc7cf5643a6e7ef9ba9897a870f5a5207368460bd86086dd6f8be62ef2c0a5fb"}, "73353ec2-8cdc-458a-8cf2-958154eef334": {"doc_hash": "fb3bf0c382ba5f04f84cd883ed00e7db872f05543230ba739f715004c722c523"}, "df7283cb-6c32-4e1e-af44-13738cd2792d": {"doc_hash": "f01fded20d721a48e43532bcf326e8fb5873da598a43e82a2f0b09856e421bfa"}, "0fb08bd3-40f0-4a84-b716-6731b03a558c": {"doc_hash": "ea74e2059127c23abccb56c8432cf1ecea52e049b25588707476831c8fdc277f"}, "902a9643-32f6-4ebc-a634-17db05a66160": {"doc_hash": "e7c9fe8366b687b420d3b7684cd5b7b545c9cbfff51bac8a1ee5aa11ccaf24df"}, "8f11be0d-f5a9-4835-896e-984d850f63b6": {"doc_hash": "2dac463985d363bd9996010a9d99fdc25a1467434d8c3794f014797ba6eee06f"}, "f00ee21b-07f9-4877-9ce4-f172d6d95f00": {"doc_hash": "d3c5dac87f017d3e3be6a895b22b0b07b16cbd9e7b02720142064c1c9e37a871"}, "69df6054-de20-4b9b-940d-196ce38c4b44": {"doc_hash": "670beac227b8c536564b581afe10a193104370362256329c1b6754b52c30ca79"}, "84226ca7-d12c-4f87-9c57-3d731f448746": {"doc_hash": "e53257c9b245ceb0a832e8a8bf6dcf4f8e96f338f8d8479533232cdc8c4ce30c"}, "a7629223-7b14-49d8-ae29-72684880bd1f": {"doc_hash": "d57eb5e747ffe338ee9710db669cbd1c47f76750dcaf35575fefda98a8beda1c"}, "eff56bdd-bbbc-47f3-9b42-dbf47a54bb6c": {"doc_hash": "bdfb9ff57d27706e64adcfc64813cbb90c50458215e6b8706f10cbfdb6703872"}, "1b398117-3447-4f3c-9c39-fa4eb40da539": {"doc_hash": "7e8f2e8034308327a68ae146fc9f3657ac319a5279ec0dfe341aee05f6b47044"}, "518576d6-d2b3-4fed-a57e-d1f69aca13c8": {"doc_hash": "99bdcc0f2a4b41d00013966cfd81d5dc55ab27badb0a8d8dc21a8d9700d50e1f"}, "13810b55-9a83-4cb0-b07f-9d7d6fe0d093": {"doc_hash": "cc1e35ce81590b670e5eea4741e142a1129b58282fd4bd834bc14545ca68f925"}, "b630b5f2-6fe3-4288-b22b-7330bb5cb398": {"doc_hash": "50ea64edac860fa5c41368045e0968dd54a42a2b231d497dc51e7a8e85002820"}, "183bb781-2d0e-4917-8533-5889925a6cde": {"doc_hash": "540237dd2341ee77628615292d75c0014d7a33feda048a279cf850acd20f154e"}, "c8133105-b3c9-4b0b-a078-2ba031ee1bd3": {"doc_hash": "cbfc11dde72394ba716d0ed9d140f165858e77e3c476387440dd5b9c5e298800"}, "c00d6022-3042-4b49-9262-16e773fd6c34": {"doc_hash": "5b9663158a043337cb693c2f0dbfa06a8d4658b4385e9b2b99644b6fb2159626"}, "f9a09b09-9a91-4ee1-bd72-0081a582fe64": {"doc_hash": "fff69c96bf632aaddabe7d0fc0e05ca8c98ed9e9d0fb99675ecfc52edd32114b"}, "bc854b50-ff5d-40d6-8113-ae91cad563e2": {"doc_hash": "b30297225f7d2a34de611e7fd6a6f4a0d6a1390f8299a7e9ebc96855c15aafc1"}, "f7e2f8e4-865b-4ac2-a9bb-d2e1f11d9b53": {"doc_hash": "f9e93d535398fe31e961d5cfc0b91898830ade6f400ca0f6000721363fab224d"}, "da8bdd5d-301f-45f5-8f8f-97fe3062a15c": {"doc_hash": "4907b2a5f46c4fc7b27274b3efa349d2da1332712b09d035d3318c2756eae1da"}, "193111f3-8368-4c37-9e51-617a9ab50fc1": {"doc_hash": "8bd1e0fdbcce20a452b50aa5108563eec1729de00089a141e395427c7d4c251a"}, "741ac371-44b9-4fd2-b844-06b296929a79": {"doc_hash": "23165fb0d41c4f41267e0f4c20bf08cd17f38c74a67074bfb5cb014e12b88a5b"}, "90d3a658-a007-4b76-b406-1e3f701861af": {"doc_hash": "5bac155873f440405f7f375b70cbdf2c2a40bf28149be4ca5b0425b94b060e95"}, "b8a5a6cb-2f04-47fb-8c27-1fd58e1c42ef": {"doc_hash": "0de181ecfe090c26e38c26740843a5924e03f79d4c869b59307c437c79777e68"}, "ed4fe457-628b-416b-8740-a1a876b21295": {"doc_hash": "d1acd3b2687a7c4591a07a51c4b5426d385fb7fa00fc2770277ca8b58b46c2cc"}, "f301b346-e266-46ea-8f4a-9d0f95773d3c": {"doc_hash": "1d3e78cb2f7e35485f53dea21fe488dab4c53b1301848dfcc59a2d14c44391d8"}, "f5dc0537-af8b-4886-95fe-35a947ad0792": {"doc_hash": "485dfba03a89517d8c615632c155e694fd5bf43a88c7cd2a43407fffb87f259c"}, "899b42d6-d9c2-414f-9bcf-09c2709eb703": {"doc_hash": "a675bb030543abdb40ac80170db4d45bbe991b3985759705219d9668dd225472"}, "937fa38a-c5d6-45f7-8b4f-981fffc75952": {"doc_hash": "e1bcd7496ad3b9b58a980adff0b22d2fa0025db1ebee1915e1ecacd4e762f2fb"}, "08a97c44-395d-4c76-9f59-7760c317aa0c": {"doc_hash": "46be9a7a4053d194c2b38f9942a3e3d250b16ade6277d4e444ac7f5bb0b3aec9"}, "c2818042-2ad7-4abd-b138-89a5db55e495": {"doc_hash": "c9c629199f70982ea0eb7596732505daebe776f6438b6ec7fbde4d1ecfb7bbe3"}, "4df77e7e-d40c-45dc-8258-7dde380c090a": {"doc_hash": "b610f420b513883b80c45ae7eb31f305a87de9ef912dc1f6a5bb5ca656f5b6a3"}, "2dcc83d2-ee7a-4cf9-bd52-5bbf83e9acfe": {"doc_hash": "0a2184014331961e9c6781c1abb1e5b6911309608f9cdcce4dd18ff7217c4a59"}, "29638380-0374-44e4-8a06-8a388d363e94": {"doc_hash": "c81c513f9a6c0b24793cd413f79b9a5eb4f7f90334be13f6ac90a79bcf8c3300"}, "8b3f79f2-2e30-4626-b112-7e77d02e1114": {"doc_hash": "441b23d46a0097e09e3f1dd8e48e0ffa73ec3cd84177957cd10ca782cfb843d6"}, "9916cf39-c9b2-440f-814b-251d39fd1ca7": {"doc_hash": "d5e2913dc5188ff698c625b22a7833bf04f1f1153853802c6dae340718fcfd6f"}, "0eee301e-92cb-45e7-a1cd-33a76354ecc7": {"doc_hash": "0219871bdb0054aa43776a8eee44bd8d3876af38974e9a4ff7a28e364b079632"}, "3197d148-a31f-4a9d-ba86-7eea55e3e93b": {"doc_hash": "4ad2f0a28b0c19450ee5712e8cb7051bc68232fd16d58f8dbdbc6ceeda9781ea"}, "db92fdab-9433-434a-9b56-e0347c9c4f70": {"doc_hash": "08c30eeb511ace41f2bfd60f33520ab5dcae5f9647333eba94bf15cbbb0d9310"}, "ce365f7f-61f1-4612-bed6-80dbe0d8d38a": {"doc_hash": "3ca7db017d3428a192e9e569ea325401876a0cb3b2d741ad6ec6ab07618a82d2"}, "f3dc674e-88fa-479b-bc1d-920110da24e5": {"doc_hash": "455779039ed8705b91083ceb502c2fee1dcea1d2e8ef4b5d2f6aa04862af4d06"}, "57c7777d-09d7-4dca-bf74-d793262d391e": {"doc_hash": "3c5fb6152eddc94b8c0fb64ecbf60b07a2fc272c0fa9da8daf566492f0ffaead"}, "544f9be2-44b6-44c8-b57f-73296e2ae042": {"doc_hash": "c0a9d5a7effeb63bcbbc2b7576d060d890b5675e21dae34d8d1f81c0f04846da"}, "f36210f0-cb96-4c10-87f2-fe8c3967031b": {"doc_hash": "e1dd9e1568c8824daa667a571bc175e3ecda737a17abaab9549864b9c1b495c2"}, "2f192f00-e7a9-4ac7-8b1e-495167475469": {"doc_hash": "ffc34dd37791721c2a9c79fa1170a703668c41518b389715b3eeda8a879f0d31"}, "5c38c906-eaa5-4d08-b233-384e670d078c": {"doc_hash": "2942804e18ebf86bc0e7cc37d57f58c5d2041e9b2646384fa848125750fb74a4"}, "5d05ab0f-e72f-4e03-bb58-71877e3b09d8": {"doc_hash": "01b15a0d624aaaacc101999927d5357fffd1612a5e91795154401aa1e4e803cd"}, "e651d47c-bd35-4235-b2bd-8176c6e90a8e": {"doc_hash": "b123d97734f60d53364734e03c7f8b09b9438f08d8fd9679f9cb25a3af4a8a3b"}, "2cab20c4-d93f-4267-9109-1b0caa0b7ebd": {"doc_hash": "d2e16aab215340dd41b22acdeb03f4eed02adec1dc3bafa64d2dce8c019eb904"}, "9703f8bf-31c8-4c5d-b1ac-da455972a874": {"doc_hash": "cd2b1c45e5e6a0e9f07b1926614b6701fbd49c25ce24784a42e03527910dbc0c"}, "0e5acad5-179c-428b-b900-4e5b917298c4": {"doc_hash": "85e522a1368d9ed63a016a0b395847820584c01c2bd21469dfa8b208b2e7d47d"}, "9e509368-b40c-462e-a062-06b751c38e29": {"doc_hash": "fa69c171c5b508b216838c788576aa05a10e2e37ae7f09d538be24376e5e3b30"}, "8f7696e3-2176-4c13-b597-2be241ceb431": {"doc_hash": "2c6545be91d9b69646cb033cc473413456fefe607143d9ec3de39324eb421a79"}, "715527b6-c851-47ef-98ba-bab6c16b03bf": {"doc_hash": "a0a39d258a655bc2db9f9efe1c667731d62813f87cebf28d27431ab67c1f8ab3"}, "b583f095-788a-427b-b3c2-1dfde255a1cd": {"doc_hash": "256f23a8d69ed773cff4dbb9a587638813a2ebfaed2ba65c45557c2168cd3f13"}, "7b338443-b567-48c4-b538-995e98a73746": {"doc_hash": "a1918097ce666729532c0858a8bfc464e4b66017eb60ef76d9052f29a7e3ce22"}, "63208d30-bf3e-493b-8e04-1397e4aa3ba5": {"doc_hash": "720528e5dced5b70d0bf7c5af8e8309ce94b7af186370558d1a70cf0de175ca6"}, "6a4bcb81-3b60-4c9c-b3b4-cc3c3f27ede8": {"doc_hash": "e3771897030152d78201a51788f7b7baeb3b1d8bf5e6a1e978dc014e380de76c"}, "b5a22cd2-7b1c-47aa-9532-b626e7cb7976": {"doc_hash": "824b959b6633ddf1c30c2eb603f6487fb4c127cb157b8f55227a523ded8bc383"}, "1591cbc1-fb00-4328-a689-90933a9bffbf": {"doc_hash": "7d2cecd3721f173047411d028a77b9035ba6d7fbede398bf140fbcbf492d2719"}, "3dddcb76-7492-4eb9-a1e9-1e1a8bf8d81d": {"doc_hash": "8b804316fa7c2b0d7c44a7d4919b6874ab00c71e2125142b4c3a8eabfe281c62"}, "d6d58e39-84af-4577-ab1d-b8ba6b9ea284": {"doc_hash": "78092c57d0c05cb4c648ad2be2625c4e2181d9160b89efdd34a4e9a97b1969f6"}, "24435b16-0a94-4f38-993f-bd3a10cdf4aa": {"doc_hash": "37dd512ea250b4d6278aaba72db3a4b6353e20f8e82dbe2a993c5d5106326dab"}, "d5c1a266-6b54-47b0-a6b8-02700e9289b5": {"doc_hash": "5a658c8b4dfa9519ba0426f60f35598af03396a2a59712ae3e88e2a1bd0b5ba7"}, "aaa84c4c-1d03-4e76-bf78-5917eac4213f": {"doc_hash": "a004496acb7492c3b801fe87d29ccedd035967b88680605d980ebe6e68e96b19"}, "9cf2c09a-217b-4eed-9122-3fe96ea89176": {"doc_hash": "8d07e53af552a01351d6a2a2b38dcef67ad6dd161f82fa0b828fc4842a8d6e4e"}, "b05d1ea7-74ad-4d67-8a1f-cce7387cf550": {"doc_hash": "3729ea93b12a7f670640a2d71d59a1da779a1ca0458e57f0a1435416271bc2f2"}, "88e87bad-705d-41f6-ae6f-93280e2432dd": {"doc_hash": "7d14fc189d17a3b2d369afe346160ea04e1ec3ce8c17636b4bd7693494939b67"}, "d5a19004-9bea-40b1-8a58-5df097fae01d": {"doc_hash": "6dae762664f15d910f79f3ce15568745c5fa994f7ebbea4211694289fb17cd7c"}, "9d542aab-24b3-405b-8af2-e05491c6312e": {"doc_hash": "9262ae968764a5ed384f75b7547e6c5bca41ce927ee81aae01934ff286fa2abc"}, "5490ccb3-328f-42ce-af17-a30cad3c2ab3": {"doc_hash": "686d4d4fc643878dfe27c2b185f268a044859d517a78c6087d3e9ab360b8a418"}, "1f551067-8c23-4a7a-a7df-6dd3870aa939": {"doc_hash": "060b62dbd0ffbe95d9028cdb876c279bf683160f804e79aff06fbae859988303"}, "eb1957ad-0e77-4c45-8f3a-28d968e52a05": {"doc_hash": "a1d9284115eb330afbc81a7b5222bf4b5e8a97d04a0dbcafaf0e6510386e8ba5"}, "0cedc109-d3ae-4311-aead-ee6e17ed0283": {"doc_hash": "d223c5a74822779a1d0f287e1e18d3a1f18e20011ea505821e8bc9f6c06a273a"}, "bafb06d1-36ba-4a2e-9733-d2c14b4f6635": {"doc_hash": "c556ddd5e8d8f328e3fc42f4ad42cc5159aa2d64790b53304203d6309dd97ce3"}, "fd0a1eed-fc78-4799-ac6b-e6c1db17e241": {"doc_hash": "bdab0c5d3c6b5c562729918dee24bc1d49b1c9b1c43805e33542aa7a7888759f"}, "6e96873a-86b9-4928-8e0a-3fb84be04a94": {"doc_hash": "71812ffd7268e1fc04783498dbe7a1d66e4c7caa6d83f68a13646b95e3b030ba"}, "52284c99-e945-4292-9546-76dd66009847": {"doc_hash": "9ad91a6faf44ac37b3ed438829978e0f73005641a7953d628d71512aecbc87e1"}, "b6cd767d-0c30-4cf1-b0a7-8ad4e3e9e545": {"doc_hash": "644b5f8372348d988c112f764368ef4e24eb9001bae369312a3d6d79899f2ad3"}, "6a709138-ad39-464f-aada-63c9033c592b": {"doc_hash": "0b15791e92502d1f4f6d1cf7f094c5685555ae90e5584c6780fe47072702b322"}, "ba4cb2de-e1fc-4358-b10f-2fca22854af9": {"doc_hash": "39c3200abc9e3c9e394efd3f8f76f0e6773d0c3307df63fc490c5d8f9522613f"}, "fc866898-16ae-448c-82b9-a07528f9cd76": {"doc_hash": "d79f7194994afbf932fe94b152aa29b26cb108df348f141e1a1a3fc2ae37a095"}, "50a1f65c-ae8d-4065-b9e8-7187c2b78138": {"doc_hash": "f9a7cd14722980a33e7f1159d4579242b080aa50c1a00bf119ab3120b285d4b6"}, "6651f453-a67d-44e0-9ec1-dd5c4ff68403": {"doc_hash": "e8c1fa2e89a79520607e7fb351b2f2021bef752428594e8aa13e39e9805d7f5b"}, "f7e80580-7dfe-495e-a356-2a0567646136": {"doc_hash": "372cd00153e3e9a88eb0c0bc615cd374e27b9af2cbc9a1197fab4ad632e4aa1d"}, "6b2268ac-304a-4dab-8c65-10122666ec5f": {"doc_hash": "b1082bd3f418f561efdff91e4587559772c7d3bdbb63d3c496a1d384d112f58b"}, "9a381a7d-cd0c-4002-9bc1-56ca7977e728": {"doc_hash": "546d00041f64d02f6a1f56cd561f12e9f6a12acc6a6c0bf89477757d3c7e994f"}, "33e1d576-095b-4aab-b3bd-e26ef6f2e005": {"doc_hash": "4587860c28193f669c8667922ca5cf9dd968ad198016bf9a66bf4ab110f4b53e"}, "d227d28d-17a2-4c4f-bdc9-e6a1912f6949": {"doc_hash": "b4879b01a1c5b8e168aaf22f4218bddc8833c6a78a77329c1d6df2aaf3fb573e"}, "7cbe6933-cccb-4ffe-8a30-99e4adc30aa2": {"doc_hash": "fe30f324680ca0db469144fe42651f7cd1a16fe67deff0e1c1c04709b6075047"}, "d52a7746-1f43-4e0b-b4fb-fc2cee85d4f6": {"doc_hash": "0e7735ea070dc097776a0f3e7fc126d6d4d341efee6bdf05c70848c45d3ac84e"}, "1eba8467-e2b8-49b1-89f3-63f3e9e25d28": {"doc_hash": "59d7dbc7beeb87ce4a587ab9636099b9460eec9ceca339569886beb792cddf84"}, "9ae11ad0-3f51-4a06-96f0-84c71be7438b": {"doc_hash": "8f99487f814619abf32ca8a7f5d03df7836baea18139fd6461cfaa8de4195162"}, "130b46b6-aa65-4a63-8411-c9e7a7fc381d": {"doc_hash": "dc53e9ce89c9f91ec2663fe433e9c023040ffb0c84234af50a2b1f79eaae70b5"}, "d83f7beb-4a42-47d5-ab2b-23ffc6c4a76a": {"doc_hash": "c73e2678f6e4bbb7a2391472fa34dc7441d48f4a63143f427f017a9e3501bb6f"}, "5da5a3ff-cae7-4f99-978f-7a4d19accc9f": {"doc_hash": "6246e2a2cde6ffc33deb965361546a5503ba9c5a1c86ea3df20d6fb045042525"}, "2dc2cd71-fa56-4c3f-9135-21a638f598e5": {"doc_hash": "c334e7a13398e9c1918c809670e3f7f99450aba55708bf90decce1fbf5090499"}, "3d09d64d-422c-486b-b216-e372123e038e": {"doc_hash": "1b082db9d46dac523eb03a36323df76b8b12431e7a517b13a06974c14e5e1ce8"}, "317b2801-0432-49fd-8d69-08d0614e520e": {"doc_hash": "f993caa9c16a4078df8f536e7fb841a5a75571fb3f520766ba73a417df51caa8"}, "7aa07549-71f3-4632-97b1-69ff90f5438e": {"doc_hash": "15d46779ace791a957a53ab21ae498329c486b56e407ad930eb6d0535ad1c16e"}, "8fe571b5-fec6-4300-ab5b-7771650c0ded": {"doc_hash": "bf484385aa905be6c27cd627baf332913215d0a0e522af5a492b12521409fdd6"}, "b811f86e-f1d7-4a43-9cbf-1e15507b38ba": {"doc_hash": "5daf9d18d86c1b7eed8da102149b0dfee65a6dcf2b83006675562403a6a5601c"}, "85d31fb6-cab4-46a9-8d4b-1ca801e25e6d": {"doc_hash": "a2b74b10ce960a93edd22beeeb78333123f5fa8cfa9688fbb9bd78395acd3f7b"}, "ba9c7bd7-49d9-4cac-bc94-1dd6df5ee730": {"doc_hash": "752cc6144c8d14e15b86c94db7eb2cabd96667e79cd264e471146649cfb3dfbf"}, "54f226c7-5dbc-4765-89f6-4db23d066799": {"doc_hash": "e7910cefe09eb0b36f2c4f0690f8274d5231c838cc75f1252379f9008b122a64"}, "933798c2-3223-4f20-98fa-d279b2246401": {"doc_hash": "80330171d6ee35a3139402e7ed1640f12f40cea378ef016827b4a7110973ca45"}, "420e00f4-cafc-4887-9b71-16ca52ca11a2": {"doc_hash": "fdcc2f8a484fadf34a07114686dd215ea4218de2589bfcff0eb445ebc14aa0a4"}, "7a6d51bf-e565-40bc-bde9-bb5a9e297c9d": {"doc_hash": "f7d10fce4203cface5dee82e6c5bd3ebad53fa22e2c18bad7e7e8d45417c89ac"}, "16261675-b0bc-4666-abbe-6a265963e1a0": {"doc_hash": "092b245897649867133cdadc8d62217a9b306cc7adbe48cfbacd285aa7b3f200"}, "5d18ca32-71b8-4ddd-b8ee-eba02b78ccda": {"doc_hash": "e23f232441a2168e3ffb6b4aa0dba413341d7b9fa95e023baad6b2e45ce29b4b"}, "09b90653-4f78-4475-b516-3530d9a96e7e": {"doc_hash": "0f5929f418b6e1dd794be06e97243ce75da4ba51c3bdde30b44a1ec872587d5f"}, "1cad1474-3962-4700-a384-3222ac908adb": {"doc_hash": "5e05e966041189fd326fdf446f223d4a6bd3ed9d80a49b1e2755a2bef43205b1"}, "2735894f-d8f9-4f6e-aaf1-f15fdea733c8": {"doc_hash": "18acb99be671eba64b34d181b304e43c2ad127fd5e68502ee34a614510359afa"}, "60ae2c9d-d5bc-41ad-b4dc-8c9f7c11bb7e": {"doc_hash": "e21b89ba7cc8791c78e3b2b022f4584da21189096c109bb22bc927b14bafe235"}, "fe4d57f5-81b9-4ff0-8c2e-95e1e59f6a41": {"doc_hash": "b340844da3b9b9d196f2453eb18df36226d40f759b89ccfef93caaae084d5965"}, "282a8b34-3df7-429a-bd8d-9e8182f9f19a": {"doc_hash": "e2c90a6492bb9c401fcdd5e84ac165deb2cd6ac3f5cf72276df4f7c00902301f"}, "329664e1-93b8-47d3-8228-779c06f43bee": {"doc_hash": "606b6bbc39d2f2b6a116808d9c8fd47669d92b877dc3de392a4759ace7829c80"}, "b2724f08-36b0-4f0a-992a-f84d40efc4f7": {"doc_hash": "e10de8e47218c2da0dce41a5bb2b7e5dc54454f9462827960cbce29f8bdd23a9"}, "a4a28d65-b44c-4b11-a1c7-1d4925562bb3": {"doc_hash": "dbe656ccf3ab64b0d8e5b33a6c9635195d6c30164806b7e41f97a244b57a0209"}, "1594be14-f158-41cf-870b-6c49b3f7bc7a": {"doc_hash": "64703fb68bb319be9809533561f3066a2663eeb442710ce17e88fe8ae2d3221c"}, "d12d9941-4b4b-4e5c-83d6-3814b9aba1a6": {"doc_hash": "649606ca05257f594ea7ca5d468d0e2d094972d88a76bb77e8e5397445de4351"}, "a3c154fc-6974-4b25-8e88-b73e082741e6": {"doc_hash": "aa73411c2c2fef0f21a4ad632bf6ddbb6159133a3dc2833403bad4d2693b9acc"}, "9cba0db7-520d-4073-8cbb-3d3281ffd877": {"doc_hash": "fb3cd7f0b0b97a51877803c16f7ed244f76cead2cea4c7b4e3ca9d1e774888e6"}, "6e317b08-05cc-4dad-908b-b88bec15f99d": {"doc_hash": "7d8024fb37e27e59783b10a364d15751ba2acaf41a784498b34235dc637a4c16"}, "9ce7d08a-fda4-4486-bc99-6a7530c893ba": {"doc_hash": "3c59a159113018f5fdd1dd8a62c90a1686df6d1a6ec266056309577996e61cbd"}, "2f19385f-3a04-44af-83a3-fc74a84e5155": {"doc_hash": "db0e75459c4d26a762ccd94c4183fb8b8fd9ec50c9c20a53f17eab35b76fabe4"}, "e2711742-f757-4022-bf22-bb821c839f2d": {"doc_hash": "cd0fda5dac43a1cd809739ef9a772d6602529c40b87ca309273d73a37637f714"}, "dd721291-856e-4a75-9837-64455143a669": {"doc_hash": "89160a7bc67310dc0ccf7262486fe497d64cde4896ada927306bc470f0b01d3f"}, "fffddfea-212c-4b5b-98a3-dc90decd275d": {"doc_hash": "2501377b6e528e49f25f21a92ceac515257590f2cd89bc1b7a626dfe63b80c42"}, "319f7530-4375-498b-a6cf-7d8fcf4dd5ec": {"doc_hash": "7494a63c0c57b8773d82f10c2266597ec497e45fb7abe685f1a4e7774fdd9020"}, "7882e238-b741-4e4c-a95f-d1f6e87080c0": {"doc_hash": "a84ac3513e63171f7a937e68d848559059171b48fff076da598bf28e31a798b2"}, "c5c84cff-1b15-4ab4-a35b-9f69fc464367": {"doc_hash": "f509aa89a2ded6ee9498527bf9faa3c2e74196b7080e837095f5e1a705a33e00"}, "c17b24b2-c75b-4897-8473-7f75ea473ff2": {"doc_hash": "308a964df2dc4fd5d0894fa9d5a77da66e2cc672fd3272eee3c674f11b6ccb15"}, "3667f914-f05d-489f-9f6c-6f4297542f0e": {"doc_hash": "b77f227c779bea6d0f85f08b3bdd794cfda21541666026abdb62fff2d8faecfb"}, "8454af88-76d1-42ca-bbba-cba6abe0bb71": {"doc_hash": "9b898fcbfa5504513865c392b78b8afe45ed8016a2f109d366f58c8a2c5c98c8"}, "15164e8e-9b3d-4256-a881-8112ac53ef63": {"doc_hash": "2d026f5814de2e0015109015d763af31181b37d98339952e2330d159a5e7e43f"}, "ab98099b-77e2-41dc-b46f-0ec927a2113d": {"doc_hash": "c0d39d9a8c621ea4763ed4021160ea304d9cf002a23283315096b46e5c480726"}, "34920f57-fb59-4c92-9817-35fc4d302cd6": {"doc_hash": "d53e0a0ae8a61eddb3183cb0ef86796312e52eef2e17dbf3d625c36fc45b597a"}, "7e566163-3f76-45f6-9269-13216856f748": {"doc_hash": "a24129e18e2488bd99f885c3069b4995ef53bfa5cb0b639f0d917189a23a143e"}, "c552cc2c-8f7a-4d21-b1e6-06ad758bdd83": {"doc_hash": "7031dfba44bdfefc55e75db0e82f8f812a781417fcc242f6569d1502d70d1f57"}, "6eb460ca-d2dc-410c-8f3a-04d290cf1146": {"doc_hash": "4c17b5448e4e80aef3a5283efacec5398349a8df44ad170cd3254a46b72c4bdf"}, "ba69243e-3a12-42c9-aeca-d4406d19ffc3": {"doc_hash": "174dc4a6a1ec955adb80f4acb00a3d44ba0482e11372de8c85cf3216aa539938"}, "2982bc50-a4e8-4841-b82f-b418d287760b": {"doc_hash": "52452aa19548474a935d33ac62bc254d2918c2f566f625a3c98a26539358b8cc"}, "a22499e8-4915-443b-b21f-64b00fd32027": {"doc_hash": "b8bae0b380687e208c2b33626d265947c57db0872874716cb7e54944e699afbe"}, "60205bdb-ebc2-4602-a4b3-13b0eb2c82f0": {"doc_hash": "0306dc69cd85a30766cdde1a2620e009d06497a81bb494597f53d03dde4e82b3"}, "ab2adc6a-e073-4b56-8a2a-34d06dfc0a31": {"doc_hash": "e72b36c16c3856a807ede7dd3463710aec6f6ac50cdefb6d04bb3947b4a91053"}, "62e4cb50-d712-410e-a0eb-61701437e07a": {"doc_hash": "89ff1ea9e00ba031919309ea76b5fe9ecdb2427461cd7a8f5f405a64ed5dfa0f"}, "2f0ea052-355b-4ed4-89e7-0326c33f7cf1": {"doc_hash": "ffb3269f1f3e8bb6747cbf4b6593a3a366b321a0777d3876e1bf10197307d885"}, "e5cf1c92-6363-4a9e-ae8a-e3fb5a75f60b": {"doc_hash": "98059c859ef939a3713df5ebad33924e76503e3f05ba46264790aad959c6fdbe"}, "855685cf-dbbd-4c93-ba41-47f7c349dc32": {"doc_hash": "438a70bf8a7a473981ddd6af62b001d650a958c3470e1e57ef8b58c4ce4c5772"}, "6c446d7e-6a87-4955-8fe7-a496ad2a53ea": {"doc_hash": "2e9ea086a0eb76b3b48b69c195b2185112b79cbe667807d54f37b8c6e18ddb4e"}, "bb46a5df-d5f2-457a-995d-47a978d431b2": {"doc_hash": "c88b3292e91e00e1977450d63cf5513bad8ab74e65c051ec72d85a1afdebca4a"}, "8d114a4e-2cb0-4873-936f-a2da6dcf9711": {"doc_hash": "a6c8866c18a18798ea8d5f187e933dc6e07ac7a5efc5c4b7d7e236ba7a629084"}, "8a69121f-1a40-443f-b0a7-0e170606c9ed": {"doc_hash": "3c9d38af95ed93b4bd6664414820b99f349fd4a0864f8bb8dfcf455e336486a3"}, "8cc15a07-0c0a-446b-95db-8d0270d9ebfc": {"doc_hash": "e2ae575bccd5e3a9550d8934cc80c35fc4c0e7471a80bf9936e5b61ef819cf73"}, "d628ee03-b299-4c6a-b21f-f770ee01651b": {"doc_hash": "ddb175054f48d07269dcb56dc7c0edecf76c61c3f39a67e6474aaccf911ddc9f"}, "cc100d8a-9eb9-4264-a6a6-6fdb2e8a1bf4": {"doc_hash": "ef0900c499873308c0b048175f6b26cf811c646207b8565a771726ccd3d2b212"}, "34c53004-df1e-415a-a1b3-523668a4ee94": {"doc_hash": "cd771fce59faeea8893d8d535766701736e2966150a8ee4f11af6f6e6e75aa75"}, "8488713f-0dd7-48de-b9e1-af422da6431d": {"doc_hash": "81d439f7403d8be8dd10335eee9a05b40ad769ac79738bff3ac55a9b50675485"}, "e34387b6-51a2-480e-aafa-1f0e7f957ec9": {"doc_hash": "9b640d7052290ea9330f08be17584cf395fa2014625ca5654feba611d620fab5"}, "546ad69f-ddc3-45af-9994-3828fb9247eb": {"doc_hash": "9b75e68c0951fcc5e105f32835d7a37bfdf4cd66065f0fe6a4b36d151a2c7e46"}, "0430fc8d-6a26-497f-898e-03b0a85b81e3": {"doc_hash": "2eacfa987ba02e00c6cc050d3a0da5382a17ffe52d2a9ef1d7b0fc67521743eb"}, "39d46e22-8060-498b-8ba2-838913edcc37": {"doc_hash": "64118f6885b7e309bc8a5845c85966d7a39dd1aaef8981201295f6155a60e4b6"}, "b11457ea-fb77-40d4-8815-d72ef7af070b": {"doc_hash": "029298d085c54f3996391a57cde7e321ddc35f9e3df6a9e17e9306458d3ae1c3"}, "dbba49b7-3dbc-4cc7-b743-7abff4a2ad6c": {"doc_hash": "124b1314de729cc7ecb58d310a94392a4ea61875274bbf0131d6f2deeed95bf8"}, "6bcadbeb-eb95-4980-89e0-d1271f16694e": {"doc_hash": "4199a0ba5de13fd47e2a4266911251a182f656d0b3480c970871cd24b0a6ef46"}, "266fe314-180c-43db-861f-0e0bd4443b78": {"doc_hash": "b20f4a85032bcfaeb4a69c71a9cd45c33908c72433ab841ad9473fb4a793c27b"}, "66e071f2-2645-4ee4-a05d-c3f66eaa0659": {"doc_hash": "60aea9a95746bbef9f117d10f211273a82ccc06c1318b1caeca0078ffacd63e4"}, "8aebb037-bc89-4ee5-aabe-45a8ec55e795": {"doc_hash": "07abf0d8d8c01071644084dea9dc3ed0b5f8b11800fe378b3d74ae710c069614"}, "fc31f3fc-d029-46a4-8617-39921d4187c3": {"doc_hash": "3c0e3904c597205a6101be4846856508352680d7e6746e95729adace3d2ae957"}, "c8c63531-2643-493a-aeca-e051b9998f22": {"doc_hash": "900f30a5ebf1b79100e5fc741cce552427eb4088988b9ae74852a78f74bfb8da"}, "8d1117cc-d2f9-4142-9eb7-16776bedb037": {"doc_hash": "1dd718f3e2ff7658b3b3e7b2b8ef4626b5ab8a89591fe83cd2911c2cf82fa1f6"}, "677c6b26-a79f-4c2d-a38d-7fb93dcbd66c": {"doc_hash": "3540697395ed2ae148ed33e4af7c9ecdf4cdfe4abbfbfaf06314fa57dff48aef"}, "da579822-a8d9-44d6-9ca2-162a163f971a": {"doc_hash": "e5138009a1840a3ca38ebf5f71d8c38805ccebb1e3c7b35e98c43b7178c62256"}, "91cb8502-219c-4eff-9de0-0a2c7237ea0a": {"doc_hash": "bd0301ccb5660e4d7e0927bb1af1a7616e1294a474f02ed0397bd184fb7b1a40"}, "a46dcfec-2c24-41d6-93da-a2310a152af9": {"doc_hash": "031c8cb6fb828e91e4079296f903dbb3e0b9bd9016134a67b139453f7cbb1ebb"}, "e89b4c78-7132-4e87-95fa-7ce530384cbf": {"doc_hash": "15af79beb2128b447a8f630dbbed7ea30009ae41ede38761b308facafb5c3971"}, "02fa8f05-2300-4c66-9309-e8ab21ffa369": {"doc_hash": "adfec9f72f1f66b80a5b300559f6499c98b51d7b0ce5308cdc047ac9bb7e8f49"}, "6aa64a4f-46e5-4974-88fe-7efd3374aa37": {"doc_hash": "688213dd076a93728f9abd846a0f1720d7e10a617d3fd248612d0a26ce5cd215"}, "2cb03bf5-7c94-4f48-a878-a3eaa70875e4": {"doc_hash": "9f1361e38e281600a23f5bc97889684c6fe8f2d39ca321ae0f679282326a8d3a"}, "1c9e1be4-e2b8-4f35-bda5-cbfa857c94b2": {"doc_hash": "e2980ed9fec8da609edc7b5288472fe38037cefb35291753e05371973f924c5a"}, "5860f938-2dfb-4f17-bb92-80870b08f490": {"doc_hash": "be340915e0d4786ff4cbd4c74fa914ba305d63b44ef18395330a17b7c2e6cf00"}, "2c946974-2911-4231-8f7f-c082b3d9e378": {"doc_hash": "78c79e1d435399ce559d6cbf9b266bc77cd4989eafdac343f3cc2c1a7d83584c"}, "5de0d47a-e4bb-4cea-8dc4-ab1e8c65c45e": {"doc_hash": "76ac7910570e84fc98efacd249b714293e7ffc9d24ed4b95f8288d2f4f89d900"}, "91598b3a-84f8-471f-9eb2-39e5b009052a": {"doc_hash": "538c2361d5cd8f9367d2619d0cdc71f0592db64faf04a8595a3206c2172fe5f4"}, "182e299a-c8af-46a2-b457-5a314f74d9f9": {"doc_hash": "f340bdcd69247abac3087d03ddedf714e5c069e7ae787008affbe8e1ded9aa20"}, "39ce3ac3-3746-49af-815f-214883e8f4b6": {"doc_hash": "a4ce7f6242ad15374774b2813daa691de667af0aec76ebc3f7b1fe15111427d3"}, "64cd83c3-9f45-4a33-9c3f-022af88bc827": {"doc_hash": "430db3ff73738b655972d39fefcd457fdeb9cf86b6c897d8c47d213f3b862535"}, "28206012-5b8f-40f8-8aa4-ad984cc002ac": {"doc_hash": "f1936a3db78de83e0aa83db6ee5f6a47b0ccdf139fe47390b714fd27015d010f"}, "8b684f6c-f6bb-4556-b366-65a4fcf11e6d": {"doc_hash": "aea7d72cc7ea5237f8336dd2dbbb7adbda954a9cef1d6dd98b581430d27980c8"}, "bf4131d1-52aa-4c34-9d31-4033ee3b9ed7": {"doc_hash": "b0ab76c09e9c9d89dd2aabc545e98bbaf5b49e158c22c2d0648d54d204e6c7b3"}, "5a7b0ad3-5d6a-498c-941e-ecd496f539bf": {"doc_hash": "369d41560e53d0d4aaafe308473004ef38d9a972bfc69385c934574ce40bd1ef"}, "fca95e2f-1efa-4d85-905a-5f7c9ff71cf5": {"doc_hash": "4810ffb5d9de69be0dcce9c71a6c79eada57f0018015988420d1005e86651705"}, "58596b44-01cf-48b5-9a29-4980a6a8bc58": {"doc_hash": "0bec59c5f498cdedb3611c875faae6210f1ad66f04c4ecbe79bd3256774e5e86"}, "21a62b73-3743-47d1-9b9e-bae68398b840": {"doc_hash": "78d33c5fa2ab3033920bbf9a1cf326ee0541cd4503a688c8b09f0e5577545dc8"}, "66fce120-6bd6-4c37-a4ee-2bd6a8d8fcbc": {"doc_hash": "ef7c61ba3a15b23c6f6e72dd66f3c8bf4e7b54df6f5936b83c32f1b8406ced23"}, "cf9cc8e9-0c58-4411-a85d-b111a9119a55": {"doc_hash": "db708eb042b08afed9d25fc6d6ac28786a87c26c008ee2804b7dc0e46bce6b51"}, "12508da3-9c2f-4421-b59d-ecf7f4908b99": {"doc_hash": "3023ff6210e4d36849f0e12173230bc45fe30e2b05c65231e29bfe62fc338ddd"}, "e222d955-4e80-4b37-a79e-9bf1fdff1c50": {"doc_hash": "344a7ae9da90b2c95f64d2d1f2c7459b1859fc427271d5c0750ea827eeaca0ab"}, "5592b931-3f83-402b-9f3a-3d539bcc499d": {"doc_hash": "87c351bfb8dbf7bb34ea6dd0bfd10d4a873bc97ed55216fb1c48a8557aeb3fed"}, "0009f90f-7556-43e5-800e-3795c22b484f": {"doc_hash": "c394bf1d26df37b809603f137e93a9e9f17693f683c41a2db13ce57516bece24"}, "5e7af52a-7fad-4005-b292-ddbe11edde82": {"doc_hash": "13c8806f3e062b7e46762ce7e8dcac548b2ee39f18622b74c345901125cc310e"}, "38561bbb-c574-4920-b0a3-1a110bd0d658": {"doc_hash": "8c89fe638de87c7ec490cff46075b2276e759b5325615c7af7398e4eaa37d160"}, "57d32a91-4be6-49d0-aef8-19f6f1cb0385": {"doc_hash": "3789f0e8d53cbfd2f710e4cef04cea1828baab321217d965d1a21bd1367260eb"}, "77bf99ad-8414-46cf-b799-e328740d3acc": {"doc_hash": "41696d865bb3125c06ceaa6c9d1bf716cd872975d0ccd1d4ff75bc6348fa3c89"}, "d8492b7e-6136-4943-a8a6-598347b4b111": {"doc_hash": "1cc287ab3577ded323dd96bc380fe10acc0f1f6a460f8d29f4e544240d66e23f"}, "d734584e-e0e1-4ca2-b774-e5103bb42ce8": {"doc_hash": "56b4fc7b76032e2badb2c132c19f2359958601e765b989371274f6208c54b38a"}}}